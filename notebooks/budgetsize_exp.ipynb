{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa49b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b16c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIRECTORY=os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "os.chdir(HOME_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a67cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # sync ids with nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ee53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script params\n",
    "port=5015\n",
    "sampling_fn=\"uncertainty\"\n",
    "lSet_partition=1\n",
    "base_seed=1\n",
    "num_GPU=1\n",
    "al_iterations=4\n",
    "num_aml_trials=5 #50\n",
    "budget_size=2500\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "init_partition=10\n",
    "step_partition=10\n",
    "clf_epochs=5 #150\n",
    "num_classes=10\n",
    "swa_lr=5e-4\n",
    "swa_freq=50\n",
    "swa_epochs=5 #50\n",
    "\n",
    "log_iter=40\n",
    "\n",
    "#Data arguments\n",
    "train_dir=f\"{HOME_DIRECTORY}/data/{dataset}/train-{dataset}/\"\n",
    "test_dir=f\"{HOME_DIRECTORY}/data/{dataset}/test-{dataset}/\"\n",
    "lSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/lSet_{dataset}.npy\"\n",
    "uSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/uSet_{dataset}.npy\"\n",
    "valSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/valSet_{dataset}.npy\"\n",
    "\n",
    "out_dir=f\"{HOME_DIRECTORY}/sample_budgetsize_results\"\n",
    "\n",
    "model_style=\"vgg_style\"\n",
    "model_type=\"vgg\"\n",
    "model_depth=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0e3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made best_automl_results directory\n",
      "Copying base classifier started....\n",
      "Copying base classifier finished!\n",
      "Made auto_ml_results directory\n",
      "Copying base classifier checkpoints and config started....\n",
      "Copying finished!\n",
      "\n",
      "Please remember to change paths in config file.\n",
      "For example do replace each \"sample_results_aml\" occurences in paths to \"sample_budgetsize_results\" # old directory name to new directory name\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It is important to note that we should point results for budget size experiment.\n",
    "# For example: If we don't take care of savepath & assume it points to 10% budget size experiment \n",
    "# then running AL for 15% will have no issues but once we go to 20% - we have earlier results which \n",
    "# should not be used. So for such experiments we just copy the base (trained on initial labeled data) \n",
    "# classifier to new directory and then run any experiments.\n",
    "\n",
    "!mkdir -p $out_dir/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16\n",
    "print(\"Made best_automl_results directory\")\n",
    "print(\"Copying base classifier started....\")\n",
    "!scp -r sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla $out_dir/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/\n",
    "print(\"Copying base classifier finished!\")\n",
    "\n",
    "# DO the copy again but this time for automl_results\n",
    "!mkdir -p $out_dir/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0\n",
    "print(\"Made auto_ml_results directory\")\n",
    "print(\"Copying base classifier checkpoints and config started....\")\n",
    "!scp -r sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/config.yaml $out_dir/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/\n",
    "!scp -r sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints $out_dir/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/\n",
    "print(\"Copying finished!\")\n",
    "\n",
    "print(\"\"\"\n",
    "Please remember to change paths in config file.\n",
    "For example do replace each \"sample_results_aml\" occurences in paths to \"sample_budgetsize_results\" # old directory name to new directory name\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Please remember to change paths in config file\n",
    "# For example do replace each \"sample_results_aml\" occurences in paths to \"sample_budgetsize_results\" # old directory name to new directory name\n",
    "\n",
    "# Please also modify budget size to 2500 in config.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4451c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= [NO ADVANCED REGULARIZATION TRICK ACTIVATED] =========\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints\n",
      "Auto ml already exists; So skip doing automl for this!\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla: 1\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_03tvcibw.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform uncertainty sampling through subprocess\n",
      "len(uSetLoader): 1250\n",
      "uSet Activations: 100%|████████████████████| 1250/1250 [00:10<00:00, 116.85it/s]\n",
      "u_ranks.shape: (40000,)\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  37500\n",
      "len(lSEt):  5000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 7500 and len(uSet): 37500\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  2500\n",
      "len(uSet):  37500\n",
      "len(lSet):  7500\n",
      "For uncertainty sampling, activeSet accuracy:  19.48\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 52.499996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 51.979999771118, \"top1_err\": 51.979999771118}\n",
      "Test Accuracy: 48.020\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 10.0% of data is 48.020000228881834\n",
      "\n",
      "Extracted Test Accuracy from subproces: 48.020000228881834\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_wrl3r5qi.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 00:10:54,962]\u001b[0m A new study created in memory with name: no-name-fd8850a6-894f-43e0-8cf0-0fc563a92ed4\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 2.404835143682204e-05\n",
      "Weight Decay : 8.994394426746868e-06\n",
      "Batch Size   : 64\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 2.404835143682204e-05\n",
      "    weight_decay: 8.994394426746868e-06\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 7500, uSet:37500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 118\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/118\", \"loss\": 2.319587588310, \"lr\": 0.000024048351, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/118\", \"loss\": 2.286918401718, \"lr\": 0.000024048351, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/118\", \"loss\": 2.293675422668, \"lr\": 0.000024048351, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/118\", \"loss\": 2.232236742973, \"lr\": 0.000024048351, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/118\", \"loss\": 2.221583962440, \"lr\": 0.000024048351, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/118\", \"loss\": 2.139910221100, \"lr\": 0.000024048351, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/118\", \"loss\": 2.053581237793, \"lr\": 0.000024048351, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/118\", \"loss\": 2.060585141182, \"lr\": 0.000024048351, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/118\", \"loss\": 2.035905838013, \"lr\": 0.000024048351, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/118\", \"loss\": 2.053225755692, \"lr\": 0.000024048351, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/118\", \"loss\": 1.931901395321, \"lr\": 0.000024048351, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.139236449114, \"lr\": 0.000024048351, \"top1_err\": 80.986666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 71.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 70.000007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 70.140001831055, \"top1_err\": 70.140001831055}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/118\", \"loss\": 1.868083775043, \"lr\": 0.000024048351, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/118\", \"loss\": 1.862309038639, \"lr\": 0.000024048351, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/118\", \"loss\": 1.840854883194, \"lr\": 0.000024048351, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/118\", \"loss\": 1.816973328590, \"lr\": 0.000024048351, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/118\", \"loss\": 1.844802200794, \"lr\": 0.000024048351, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/118\", \"loss\": 1.767365455627, \"lr\": 0.000024048351, \"top1_err\": 63.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/118\", \"loss\": 1.769188702106, \"lr\": 0.000024048351, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/118\", \"loss\": 1.803293406963, \"lr\": 0.000024048351, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/118\", \"loss\": 1.788282275200, \"lr\": 0.000024048351, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/118\", \"loss\": 1.697888433933, \"lr\": 0.000024048351, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/118\", \"loss\": 1.760869801044, \"lr\": 0.000024048351, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.800846972466, \"lr\": 0.000024048351, \"top1_err\": 68.080000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 61.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 57.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 59.940000610352, \"top1_err\": 59.940000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/118\", \"loss\": 1.607650399208, \"lr\": 0.000024048351, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/118\", \"loss\": 1.583754181862, \"lr\": 0.000024048351, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/118\", \"loss\": 1.581835210323, \"lr\": 0.000024048351, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/118\", \"loss\": 1.595648467541, \"lr\": 0.000024048351, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/118\", \"loss\": 1.502441108227, \"lr\": 0.000024048351, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/118\", \"loss\": 1.503052830696, \"lr\": 0.000024048351, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/118\", \"loss\": 1.501203715801, \"lr\": 0.000024048351, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/118\", \"loss\": 1.573709130287, \"lr\": 0.000024048351, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/118\", \"loss\": 1.541193068027, \"lr\": 0.000024048351, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/118\", \"loss\": 1.526269853115, \"lr\": 0.000024048351, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/118\", \"loss\": 1.576009333134, \"lr\": 0.000024048351, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.553727699216, \"lr\": 0.000024048351, \"top1_err\": 57.573333329264}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 54.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 57.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 56.540000762939, \"top1_err\": 56.540000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/118\", \"loss\": 1.330041110516, \"lr\": 0.000024048351, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/118\", \"loss\": 1.354446172714, \"lr\": 0.000024048351, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/118\", \"loss\": 1.308695554733, \"lr\": 0.000024048351, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/118\", \"loss\": 1.347649633884, \"lr\": 0.000024048351, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/118\", \"loss\": 1.304931104183, \"lr\": 0.000024048351, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/118\", \"loss\": 1.259977161884, \"lr\": 0.000024048351, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/118\", \"loss\": 1.282041728497, \"lr\": 0.000024048351, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/118\", \"loss\": 1.335278332233, \"lr\": 0.000024048351, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/118\", \"loss\": 1.414674699306, \"lr\": 0.000024048351, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/118\", \"loss\": 1.361045122147, \"lr\": 0.000024048351, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/118\", \"loss\": 1.255497038364, \"lr\": 0.000024048351, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.334864441744, \"lr\": 0.000024048351, \"top1_err\": 48.613333329264}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 52.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 52.999996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 51.800000152588, \"top1_err\": 51.800000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/118\", \"loss\": 1.155061006546, \"lr\": 0.000024048351, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/118\", \"loss\": 1.089377999306, \"lr\": 0.000024048351, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/118\", \"loss\": 1.071190237999, \"lr\": 0.000024048351, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/118\", \"loss\": 1.089328229427, \"lr\": 0.000024048351, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/118\", \"loss\": 1.190424084663, \"lr\": 0.000024048351, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/118\", \"loss\": 1.123891949654, \"lr\": 0.000024048351, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/118\", \"loss\": 1.048993527889, \"lr\": 0.000024048351, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/118\", \"loss\": 1.093020975590, \"lr\": 0.000024048351, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/118\", \"loss\": 1.049291729927, \"lr\": 0.000024048351, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/118\", \"loss\": 1.084616422653, \"lr\": 0.000024048351, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/118\", \"loss\": 1.131653726101, \"lr\": 0.000024048351, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.098180168215, \"lr\": 0.000024048351, \"top1_err\": 39.973333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 51.800000152588, \"top1_err\": 52.120000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 00:12:20,517]\u001b[0m Trial 0 finished with value: 48.19999984741211 and parameters: {'learning_rate': 2.404835143682204e-05, 'weight_decay': 8.994394426746868e-06, 'batch_size': 64, 'optimizer': 'ADAM'}. Best is trial 0 with value: 48.19999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.00011534911629216944\n",
      "Weight Decay : 5.777842675922974e-06\n",
      "Batch Size   : 8\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00011534911629216944\n",
      "    weight_decay: 5.777842675922974e-06\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 7500, uSet:37500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 938\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/938\", \"loss\": 2.672898054123, \"lr\": 0.000115349116, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/938\", \"loss\": 2.522373080254, \"lr\": 0.000115349116, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/938\", \"loss\": 2.955877900124, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/938\", \"loss\": 2.720593452454, \"lr\": 0.000115349116, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/938\", \"loss\": 2.479331612587, \"lr\": 0.000115349116, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/938\", \"loss\": 2.602016210556, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/938\", \"loss\": 2.476011157036, \"lr\": 0.000115349116, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/938\", \"loss\": 2.533635258675, \"lr\": 0.000115349116, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/938\", \"loss\": 2.324215292931, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/938\", \"loss\": 2.442655086517, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/938\", \"loss\": 2.156931161880, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/938\", \"loss\": 2.255162835121, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/938\", \"loss\": 2.219174385071, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/938\", \"loss\": 2.150254607201, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/938\", \"loss\": 2.330637216568, \"lr\": 0.000115349116, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/938\", \"loss\": 2.246990799904, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/938\", \"loss\": 2.076437354088, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/938\", \"loss\": 2.102687597275, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/938\", \"loss\": 2.429694175720, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/938\", \"loss\": 2.219651937485, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/938\", \"loss\": 2.102994799614, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/938\", \"loss\": 2.143843889236, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/938\", \"loss\": 2.205879569054, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/938\", \"loss\": 2.216023087502, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/938\", \"loss\": 2.189386129379, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/938\", \"loss\": 2.163377761841, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/938\", \"loss\": 2.170418620110, \"lr\": 0.000115349116, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/938\", \"loss\": 2.110720753670, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/938\", \"loss\": 2.069390892982, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/938\", \"loss\": 2.113591432571, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/938\", \"loss\": 2.212282061577, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/938\", \"loss\": 2.219860196114, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/938\", \"loss\": 2.068291544914, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/938\", \"loss\": 2.039039015770, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/938\", \"loss\": 1.985455989838, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/938\", \"loss\": 2.045120239258, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/938\", \"loss\": 2.083679676056, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/938\", \"loss\": 2.104439377785, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/938\", \"loss\": 2.234471678734, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/938\", \"loss\": 2.095782518387, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/938\", \"loss\": 1.952678203583, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/938\", \"loss\": 2.121794223785, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/938\", \"loss\": 2.177657723427, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/938\", \"loss\": 2.047818183899, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/938\", \"loss\": 2.213732481003, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/938\", \"loss\": 2.092738628387, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/938\", \"loss\": 2.101802229881, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/938\", \"loss\": 2.107412576675, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/938\", \"loss\": 1.919164001942, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/938\", \"loss\": 2.021999359131, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/938\", \"loss\": 2.031953573227, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/938\", \"loss\": 1.969550669193, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/938\", \"loss\": 2.091783940792, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/938\", \"loss\": 2.053227901459, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/938\", \"loss\": 2.241539001465, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/938\", \"loss\": 2.091139197350, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/938\", \"loss\": 2.139042496681, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/938\", \"loss\": 2.061480522156, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/938\", \"loss\": 2.078932046890, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/938\", \"loss\": 2.245459556580, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/938\", \"loss\": 2.226441383362, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/938\", \"loss\": 2.138365626335, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/938\", \"loss\": 2.123543977737, \"lr\": 0.000115349116, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/938\", \"loss\": 2.158701181412, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/938\", \"loss\": 2.153840184212, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/938\", \"loss\": 2.102882146835, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/938\", \"loss\": 2.116032958031, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/938\", \"loss\": 2.115718126297, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/938\", \"loss\": 1.979614257812, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/938\", \"loss\": 1.882006406784, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/938\", \"loss\": 2.045723676682, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/938\", \"loss\": 2.012114286423, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/938\", \"loss\": 2.017173707485, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/938\", \"loss\": 2.012180328369, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/938\", \"loss\": 2.069688439369, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/938\", \"loss\": 2.175229549408, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/938\", \"loss\": 1.894490897655, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/938\", \"loss\": 2.061736226082, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/938\", \"loss\": 1.967407763004, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/938\", \"loss\": 2.242401957512, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/938\", \"loss\": 2.004386067390, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/938\", \"loss\": 2.063918113708, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/938\", \"loss\": 2.003953337669, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/938\", \"loss\": 2.091322064400, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/938\", \"loss\": 1.886658966541, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/938\", \"loss\": 2.049049973488, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/938\", \"loss\": 2.160483002663, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/938\", \"loss\": 1.933591544628, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/938\", \"loss\": 1.934247016907, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/938\", \"loss\": 1.916243553162, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/938\", \"loss\": 2.162006258965, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/938\", \"loss\": 2.070337653160, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/938\", \"loss\": 2.107373833656, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.166258034261, \"lr\": 0.000115349116, \"top1_err\": 82.400000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 78.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 76.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 77.440000000000, \"top1_err\": 77.440000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/938\", \"loss\": 2.161979317665, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/938\", \"loss\": 2.067577838898, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/938\", \"loss\": 2.125571131706, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/938\", \"loss\": 1.910478711128, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/938\", \"loss\": 2.087630510330, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/938\", \"loss\": 2.004741430283, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/938\", \"loss\": 1.946473181248, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/938\", \"loss\": 1.929612100124, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/938\", \"loss\": 1.938730418682, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/938\", \"loss\": 2.062672972679, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/938\", \"loss\": 2.028188824654, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/938\", \"loss\": 1.979755818844, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/938\", \"loss\": 1.951343715191, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/938\", \"loss\": 1.970790624619, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/938\", \"loss\": 2.090607881546, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/938\", \"loss\": 1.946822404861, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/938\", \"loss\": 2.077008008957, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/938\", \"loss\": 1.832218647003, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/938\", \"loss\": 1.990029394627, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/938\", \"loss\": 2.110879421234, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/938\", \"loss\": 1.890116393566, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/938\", \"loss\": 2.052772641182, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/938\", \"loss\": 1.949852705002, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/938\", \"loss\": 1.845706999302, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/938\", \"loss\": 2.029385685921, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/938\", \"loss\": 1.940697193146, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/938\", \"loss\": 1.931106805801, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/938\", \"loss\": 1.838012933731, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/938\", \"loss\": 1.821722328663, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/938\", \"loss\": 1.956734597683, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/938\", \"loss\": 2.026294946671, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/938\", \"loss\": 1.798790812492, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/938\", \"loss\": 2.053890347481, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/938\", \"loss\": 1.925268828869, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/938\", \"loss\": 1.917107462883, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/938\", \"loss\": 1.883640110493, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/938\", \"loss\": 1.811475753784, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/938\", \"loss\": 2.009620726109, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/938\", \"loss\": 1.987825095654, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/938\", \"loss\": 2.058646798134, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/938\", \"loss\": 1.877747356892, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/938\", \"loss\": 2.051275789738, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/938\", \"loss\": 2.037569403648, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/938\", \"loss\": 2.062705159187, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/938\", \"loss\": 1.920375287533, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/938\", \"loss\": 1.978998064995, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/938\", \"loss\": 1.934015214443, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/938\", \"loss\": 1.867190778255, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/938\", \"loss\": 1.850742816925, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/938\", \"loss\": 1.926908016205, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/938\", \"loss\": 1.801699936390, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/938\", \"loss\": 1.948333084583, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/938\", \"loss\": 1.763969242573, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/938\", \"loss\": 1.999112963676, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/938\", \"loss\": 2.019445538521, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/938\", \"loss\": 1.993099391460, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/938\", \"loss\": 2.030663788319, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/938\", \"loss\": 2.012375116348, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/938\", \"loss\": 1.990250110626, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/938\", \"loss\": 2.045800447464, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/938\", \"loss\": 2.014182746410, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/938\", \"loss\": 1.960292220116, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/938\", \"loss\": 1.872375845909, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/938\", \"loss\": 1.955917239189, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/938\", \"loss\": 1.864930212498, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/938\", \"loss\": 1.911236822605, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/938\", \"loss\": 1.952794492245, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/938\", \"loss\": 2.125995755196, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/938\", \"loss\": 1.996350407600, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/938\", \"loss\": 1.871051728725, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/938\", \"loss\": 2.084107160568, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/938\", \"loss\": 2.017457485199, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/938\", \"loss\": 1.845534980297, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/938\", \"loss\": 1.826229572296, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/938\", \"loss\": 1.868956923485, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/938\", \"loss\": 1.982388854027, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/938\", \"loss\": 2.074054956436, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/938\", \"loss\": 1.930206358433, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/938\", \"loss\": 2.021389245987, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/938\", \"loss\": 1.833412706852, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/938\", \"loss\": 1.834607958794, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/938\", \"loss\": 1.871051847935, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/938\", \"loss\": 1.885426878929, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/938\", \"loss\": 1.823797702789, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/938\", \"loss\": 1.944917917252, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/938\", \"loss\": 2.019610226154, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/938\", \"loss\": 1.983567655087, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/938\", \"loss\": 1.976108074188, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/938\", \"loss\": 1.805321514606, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/938\", \"loss\": 1.870318055153, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/938\", \"loss\": 1.871894896030, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/938\", \"loss\": 1.894537627697, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/938\", \"loss\": 1.893548190594, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.996971103541, \"lr\": 0.000115349116, \"top1_err\": 77.480000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 73.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 72.800000610352, \"top1_err\": 72.800000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/938\", \"loss\": 1.935679197311, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/938\", \"loss\": 1.972918033600, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/938\", \"loss\": 1.870557606220, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/938\", \"loss\": 1.909739553928, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/938\", \"loss\": 1.925946712494, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/938\", \"loss\": 1.845823168755, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/938\", \"loss\": 1.765588283539, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/938\", \"loss\": 1.941941320896, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/938\", \"loss\": 1.798288166523, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/938\", \"loss\": 1.916220068932, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/938\", \"loss\": 1.905060946941, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/938\", \"loss\": 1.993488907814, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/938\", \"loss\": 1.927702724934, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/938\", \"loss\": 2.078041315079, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/938\", \"loss\": 1.879161059856, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/938\", \"loss\": 1.977935612202, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/938\", \"loss\": 2.036769032478, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/938\", \"loss\": 2.007155954838, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/938\", \"loss\": 1.979732751846, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/938\", \"loss\": 1.871590018272, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/938\", \"loss\": 1.850152492523, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/938\", \"loss\": 1.982085347176, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/938\", \"loss\": 1.821967601776, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/938\", \"loss\": 1.748024582863, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/938\", \"loss\": 1.845188975334, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/938\", \"loss\": 1.974204301834, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/938\", \"loss\": 1.738907158375, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/938\", \"loss\": 1.754003942013, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/938\", \"loss\": 1.979009270668, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/938\", \"loss\": 1.974432349205, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/938\", \"loss\": 1.814747631550, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/938\", \"loss\": 1.894184052944, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/938\", \"loss\": 1.996731162071, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/938\", \"loss\": 1.939014673233, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/938\", \"loss\": 2.016573250294, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/938\", \"loss\": 1.863202512264, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/938\", \"loss\": 1.767159819603, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/938\", \"loss\": 1.808685779572, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/938\", \"loss\": 1.857609629631, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/938\", \"loss\": 1.854025959969, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/938\", \"loss\": 2.101627469063, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/938\", \"loss\": 2.117804050446, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/938\", \"loss\": 1.851595878601, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/938\", \"loss\": 1.921242535114, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/938\", \"loss\": 1.789098381996, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/938\", \"loss\": 1.833867549896, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/938\", \"loss\": 1.765154480934, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/938\", \"loss\": 1.823892593384, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/938\", \"loss\": 1.945559322834, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/938\", \"loss\": 1.866745054722, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/938\", \"loss\": 1.856365144253, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/938\", \"loss\": 1.795848727226, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/938\", \"loss\": 1.734318315983, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/938\", \"loss\": 2.095029950142, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/938\", \"loss\": 1.745401322842, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/938\", \"loss\": 1.981960415840, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/938\", \"loss\": 1.817439615726, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/938\", \"loss\": 1.879767954350, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/938\", \"loss\": 2.118526220322, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/938\", \"loss\": 1.857953071594, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/938\", \"loss\": 1.931061983109, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/938\", \"loss\": 2.102956533432, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/938\", \"loss\": 2.061004877090, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/938\", \"loss\": 1.937517762184, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/938\", \"loss\": 1.833468556404, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/938\", \"loss\": 1.887228131294, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/938\", \"loss\": 1.790395021439, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/938\", \"loss\": 1.854383230209, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/938\", \"loss\": 1.747743427753, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/938\", \"loss\": 1.819717645645, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/938\", \"loss\": 1.920984148979, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/938\", \"loss\": 1.953964889050, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/938\", \"loss\": 1.854318261147, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/938\", \"loss\": 1.730576872826, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/938\", \"loss\": 1.968407392502, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/938\", \"loss\": 1.805728495121, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/938\", \"loss\": 1.954316139221, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/938\", \"loss\": 1.779118180275, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/938\", \"loss\": 1.804894924164, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/938\", \"loss\": 1.904807567596, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/938\", \"loss\": 1.828064858913, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/938\", \"loss\": 1.878592789173, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/938\", \"loss\": 1.849083423615, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/938\", \"loss\": 1.811696946621, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/938\", \"loss\": 2.032093763351, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/938\", \"loss\": 1.882560968399, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/938\", \"loss\": 1.899406433105, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/938\", \"loss\": 1.930375695229, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/938\", \"loss\": 1.801498591900, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/938\", \"loss\": 1.929393172264, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/938\", \"loss\": 1.941865503788, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/938\", \"loss\": 1.849144816399, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/938\", \"loss\": 1.886049330235, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.913270766640, \"lr\": 0.000115349116, \"top1_err\": 75.440000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 71.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 71.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 71.240000610352, \"top1_err\": 71.240000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/938\", \"loss\": 1.774553477764, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/938\", \"loss\": 1.836624085903, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/938\", \"loss\": 1.796044349670, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/938\", \"loss\": 1.724500477314, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/938\", \"loss\": 1.687710225582, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/938\", \"loss\": 1.636971652508, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/938\", \"loss\": 1.966177403927, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/938\", \"loss\": 1.848338663578, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/938\", \"loss\": 1.893868446350, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/938\", \"loss\": 2.022305846214, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/938\", \"loss\": 1.727725505829, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/938\", \"loss\": 1.727968394756, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/938\", \"loss\": 1.665575265884, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/938\", \"loss\": 1.824431717396, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/938\", \"loss\": 1.865359544754, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/938\", \"loss\": 1.652507126331, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/938\", \"loss\": 1.795231044292, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/938\", \"loss\": 1.806774616241, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/938\", \"loss\": 1.963321805000, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/938\", \"loss\": 1.709520697594, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/938\", \"loss\": 1.956888318062, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/938\", \"loss\": 1.783459126949, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/938\", \"loss\": 1.826801121235, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/938\", \"loss\": 1.918613910675, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/938\", \"loss\": 1.851808547974, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/938\", \"loss\": 1.731215417385, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/938\", \"loss\": 1.921697676182, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/938\", \"loss\": 1.645541906357, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/938\", \"loss\": 1.837074279785, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/938\", \"loss\": 1.865820646286, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/938\", \"loss\": 1.673276126385, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/938\", \"loss\": 1.827818274498, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/938\", \"loss\": 1.913318991661, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/938\", \"loss\": 1.761491835117, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/938\", \"loss\": 1.917844176292, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/938\", \"loss\": 1.799230158329, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/938\", \"loss\": 1.859218895435, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/938\", \"loss\": 1.783119082451, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/938\", \"loss\": 1.769363045692, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/938\", \"loss\": 1.846947312355, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/938\", \"loss\": 1.674269139767, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/938\", \"loss\": 1.960883021355, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/938\", \"loss\": 1.808929800987, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/938\", \"loss\": 1.761102616787, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/938\", \"loss\": 1.874038279057, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/938\", \"loss\": 1.736378908157, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/938\", \"loss\": 1.733451128006, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/938\", \"loss\": 1.882484316826, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/938\", \"loss\": 1.727500796318, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/938\", \"loss\": 1.665286242962, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/938\", \"loss\": 1.683178722858, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/938\", \"loss\": 1.685279786587, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/938\", \"loss\": 1.720655500889, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/938\", \"loss\": 1.846563518047, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/938\", \"loss\": 2.028664112091, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/938\", \"loss\": 1.938078939915, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/938\", \"loss\": 1.762320876122, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/938\", \"loss\": 1.792755186558, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/938\", \"loss\": 1.616152048111, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/938\", \"loss\": 1.980434119701, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/938\", \"loss\": 1.807598114014, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/938\", \"loss\": 1.856783509254, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/938\", \"loss\": 1.674382865429, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/938\", \"loss\": 1.877719819546, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/938\", \"loss\": 1.843789458275, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/938\", \"loss\": 1.735229372978, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/938\", \"loss\": 1.781573414803, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/938\", \"loss\": 1.793979465961, \"lr\": 0.000115349116, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/938\", \"loss\": 1.875881373882, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/938\", \"loss\": 1.771206140518, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/938\", \"loss\": 1.764537632465, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/938\", \"loss\": 1.802198767662, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/938\", \"loss\": 1.643977701664, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/938\", \"loss\": 1.801576614380, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/938\", \"loss\": 1.880766689777, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/938\", \"loss\": 1.964813828468, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/938\", \"loss\": 1.786995351315, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/938\", \"loss\": 1.749026358128, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/938\", \"loss\": 1.743423581123, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/938\", \"loss\": 1.757189333439, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/938\", \"loss\": 1.748144984245, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/938\", \"loss\": 1.802333712578, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/938\", \"loss\": 1.808642923832, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/938\", \"loss\": 1.686237215996, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/938\", \"loss\": 1.717147409916, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/938\", \"loss\": 1.684092283249, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/938\", \"loss\": 1.753130912781, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/938\", \"loss\": 1.787197053432, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/938\", \"loss\": 1.893346309662, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/938\", \"loss\": 1.864378571510, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/938\", \"loss\": 1.974592566490, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/938\", \"loss\": 1.753368675709, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/938\", \"loss\": 1.779912769794, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.853253237534, \"lr\": 0.000115349116, \"top1_err\": 74.386666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 64.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 65.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 65.600000152588, \"top1_err\": 65.600000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/938\", \"loss\": 1.791170060635, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/938\", \"loss\": 1.623853266239, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/938\", \"loss\": 1.720710992813, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/938\", \"loss\": 1.735962569714, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/938\", \"loss\": 1.862026154995, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/938\", \"loss\": 1.862794935703, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/938\", \"loss\": 1.865068674088, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/938\", \"loss\": 1.854370355606, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/938\", \"loss\": 1.740395605564, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/938\", \"loss\": 1.862437725067, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/938\", \"loss\": 1.930346190929, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/938\", \"loss\": 1.648575544357, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/938\", \"loss\": 1.714424312115, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/938\", \"loss\": 1.660160601139, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/938\", \"loss\": 1.869348585606, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/938\", \"loss\": 1.588922858238, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/938\", \"loss\": 1.721064746380, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/938\", \"loss\": 1.825501024723, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/938\", \"loss\": 1.687763690948, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/938\", \"loss\": 1.757326960564, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/938\", \"loss\": 1.692168772221, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/938\", \"loss\": 1.647394120693, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/938\", \"loss\": 1.779154717922, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/938\", \"loss\": 1.771194756031, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/938\", \"loss\": 1.772393822670, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/938\", \"loss\": 1.709782004356, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/938\", \"loss\": 1.706350922585, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/938\", \"loss\": 1.728858649731, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/938\", \"loss\": 1.799086570740, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/938\", \"loss\": 1.680371046066, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/938\", \"loss\": 1.736923635006, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/938\", \"loss\": 1.769659042358, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/938\", \"loss\": 1.761027991772, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/938\", \"loss\": 1.833445668221, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/938\", \"loss\": 1.770901560783, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/938\", \"loss\": 1.635839164257, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/938\", \"loss\": 1.639959573746, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/938\", \"loss\": 1.527590095997, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/938\", \"loss\": 1.892037630081, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/938\", \"loss\": 1.742491900921, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/938\", \"loss\": 1.753388822079, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/938\", \"loss\": 1.688104271889, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/938\", \"loss\": 1.762499511242, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/938\", \"loss\": 1.560197234154, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/938\", \"loss\": 1.771372616291, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/938\", \"loss\": 1.886735618114, \"lr\": 0.000115349116, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/938\", \"loss\": 1.698249459267, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/938\", \"loss\": 1.932335853577, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/938\", \"loss\": 1.793783247471, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/938\", \"loss\": 1.638215899467, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/938\", \"loss\": 1.858920693398, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/938\", \"loss\": 1.630581438541, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/938\", \"loss\": 1.665939927101, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/938\", \"loss\": 1.615704655647, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/938\", \"loss\": 1.712990343571, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/938\", \"loss\": 1.750980317593, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/938\", \"loss\": 1.650263965130, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/938\", \"loss\": 1.715023219585, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/938\", \"loss\": 1.663571834564, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/938\", \"loss\": 1.661980271339, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/938\", \"loss\": 1.637131512165, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/938\", \"loss\": 1.823262214661, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/938\", \"loss\": 1.641072630882, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/938\", \"loss\": 1.611815094948, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/938\", \"loss\": 1.490381956100, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/938\", \"loss\": 1.733341574669, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/938\", \"loss\": 1.531318128109, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/938\", \"loss\": 1.852045059204, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/938\", \"loss\": 1.817795753479, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/938\", \"loss\": 1.627247512341, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/938\", \"loss\": 1.697211563587, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/938\", \"loss\": 1.773871660233, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/938\", \"loss\": 1.758786320686, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/938\", \"loss\": 1.763004422188, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/938\", \"loss\": 1.861438870430, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/938\", \"loss\": 1.769667983055, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/938\", \"loss\": 1.617930948734, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/938\", \"loss\": 1.722175061703, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/938\", \"loss\": 1.667562007904, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/938\", \"loss\": 1.638546943665, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/938\", \"loss\": 1.594736993313, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/938\", \"loss\": 1.675297141075, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/938\", \"loss\": 1.765817105770, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/938\", \"loss\": 1.649182617664, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/938\", \"loss\": 1.753306746483, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/938\", \"loss\": 1.745768010616, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/938\", \"loss\": 1.738661170006, \"lr\": 0.000115349116, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/938\", \"loss\": 1.756438314915, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/938\", \"loss\": 1.649067401886, \"lr\": 0.000115349116, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/938\", \"loss\": 1.624996185303, \"lr\": 0.000115349116, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/938\", \"loss\": 1.805721342564, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/938\", \"loss\": 1.841885983944, \"lr\": 0.000115349116, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/938\", \"loss\": 1.696271419525, \"lr\": 0.000115349116, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.767028059451, \"lr\": 0.000115349116, \"top1_err\": 70.866666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 64.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 61.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 64.500000915527, \"top1_err\": 64.500000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_35.49999908447266_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_35.49999908447266_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:18:42,693]\u001b[0m Trial 1 finished with value: 35.49999908447266 and parameters: {'learning_rate': 0.00011534911629216944, 'weight_decay': 5.777842675922974e-06, 'batch_size': 8, 'optimizer': 'ADAM'}. Best is trial 0 with value: 48.19999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.000714770647942958\n",
      "Weight Decay : 9.783893365758146e-07\n",
      "Batch Size   : 128\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.000714770647942958\n",
      "    weight_decay: 9.783893365758146e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 7500, uSet:37500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 59\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/59\", \"loss\": 5.717864036560, \"lr\": 0.000714770648, \"top1_err\": 88.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/59\", \"loss\": 2.374529242516, \"lr\": 0.000714770648, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/59\", \"loss\": 2.301192998886, \"lr\": 0.000714770648, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/59\", \"loss\": 2.289093494415, \"lr\": 0.000714770648, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/59\", \"loss\": 2.282650947571, \"lr\": 0.000714770648, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.849034795634, \"lr\": 0.000714770648, \"top1_err\": 87.146666711426}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 90.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 89.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.400000000000, \"top1_err\": 89.400000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/59\", \"loss\": 2.274854540825, \"lr\": 0.000714770648, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/59\", \"loss\": 2.240886449814, \"lr\": 0.000714770648, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/59\", \"loss\": 2.232324719429, \"lr\": 0.000714770648, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/59\", \"loss\": 2.215469360352, \"lr\": 0.000714770648, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/59\", \"loss\": 2.144758820534, \"lr\": 0.000714770648, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.208257734934, \"lr\": 0.000714770648, \"top1_err\": 83.373333284505}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 83.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 82.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 82.040000000000, \"top1_err\": 82.040000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/59\", \"loss\": 2.123129725456, \"lr\": 0.000714770648, \"top1_err\": 80.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/59\", \"loss\": 2.125942826271, \"lr\": 0.000714770648, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/59\", \"loss\": 2.072466850281, \"lr\": 0.000714770648, \"top1_err\": 83.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/59\", \"loss\": 2.033275127411, \"lr\": 0.000714770648, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/59\", \"loss\": 2.074504852295, \"lr\": 0.000714770648, \"top1_err\": 80.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.075365451686, \"lr\": 0.000714770648, \"top1_err\": 81.519999995931}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 82.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 84.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 82.040000000000, \"top1_err\": 82.860000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/59\", \"loss\": 1.969368934631, \"lr\": 0.000714770648, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/59\", \"loss\": 1.991177856922, \"lr\": 0.000714770648, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/59\", \"loss\": 1.953553080559, \"lr\": 0.000714770648, \"top1_err\": 79.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/59\", \"loss\": 1.932619988918, \"lr\": 0.000714770648, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/59\", \"loss\": 1.971053361893, \"lr\": 0.000714770648, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.972331372007, \"lr\": 0.000714770648, \"top1_err\": 80.546666630046}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 76.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 79.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 78.780000305176, \"top1_err\": 78.780000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/59\", \"loss\": 1.985628545284, \"lr\": 0.000714770648, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/59\", \"loss\": 1.961617171764, \"lr\": 0.000714770648, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/59\", \"loss\": 1.949272632599, \"lr\": 0.000714770648, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/59\", \"loss\": 1.913058400154, \"lr\": 0.000714770648, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/59\", \"loss\": 1.910746097565, \"lr\": 0.000714770648, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.938567399470, \"lr\": 0.000714770648, \"top1_err\": 79.346666654460}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 80.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 81.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 78.780000305176, \"top1_err\": 80.500000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_21.219999694824224_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_21.219999694824224_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 00:19:37,610]\u001b[0m Trial 2 finished with value: 21.219999694824224 and parameters: {'learning_rate': 0.000714770647942958, 'weight_decay': 9.783893365758146e-07, 'batch_size': 128, 'optimizer': 'ADAM'}. Best is trial 0 with value: 48.19999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.0007635886731289256\n",
      "Weight Decay : 2.9954846173576525e-05\n",
      "Batch Size   : 64\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0007635886731289256\n",
      "    weight_decay: 2.9954846173576525e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 7500, uSet:37500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 118\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/118\", \"loss\": 5.553692579269, \"lr\": 0.000763588673, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/118\", \"loss\": 2.578557014465, \"lr\": 0.000763588673, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/118\", \"loss\": 2.298525929451, \"lr\": 0.000763588673, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/118\", \"loss\": 2.290314197540, \"lr\": 0.000763588673, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/118\", \"loss\": 2.261771559715, \"lr\": 0.000763588673, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/118\", \"loss\": 2.238450884819, \"lr\": 0.000763588673, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/118\", \"loss\": 2.239690303802, \"lr\": 0.000763588673, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/118\", \"loss\": 2.235819339752, \"lr\": 0.000763588673, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/118\", \"loss\": 2.218485593796, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/118\", \"loss\": 2.229457974434, \"lr\": 0.000763588673, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/118\", \"loss\": 2.224019408226, \"lr\": 0.000763588673, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.750039538447, \"lr\": 0.000763588673, \"top1_err\": 85.546666674805}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 88.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 87.920000000000, \"top1_err\": 87.920000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/118\", \"loss\": 2.228631019592, \"lr\": 0.000763588673, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/118\", \"loss\": 2.238545536995, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/118\", \"loss\": 2.195603251457, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/118\", \"loss\": 2.197984457016, \"lr\": 0.000763588673, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/118\", \"loss\": 2.218191146851, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/118\", \"loss\": 2.195283055305, \"lr\": 0.000763588673, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/118\", \"loss\": 2.190439701080, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/118\", \"loss\": 2.172651529312, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/118\", \"loss\": 2.164142131805, \"lr\": 0.000763588673, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/118\", \"loss\": 2.150636196136, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/118\", \"loss\": 2.184659242630, \"lr\": 0.000763588673, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.191143685786, \"lr\": 0.000763588673, \"top1_err\": 82.373333341471}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 83.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 83.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 83.360000000000, \"top1_err\": 83.360000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/118\", \"loss\": 2.161311864853, \"lr\": 0.000763588673, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/118\", \"loss\": 2.166170954704, \"lr\": 0.000763588673, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/118\", \"loss\": 2.130000948906, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/118\", \"loss\": 2.133185386658, \"lr\": 0.000763588673, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/118\", \"loss\": 2.144285798073, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/118\", \"loss\": 2.087545156479, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/118\", \"loss\": 2.090347409248, \"lr\": 0.000763588673, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/118\", \"loss\": 2.131276369095, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/118\", \"loss\": 2.091246366501, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/118\", \"loss\": 2.067387342453, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/118\", \"loss\": 2.069122433662, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.117352511787, \"lr\": 0.000763588673, \"top1_err\": 81.520000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 80.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 79.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 80.160000000000, \"top1_err\": 80.160000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/118\", \"loss\": 2.040428280830, \"lr\": 0.000763588673, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/118\", \"loss\": 2.031165957451, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/118\", \"loss\": 2.028040409088, \"lr\": 0.000763588673, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/118\", \"loss\": 2.055573701859, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/118\", \"loss\": 1.998998582363, \"lr\": 0.000763588673, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/118\", \"loss\": 2.024343013763, \"lr\": 0.000763588673, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/118\", \"loss\": 2.003275632858, \"lr\": 0.000763588673, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/118\", \"loss\": 2.023114085197, \"lr\": 0.000763588673, \"top1_err\": 77.343750000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/118\", \"loss\": 1.998152375221, \"lr\": 0.000763588673, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/118\", \"loss\": 2.036503672600, \"lr\": 0.000763588673, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/118\", \"loss\": 2.030070900917, \"lr\": 0.000763588673, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.023403047498, \"lr\": 0.000763588673, \"top1_err\": 79.679999991862}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 78.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 78.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 79.280000000000, \"top1_err\": 79.280000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/118\", \"loss\": 1.994544327259, \"lr\": 0.000763588673, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/118\", \"loss\": 1.987680077553, \"lr\": 0.000763588673, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/118\", \"loss\": 1.982688844204, \"lr\": 0.000763588673, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/118\", \"loss\": 2.000104427338, \"lr\": 0.000763588673, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/118\", \"loss\": 1.997890710831, \"lr\": 0.000763588673, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/118\", \"loss\": 2.047268986702, \"lr\": 0.000763588673, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/118\", \"loss\": 1.922501206398, \"lr\": 0.000763588673, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/118\", \"loss\": 1.940473973751, \"lr\": 0.000763588673, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/118\", \"loss\": 1.969394862652, \"lr\": 0.000763588673, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/118\", \"loss\": 1.916678369045, \"lr\": 0.000763588673, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/118\", \"loss\": 1.953707873821, \"lr\": 0.000763588673, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.978340008863, \"lr\": 0.000763588673, \"top1_err\": 78.626666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 81.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 83.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 79.280000000000, \"top1_err\": 82.340000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_20.72_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_20.72_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 00:20:56,619]\u001b[0m Trial 3 finished with value: 20.72 and parameters: {'learning_rate': 0.0007635886731289256, 'weight_decay': 2.9954846173576525e-05, 'batch_size': 64, 'optimizer': 'ADAM'}. Best is trial 0 with value: 48.19999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 1.0167342099428397e-05\n",
      "Weight Decay : 0.00010932387237615299\n",
      "Batch Size   : 16\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1.0167342099428397e-05\n",
      "    weight_decay: 0.00010932387237615299\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 7500, uSet:37500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 469\n",
      "[train_al.py: 450]: Start epoch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/469\", \"loss\": 2.316357135773, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/469\", \"loss\": 2.318322658539, \"lr\": 0.000010167342, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/469\", \"loss\": 2.304363846779, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/469\", \"loss\": 2.331359744072, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/469\", \"loss\": 2.300356149673, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/469\", \"loss\": 2.298744201660, \"lr\": 0.000010167342, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/469\", \"loss\": 2.274655222893, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/469\", \"loss\": 2.277583599091, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/469\", \"loss\": 2.240850925446, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/469\", \"loss\": 2.357782125473, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/469\", \"loss\": 2.259519100189, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/469\", \"loss\": 2.290355920792, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/469\", \"loss\": 2.208559393883, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/469\", \"loss\": 2.198064804077, \"lr\": 0.000010167342, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/469\", \"loss\": 2.242450237274, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/469\", \"loss\": 2.254772305489, \"lr\": 0.000010167342, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/469\", \"loss\": 2.214229464531, \"lr\": 0.000010167342, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/469\", \"loss\": 2.225006103516, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/469\", \"loss\": 2.176993131638, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/469\", \"loss\": 2.135838747025, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/469\", \"loss\": 2.141589045525, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/469\", \"loss\": 2.097560167313, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/469\", \"loss\": 2.158901572227, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/469\", \"loss\": 2.094672560692, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/469\", \"loss\": 2.131539344788, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/469\", \"loss\": 2.147569417953, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/469\", \"loss\": 2.033433079720, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/469\", \"loss\": 2.005580723286, \"lr\": 0.000010167342, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/469\", \"loss\": 2.096852540970, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/469\", \"loss\": 2.039637207985, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/469\", \"loss\": 2.066198706627, \"lr\": 0.000010167342, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/469\", \"loss\": 2.138370990753, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/469\", \"loss\": 2.030299544334, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/469\", \"loss\": 2.015722274780, \"lr\": 0.000010167342, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/469\", \"loss\": 2.023310303688, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/469\", \"loss\": 1.969736099243, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/469\", \"loss\": 2.005361139774, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/469\", \"loss\": 2.072765827179, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/469\", \"loss\": 1.961341619492, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/469\", \"loss\": 2.149224638939, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/469\", \"loss\": 1.972003221512, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/469\", \"loss\": 2.021020054817, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/469\", \"loss\": 1.957748293877, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/469\", \"loss\": 2.049994945526, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/469\", \"loss\": 1.929536640644, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/469\", \"loss\": 2.021520495415, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.146942964999, \"lr\": 0.000010167342, \"top1_err\": 81.280000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 71.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 70.500007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 70.760001525879, \"top1_err\": 70.760001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/469\", \"loss\": 1.945694684982, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/469\", \"loss\": 1.938262939453, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/469\", \"loss\": 1.913088023663, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/469\", \"loss\": 1.904344975948, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/469\", \"loss\": 1.831745028496, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/469\", \"loss\": 1.896848559380, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/469\", \"loss\": 1.936657726765, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/469\", \"loss\": 1.996294260025, \"lr\": 0.000010167342, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/469\", \"loss\": 1.784357905388, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/469\", \"loss\": 1.946988880634, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/469\", \"loss\": 2.019990086555, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/469\", \"loss\": 1.791110575199, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/469\", \"loss\": 1.946655809879, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/469\", \"loss\": 1.914942264557, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/469\", \"loss\": 1.856384217739, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/469\", \"loss\": 1.952675580978, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/469\", \"loss\": 1.946187138557, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/469\", \"loss\": 1.855057716370, \"lr\": 0.000010167342, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/469\", \"loss\": 1.854037523270, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/469\", \"loss\": 1.852876901627, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/469\", \"loss\": 1.855176329613, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/469\", \"loss\": 1.859288811684, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/469\", \"loss\": 1.805339753628, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/469\", \"loss\": 1.817069530487, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/469\", \"loss\": 1.860999703407, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/469\", \"loss\": 1.883999764919, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/469\", \"loss\": 1.750882327557, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/469\", \"loss\": 1.838001787663, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/469\", \"loss\": 1.879366457462, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/469\", \"loss\": 1.860295593739, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/469\", \"loss\": 1.870427250862, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/469\", \"loss\": 1.776276230812, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/469\", \"loss\": 1.846644043922, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/469\", \"loss\": 1.836478888988, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/469\", \"loss\": 1.753166913986, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/469\", \"loss\": 1.838251531124, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/469\", \"loss\": 1.800828218460, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/469\", \"loss\": 1.819521963596, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/469\", \"loss\": 1.932631850243, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/469\", \"loss\": 1.795826554298, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/469\", \"loss\": 1.760165274143, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/469\", \"loss\": 1.708478510380, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/469\", \"loss\": 1.783926069736, \"lr\": 0.000010167342, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/469\", \"loss\": 1.777025461197, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/469\", \"loss\": 1.737850248814, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/469\", \"loss\": 1.792101442814, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.858986631711, \"lr\": 0.000010167342, \"top1_err\": 70.319999995931}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 64.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 62.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 63.280000762939, \"top1_err\": 63.280000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/469\", \"loss\": 1.853488981724, \"lr\": 0.000010167342, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/469\", \"loss\": 1.776112556458, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/469\", \"loss\": 1.725302159786, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/469\", \"loss\": 1.594495713711, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/469\", \"loss\": 1.540545105934, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/469\", \"loss\": 1.801919817924, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/469\", \"loss\": 1.807758092880, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/469\", \"loss\": 1.636313498020, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/469\", \"loss\": 1.772918283939, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/469\", \"loss\": 1.629887640476, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/469\", \"loss\": 1.648229122162, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/469\", \"loss\": 1.633104801178, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/469\", \"loss\": 1.632086813450, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/469\", \"loss\": 1.713386118412, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/469\", \"loss\": 1.710138082504, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/469\", \"loss\": 1.621777117252, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/469\", \"loss\": 1.621060132980, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/469\", \"loss\": 1.590490400791, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/469\", \"loss\": 1.546338379383, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/469\", \"loss\": 1.691871404648, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/469\", \"loss\": 1.878181993961, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/469\", \"loss\": 1.602567732334, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/469\", \"loss\": 1.712021708488, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/469\", \"loss\": 1.579493880272, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/469\", \"loss\": 1.585351586342, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/469\", \"loss\": 1.644467055798, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/469\", \"loss\": 1.684140920639, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/469\", \"loss\": 1.561888813972, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/469\", \"loss\": 1.527958512306, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/469\", \"loss\": 1.639784932137, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/469\", \"loss\": 1.800945580006, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/469\", \"loss\": 1.732815921307, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/469\", \"loss\": 1.813357412815, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/469\", \"loss\": 1.637773692608, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/469\", \"loss\": 1.373501002789, \"lr\": 0.000010167342, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/469\", \"loss\": 1.704137206078, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/469\", \"loss\": 1.483408689499, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/469\", \"loss\": 1.611464321613, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/469\", \"loss\": 1.704890012741, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/469\", \"loss\": 1.567093014717, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/469\", \"loss\": 1.562938332558, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/469\", \"loss\": 1.687615454197, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/469\", \"loss\": 1.653466701508, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/469\", \"loss\": 1.690178632736, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/469\", \"loss\": 1.632457077503, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/469\", \"loss\": 1.606906414032, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.680149583371, \"lr\": 0.000010167342, \"top1_err\": 62.666666662598}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 55.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 54.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 55.320000610352, \"top1_err\": 55.320000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/469\", \"loss\": 1.487183809280, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/469\", \"loss\": 1.509652614594, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/469\", \"loss\": 1.369646608829, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/469\", \"loss\": 1.631718575954, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/469\", \"loss\": 1.505387663841, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/469\", \"loss\": 1.356183171272, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/469\", \"loss\": 1.523576557636, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/469\", \"loss\": 1.593120157719, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/469\", \"loss\": 1.548508286476, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/469\", \"loss\": 1.552051126957, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/469\", \"loss\": 1.402321040630, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/469\", \"loss\": 1.636978805065, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/469\", \"loss\": 1.557192146778, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/469\", \"loss\": 1.663470327854, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/469\", \"loss\": 1.560311317444, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/469\", \"loss\": 1.393431186676, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/469\", \"loss\": 1.548237204552, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/469\", \"loss\": 1.401271522045, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/469\", \"loss\": 1.621789693832, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/469\", \"loss\": 1.472956955433, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/469\", \"loss\": 1.580903053284, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/469\", \"loss\": 1.607586622238, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/469\", \"loss\": 1.472065567970, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/469\", \"loss\": 1.615123808384, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/469\", \"loss\": 1.454795181751, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/469\", \"loss\": 1.439231038094, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/469\", \"loss\": 1.610064327717, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/469\", \"loss\": 1.404056847095, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/469\", \"loss\": 1.445941030979, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/469\", \"loss\": 1.530566573143, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/469\", \"loss\": 1.591198980808, \"lr\": 0.000010167342, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/469\", \"loss\": 1.550264954567, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/469\", \"loss\": 1.599684715271, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/469\", \"loss\": 1.687902450562, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/469\", \"loss\": 1.561911761761, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/469\", \"loss\": 1.515309810638, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/469\", \"loss\": 1.346651494503, \"lr\": 0.000010167342, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/469\", \"loss\": 1.624041378498, \"lr\": 0.000010167342, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/469\", \"loss\": 1.455925703049, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/469\", \"loss\": 1.451764047146, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/469\", \"loss\": 1.512854278088, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/469\", \"loss\": 1.523539245129, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/469\", \"loss\": 1.496938526630, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/469\", \"loss\": 1.577257752419, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/469\", \"loss\": 1.610519409180, \"lr\": 0.000010167342, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/469\", \"loss\": 1.479809641838, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.554104770660, \"lr\": 0.000010167342, \"top1_err\": 57.706666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 54.249998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 55.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 54.820000457764, \"top1_err\": 54.820000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/469\", \"loss\": 1.411094725132, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/469\", \"loss\": 1.396398544312, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/469\", \"loss\": 1.416020035744, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/469\", \"loss\": 1.571438312531, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/469\", \"loss\": 1.292701005936, \"lr\": 0.000010167342, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/469\", \"loss\": 1.209756493568, \"lr\": 0.000010167342, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/469\", \"loss\": 1.520365476608, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/469\", \"loss\": 1.494172275066, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/469\", \"loss\": 1.397140324116, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/469\", \"loss\": 1.398493885994, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/469\", \"loss\": 1.300399422646, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/469\", \"loss\": 1.297099113464, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/469\", \"loss\": 1.400337100029, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/469\", \"loss\": 1.304985702038, \"lr\": 0.000010167342, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/469\", \"loss\": 1.386422693729, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/469\", \"loss\": 1.303356349468, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/469\", \"loss\": 1.416397750378, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/469\", \"loss\": 1.463428080082, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/469\", \"loss\": 1.373314499855, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/469\", \"loss\": 1.299541294575, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/469\", \"loss\": 1.603616595268, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/469\", \"loss\": 1.308460652828, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/469\", \"loss\": 1.444848060608, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/469\", \"loss\": 1.404371321201, \"lr\": 0.000010167342, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/469\", \"loss\": 1.580526769161, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/469\", \"loss\": 1.474738419056, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/469\", \"loss\": 1.339834630489, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/469\", \"loss\": 1.380014717579, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/469\", \"loss\": 1.340618848801, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/469\", \"loss\": 1.479115724564, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/469\", \"loss\": 1.490634441376, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/469\", \"loss\": 1.373560667038, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/469\", \"loss\": 1.290656030178, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/469\", \"loss\": 1.356913447380, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/469\", \"loss\": 1.279975414276, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/469\", \"loss\": 1.523788928986, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/469\", \"loss\": 1.265495061874, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/469\", \"loss\": 1.325779557228, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/469\", \"loss\": 1.413463473320, \"lr\": 0.000010167342, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/469\", \"loss\": 1.374500989914, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/469\", \"loss\": 1.366746604443, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/469\", \"loss\": 1.530751347542, \"lr\": 0.000010167342, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/469\", \"loss\": 1.277230143547, \"lr\": 0.000010167342, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/469\", \"loss\": 1.476018905640, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/469\", \"loss\": 1.427347838879, \"lr\": 0.000010167342, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/469\", \"loss\": 1.546793997288, \"lr\": 0.000010167342, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.399395998700, \"lr\": 0.000010167342, \"top1_err\": 51.573333331299}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 52.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 51.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 52.160000457764, \"top1_err\": 52.160000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_47.83999954223633_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_47.83999954223633_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:24:29,594]\u001b[0m Trial 4 finished with value: 47.83999954223633 and parameters: {'learning_rate': 1.0167342099428397e-05, 'weight_decay': 0.00010932387237615299, 'batch_size': 16, 'optimizer': 'ADAM'}. Best is trial 0 with value: 48.19999984741211.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 814.6322584152222 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 48.19999984741211\n",
      "  Params: \n",
      "    learning_rate: 2.404835143682204e-05\n",
      "    weight_decay: 8.994394426746868e-06\n",
      "    batch_size: 64\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_5oh_rkeo.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform uncertainty sampling through subprocess\n",
      "len(uSetLoader): 586\n",
      "uSet Activations: 100%|███████████████████████| 586/586 [00:08<00:00, 71.37it/s]\n",
      "u_ranks.shape: (37500,)\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  35000\n",
      "len(lSEt):  7500\n",
      "==================\n",
      "After including activeSet -- len(lSet): 10000 and len(uSet): 35000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  2500\n",
      "len(uSet):  35000\n",
      "len(lSet):  10000\n",
      "For uncertainty sampling, activeSet accuracy:  23.6\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 52.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 50.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 52.249998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 52.249998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 51.650000000000, \"top1_err\": 51.650000000000}\n",
      "Test Accuracy: 48.350\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:uncertainty;Seed:1]Test accuracy on cifar10 using 20.0% of data is 48.35\n",
      "\n",
      "Extracted Test Accuracy from subproces: 48.35\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_gcveknlw.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 00:27:12,485]\u001b[0m A new study created in memory with name: no-name-fbc3b1fa-b94f-4cce-9fb3-41edf1f5bc79\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 1.0474208423545323e-05\n",
      "Weight Decay : 6.936375527090807e-08\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1.0474208423545323e-05\n",
      "    weight_decay: 6.936375527090807e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 20\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/20\", \"loss\": 2.268629074097, \"lr\": 0.000010474208, \"top1_err\": 86.132812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/20\", \"loss\": 2.235818266869, \"lr\": 0.000010474208, \"top1_err\": 84.082031250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.257254592896, \"lr\": 0.000010474208, \"top1_err\": 85.530000024414}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 89.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 91.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 90.060000000000, \"top1_err\": 90.060000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/20\", \"loss\": 2.199109792709, \"lr\": 0.000010474208, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/20\", \"loss\": 2.152894616127, \"lr\": 0.000010474208, \"top1_err\": 80.957031250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.176357595825, \"lr\": 0.000010474208, \"top1_err\": 81.859999938965}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 90.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 89.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 90.000000000000, \"top1_err\": 90.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/20\", \"loss\": 2.088630318642, \"lr\": 0.000010474208, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/20\", \"loss\": 2.027671337128, \"lr\": 0.000010474208, \"top1_err\": 75.585937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.059734406662, \"lr\": 0.000010474208, \"top1_err\": 76.740000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 82.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 81.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 81.040000305176, \"top1_err\": 81.040000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/20\", \"loss\": 1.961308956146, \"lr\": 0.000010474208, \"top1_err\": 73.925781250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/20\", \"loss\": 1.923817694187, \"lr\": 0.000010474208, \"top1_err\": 72.949218750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.949504108238, \"lr\": 0.000010474208, \"top1_err\": 73.009999938965}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 67.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 68.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 67.180000305176, \"top1_err\": 67.180000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/20\", \"loss\": 1.851029634476, \"lr\": 0.000010474208, \"top1_err\": 68.652343750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/20\", \"loss\": 1.853290736675, \"lr\": 0.000010474208, \"top1_err\": 68.457031250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.848222164726, \"lr\": 0.000010474208, \"top1_err\": 68.320000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 64.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 60.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 63.240001068115, \"top1_err\": 63.240001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_36.759998931884766_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_36.759998931884766_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:28:14,009]\u001b[0m Trial 0 finished with value: 36.759998931884766 and parameters: {'learning_rate': 1.0474208423545323e-05, 'weight_decay': 6.936375527090807e-08, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 0 with value: 36.759998931884766.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 9.798531688310364e-05\n",
      "Weight Decay : 6.524303746104518e-08\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 9.798531688310364e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 6.524303746104518e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.320082902908, \"lr\": 0.000097985317, \"top1_err\": 89.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.295086026192, \"lr\": 0.000097985317, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.290255904198, \"lr\": 0.000097985317, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 2.285606145859, \"lr\": 0.000097985317, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 2.287843942642, \"lr\": 0.000097985317, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 2.296287059784, \"lr\": 0.000097985317, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 2.278761506081, \"lr\": 0.000097985317, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.293467487335, \"lr\": 0.000097985317, \"top1_err\": 86.950000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 91.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 89.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 90.260000000000, \"top1_err\": 90.260000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 2.276429176331, \"lr\": 0.000097985317, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 2.291087746620, \"lr\": 0.000097985317, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 2.267914414406, \"lr\": 0.000097985317, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 2.267148852348, \"lr\": 0.000097985317, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 2.271894693375, \"lr\": 0.000097985317, \"top1_err\": 84.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 2.271579504013, \"lr\": 0.000097985317, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 2.270679235458, \"lr\": 0.000097985317, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.272606587601, \"lr\": 0.000097985317, \"top1_err\": 86.010000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 88.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 90.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 89.280000000000, \"top1_err\": 89.280000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 2.252729058266, \"lr\": 0.000097985317, \"top1_err\": 84.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 2.284216403961, \"lr\": 0.000097985317, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 2.252083897591, \"lr\": 0.000097985317, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 2.263641238213, \"lr\": 0.000097985317, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 2.264685630798, \"lr\": 0.000097985317, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 2.254968166351, \"lr\": 0.000097985317, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 2.258858442307, \"lr\": 0.000097985317, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.259972491455, \"lr\": 0.000097985317, \"top1_err\": 85.950000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 88.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 86.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 87.620000000000, \"top1_err\": 87.620000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 2.249757409096, \"lr\": 0.000097985317, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 2.243811726570, \"lr\": 0.000097985317, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 2.246885418892, \"lr\": 0.000097985317, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 2.220655083656, \"lr\": 0.000097985317, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 2.243533134460, \"lr\": 0.000097985317, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 2.251574635506, \"lr\": 0.000097985317, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 2.232678055763, \"lr\": 0.000097985317, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.244231075287, \"lr\": 0.000097985317, \"top1_err\": 84.960000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 85.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 86.860000000000, \"top1_err\": 86.860000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 2.243763685226, \"lr\": 0.000097985317, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 2.217424869537, \"lr\": 0.000097985317, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 2.230244398117, \"lr\": 0.000097985317, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 2.226092100143, \"lr\": 0.000097985317, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 2.236108899117, \"lr\": 0.000097985317, \"top1_err\": 84.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 2.224303483963, \"lr\": 0.000097985317, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 2.235235452652, \"lr\": 0.000097985317, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.228354311371, \"lr\": 0.000097985317, \"top1_err\": 84.070000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 84.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 82.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 83.860000000000, \"top1_err\": 83.860000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_16.14_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_16.14_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:29:17,262]\u001b[0m Trial 1 finished with value: 16.14 and parameters: {'learning_rate': 9.798531688310364e-05, 'weight_decay': 6.524303746104518e-08, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 0 with value: 36.759998931884766.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0004996657652096068\n",
      "Weight Decay : 2.3691531563099294e-05\n",
      "Batch Size   : 8\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0004996657652096068\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.3691531563099294e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 1250\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/1250\", \"loss\": 2.297585129738, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/1250\", \"loss\": 2.363754749298, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/1250\", \"loss\": 2.281966090202, \"lr\": 0.000499665765, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/1250\", \"loss\": 2.324413061142, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/1250\", \"loss\": 2.292044162750, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/1250\", \"loss\": 2.279033660889, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/1250\", \"loss\": 2.289401054382, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/1250\", \"loss\": 2.225846529007, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/1250\", \"loss\": 2.260941386223, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/1250\", \"loss\": 2.267361998558, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/1250\", \"loss\": 2.258482336998, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/1250\", \"loss\": 2.304100513458, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/1250\", \"loss\": 2.346352577209, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/1250\", \"loss\": 2.259991049767, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/1250\", \"loss\": 2.303966879845, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/1250\", \"loss\": 2.258030891418, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/1250\", \"loss\": 2.218173384666, \"lr\": 0.000499665765, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/1250\", \"loss\": 2.200094580650, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/1250\", \"loss\": 2.263748049736, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/1250\", \"loss\": 2.187415242195, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/1250\", \"loss\": 2.216447234154, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/1250\", \"loss\": 2.325685620308, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/1250\", \"loss\": 2.142015933990, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/1250\", \"loss\": 2.152909398079, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/1250\", \"loss\": 2.201980948448, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/1250\", \"loss\": 2.092215418816, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/1250\", \"loss\": 2.181773900986, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/1250\", \"loss\": 2.211338639259, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/1250\", \"loss\": 2.143651366234, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/1250\", \"loss\": 2.270453214645, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/1250\", \"loss\": 2.127912759781, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/1250\", \"loss\": 2.128084778786, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/1250\", \"loss\": 2.204502224922, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/1250\", \"loss\": 2.156793236732, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/1250\", \"loss\": 2.144683957100, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/1250\", \"loss\": 2.176399946213, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/1250\", \"loss\": 2.208745718002, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/1250\", \"loss\": 2.139448642731, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/1250\", \"loss\": 2.061656832695, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/1250\", \"loss\": 2.101057052612, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/1250\", \"loss\": 2.142194747925, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/1250\", \"loss\": 1.980123102665, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/1250\", \"loss\": 2.317404150963, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/1250\", \"loss\": 2.182119965553, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/1250\", \"loss\": 2.135203838348, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/1250\", \"loss\": 2.082915306091, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/1250\", \"loss\": 2.005735993385, \"lr\": 0.000499665765, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/1250\", \"loss\": 2.157720208168, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/1250\", \"loss\": 2.126818180084, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/1250\", \"loss\": 2.156095027924, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/1250\", \"loss\": 2.145590782166, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/1250\", \"loss\": 1.980826795101, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/1250\", \"loss\": 2.102702260017, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/1250\", \"loss\": 1.971046090126, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/1250\", \"loss\": 1.961031079292, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/1250\", \"loss\": 2.066864252090, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/1250\", \"loss\": 2.071977496147, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/1250\", \"loss\": 1.992252111435, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/1250\", \"loss\": 2.151351332664, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/1250\", \"loss\": 2.064314126968, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/1250\", \"loss\": 1.974044620991, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/1250\", \"loss\": 2.010573446751, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/1250\", \"loss\": 2.200571894646, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/1250\", \"loss\": 2.022220611572, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/1250\", \"loss\": 2.018619775772, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/1250\", \"loss\": 2.042095303535, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/1250\", \"loss\": 1.978285133839, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/1250\", \"loss\": 2.040230751038, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/1250\", \"loss\": 1.978654086590, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/1250\", \"loss\": 2.095559239388, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/1250\", \"loss\": 2.135632157326, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/1250\", \"loss\": 1.983836770058, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/1250\", \"loss\": 2.042059898376, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/1250\", \"loss\": 1.950168132782, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/1250\", \"loss\": 1.930979311466, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/1250\", \"loss\": 2.135887384415, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/1250\", \"loss\": 1.986798286438, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/1250\", \"loss\": 2.172223210335, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/1250\", \"loss\": 1.958561599255, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/1250\", \"loss\": 2.042172789574, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/1250\", \"loss\": 2.016769886017, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/1250\", \"loss\": 2.008077740669, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/1250\", \"loss\": 2.005658388138, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/1250\", \"loss\": 1.987073302269, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/1250\", \"loss\": 1.899104893208, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/1250\", \"loss\": 1.953847527504, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/1250\", \"loss\": 1.910204946995, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/1250\", \"loss\": 1.776035726070, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/1250\", \"loss\": 1.898500561714, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/1250\", \"loss\": 1.965661406517, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/1250\", \"loss\": 2.003383696079, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/1250\", \"loss\": 1.915760636330, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/1250\", \"loss\": 1.979489088058, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"940/1250\", \"loss\": 1.840943038464, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"950/1250\", \"loss\": 2.044870972633, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"960/1250\", \"loss\": 1.854802608490, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"970/1250\", \"loss\": 1.884748637676, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"980/1250\", \"loss\": 2.104220390320, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"990/1250\", \"loss\": 1.926278769970, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1000/1250\", \"loss\": 2.223294734955, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1010/1250\", \"loss\": 1.901662945747, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1020/1250\", \"loss\": 1.923435449600, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1030/1250\", \"loss\": 1.944661617279, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1040/1250\", \"loss\": 1.747758150101, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1050/1250\", \"loss\": 1.956045150757, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1060/1250\", \"loss\": 2.043692946434, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1070/1250\", \"loss\": 2.063891887665, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1080/1250\", \"loss\": 1.955625653267, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1090/1250\", \"loss\": 2.076595306396, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1100/1250\", \"loss\": 1.871124446392, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1110/1250\", \"loss\": 1.974774241447, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1120/1250\", \"loss\": 2.142075300217, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1130/1250\", \"loss\": 2.060817003250, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1140/1250\", \"loss\": 1.818112194538, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1150/1250\", \"loss\": 1.766881465912, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1160/1250\", \"loss\": 2.063828825951, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1170/1250\", \"loss\": 1.809487998486, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1180/1250\", \"loss\": 1.967592537403, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1190/1250\", \"loss\": 1.856499671936, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1200/1250\", \"loss\": 1.963535785675, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1210/1250\", \"loss\": 1.939957082272, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1220/1250\", \"loss\": 2.072850704193, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1230/1250\", \"loss\": 2.076561331749, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1240/1250\", \"loss\": 1.930405795574, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1250/1250\", \"loss\": 2.028958380222, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.090957927322, \"lr\": 0.000499665765, \"top1_err\": 80.220000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 65.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 67.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 66.480000915527, \"top1_err\": 66.480000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/1250\", \"loss\": 1.858978569508, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/1250\", \"loss\": 1.880448997021, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/1250\", \"loss\": 1.947067141533, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/1250\", \"loss\": 2.012515366077, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/1250\", \"loss\": 1.846886813641, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/1250\", \"loss\": 1.789265692234, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/1250\", \"loss\": 1.993788838387, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/1250\", \"loss\": 1.968382954597, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/1250\", \"loss\": 1.964819967747, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/1250\", \"loss\": 1.817742884159, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/1250\", \"loss\": 1.946866393089, \"lr\": 0.000499665765, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/1250\", \"loss\": 2.168289780617, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/1250\", \"loss\": 2.005655288696, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/1250\", \"loss\": 2.009379267693, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/1250\", \"loss\": 2.058961272240, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/1250\", \"loss\": 1.914091885090, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/1250\", \"loss\": 1.830426573753, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/1250\", \"loss\": 2.163383126259, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/1250\", \"loss\": 1.925022542477, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/1250\", \"loss\": 1.997469246387, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/1250\", \"loss\": 1.951201021671, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/1250\", \"loss\": 1.888347387314, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/1250\", \"loss\": 1.923658907413, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/1250\", \"loss\": 2.023703455925, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/1250\", \"loss\": 1.977947890759, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/1250\", \"loss\": 1.870406389236, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/1250\", \"loss\": 1.836598396301, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/1250\", \"loss\": 1.855240821838, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/1250\", \"loss\": 1.979110717773, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/1250\", \"loss\": 1.997459173203, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/1250\", \"loss\": 1.993131160736, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/1250\", \"loss\": 1.920616209507, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/1250\", \"loss\": 1.883784115314, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/1250\", \"loss\": 1.744212746620, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/1250\", \"loss\": 1.999491870403, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/1250\", \"loss\": 1.956792712212, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/1250\", \"loss\": 1.995197653770, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/1250\", \"loss\": 1.928268909454, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/1250\", \"loss\": 1.897477924824, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/1250\", \"loss\": 1.913479804993, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/1250\", \"loss\": 2.123603463173, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/1250\", \"loss\": 1.961806297302, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/1250\", \"loss\": 1.935355246067, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/1250\", \"loss\": 1.849683105946, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/1250\", \"loss\": 1.744117259979, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/1250\", \"loss\": 1.821808040142, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/1250\", \"loss\": 1.936799883842, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/1250\", \"loss\": 1.980404138565, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/1250\", \"loss\": 1.850324213505, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/1250\", \"loss\": 1.923707604408, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/1250\", \"loss\": 1.916779458523, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/1250\", \"loss\": 1.949739873409, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/1250\", \"loss\": 1.934474587440, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/1250\", \"loss\": 1.825916171074, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/1250\", \"loss\": 1.885193407536, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/1250\", \"loss\": 1.828855991364, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/1250\", \"loss\": 2.029888391495, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/1250\", \"loss\": 1.776152610779, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/1250\", \"loss\": 1.798286676407, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/1250\", \"loss\": 1.822195708752, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/1250\", \"loss\": 2.047492384911, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/1250\", \"loss\": 1.870975613594, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/1250\", \"loss\": 1.832192838192, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/1250\", \"loss\": 2.052215278149, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/1250\", \"loss\": 1.808750331402, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/1250\", \"loss\": 1.941109955311, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/1250\", \"loss\": 1.950197815895, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/1250\", \"loss\": 1.659055709839, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/1250\", \"loss\": 1.958564162254, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/1250\", \"loss\": 1.923208653927, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/1250\", \"loss\": 1.949232518673, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/1250\", \"loss\": 1.927830278873, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/1250\", \"loss\": 1.857903420925, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/1250\", \"loss\": 1.693163096905, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/1250\", \"loss\": 1.828188598156, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/1250\", \"loss\": 1.803325057030, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/1250\", \"loss\": 2.031928777695, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/1250\", \"loss\": 1.823470652103, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/1250\", \"loss\": 1.803031742573, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/1250\", \"loss\": 1.803705394268, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/1250\", \"loss\": 1.985415041447, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/1250\", \"loss\": 1.849223136902, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/1250\", \"loss\": 1.948564946651, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/1250\", \"loss\": 1.864808917046, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/1250\", \"loss\": 1.904860854149, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/1250\", \"loss\": 1.605159699917, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/1250\", \"loss\": 1.954497456551, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/1250\", \"loss\": 1.949092209339, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/1250\", \"loss\": 1.740671932697, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/1250\", \"loss\": 2.085065960884, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/1250\", \"loss\": 1.736833631992, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/1250\", \"loss\": 1.810805559158, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/1250\", \"loss\": 1.873547434807, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"940/1250\", \"loss\": 1.906920194626, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"950/1250\", \"loss\": 1.854570627213, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"960/1250\", \"loss\": 1.781753242016, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"970/1250\", \"loss\": 1.881911158562, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"980/1250\", \"loss\": 2.095808267593, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"990/1250\", \"loss\": 1.702314555645, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1000/1250\", \"loss\": 1.972655892372, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1010/1250\", \"loss\": 2.027766942978, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1020/1250\", \"loss\": 1.736485421658, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1030/1250\", \"loss\": 1.962314009666, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1040/1250\", \"loss\": 1.853209018707, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1050/1250\", \"loss\": 2.047281503677, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1060/1250\", \"loss\": 1.862230718136, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1070/1250\", \"loss\": 1.970065236092, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1080/1250\", \"loss\": 1.811081349850, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1090/1250\", \"loss\": 1.753685116768, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1100/1250\", \"loss\": 1.855489671230, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1110/1250\", \"loss\": 1.907771706581, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1120/1250\", \"loss\": 1.812302827835, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1130/1250\", \"loss\": 1.764241814613, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1140/1250\", \"loss\": 1.906793177128, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1150/1250\", \"loss\": 1.731566965580, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1160/1250\", \"loss\": 1.863049387932, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1170/1250\", \"loss\": 2.015254974365, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1180/1250\", \"loss\": 1.910806655884, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1190/1250\", \"loss\": 1.815051734447, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1200/1250\", \"loss\": 1.889502227306, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1210/1250\", \"loss\": 1.934590935707, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1220/1250\", \"loss\": 1.875021517277, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1230/1250\", \"loss\": 1.814148247242, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1240/1250\", \"loss\": 1.757882833481, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1250/1250\", \"loss\": 2.038581669331, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.911508486271, \"lr\": 0.000499665765, \"top1_err\": 72.310000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 59.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 60.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 60.140001678467, \"top1_err\": 60.140001678467}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/1250\", \"loss\": 1.777547061443, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/1250\", \"loss\": 1.871005833149, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/1250\", \"loss\": 1.698093414307, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/1250\", \"loss\": 1.818244695663, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/1250\", \"loss\": 1.697527170181, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/1250\", \"loss\": 1.844386875629, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/1250\", \"loss\": 1.829418420792, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/1250\", \"loss\": 1.741149544716, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/1250\", \"loss\": 1.657849669456, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/1250\", \"loss\": 1.769164264202, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/1250\", \"loss\": 1.593637883663, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/1250\", \"loss\": 2.031443119049, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/1250\", \"loss\": 1.641081094742, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/1250\", \"loss\": 1.784249126911, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/1250\", \"loss\": 1.859310984612, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/1250\", \"loss\": 1.711663782597, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/1250\", \"loss\": 1.984797120094, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/1250\", \"loss\": 1.680445075035, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/1250\", \"loss\": 1.629292726517, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/1250\", \"loss\": 1.752485573292, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/1250\", \"loss\": 1.922392785549, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/1250\", \"loss\": 1.850092828274, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/1250\", \"loss\": 1.846000373363, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/1250\", \"loss\": 1.685675978661, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/1250\", \"loss\": 1.556181967258, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/1250\", \"loss\": 1.851275920868, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/1250\", \"loss\": 2.041474938393, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/1250\", \"loss\": 1.823898553848, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/1250\", \"loss\": 1.753848969936, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/1250\", \"loss\": 1.785859644413, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/1250\", \"loss\": 1.844829678535, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/1250\", \"loss\": 1.624121904373, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/1250\", \"loss\": 1.706176400185, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/1250\", \"loss\": 1.625770509243, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/1250\", \"loss\": 1.796047687531, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/1250\", \"loss\": 1.606135487556, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/1250\", \"loss\": 1.809965908527, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/1250\", \"loss\": 1.613776683807, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/1250\", \"loss\": 1.861242055893, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/1250\", \"loss\": 1.706847488880, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/1250\", \"loss\": 1.670113205910, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/1250\", \"loss\": 1.871267974377, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/1250\", \"loss\": 1.792397677898, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/1250\", \"loss\": 1.887633025646, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/1250\", \"loss\": 1.823472261429, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/1250\", \"loss\": 1.841732025146, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/1250\", \"loss\": 1.756174087524, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/1250\", \"loss\": 1.617422521114, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/1250\", \"loss\": 1.527795016766, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/1250\", \"loss\": 1.770707607269, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/1250\", \"loss\": 1.724977493286, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/1250\", \"loss\": 1.573681235313, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/1250\", \"loss\": 1.626755475998, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/1250\", \"loss\": 1.717392325401, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/1250\", \"loss\": 1.426534235477, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/1250\", \"loss\": 1.802173554897, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/1250\", \"loss\": 1.872131347656, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/1250\", \"loss\": 1.831655263901, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/1250\", \"loss\": 1.817560911179, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/1250\", \"loss\": 1.652714908123, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/1250\", \"loss\": 1.820639431477, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/1250\", \"loss\": 1.773107886314, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/1250\", \"loss\": 1.699873447418, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/1250\", \"loss\": 1.932093143463, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/1250\", \"loss\": 1.663201987743, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/1250\", \"loss\": 1.893710911274, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/1250\", \"loss\": 1.839428126812, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/1250\", \"loss\": 1.916431963444, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/1250\", \"loss\": 1.741214334965, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/1250\", \"loss\": 1.986091554165, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/1250\", \"loss\": 1.691077649593, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/1250\", \"loss\": 1.755762040615, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/1250\", \"loss\": 1.759460628033, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/1250\", \"loss\": 1.695447564125, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/1250\", \"loss\": 1.650415599346, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/1250\", \"loss\": 1.768607556820, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/1250\", \"loss\": 1.691501319408, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/1250\", \"loss\": 1.901884317398, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/1250\", \"loss\": 1.724781751633, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/1250\", \"loss\": 1.734638571739, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/1250\", \"loss\": 1.666423559189, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/1250\", \"loss\": 1.757398068905, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/1250\", \"loss\": 1.658731937408, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/1250\", \"loss\": 1.962376713753, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/1250\", \"loss\": 1.805810213089, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/1250\", \"loss\": 1.837188661098, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/1250\", \"loss\": 1.674363374710, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/1250\", \"loss\": 1.727319180965, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/1250\", \"loss\": 1.791656434536, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/1250\", \"loss\": 2.043225049973, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/1250\", \"loss\": 1.934915721416, \"lr\": 0.000499665765, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/1250\", \"loss\": 1.644629597664, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/1250\", \"loss\": 1.775432229042, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"940/1250\", \"loss\": 1.900189101696, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"950/1250\", \"loss\": 1.897055327892, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"960/1250\", \"loss\": 1.702139198780, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"970/1250\", \"loss\": 1.766253769398, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"980/1250\", \"loss\": 1.885438680649, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"990/1250\", \"loss\": 1.626751482487, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1000/1250\", \"loss\": 1.739646613598, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1010/1250\", \"loss\": 1.759223341942, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1020/1250\", \"loss\": 1.610794663429, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1030/1250\", \"loss\": 1.873871862888, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1040/1250\", \"loss\": 1.827793002129, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1050/1250\", \"loss\": 1.659777641296, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1060/1250\", \"loss\": 1.791674196720, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1070/1250\", \"loss\": 1.861851155758, \"lr\": 0.000499665765, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1080/1250\", \"loss\": 1.562946140766, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1090/1250\", \"loss\": 1.810368299484, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1100/1250\", \"loss\": 1.686590075493, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1110/1250\", \"loss\": 1.696368694305, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1120/1250\", \"loss\": 1.642710983753, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1130/1250\", \"loss\": 1.575841188431, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1140/1250\", \"loss\": 1.474331021309, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1150/1250\", \"loss\": 1.819314777851, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1160/1250\", \"loss\": 1.644055366516, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1170/1250\", \"loss\": 1.820428133011, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1180/1250\", \"loss\": 1.678333342075, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1190/1250\", \"loss\": 1.667780995369, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1200/1250\", \"loss\": 1.716889142990, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1210/1250\", \"loss\": 1.820718944073, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1220/1250\", \"loss\": 1.566448271275, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1230/1250\", \"loss\": 1.741303622723, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1240/1250\", \"loss\": 1.779669106007, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1250/1250\", \"loss\": 1.654927730560, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.775353847551, \"lr\": 0.000499665765, \"top1_err\": 66.610000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 53.249996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 52.100000000000, \"top1_err\": 52.100000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/1250\", \"loss\": 1.570708274841, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/1250\", \"loss\": 2.001635611057, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/1250\", \"loss\": 1.806819677353, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/1250\", \"loss\": 1.702185928822, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/1250\", \"loss\": 1.631150722504, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/1250\", \"loss\": 1.762240707874, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/1250\", \"loss\": 1.499408781528, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/1250\", \"loss\": 1.527547955513, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/1250\", \"loss\": 1.619338214397, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/1250\", \"loss\": 1.567594587803, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/1250\", \"loss\": 1.390981376171, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/1250\", \"loss\": 1.604871869087, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/1250\", \"loss\": 1.520707964897, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/1250\", \"loss\": 1.728717207909, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/1250\", \"loss\": 1.634248673916, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/1250\", \"loss\": 1.562604546547, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/1250\", \"loss\": 1.594318747520, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/1250\", \"loss\": 1.561092495918, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/1250\", \"loss\": 1.626482844353, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/1250\", \"loss\": 1.566221535206, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/1250\", \"loss\": 1.849785327911, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/1250\", \"loss\": 1.521763563156, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/1250\", \"loss\": 1.901746034622, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/1250\", \"loss\": 1.749488472939, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/1250\", \"loss\": 1.572914600372, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/1250\", \"loss\": 1.517669141293, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/1250\", \"loss\": 1.647144138813, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/1250\", \"loss\": 1.319663643837, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/1250\", \"loss\": 1.716460585594, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/1250\", \"loss\": 1.622053205967, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/1250\", \"loss\": 1.624225854874, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/1250\", \"loss\": 1.672492384911, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/1250\", \"loss\": 1.866829216480, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/1250\", \"loss\": 1.503978669643, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/1250\", \"loss\": 1.728929221630, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/1250\", \"loss\": 1.846289873123, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/1250\", \"loss\": 1.733088970184, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/1250\", \"loss\": 1.513922512531, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/1250\", \"loss\": 1.561286926270, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/1250\", \"loss\": 1.561969876289, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/1250\", \"loss\": 1.601831793785, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/1250\", \"loss\": 1.583342194557, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/1250\", \"loss\": 1.691669583321, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/1250\", \"loss\": 1.653097629547, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/1250\", \"loss\": 1.640080571175, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/1250\", \"loss\": 1.594611823559, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/1250\", \"loss\": 1.709420502186, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/1250\", \"loss\": 1.492834329605, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/1250\", \"loss\": 1.742160677910, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/1250\", \"loss\": 1.617598533630, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/1250\", \"loss\": 1.774720907211, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/1250\", \"loss\": 1.694994807243, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/1250\", \"loss\": 1.508141219616, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/1250\", \"loss\": 1.509670257568, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/1250\", \"loss\": 1.296909272671, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/1250\", \"loss\": 1.679402410984, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/1250\", \"loss\": 1.668682396412, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/1250\", \"loss\": 1.568289577961, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/1250\", \"loss\": 1.680191934109, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/1250\", \"loss\": 1.624252796173, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/1250\", \"loss\": 1.596866667271, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/1250\", \"loss\": 1.538945615292, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/1250\", \"loss\": 1.743340194225, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/1250\", \"loss\": 1.646757006645, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/1250\", \"loss\": 1.528326094151, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/1250\", \"loss\": 1.709756195545, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/1250\", \"loss\": 1.634000957012, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/1250\", \"loss\": 1.743113517761, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/1250\", \"loss\": 1.559355914593, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/1250\", \"loss\": 1.368168234825, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/1250\", \"loss\": 1.606781184673, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/1250\", \"loss\": 1.497724652290, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/1250\", \"loss\": 1.614624798298, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/1250\", \"loss\": 1.244474470615, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/1250\", \"loss\": 1.773895263672, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/1250\", \"loss\": 1.663100779057, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/1250\", \"loss\": 1.581899642944, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/1250\", \"loss\": 1.689696490765, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/1250\", \"loss\": 1.683455169201, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/1250\", \"loss\": 1.815625131130, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/1250\", \"loss\": 1.711082756519, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/1250\", \"loss\": 1.570409715176, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/1250\", \"loss\": 1.501820564270, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/1250\", \"loss\": 1.701933860779, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/1250\", \"loss\": 1.842188179493, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/1250\", \"loss\": 1.718915164471, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/1250\", \"loss\": 1.671159029007, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/1250\", \"loss\": 1.563355982304, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/1250\", \"loss\": 1.518967270851, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/1250\", \"loss\": 1.722747445107, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/1250\", \"loss\": 1.802301704884, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/1250\", \"loss\": 1.556964516640, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/1250\", \"loss\": 1.667486250401, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"940/1250\", \"loss\": 1.557309985161, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"950/1250\", \"loss\": 1.525402605534, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"960/1250\", \"loss\": 1.521232962608, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"970/1250\", \"loss\": 1.437686860561, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"980/1250\", \"loss\": 1.633092761040, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"990/1250\", \"loss\": 1.686798393726, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1000/1250\", \"loss\": 1.813755273819, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1010/1250\", \"loss\": 1.592457175255, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1020/1250\", \"loss\": 1.445781767368, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1030/1250\", \"loss\": 1.815466403961, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1040/1250\", \"loss\": 1.637118041515, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1050/1250\", \"loss\": 1.626631498337, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1060/1250\", \"loss\": 1.456542670727, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1070/1250\", \"loss\": 1.585204422474, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1080/1250\", \"loss\": 1.749054610729, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1090/1250\", \"loss\": 1.692449927330, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1100/1250\", \"loss\": 1.543740212917, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1110/1250\", \"loss\": 1.619729757309, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1120/1250\", \"loss\": 1.685740947723, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1130/1250\", \"loss\": 1.522292912006, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1140/1250\", \"loss\": 1.746781885624, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1150/1250\", \"loss\": 1.851473450661, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1160/1250\", \"loss\": 1.854815125465, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1170/1250\", \"loss\": 1.723004758358, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1180/1250\", \"loss\": 1.568329930305, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1190/1250\", \"loss\": 1.843560397625, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1200/1250\", \"loss\": 1.527865111828, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1210/1250\", \"loss\": 1.539423048496, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1220/1250\", \"loss\": 1.530485749245, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1230/1250\", \"loss\": 1.449524879456, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1240/1250\", \"loss\": 1.492656886578, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1250/1250\", \"loss\": 1.517620623112, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.645470522690, \"lr\": 0.000499665765, \"top1_err\": 61.060000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 46.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 48.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 46.900000915527, \"top1_err\": 46.900000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/1250\", \"loss\": 1.437513291836, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/1250\", \"loss\": 1.688659846783, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/1250\", \"loss\": 1.564067304134, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/1250\", \"loss\": 1.416708767414, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/1250\", \"loss\": 1.679818272591, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/1250\", \"loss\": 1.500809609890, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/1250\", \"loss\": 1.486950814724, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/1250\", \"loss\": 1.562894821167, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/1250\", \"loss\": 1.490708529949, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/1250\", \"loss\": 1.551248610020, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/1250\", \"loss\": 1.575665712357, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/1250\", \"loss\": 1.531675696373, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/1250\", \"loss\": 1.522131264210, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/1250\", \"loss\": 1.417034745216, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/1250\", \"loss\": 1.416630804539, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/1250\", \"loss\": 1.459122538567, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/1250\", \"loss\": 1.731376707554, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/1250\", \"loss\": 1.585801362991, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/1250\", \"loss\": 1.538591384888, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/1250\", \"loss\": 1.558651864529, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/1250\", \"loss\": 1.616863548756, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/1250\", \"loss\": 1.478828489780, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/1250\", \"loss\": 1.405110359192, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/1250\", \"loss\": 1.624305009842, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/1250\", \"loss\": 1.392613649368, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/1250\", \"loss\": 1.556064069271, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/1250\", \"loss\": 1.597032606602, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/1250\", \"loss\": 1.595156371593, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/1250\", \"loss\": 1.307987272739, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/1250\", \"loss\": 1.462571620941, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/1250\", \"loss\": 1.481455802917, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/1250\", \"loss\": 1.642181694508, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/1250\", \"loss\": 1.510263979435, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/1250\", \"loss\": 1.516957521439, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/1250\", \"loss\": 1.589476883411, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/1250\", \"loss\": 1.365935146809, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/1250\", \"loss\": 1.549052715302, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/1250\", \"loss\": 1.459138691425, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/1250\", \"loss\": 1.420121133327, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/1250\", \"loss\": 1.474317073822, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/1250\", \"loss\": 1.435953497887, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/1250\", \"loss\": 1.550231933594, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/1250\", \"loss\": 1.418228030205, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/1250\", \"loss\": 1.408397376537, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/1250\", \"loss\": 1.454791963100, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/1250\", \"loss\": 1.298292219639, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/1250\", \"loss\": 1.595975637436, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/1250\", \"loss\": 1.570644497871, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/1250\", \"loss\": 1.582072973251, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/1250\", \"loss\": 1.436896860600, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/1250\", \"loss\": 1.441191136837, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/1250\", \"loss\": 1.477627098560, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/1250\", \"loss\": 1.711891114712, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/1250\", \"loss\": 1.428878009319, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/1250\", \"loss\": 1.688368916512, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/1250\", \"loss\": 1.559118747711, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/1250\", \"loss\": 1.518323600292, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/1250\", \"loss\": 1.707217872143, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/1250\", \"loss\": 1.448552131653, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/1250\", \"loss\": 1.367563605309, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/1250\", \"loss\": 1.531300723553, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/1250\", \"loss\": 1.708431899548, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/1250\", \"loss\": 1.760232508183, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/1250\", \"loss\": 1.481848657131, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/1250\", \"loss\": 1.532322645187, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/1250\", \"loss\": 1.283448517323, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/1250\", \"loss\": 1.833339691162, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/1250\", \"loss\": 1.531819403172, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/1250\", \"loss\": 1.482062339783, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/1250\", \"loss\": 1.296492516994, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/1250\", \"loss\": 1.813892126083, \"lr\": 0.000499665765, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/1250\", \"loss\": 1.261199474335, \"lr\": 0.000499665765, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/1250\", \"loss\": 1.362295806408, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/1250\", \"loss\": 1.422679424286, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/1250\", \"loss\": 1.527489960194, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/1250\", \"loss\": 1.207065522671, \"lr\": 0.000499665765, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/1250\", \"loss\": 1.558764040470, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/1250\", \"loss\": 1.533889293671, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/1250\", \"loss\": 1.602073073387, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/1250\", \"loss\": 1.534340023994, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/1250\", \"loss\": 1.614202797413, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/1250\", \"loss\": 1.266938984394, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/1250\", \"loss\": 1.656754732132, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/1250\", \"loss\": 1.522466003895, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/1250\", \"loss\": 1.331430137157, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/1250\", \"loss\": 1.570869684219, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/1250\", \"loss\": 1.449016094208, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/1250\", \"loss\": 1.356438040733, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/1250\", \"loss\": 1.582888782024, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/1250\", \"loss\": 1.505888521671, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/1250\", \"loss\": 1.520171940327, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/1250\", \"loss\": 1.454708933830, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/1250\", \"loss\": 1.345256030560, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"940/1250\", \"loss\": 1.583713173866, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"950/1250\", \"loss\": 1.641823410988, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"960/1250\", \"loss\": 1.483368813992, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"970/1250\", \"loss\": 1.513990521431, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"980/1250\", \"loss\": 1.473001778126, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"990/1250\", \"loss\": 1.479583799839, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1000/1250\", \"loss\": 1.199414789677, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1010/1250\", \"loss\": 1.239134669304, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1020/1250\", \"loss\": 1.536568284035, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1030/1250\", \"loss\": 1.666363596916, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1040/1250\", \"loss\": 1.528679490089, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1050/1250\", \"loss\": 1.638867795467, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1060/1250\", \"loss\": 1.459026157856, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1070/1250\", \"loss\": 1.534799277782, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1080/1250\", \"loss\": 1.743695557117, \"lr\": 0.000499665765, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1090/1250\", \"loss\": 1.545228958130, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1100/1250\", \"loss\": 1.419683933258, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1110/1250\", \"loss\": 1.473275959492, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1120/1250\", \"loss\": 1.340062379837, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1130/1250\", \"loss\": 1.368054568768, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1140/1250\", \"loss\": 1.291666448116, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1150/1250\", \"loss\": 1.315985083580, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1160/1250\", \"loss\": 1.406110525131, \"lr\": 0.000499665765, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1170/1250\", \"loss\": 1.524585723877, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1180/1250\", \"loss\": 1.504967629910, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1190/1250\", \"loss\": 1.614289939404, \"lr\": 0.000499665765, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1200/1250\", \"loss\": 1.547270715237, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1210/1250\", \"loss\": 1.543219625950, \"lr\": 0.000499665765, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1220/1250\", \"loss\": 1.432606399059, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1230/1250\", \"loss\": 1.480737328529, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1240/1250\", \"loss\": 1.573365807533, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1250/1250\", \"loss\": 1.336865127087, \"lr\": 0.000499665765, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.529243292904, \"lr\": 0.000499665765, \"top1_err\": 56.570000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 42.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 43.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 43.300001068115, \"top1_err\": 43.300001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:37:16,799]\u001b[0m Trial 2 finished with value: 56.699998931884764 and parameters: {'learning_rate': 0.0004996657652096068, 'weight_decay': 2.3691531563099294e-05, 'batch_size': 8, 'optimizer': 'SGD'}. Best is trial 2 with value: 56.699998931884764.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 4.5442160786908184e-05\n",
      "Weight Decay : 1.6971924806547293e-07\n",
      "Batch Size   : 64\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 4.5442160786908184e-05\n",
      "    weight_decay: 1.6971924806547293e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/157\", \"loss\": 2.343595981598, \"lr\": 0.000045442161, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/157\", \"loss\": 2.321284532547, \"lr\": 0.000045442161, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/157\", \"loss\": 2.258763790131, \"lr\": 0.000045442161, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 2.200790166855, \"lr\": 0.000045442161, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 2.169500470161, \"lr\": 0.000045442161, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/157\", \"loss\": 2.167326450348, \"lr\": 0.000045442161, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/157\", \"loss\": 2.078926682472, \"lr\": 0.000045442161, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 2.073642969131, \"lr\": 0.000045442161, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/157\", \"loss\": 2.032578229904, \"lr\": 0.000045442161, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 2.003682851791, \"lr\": 0.000045442161, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/157\", \"loss\": 1.958594083786, \"lr\": 0.000045442161, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 1.924088180065, \"lr\": 0.000045442161, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/157\", \"loss\": 1.915186226368, \"lr\": 0.000045442161, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/157\", \"loss\": 1.945723235607, \"lr\": 0.000045442161, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.866311967373, \"lr\": 0.000045442161, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.079517084694, \"lr\": 0.000045442161, \"top1_err\": 79.390000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 61.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 64.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 63.120000457764, \"top1_err\": 63.120000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/157\", \"loss\": 1.804871082306, \"lr\": 0.000045442161, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/157\", \"loss\": 1.857991755009, \"lr\": 0.000045442161, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/157\", \"loss\": 1.749721825123, \"lr\": 0.000045442161, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 1.747850596905, \"lr\": 0.000045442161, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.769454300404, \"lr\": 0.000045442161, \"top1_err\": 64.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/157\", \"loss\": 1.785854876041, \"lr\": 0.000045442161, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/157\", \"loss\": 1.758946716785, \"lr\": 0.000045442161, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 1.702737629414, \"lr\": 0.000045442161, \"top1_err\": 64.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/157\", \"loss\": 1.653029203415, \"lr\": 0.000045442161, \"top1_err\": 64.062500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.604391574860, \"lr\": 0.000045442161, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/157\", \"loss\": 1.637492120266, \"lr\": 0.000045442161, \"top1_err\": 63.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 1.687926173210, \"lr\": 0.000045442161, \"top1_err\": 63.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/157\", \"loss\": 1.716077983379, \"lr\": 0.000045442161, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/157\", \"loss\": 1.644452393055, \"lr\": 0.000045442161, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.707549035549, \"lr\": 0.000045442161, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.717647189713, \"lr\": 0.000045442161, \"top1_err\": 64.910000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 52.999996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 52.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 52.360000152588, \"top1_err\": 52.360000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/157\", \"loss\": 1.554519951344, \"lr\": 0.000045442161, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/157\", \"loss\": 1.531506538391, \"lr\": 0.000045442161, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/157\", \"loss\": 1.441464185715, \"lr\": 0.000045442161, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 1.542320072651, \"lr\": 0.000045442161, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.382273018360, \"lr\": 0.000045442161, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/157\", \"loss\": 1.459519445896, \"lr\": 0.000045442161, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/157\", \"loss\": 1.417156338692, \"lr\": 0.000045442161, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 1.546746015549, \"lr\": 0.000045442161, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/157\", \"loss\": 1.472426354885, \"lr\": 0.000045442161, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.566390752792, \"lr\": 0.000045442161, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/157\", \"loss\": 1.447055995464, \"lr\": 0.000045442161, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 1.526812970638, \"lr\": 0.000045442161, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/157\", \"loss\": 1.508037745953, \"lr\": 0.000045442161, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/157\", \"loss\": 1.467965006828, \"lr\": 0.000045442161, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.425934255123, \"lr\": 0.000045442161, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.480379730415, \"lr\": 0.000045442161, \"top1_err\": 54.820000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 49.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 51.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 50.299999237061, \"top1_err\": 50.299999237061}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/157\", \"loss\": 1.165298700333, \"lr\": 0.000045442161, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/157\", \"loss\": 1.153489351273, \"lr\": 0.000045442161, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/157\", \"loss\": 1.241272449493, \"lr\": 0.000045442161, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 1.191273450851, \"lr\": 0.000045442161, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 1.219758391380, \"lr\": 0.000045442161, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/157\", \"loss\": 1.223364233971, \"lr\": 0.000045442161, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/157\", \"loss\": 1.239172339439, \"lr\": 0.000045442161, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 1.366630375385, \"lr\": 0.000045442161, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/157\", \"loss\": 1.298816323280, \"lr\": 0.000045442161, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 1.150681853294, \"lr\": 0.000045442161, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/157\", \"loss\": 1.256046831608, \"lr\": 0.000045442161, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 1.301492810249, \"lr\": 0.000045442161, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/157\", \"loss\": 1.273676693439, \"lr\": 0.000045442161, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/157\", \"loss\": 1.261212587357, \"lr\": 0.000045442161, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 1.382664918900, \"lr\": 0.000045442161, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.256623399544, \"lr\": 0.000045442161, \"top1_err\": 45.980000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 46.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 47.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 46.740001220703, \"top1_err\": 46.740001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/157\", \"loss\": 1.113619565964, \"lr\": 0.000045442161, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/157\", \"loss\": 1.038960516453, \"lr\": 0.000045442161, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/157\", \"loss\": 1.005493491888, \"lr\": 0.000045442161, \"top1_err\": 35.156250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 1.015813767910, \"lr\": 0.000045442161, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 0.937493324280, \"lr\": 0.000045442161, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/157\", \"loss\": 0.961691766977, \"lr\": 0.000045442161, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/157\", \"loss\": 1.064823210239, \"lr\": 0.000045442161, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 1.066153883934, \"lr\": 0.000045442161, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/157\", \"loss\": 1.056636929512, \"lr\": 0.000045442161, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 1.085551440716, \"lr\": 0.000045442161, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/157\", \"loss\": 1.127800941467, \"lr\": 0.000045442161, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 1.139027714729, \"lr\": 0.000045442161, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/157\", \"loss\": 1.086798489094, \"lr\": 0.000045442161, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/157\", \"loss\": 1.038065373898, \"lr\": 0.000045442161, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 0.987815052271, \"lr\": 0.000045442161, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.060906751633, \"lr\": 0.000045442161, \"top1_err\": 38.200000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 47.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 47.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 46.740001220703, \"top1_err\": 47.860000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_53.25999877929687_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_53.25999877929687_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 00:38:54,883]\u001b[0m Trial 3 finished with value: 53.25999877929687 and parameters: {'learning_rate': 4.5442160786908184e-05, 'weight_decay': 1.6971924806547293e-07, 'batch_size': 64, 'optimizer': 'ADAM'}. Best is trial 2 with value: 56.699998931884764.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.0016363089750560495\n",
      "Weight Decay : 2.69569006557824e-08\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0016363089750560495\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.69569006557824e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.19999984741211_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 40\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/40\", \"loss\": 2.296259522438, \"lr\": 0.001636308975, \"top1_err\": 88.867187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/40\", \"loss\": 2.268179655075, \"lr\": 0.001636308975, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/40\", \"loss\": 2.266532421112, \"lr\": 0.001636308975, \"top1_err\": 84.570312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/40\", \"loss\": 2.240391850471, \"lr\": 0.001636308975, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.268141331482, \"lr\": 0.001636308975, \"top1_err\": 86.110000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 89.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 90.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.560000000000, \"top1_err\": 89.560000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/40\", \"loss\": 2.218236327171, \"lr\": 0.001636308975, \"top1_err\": 84.570312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/40\", \"loss\": 2.169761776924, \"lr\": 0.001636308975, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/40\", \"loss\": 2.109730720520, \"lr\": 0.001636308975, \"top1_err\": 80.664062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/40\", \"loss\": 2.078815340996, \"lr\": 0.001636308975, \"top1_err\": 79.882812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.147293704987, \"lr\": 0.001636308975, \"top1_err\": 81.320000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 74.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 76.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 74.500000305176, \"top1_err\": 74.500000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/40\", \"loss\": 2.051800608635, \"lr\": 0.001636308975, \"top1_err\": 78.320312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/40\", \"loss\": 1.993973314762, \"lr\": 0.001636308975, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/40\", \"loss\": 1.974652051926, \"lr\": 0.001636308975, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/40\", \"loss\": 1.932787895203, \"lr\": 0.001636308975, \"top1_err\": 74.804687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.993993636703, \"lr\": 0.001636308975, \"top1_err\": 76.290000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 70.000007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 69.020001220703, \"top1_err\": 69.020001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/40\", \"loss\": 1.887977957726, \"lr\": 0.001636308975, \"top1_err\": 72.070312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/40\", \"loss\": 1.870482444763, \"lr\": 0.001636308975, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/40\", \"loss\": 1.842941105366, \"lr\": 0.001636308975, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/40\", \"loss\": 1.828877329826, \"lr\": 0.001636308975, \"top1_err\": 69.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.863270534325, \"lr\": 0.001636308975, \"top1_err\": 71.620000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 65.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 63.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 64.620000305176, \"top1_err\": 64.620000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/40\", \"loss\": 1.775365352631, \"lr\": 0.001636308975, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/40\", \"loss\": 1.743262827396, \"lr\": 0.001636308975, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/40\", \"loss\": 1.773821055889, \"lr\": 0.001636308975, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/40\", \"loss\": 1.758190333843, \"lr\": 0.001636308975, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.766226629829, \"lr\": 0.001636308975, \"top1_err\": 67.910000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 65.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 63.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 64.400001525879, \"top1_err\": 64.400001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_35.599998474121094_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_35.599998474121094_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:39:46,050]\u001b[0m Trial 4 finished with value: 35.599998474121094 and parameters: {'learning_rate': 0.0016363089750560495, 'weight_decay': 2.69569006557824e-08, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 2 with value: 56.699998931884764.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 753.5641937255859 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 56.699998931884764\n",
      "  Params: \n",
      "    learning_rate: 0.0004996657652096068\n",
      "    weight_decay: 2.3691531563099294e-05\n",
      "    batch_size: 8\n",
      "    optimizer: SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_4uqg0dhi.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform uncertainty sampling through subprocess\n",
      "len(uSetLoader): 4375\n",
      "uSet Activations: 100%|████████████████████| 4375/4375 [00:19<00:00, 230.26it/s]\n",
      "u_ranks.shape: (35000,)\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  32500\n",
      "len(lSEt):  10000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 12500 and len(uSet): 32500\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  2500\n",
      "len(uSet):  32500\n",
      "len(lSet):  12500\n",
      "For uncertainty sampling, activeSet accuracy:  24.76\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 43.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 43.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 45.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 43.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 44.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 43.540001296997, \"top1_err\": 43.540001296997}\n",
      "Test Accuracy: 56.460\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:uncertainty;Seed:1]Test accuracy on cifar10 using 30.0% of data is 56.45999870300293\n",
      "\n",
      "Extracted Test Accuracy from subproces: 56.45999870300293\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_yj_7dnoj.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 00:42:43,198]\u001b[0m A new study created in memory with name: no-name-47e426c9-1f3b-4a4c-ac71-236908b6b005\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 2.1623953627688758e-05\n",
      "Weight Decay : 6.831537480127755e-07\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 2.1623953627688758e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 6.831537480127755e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 12500, uSet:32500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 49\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/49\", \"loss\": 2.305411338806, \"lr\": 0.000021623954, \"top1_err\": 89.257812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/49\", \"loss\": 2.305034041405, \"lr\": 0.000021623954, \"top1_err\": 88.476562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/49\", \"loss\": 2.300451636314, \"lr\": 0.000021623954, \"top1_err\": 88.476562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/49\", \"loss\": 2.287528872490, \"lr\": 0.000021623954, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.299646710052, \"lr\": 0.000021623954, \"top1_err\": 88.223999995117}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 90.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 91.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 90.140000000000, \"top1_err\": 90.140000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/49\", \"loss\": 2.300007939339, \"lr\": 0.000021623954, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/49\", \"loss\": 2.289186120033, \"lr\": 0.000021623954, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/49\", \"loss\": 2.288384437561, \"lr\": 0.000021623954, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/49\", \"loss\": 2.283080339432, \"lr\": 0.000021623954, \"top1_err\": 87.695312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.289110814056, \"lr\": 0.000021623954, \"top1_err\": 87.151999951172}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 91.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 89.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 90.140000000000, \"top1_err\": 90.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/49\", \"loss\": 2.278875470161, \"lr\": 0.000021623954, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/49\", \"loss\": 2.279870867729, \"lr\": 0.000021623954, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/49\", \"loss\": 2.285943627357, \"lr\": 0.000021623954, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/49\", \"loss\": 2.283226132393, \"lr\": 0.000021623954, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.283659820023, \"lr\": 0.000021623954, \"top1_err\": 86.832000036621}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 89.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 90.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 89.980000000000, \"top1_err\": 89.980000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/49\", \"loss\": 2.272620558739, \"lr\": 0.000021623954, \"top1_err\": 85.351562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/49\", \"loss\": 2.283150911331, \"lr\": 0.000021623954, \"top1_err\": 84.960937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/49\", \"loss\": 2.281083822250, \"lr\": 0.000021623954, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/49\", \"loss\": 2.279705047607, \"lr\": 0.000021623954, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.278545564499, \"lr\": 0.000021623954, \"top1_err\": 86.335999995117}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 88.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 89.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 89.540000000000, \"top1_err\": 89.540000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/49\", \"loss\": 2.285176634789, \"lr\": 0.000021623954, \"top1_err\": 84.960937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/49\", \"loss\": 2.267303705215, \"lr\": 0.000021623954, \"top1_err\": 87.695312500000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/49\", \"loss\": 2.275945305824, \"lr\": 0.000021623954, \"top1_err\": 86.523437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/49\", \"loss\": 2.281986594200, \"lr\": 0.000021623954, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.278757399673, \"lr\": 0.000021623954, \"top1_err\": 86.504000017090}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 87.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 89.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 89.360000000000, \"top1_err\": 89.360000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_10.64_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_10.64_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:43:54,564]\u001b[0m Trial 0 finished with value: 10.64 and parameters: {'learning_rate': 2.1623953627688758e-05, 'weight_decay': 6.831537480127755e-07, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 0 with value: 10.64.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.0001344031838522584\n",
      "Weight Decay : 5.044856083270199e-07\n",
      "Batch Size   : 8\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0001344031838522584\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 5.044856083270199e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 12500, uSet:32500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 1563\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/1563\", \"loss\": 2.288081884384, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/1563\", \"loss\": 2.325425624847, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/1563\", \"loss\": 2.300349712372, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/1563\", \"loss\": 2.305788993835, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/1563\", \"loss\": 2.300387024879, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/1563\", \"loss\": 2.281859040260, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/1563\", \"loss\": 2.305314064026, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/1563\", \"loss\": 2.295088052750, \"lr\": 0.000134403184, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/1563\", \"loss\": 2.308277487755, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/1563\", \"loss\": 2.245318174362, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/1563\", \"loss\": 2.229924917221, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/1563\", \"loss\": 2.258424162865, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/1563\", \"loss\": 2.260994434357, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/1563\", \"loss\": 2.392315149307, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/1563\", \"loss\": 2.252919554710, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/1563\", \"loss\": 2.316506266594, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/1563\", \"loss\": 2.244764089584, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/1563\", \"loss\": 2.262023091316, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/1563\", \"loss\": 2.263922095299, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/1563\", \"loss\": 2.333457589149, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/1563\", \"loss\": 2.270123720169, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/1563\", \"loss\": 2.195262074471, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/1563\", \"loss\": 2.266386508942, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/1563\", \"loss\": 2.298316836357, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/1563\", \"loss\": 2.311316013336, \"lr\": 0.000134403184, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/1563\", \"loss\": 2.242551326752, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/1563\", \"loss\": 2.233341693878, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/1563\", \"loss\": 2.184723973274, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/1563\", \"loss\": 2.228456020355, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/1563\", \"loss\": 2.173510074615, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/1563\", \"loss\": 2.273584127426, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/1563\", \"loss\": 2.220846772194, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/1563\", \"loss\": 2.259271502495, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/1563\", \"loss\": 2.210764169693, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/1563\", \"loss\": 2.161253690720, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/1563\", \"loss\": 2.244036674500, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/1563\", \"loss\": 2.208631873131, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/1563\", \"loss\": 2.290823459625, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/1563\", \"loss\": 2.255211114883, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/1563\", \"loss\": 2.223274827003, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/1563\", \"loss\": 2.176802396774, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/1563\", \"loss\": 2.181688070297, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/1563\", \"loss\": 2.176066398621, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/1563\", \"loss\": 2.275601029396, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/1563\", \"loss\": 2.146565914154, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/1563\", \"loss\": 2.245841264725, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/1563\", \"loss\": 2.284994959831, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/1563\", \"loss\": 2.259988903999, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/1563\", \"loss\": 2.317761182785, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/1563\", \"loss\": 2.186116814613, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/1563\", \"loss\": 2.182531476021, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/1563\", \"loss\": 2.222731471062, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/1563\", \"loss\": 2.192679524422, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/1563\", \"loss\": 2.205405712128, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/1563\", \"loss\": 2.193053126335, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/1563\", \"loss\": 2.219867229462, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/1563\", \"loss\": 2.244484901428, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/1563\", \"loss\": 2.243027448654, \"lr\": 0.000134403184, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/1563\", \"loss\": 2.201108932495, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/1563\", \"loss\": 2.200997233391, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/1563\", \"loss\": 2.129670381546, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/1563\", \"loss\": 2.076677083969, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/1563\", \"loss\": 2.144412398338, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/1563\", \"loss\": 2.258900403976, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/1563\", \"loss\": 2.146983504295, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/1563\", \"loss\": 2.218958616257, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/1563\", \"loss\": 2.297968745232, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/1563\", \"loss\": 2.204275846481, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/1563\", \"loss\": 2.164582490921, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/1563\", \"loss\": 2.161788940430, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/1563\", \"loss\": 2.168964266777, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/1563\", \"loss\": 2.179816603661, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/1563\", \"loss\": 2.197380542755, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/1563\", \"loss\": 2.157538890839, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/1563\", \"loss\": 2.126520872116, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/1563\", \"loss\": 2.006388425827, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/1563\", \"loss\": 2.165944576263, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/1563\", \"loss\": 2.261808037758, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/1563\", \"loss\": 2.138056635857, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/1563\", \"loss\": 2.311157226562, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/1563\", \"loss\": 2.083274602890, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/1563\", \"loss\": 2.118840456009, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/1563\", \"loss\": 2.033294558525, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/1563\", \"loss\": 2.067630290985, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/1563\", \"loss\": 2.196050524712, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/1563\", \"loss\": 2.086759805679, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/1563\", \"loss\": 2.090484976768, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/1563\", \"loss\": 2.178746342659, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/1563\", \"loss\": 2.181975126266, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/1563\", \"loss\": 2.070042133331, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/1563\", \"loss\": 2.138123273849, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/1563\", \"loss\": 2.149306654930, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/1563\", \"loss\": 2.146327018738, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"940/1563\", \"loss\": 2.135212302208, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"950/1563\", \"loss\": 2.131764888763, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"960/1563\", \"loss\": 2.032037854195, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"970/1563\", \"loss\": 2.070518970490, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"980/1563\", \"loss\": 2.164751529694, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"990/1563\", \"loss\": 2.081512570381, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1000/1563\", \"loss\": 2.118230223656, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1010/1563\", \"loss\": 2.147365927696, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1020/1563\", \"loss\": 2.081687331200, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1030/1563\", \"loss\": 2.088977217674, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1040/1563\", \"loss\": 2.075437784195, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1050/1563\", \"loss\": 2.158705949783, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1060/1563\", \"loss\": 2.028936147690, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1070/1563\", \"loss\": 2.074419140816, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1080/1563\", \"loss\": 1.951773822308, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1090/1563\", \"loss\": 2.183276653290, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1100/1563\", \"loss\": 2.058600425720, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1110/1563\", \"loss\": 2.066293478012, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1120/1563\", \"loss\": 2.136645913124, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1130/1563\", \"loss\": 2.121325373650, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1140/1563\", \"loss\": 2.190898180008, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1150/1563\", \"loss\": 2.135453462601, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1160/1563\", \"loss\": 2.006152749062, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1170/1563\", \"loss\": 2.028758883476, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1180/1563\", \"loss\": 2.132168412209, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1190/1563\", \"loss\": 2.044103622437, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1200/1563\", \"loss\": 2.041182756424, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1210/1563\", \"loss\": 2.030140995979, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1220/1563\", \"loss\": 2.152230381966, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1230/1563\", \"loss\": 2.047896265984, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1240/1563\", \"loss\": 2.074702382088, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1250/1563\", \"loss\": 2.098449707031, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1260/1563\", \"loss\": 2.155963420868, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1270/1563\", \"loss\": 2.037623524666, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1280/1563\", \"loss\": 1.924386560917, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1290/1563\", \"loss\": 2.038077116013, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1300/1563\", \"loss\": 2.011938393116, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1310/1563\", \"loss\": 2.191428899765, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1320/1563\", \"loss\": 1.972679674625, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1330/1563\", \"loss\": 2.085652947426, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1340/1563\", \"loss\": 2.083929300308, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1350/1563\", \"loss\": 2.087631106377, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1360/1563\", \"loss\": 2.123118281364, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1370/1563\", \"loss\": 1.967336297035, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1380/1563\", \"loss\": 2.193367600441, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1390/1563\", \"loss\": 2.141272187233, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1400/1563\", \"loss\": 2.078307509422, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1410/1563\", \"loss\": 2.105346679688, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1420/1563\", \"loss\": 2.026899576187, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1430/1563\", \"loss\": 2.083298683167, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1440/1563\", \"loss\": 2.088455796242, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1450/1563\", \"loss\": 2.119712591171, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1460/1563\", \"loss\": 2.063245177269, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1470/1563\", \"loss\": 2.170833349228, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1480/1563\", \"loss\": 1.838740825653, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1490/1563\", \"loss\": 2.034811019897, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1500/1563\", \"loss\": 2.012447059155, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1510/1563\", \"loss\": 2.038132429123, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1520/1563\", \"loss\": 2.116503357887, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1530/1563\", \"loss\": 2.054156064987, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1540/1563\", \"loss\": 1.988401412964, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1550/1563\", \"loss\": 1.976167440414, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1560/1563\", \"loss\": 1.995407283306, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.162824147186, \"lr\": 0.000134403184, \"top1_err\": 82.648000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 70.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 72.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 72.260000305176, \"top1_err\": 72.260000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/1563\", \"loss\": 2.070250630379, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/1563\", \"loss\": 1.924907088280, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/1563\", \"loss\": 2.003426015377, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/1563\", \"loss\": 2.089584231377, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/1563\", \"loss\": 1.956198811531, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/1563\", \"loss\": 2.018156051636, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/1563\", \"loss\": 2.142272830009, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/1563\", \"loss\": 2.045504093170, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/1563\", \"loss\": 2.026545524597, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/1563\", \"loss\": 2.071542620659, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/1563\", \"loss\": 2.087856650352, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/1563\", \"loss\": 1.996225476265, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/1563\", \"loss\": 1.934892356396, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/1563\", \"loss\": 1.992511808872, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/1563\", \"loss\": 1.954944610596, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/1563\", \"loss\": 2.043505549431, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/1563\", \"loss\": 1.928254485130, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/1563\", \"loss\": 2.023865342140, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/1563\", \"loss\": 2.104802131653, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/1563\", \"loss\": 1.940426945686, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/1563\", \"loss\": 2.007590770721, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/1563\", \"loss\": 1.913419365883, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/1563\", \"loss\": 1.954840719700, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/1563\", \"loss\": 2.138450026512, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/1563\", \"loss\": 1.995894849300, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/1563\", \"loss\": 1.996039927006, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/1563\", \"loss\": 1.986160278320, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/1563\", \"loss\": 2.054389238358, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/1563\", \"loss\": 1.862187206745, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/1563\", \"loss\": 1.936179280281, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/1563\", \"loss\": 1.944659292698, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/1563\", \"loss\": 1.992338240147, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/1563\", \"loss\": 2.012673974037, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/1563\", \"loss\": 1.940387248993, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/1563\", \"loss\": 1.923751175404, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/1563\", \"loss\": 2.188648581505, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/1563\", \"loss\": 2.071251034737, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/1563\", \"loss\": 1.911114394665, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/1563\", \"loss\": 1.921594023705, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/1563\", \"loss\": 2.108777642250, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/1563\", \"loss\": 1.889289319515, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/1563\", \"loss\": 2.012449026108, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/1563\", \"loss\": 2.038148403168, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/1563\", \"loss\": 2.084337592125, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/1563\", \"loss\": 1.946962296963, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/1563\", \"loss\": 2.066547751427, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/1563\", \"loss\": 1.992401957512, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/1563\", \"loss\": 1.962503671646, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/1563\", \"loss\": 2.048075199127, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/1563\", \"loss\": 2.005102157593, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/1563\", \"loss\": 1.994076550007, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/1563\", \"loss\": 2.016295075417, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/1563\", \"loss\": 1.959344267845, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/1563\", \"loss\": 1.832922697067, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/1563\", \"loss\": 2.050464689732, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/1563\", \"loss\": 2.155402183533, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/1563\", \"loss\": 1.944179415703, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/1563\", \"loss\": 1.968167662621, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/1563\", \"loss\": 1.985111534595, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/1563\", \"loss\": 2.137805461884, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/1563\", \"loss\": 1.886861443520, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/1563\", \"loss\": 2.068311095238, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/1563\", \"loss\": 1.937653541565, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/1563\", \"loss\": 1.848843812943, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/1563\", \"loss\": 2.088176608086, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/1563\", \"loss\": 1.980236172676, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/1563\", \"loss\": 2.089630007744, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/1563\", \"loss\": 2.052645564079, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/1563\", \"loss\": 1.908199071884, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/1563\", \"loss\": 1.933886229992, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/1563\", \"loss\": 2.051509261131, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/1563\", \"loss\": 2.000698626041, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/1563\", \"loss\": 2.012563765049, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/1563\", \"loss\": 2.111383080482, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/1563\", \"loss\": 1.808607697487, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/1563\", \"loss\": 1.951506018639, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/1563\", \"loss\": 1.777940928936, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/1563\", \"loss\": 2.125801920891, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/1563\", \"loss\": 1.850183665752, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/1563\", \"loss\": 1.930712521076, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/1563\", \"loss\": 1.992523849010, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/1563\", \"loss\": 1.811203479767, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/1563\", \"loss\": 1.854230463505, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/1563\", \"loss\": 1.896143376827, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/1563\", \"loss\": 1.982547044754, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/1563\", \"loss\": 1.735286235809, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/1563\", \"loss\": 1.873328506947, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/1563\", \"loss\": 1.994144558907, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/1563\", \"loss\": 1.824739038944, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/1563\", \"loss\": 1.734258174896, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/1563\", \"loss\": 2.037395954132, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/1563\", \"loss\": 2.026628851891, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/1563\", \"loss\": 1.871609032154, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"940/1563\", \"loss\": 1.941065669060, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"950/1563\", \"loss\": 2.055108547211, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"960/1563\", \"loss\": 2.012509942055, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"970/1563\", \"loss\": 1.994739949703, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"980/1563\", \"loss\": 1.969174683094, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"990/1563\", \"loss\": 1.962288200855, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1000/1563\", \"loss\": 1.926353096962, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1010/1563\", \"loss\": 1.925761401653, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1020/1563\", \"loss\": 1.954544425011, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1030/1563\", \"loss\": 1.974180757999, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1040/1563\", \"loss\": 1.912883937359, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1050/1563\", \"loss\": 2.086354255676, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1060/1563\", \"loss\": 1.901799023151, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1070/1563\", \"loss\": 1.887510418892, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1080/1563\", \"loss\": 1.883060693741, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1090/1563\", \"loss\": 1.959739744663, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1100/1563\", \"loss\": 1.956792891026, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1110/1563\", \"loss\": 1.983565986156, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1120/1563\", \"loss\": 1.959675252438, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1130/1563\", \"loss\": 1.819478452206, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1140/1563\", \"loss\": 1.996333956718, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1150/1563\", \"loss\": 2.062836647034, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1160/1563\", \"loss\": 2.121815800667, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1170/1563\", \"loss\": 1.916238665581, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1180/1563\", \"loss\": 1.769249320030, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1190/1563\", \"loss\": 1.987946987152, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1200/1563\", \"loss\": 1.903317034245, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1210/1563\", \"loss\": 1.786005437374, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1220/1563\", \"loss\": 1.970926582813, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1230/1563\", \"loss\": 2.002483308315, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1240/1563\", \"loss\": 2.000935733318, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1250/1563\", \"loss\": 1.978967845440, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1260/1563\", \"loss\": 1.963518261909, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1270/1563\", \"loss\": 2.138772964478, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1280/1563\", \"loss\": 2.029499053955, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1290/1563\", \"loss\": 1.878061771393, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1300/1563\", \"loss\": 2.005137503147, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1310/1563\", \"loss\": 1.862175285816, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1320/1563\", \"loss\": 1.972305536270, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1330/1563\", \"loss\": 1.984329760075, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1340/1563\", \"loss\": 1.955758869648, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1350/1563\", \"loss\": 2.062734365463, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1360/1563\", \"loss\": 1.850313842297, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1370/1563\", \"loss\": 1.901053309441, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1380/1563\", \"loss\": 2.012501537800, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1390/1563\", \"loss\": 1.866063356400, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1400/1563\", \"loss\": 1.885140240192, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1410/1563\", \"loss\": 1.898622572422, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1420/1563\", \"loss\": 1.894214391708, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1430/1563\", \"loss\": 2.010102868080, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1440/1563\", \"loss\": 1.908787012100, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1450/1563\", \"loss\": 1.871684074402, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1460/1563\", \"loss\": 1.933215081692, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1470/1563\", \"loss\": 1.843223452568, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1480/1563\", \"loss\": 1.937878131866, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1490/1563\", \"loss\": 1.862111032009, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1500/1563\", \"loss\": 1.910647153854, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1510/1563\", \"loss\": 2.015538811684, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1520/1563\", \"loss\": 2.016216933727, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1530/1563\", \"loss\": 1.822171866894, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1540/1563\", \"loss\": 2.096295595169, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1550/1563\", \"loss\": 1.861613869667, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1560/1563\", \"loss\": 1.957817375660, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.982460669632, \"lr\": 0.000134403184, \"top1_err\": 75.416000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 63.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 62.700000305176, \"top1_err\": 62.700000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/1563\", \"loss\": 2.135661959648, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/1563\", \"loss\": 1.853907287121, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/1563\", \"loss\": 1.873214721680, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/1563\", \"loss\": 1.932074248791, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/1563\", \"loss\": 1.836363911629, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/1563\", \"loss\": 1.812876701355, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/1563\", \"loss\": 1.979254186153, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/1563\", \"loss\": 1.973393619061, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/1563\", \"loss\": 2.032050609589, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/1563\", \"loss\": 1.871998190880, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/1563\", \"loss\": 1.862681806087, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/1563\", \"loss\": 1.971121668816, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/1563\", \"loss\": 1.947935104370, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/1563\", \"loss\": 1.870869278908, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/1563\", \"loss\": 1.935546040535, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/1563\", \"loss\": 1.926856458187, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/1563\", \"loss\": 1.908198475838, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/1563\", \"loss\": 1.863888859749, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/1563\", \"loss\": 1.844869732857, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/1563\", \"loss\": 1.755999028683, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/1563\", \"loss\": 2.056997060776, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/1563\", \"loss\": 1.835579812527, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/1563\", \"loss\": 2.083377361298, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/1563\", \"loss\": 1.872248470783, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/1563\", \"loss\": 1.897903561592, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/1563\", \"loss\": 1.892137825489, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/1563\", \"loss\": 1.979991734028, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/1563\", \"loss\": 2.036882042885, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/1563\", \"loss\": 1.809608161449, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/1563\", \"loss\": 2.014320373535, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/1563\", \"loss\": 1.956649065018, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/1563\", \"loss\": 2.036150097847, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/1563\", \"loss\": 1.773592829704, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/1563\", \"loss\": 1.760105252266, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/1563\", \"loss\": 1.917061924934, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/1563\", \"loss\": 1.999168872833, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/1563\", \"loss\": 1.863055467606, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/1563\", \"loss\": 1.937726795673, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/1563\", \"loss\": 1.943926930428, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/1563\", \"loss\": 1.739230275154, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/1563\", \"loss\": 1.971630454063, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/1563\", \"loss\": 1.786173284054, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/1563\", \"loss\": 1.738925158978, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/1563\", \"loss\": 1.772370517254, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/1563\", \"loss\": 1.961147785187, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/1563\", \"loss\": 2.012090563774, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/1563\", \"loss\": 1.899505078793, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/1563\", \"loss\": 2.002719402313, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/1563\", \"loss\": 1.701518654823, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/1563\", \"loss\": 2.036984324455, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/1563\", \"loss\": 1.794548869133, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/1563\", \"loss\": 1.828158855438, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/1563\", \"loss\": 1.860909700394, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/1563\", \"loss\": 1.812147617340, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/1563\", \"loss\": 2.034549951553, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/1563\", \"loss\": 1.780442953110, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/1563\", \"loss\": 1.784164309502, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/1563\", \"loss\": 1.910339117050, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/1563\", \"loss\": 2.076313614845, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/1563\", \"loss\": 1.854056894779, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/1563\", \"loss\": 1.735534906387, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/1563\", \"loss\": 2.035825252533, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/1563\", \"loss\": 1.780240833759, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/1563\", \"loss\": 1.853382825851, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/1563\", \"loss\": 2.058509826660, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/1563\", \"loss\": 1.791891872883, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/1563\", \"loss\": 1.964235842228, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/1563\", \"loss\": 1.891340792179, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/1563\", \"loss\": 1.751846075058, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/1563\", \"loss\": 1.882778704166, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/1563\", \"loss\": 1.873130917549, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/1563\", \"loss\": 1.825644373894, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/1563\", \"loss\": 1.932224273682, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/1563\", \"loss\": 1.738585352898, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/1563\", \"loss\": 1.806112885475, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/1563\", \"loss\": 1.908823490143, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/1563\", \"loss\": 1.942666232586, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/1563\", \"loss\": 1.688154995441, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/1563\", \"loss\": 2.054336667061, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/1563\", \"loss\": 1.855156123638, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/1563\", \"loss\": 1.838983416557, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/1563\", \"loss\": 1.930362939835, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/1563\", \"loss\": 1.992366909981, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/1563\", \"loss\": 1.820647656918, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/1563\", \"loss\": 1.753468394279, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/1563\", \"loss\": 1.827010750771, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/1563\", \"loss\": 1.855954289436, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/1563\", \"loss\": 1.846130907536, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/1563\", \"loss\": 1.948448181152, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/1563\", \"loss\": 1.715481042862, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/1563\", \"loss\": 1.903562009335, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/1563\", \"loss\": 1.943246483803, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/1563\", \"loss\": 1.974042296410, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"940/1563\", \"loss\": 1.872212707996, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"950/1563\", \"loss\": 1.935972869396, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"960/1563\", \"loss\": 1.978375375271, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"970/1563\", \"loss\": 1.711598515511, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"980/1563\", \"loss\": 1.705809235573, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"990/1563\", \"loss\": 1.859788894653, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1000/1563\", \"loss\": 1.895240783691, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1010/1563\", \"loss\": 1.869934022427, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1020/1563\", \"loss\": 1.891320586205, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1030/1563\", \"loss\": 1.847865164280, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1040/1563\", \"loss\": 1.885564744473, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1050/1563\", \"loss\": 1.910678148270, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1060/1563\", \"loss\": 1.865292489529, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1070/1563\", \"loss\": 1.726091384888, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1080/1563\", \"loss\": 1.583981573582, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1090/1563\", \"loss\": 1.941259384155, \"lr\": 0.000134403184, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1100/1563\", \"loss\": 1.992743313313, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1110/1563\", \"loss\": 1.961030602455, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1120/1563\", \"loss\": 1.901349782944, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1130/1563\", \"loss\": 1.850771784782, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1140/1563\", \"loss\": 1.822075784206, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1150/1563\", \"loss\": 1.824317395687, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1160/1563\", \"loss\": 1.920339345932, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1170/1563\", \"loss\": 1.696554839611, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1180/1563\", \"loss\": 2.018299520016, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1190/1563\", \"loss\": 1.971081495285, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1200/1563\", \"loss\": 1.646737873554, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1210/1563\", \"loss\": 1.932644844055, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1220/1563\", \"loss\": 1.871078968048, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1230/1563\", \"loss\": 1.917249202728, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1240/1563\", \"loss\": 2.052022695541, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1250/1563\", \"loss\": 1.840430498123, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1260/1563\", \"loss\": 1.765806078911, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1270/1563\", \"loss\": 1.932301163673, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1280/1563\", \"loss\": 1.690062046051, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1290/1563\", \"loss\": 1.818403542042, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1300/1563\", \"loss\": 1.861061811447, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1310/1563\", \"loss\": 1.939109325409, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1320/1563\", \"loss\": 1.933282375336, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1330/1563\", \"loss\": 1.638628721237, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1340/1563\", \"loss\": 1.817948520184, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1350/1563\", \"loss\": 1.980523288250, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1360/1563\", \"loss\": 1.811147332191, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1370/1563\", \"loss\": 2.290110826492, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1380/1563\", \"loss\": 1.731136202812, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1390/1563\", \"loss\": 1.914850234985, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1400/1563\", \"loss\": 1.833833456039, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1410/1563\", \"loss\": 1.778491318226, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1420/1563\", \"loss\": 1.909819543362, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1430/1563\", \"loss\": 1.761124670506, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1440/1563\", \"loss\": 1.910415351391, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1450/1563\", \"loss\": 1.743812203407, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1460/1563\", \"loss\": 1.870133817196, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1470/1563\", \"loss\": 1.844397962093, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1480/1563\", \"loss\": 1.988862812519, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1490/1563\", \"loss\": 2.003418087959, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1500/1563\", \"loss\": 1.825636923313, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1510/1563\", \"loss\": 1.843195438385, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1520/1563\", \"loss\": 1.806703269482, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1530/1563\", \"loss\": 1.860133171082, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1540/1563\", \"loss\": 1.954460382462, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1550/1563\", \"loss\": 1.802437901497, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1560/1563\", \"loss\": 1.889286696911, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.888034547195, \"lr\": 0.000134403184, \"top1_err\": 71.440000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 53.499996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 55.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 55.160000305176, \"top1_err\": 55.160000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/1563\", \"loss\": 1.756578803062, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/1563\", \"loss\": 1.649815380573, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/1563\", \"loss\": 1.894796729088, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/1563\", \"loss\": 1.723164379597, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/1563\", \"loss\": 1.770807981491, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/1563\", \"loss\": 1.796513259411, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/1563\", \"loss\": 2.004566431046, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/1563\", \"loss\": 1.635537981987, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/1563\", \"loss\": 1.757142126560, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/1563\", \"loss\": 1.629325807095, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/1563\", \"loss\": 1.631493985653, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/1563\", \"loss\": 1.762516736984, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/1563\", \"loss\": 1.960099697113, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/1563\", \"loss\": 1.848164260387, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/1563\", \"loss\": 1.805544078350, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/1563\", \"loss\": 1.832580208778, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/1563\", \"loss\": 1.930068671703, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/1563\", \"loss\": 1.808754742146, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/1563\", \"loss\": 1.680068731308, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/1563\", \"loss\": 1.940749108791, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/1563\", \"loss\": 1.665877759457, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/1563\", \"loss\": 1.825127601624, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/1563\", \"loss\": 1.940250813961, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/1563\", \"loss\": 1.734360814095, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/1563\", \"loss\": 1.836176633835, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/1563\", \"loss\": 1.807321071625, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/1563\", \"loss\": 1.830168783665, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/1563\", \"loss\": 1.886136651039, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/1563\", \"loss\": 1.732693016529, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/1563\", \"loss\": 1.980436384678, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/1563\", \"loss\": 1.743399024010, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/1563\", \"loss\": 1.659309387207, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/1563\", \"loss\": 1.687745749950, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/1563\", \"loss\": 1.989110589027, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/1563\", \"loss\": 1.983337879181, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/1563\", \"loss\": 1.715458154678, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/1563\", \"loss\": 1.701680123806, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/1563\", \"loss\": 1.790521919727, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/1563\", \"loss\": 1.449796617031, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/1563\", \"loss\": 1.849471986294, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/1563\", \"loss\": 2.071282148361, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/1563\", \"loss\": 1.825162053108, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/1563\", \"loss\": 2.023518800735, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/1563\", \"loss\": 1.762063562870, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/1563\", \"loss\": 1.863988041878, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/1563\", \"loss\": 1.962215721607, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/1563\", \"loss\": 2.037898302078, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/1563\", \"loss\": 1.953984260559, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/1563\", \"loss\": 1.859817743301, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/1563\", \"loss\": 1.677122712135, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/1563\", \"loss\": 1.731833815575, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/1563\", \"loss\": 1.763321280479, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/1563\", \"loss\": 1.864798307419, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/1563\", \"loss\": 1.787687361240, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/1563\", \"loss\": 1.663297057152, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/1563\", \"loss\": 1.817772448063, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/1563\", \"loss\": 1.586480021477, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/1563\", \"loss\": 1.714508414268, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/1563\", \"loss\": 1.870880484581, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/1563\", \"loss\": 1.736025750637, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/1563\", \"loss\": 1.742665827274, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/1563\", \"loss\": 1.863639771938, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/1563\", \"loss\": 1.831516861916, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/1563\", \"loss\": 1.593940377235, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/1563\", \"loss\": 1.635984241962, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/1563\", \"loss\": 1.758170783520, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/1563\", \"loss\": 1.803901493549, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/1563\", \"loss\": 1.659735560417, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/1563\", \"loss\": 1.800720036030, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/1563\", \"loss\": 1.797456502914, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/1563\", \"loss\": 1.869932472706, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/1563\", \"loss\": 1.742304921150, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/1563\", \"loss\": 1.860944390297, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/1563\", \"loss\": 1.835191726685, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/1563\", \"loss\": 1.828121304512, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/1563\", \"loss\": 1.893578350544, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/1563\", \"loss\": 1.757808506489, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/1563\", \"loss\": 1.608082950115, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/1563\", \"loss\": 1.898237884045, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/1563\", \"loss\": 1.656454026699, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/1563\", \"loss\": 1.854200363159, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/1563\", \"loss\": 1.616504371166, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/1563\", \"loss\": 1.805470943451, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/1563\", \"loss\": 1.892364919186, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/1563\", \"loss\": 1.792455375195, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/1563\", \"loss\": 1.851611256599, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/1563\", \"loss\": 1.950741291046, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/1563\", \"loss\": 1.730390906334, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/1563\", \"loss\": 1.898012697697, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/1563\", \"loss\": 1.681638360023, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/1563\", \"loss\": 1.851767957211, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/1563\", \"loss\": 1.890176951885, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/1563\", \"loss\": 1.824813246727, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"940/1563\", \"loss\": 1.937212467194, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"950/1563\", \"loss\": 1.710259139538, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"960/1563\", \"loss\": 1.733127593994, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"970/1563\", \"loss\": 1.808477342129, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"980/1563\", \"loss\": 1.902905285358, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"990/1563\", \"loss\": 1.801484286785, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1000/1563\", \"loss\": 1.759460508823, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1010/1563\", \"loss\": 1.764347612858, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1020/1563\", \"loss\": 1.978457570076, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1030/1563\", \"loss\": 1.866087198257, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1040/1563\", \"loss\": 1.763554334641, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1050/1563\", \"loss\": 1.764046251774, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1060/1563\", \"loss\": 1.735045313835, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1070/1563\", \"loss\": 1.944700837135, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1080/1563\", \"loss\": 1.614044606686, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1090/1563\", \"loss\": 1.718506038189, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1100/1563\", \"loss\": 1.792795956135, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1110/1563\", \"loss\": 1.793776810169, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1120/1563\", \"loss\": 1.828408122063, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1130/1563\", \"loss\": 1.795539617538, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1140/1563\", \"loss\": 1.905378580093, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1150/1563\", \"loss\": 1.678635716438, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1160/1563\", \"loss\": 1.724722325802, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1170/1563\", \"loss\": 1.715214848518, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1180/1563\", \"loss\": 1.778225064278, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1190/1563\", \"loss\": 1.632396697998, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1200/1563\", \"loss\": 1.785374104977, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1210/1563\", \"loss\": 1.757203102112, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1220/1563\", \"loss\": 1.738915622234, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1230/1563\", \"loss\": 1.487354338169, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1240/1563\", \"loss\": 1.743870556355, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1250/1563\", \"loss\": 1.619976639748, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1260/1563\", \"loss\": 2.095131516457, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1270/1563\", \"loss\": 1.713275074959, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1280/1563\", \"loss\": 1.857173144817, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1290/1563\", \"loss\": 1.717839896679, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1300/1563\", \"loss\": 1.608471572399, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1310/1563\", \"loss\": 1.861656248569, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1320/1563\", \"loss\": 1.876049280167, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1330/1563\", \"loss\": 1.782285809517, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1340/1563\", \"loss\": 1.804494082928, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1350/1563\", \"loss\": 1.928754746914, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1360/1563\", \"loss\": 1.626326620579, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1370/1563\", \"loss\": 1.834865391254, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1380/1563\", \"loss\": 1.520991444588, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1390/1563\", \"loss\": 1.998612940311, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1400/1563\", \"loss\": 1.721991717815, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1410/1563\", \"loss\": 1.732953846455, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1420/1563\", \"loss\": 1.886211693287, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1430/1563\", \"loss\": 2.022786736488, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1440/1563\", \"loss\": 1.660322606564, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1450/1563\", \"loss\": 1.803682148457, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1460/1563\", \"loss\": 1.829515159130, \"lr\": 0.000134403184, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1470/1563\", \"loss\": 1.671596169472, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1480/1563\", \"loss\": 1.675620973110, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1490/1563\", \"loss\": 1.831505775452, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1500/1563\", \"loss\": 1.823439419270, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1510/1563\", \"loss\": 1.833145916462, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1520/1563\", \"loss\": 1.756552159786, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1530/1563\", \"loss\": 1.655203044415, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1540/1563\", \"loss\": 1.793933033943, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1550/1563\", \"loss\": 1.575253963470, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1560/1563\", \"loss\": 1.887646377087, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.800705787086, \"lr\": 0.000134403184, \"top1_err\": 67.192000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 50.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 51.260000152588, \"top1_err\": 51.260000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/1563\", \"loss\": 1.577120423317, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/1563\", \"loss\": 1.578214108944, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/1563\", \"loss\": 1.571286141872, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/1563\", \"loss\": 1.555482745171, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/1563\", \"loss\": 1.832033813000, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/1563\", \"loss\": 1.745314061642, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/1563\", \"loss\": 1.767909049988, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/1563\", \"loss\": 1.740900337696, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/1563\", \"loss\": 1.601584076881, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/1563\", \"loss\": 1.683785319328, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/1563\", \"loss\": 1.688555777073, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/1563\", \"loss\": 1.781294286251, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/1563\", \"loss\": 1.923910558224, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/1563\", \"loss\": 1.916609704494, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/1563\", \"loss\": 1.829874336720, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/1563\", \"loss\": 1.729165375233, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/1563\", \"loss\": 1.608573377132, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/1563\", \"loss\": 1.848213195801, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/1563\", \"loss\": 1.579300403595, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/1563\", \"loss\": 1.617875158787, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/1563\", \"loss\": 1.501629769802, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/1563\", \"loss\": 1.770438075066, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/1563\", \"loss\": 1.734000980854, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/1563\", \"loss\": 1.671610891819, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/1563\", \"loss\": 1.660589098930, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/1563\", \"loss\": 1.544383764267, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/1563\", \"loss\": 1.759217798710, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/1563\", \"loss\": 1.671838879585, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/1563\", \"loss\": 1.612965047359, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/1563\", \"loss\": 1.681953847408, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/1563\", \"loss\": 1.703706145287, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/1563\", \"loss\": 1.638351857662, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/1563\", \"loss\": 1.620427608490, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/1563\", \"loss\": 1.732458055019, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/1563\", \"loss\": 1.642317771912, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/1563\", \"loss\": 1.600212335587, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/1563\", \"loss\": 1.734728276730, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/1563\", \"loss\": 1.863640725613, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/1563\", \"loss\": 1.649250566959, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/1563\", \"loss\": 1.529287159443, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/1563\", \"loss\": 1.592166066170, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/1563\", \"loss\": 1.565410077572, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/1563\", \"loss\": 1.706848621368, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/1563\", \"loss\": 1.620830118656, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/1563\", \"loss\": 1.730839967728, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/1563\", \"loss\": 1.828723967075, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/1563\", \"loss\": 1.787979841232, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/1563\", \"loss\": 1.710872054100, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/1563\", \"loss\": 1.783352971077, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/1563\", \"loss\": 1.638335049152, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/1563\", \"loss\": 1.561396360397, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/1563\", \"loss\": 1.616961002350, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/1563\", \"loss\": 1.800122439861, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/1563\", \"loss\": 1.748446106911, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/1563\", \"loss\": 1.869375824928, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/1563\", \"loss\": 1.508494198322, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/1563\", \"loss\": 1.631089389324, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/1563\", \"loss\": 1.826607763767, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/1563\", \"loss\": 1.627265870571, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/1563\", \"loss\": 1.545558691025, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/1563\", \"loss\": 1.763756334782, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/1563\", \"loss\": 1.823441743851, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/1563\", \"loss\": 1.676417708397, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/1563\", \"loss\": 1.543807744980, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/1563\", \"loss\": 1.640458405018, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/1563\", \"loss\": 1.718025445938, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/1563\", \"loss\": 1.640344738960, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/1563\", \"loss\": 1.866222739220, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/1563\", \"loss\": 1.512734115124, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/1563\", \"loss\": 1.541866362095, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/1563\", \"loss\": 1.853414773941, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/1563\", \"loss\": 1.747408509254, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/1563\", \"loss\": 1.543636798859, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/1563\", \"loss\": 1.797076106071, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/1563\", \"loss\": 1.689927995205, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/1563\", \"loss\": 1.632204949856, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/1563\", \"loss\": 1.692015826702, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/1563\", \"loss\": 1.716276288033, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/1563\", \"loss\": 1.673579216003, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/1563\", \"loss\": 1.414562642574, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/1563\", \"loss\": 1.682218551636, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/1563\", \"loss\": 1.494231343269, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/1563\", \"loss\": 1.681901872158, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/1563\", \"loss\": 1.598057627678, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/1563\", \"loss\": 1.853653788567, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/1563\", \"loss\": 1.612733781338, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/1563\", \"loss\": 1.762039840221, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/1563\", \"loss\": 1.613532960415, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/1563\", \"loss\": 1.662312626839, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/1563\", \"loss\": 1.521011650562, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/1563\", \"loss\": 1.661263823509, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/1563\", \"loss\": 1.534077107906, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/1563\", \"loss\": 1.899983108044, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"940/1563\", \"loss\": 1.586253643036, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"950/1563\", \"loss\": 1.612257301807, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"960/1563\", \"loss\": 1.722262978554, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"970/1563\", \"loss\": 1.688314795494, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"980/1563\", \"loss\": 1.705502629280, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"990/1563\", \"loss\": 1.665758848190, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1000/1563\", \"loss\": 1.663469612598, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1010/1563\", \"loss\": 1.466539025307, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1020/1563\", \"loss\": 1.586644709110, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1030/1563\", \"loss\": 1.842026710510, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1040/1563\", \"loss\": 1.642270088196, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1050/1563\", \"loss\": 1.737397074699, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1060/1563\", \"loss\": 1.706833541393, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1070/1563\", \"loss\": 1.495017826557, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1080/1563\", \"loss\": 1.688107728958, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1090/1563\", \"loss\": 1.647306442261, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1100/1563\", \"loss\": 1.807925999165, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1110/1563\", \"loss\": 1.688597381115, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1120/1563\", \"loss\": 1.982006311417, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1130/1563\", \"loss\": 1.545556366444, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1140/1563\", \"loss\": 1.647175788879, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1150/1563\", \"loss\": 1.758971393108, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1160/1563\", \"loss\": 1.632600367069, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1170/1563\", \"loss\": 1.643612265587, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1180/1563\", \"loss\": 1.914200901985, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1190/1563\", \"loss\": 1.697962760925, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1200/1563\", \"loss\": 1.830146610737, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1210/1563\", \"loss\": 1.609389662743, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1220/1563\", \"loss\": 1.590561628342, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1230/1563\", \"loss\": 1.753029704094, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1240/1563\", \"loss\": 1.525547742844, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1250/1563\", \"loss\": 1.807342290878, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1260/1563\", \"loss\": 1.374638020992, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1270/1563\", \"loss\": 1.655097723007, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1280/1563\", \"loss\": 1.613769292831, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1290/1563\", \"loss\": 1.623140752316, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1300/1563\", \"loss\": 1.832838058472, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1310/1563\", \"loss\": 1.552241981030, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1320/1563\", \"loss\": 1.415519475937, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1330/1563\", \"loss\": 1.845933616161, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1340/1563\", \"loss\": 1.602476954460, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1350/1563\", \"loss\": 1.457647323608, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1360/1563\", \"loss\": 1.963763535023, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1370/1563\", \"loss\": 1.864315569401, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1380/1563\", \"loss\": 1.662742912769, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1390/1563\", \"loss\": 1.626384556293, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1400/1563\", \"loss\": 1.686203718185, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1410/1563\", \"loss\": 1.724718630314, \"lr\": 0.000134403184, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1420/1563\", \"loss\": 1.575132608414, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1430/1563\", \"loss\": 1.830738127232, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1440/1563\", \"loss\": 1.630865514278, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1450/1563\", \"loss\": 1.517771601677, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1460/1563\", \"loss\": 1.838080883026, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1470/1563\", \"loss\": 1.662760496140, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1480/1563\", \"loss\": 1.865379035473, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1490/1563\", \"loss\": 1.643750905991, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1500/1563\", \"loss\": 1.673375368118, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1510/1563\", \"loss\": 1.612721264362, \"lr\": 0.000134403184, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1520/1563\", \"loss\": 1.677292227745, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1530/1563\", \"loss\": 1.791123628616, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1540/1563\", \"loss\": 1.820066094398, \"lr\": 0.000134403184, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1550/1563\", \"loss\": 1.446231365204, \"lr\": 0.000134403184, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1560/1563\", \"loss\": 1.454557299614, \"lr\": 0.000134403184, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.703216798706, \"lr\": 0.000134403184, \"top1_err\": 62.656000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 49.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 50.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 49.360000000000, \"top1_err\": 49.360000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_50.64_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_50.64_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:56:24,013]\u001b[0m Trial 1 finished with value: 50.64 and parameters: {'learning_rate': 0.0001344031838522584, 'weight_decay': 5.044856083270199e-07, 'batch_size': 8, 'optimizer': 'SGD'}. Best is trial 1 with value: 50.64.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 1.316942810283221e-05\n",
      "Weight Decay : 3.6984186983708617e-07\n",
      "Batch Size   : 128\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1.316942810283221e-05\n",
      "    weight_decay: 3.6984186983708617e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 12500, uSet:32500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 98\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/98\", \"loss\": 2.283343315125, \"lr\": 0.000013169428, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/98\", \"loss\": 2.254545211792, \"lr\": 0.000013169428, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/98\", \"loss\": 2.240556597710, \"lr\": 0.000013169428, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/98\", \"loss\": 2.240578413010, \"lr\": 0.000013169428, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/98\", \"loss\": 2.223954558372, \"lr\": 0.000013169428, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/98\", \"loss\": 2.196121931076, \"lr\": 0.000013169428, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/98\", \"loss\": 2.167409777641, \"lr\": 0.000013169428, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/98\", \"loss\": 2.161536335945, \"lr\": 0.000013169428, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/98\", \"loss\": 2.145669102669, \"lr\": 0.000013169428, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.205390467682, \"lr\": 0.000013169428, \"top1_err\": 83.407999995117}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 78.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 78.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 77.620000000000, \"top1_err\": 77.620000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/98\", \"loss\": 2.078516840935, \"lr\": 0.000013169428, \"top1_err\": 79.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/98\", \"loss\": 2.067752838135, \"lr\": 0.000013169428, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/98\", \"loss\": 2.052408814430, \"lr\": 0.000013169428, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/98\", \"loss\": 2.023028969765, \"lr\": 0.000013169428, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/98\", \"loss\": 2.005733132362, \"lr\": 0.000013169428, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/98\", \"loss\": 1.961611568928, \"lr\": 0.000013169428, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/98\", \"loss\": 1.966329693794, \"lr\": 0.000013169428, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/98\", \"loss\": 1.951716721058, \"lr\": 0.000013169428, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/98\", \"loss\": 1.947195291519, \"lr\": 0.000013169428, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.003244714622, \"lr\": 0.000013169428, \"top1_err\": 76.575999982910}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 63.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 66.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 64.860000457764, \"top1_err\": 64.860000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/98\", \"loss\": 1.867932617664, \"lr\": 0.000013169428, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/98\", \"loss\": 1.831346511841, \"lr\": 0.000013169428, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/98\", \"loss\": 1.804778695107, \"lr\": 0.000013169428, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/98\", \"loss\": 1.817481994629, \"lr\": 0.000013169428, \"top1_err\": 69.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/98\", \"loss\": 1.811625242233, \"lr\": 0.000013169428, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/98\", \"loss\": 1.840741932392, \"lr\": 0.000013169428, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/98\", \"loss\": 1.779292821884, \"lr\": 0.000013169428, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/98\", \"loss\": 1.809228837490, \"lr\": 0.000013169428, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/98\", \"loss\": 1.741897881031, \"lr\": 0.000013169428, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.812874215469, \"lr\": 0.000013169428, \"top1_err\": 68.839999982910}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 59.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 59.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 59.520001525879, \"top1_err\": 59.520001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/98\", \"loss\": 1.665372788906, \"lr\": 0.000013169428, \"top1_err\": 59.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/98\", \"loss\": 1.672192692757, \"lr\": 0.000013169428, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/98\", \"loss\": 1.676498770714, \"lr\": 0.000013169428, \"top1_err\": 60.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/98\", \"loss\": 1.627230703831, \"lr\": 0.000013169428, \"top1_err\": 59.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/98\", \"loss\": 1.608432948589, \"lr\": 0.000013169428, \"top1_err\": 57.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/98\", \"loss\": 1.668015241623, \"lr\": 0.000013169428, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/98\", \"loss\": 1.604458928108, \"lr\": 0.000013169428, \"top1_err\": 56.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/98\", \"loss\": 1.579175055027, \"lr\": 0.000013169428, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/98\", \"loss\": 1.621076643467, \"lr\": 0.000013169428, \"top1_err\": 58.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.637373417587, \"lr\": 0.000013169428, \"top1_err\": 60.351999991455}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 56.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 53.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 55.280001525879, \"top1_err\": 55.280001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/98\", \"loss\": 1.483294010162, \"lr\": 0.000013169428, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/98\", \"loss\": 1.488481342793, \"lr\": 0.000013169428, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/98\", \"loss\": 1.463316857815, \"lr\": 0.000013169428, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/98\", \"loss\": 1.484108448029, \"lr\": 0.000013169428, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/98\", \"loss\": 1.407206475735, \"lr\": 0.000013169428, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/98\", \"loss\": 1.426352381706, \"lr\": 0.000013169428, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/98\", \"loss\": 1.479798913002, \"lr\": 0.000013169428, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/98\", \"loss\": 1.476264476776, \"lr\": 0.000013169428, \"top1_err\": 52.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/98\", \"loss\": 1.461209833622, \"lr\": 0.000013169428, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.456948374023, \"lr\": 0.000013169428, \"top1_err\": 53.080000001221}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 51.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 53.249996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 52.220000457764, \"top1_err\": 52.220000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_47.779999542236325_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_47.779999542236325_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:57:49,760]\u001b[0m Trial 2 finished with value: 47.779999542236325 and parameters: {'learning_rate': 1.316942810283221e-05, 'weight_decay': 3.6984186983708617e-07, 'batch_size': 128, 'optimizer': 'ADAM'}. Best is trial 1 with value: 50.64.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.0006798650261761506\n",
      "Weight Decay : 1.1951638482121132e-07\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0006798650261761506\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.1951638482121132e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 12500, uSet:32500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 98\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/98\", \"loss\": 2.304312705994, \"lr\": 0.000679865026, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/98\", \"loss\": 2.282213926315, \"lr\": 0.000679865026, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/98\", \"loss\": 2.274951219559, \"lr\": 0.000679865026, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/98\", \"loss\": 2.275123596191, \"lr\": 0.000679865026, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/98\", \"loss\": 2.267823934555, \"lr\": 0.000679865026, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/98\", \"loss\": 2.261927366257, \"lr\": 0.000679865026, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/98\", \"loss\": 2.228487491608, \"lr\": 0.000679865026, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/98\", \"loss\": 2.223989605904, \"lr\": 0.000679865026, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/98\", \"loss\": 2.229337573051, \"lr\": 0.000679865026, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.255082583084, \"lr\": 0.000679865026, \"top1_err\": 85.655999995117}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 85.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 85.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 83.660000000000, \"top1_err\": 83.660000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/98\", \"loss\": 2.197662353516, \"lr\": 0.000679865026, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/98\", \"loss\": 2.183748245239, \"lr\": 0.000679865026, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/98\", \"loss\": 2.165702939034, \"lr\": 0.000679865026, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/98\", \"loss\": 2.148400902748, \"lr\": 0.000679865026, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/98\", \"loss\": 2.124181985855, \"lr\": 0.000679865026, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/98\", \"loss\": 2.089712381363, \"lr\": 0.000679865026, \"top1_err\": 79.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/98\", \"loss\": 2.095234990120, \"lr\": 0.000679865026, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/98\", \"loss\": 2.074579238892, \"lr\": 0.000679865026, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/98\", \"loss\": 2.063942909241, \"lr\": 0.000679865026, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.122830761566, \"lr\": 0.000679865026, \"top1_err\": 80.431999980469}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 72.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 73.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 73.400000915527, \"top1_err\": 73.400000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/98\", \"loss\": 2.044769525528, \"lr\": 0.000679865026, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/98\", \"loss\": 2.027150988579, \"lr\": 0.000679865026, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/98\", \"loss\": 1.987094044685, \"lr\": 0.000679865026, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/98\", \"loss\": 1.992728292942, \"lr\": 0.000679865026, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/98\", \"loss\": 1.997119188309, \"lr\": 0.000679865026, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/98\", \"loss\": 2.023430466652, \"lr\": 0.000679865026, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/98\", \"loss\": 1.961006581783, \"lr\": 0.000679865026, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/98\", \"loss\": 1.978996992111, \"lr\": 0.000679865026, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/98\", \"loss\": 1.921266496181, \"lr\": 0.000679865026, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.991814463234, \"lr\": 0.000679865026, \"top1_err\": 76.472000014648}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 68.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 67.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 67.900000610352, \"top1_err\": 67.900000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/98\", \"loss\": 1.871761620045, \"lr\": 0.000679865026, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/98\", \"loss\": 1.890873789787, \"lr\": 0.000679865026, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/98\", \"loss\": 1.903002798557, \"lr\": 0.000679865026, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/98\", \"loss\": 1.882693886757, \"lr\": 0.000679865026, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/98\", \"loss\": 1.871966540813, \"lr\": 0.000679865026, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/98\", \"loss\": 1.889405965805, \"lr\": 0.000679865026, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/98\", \"loss\": 1.848200380802, \"lr\": 0.000679865026, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/98\", \"loss\": 1.843414962292, \"lr\": 0.000679865026, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/98\", \"loss\": 1.883146762848, \"lr\": 0.000679865026, \"top1_err\": 73.828125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.883109294281, \"lr\": 0.000679865026, \"top1_err\": 72.167999980469}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 68.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 66.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 66.860000915527, \"top1_err\": 66.860000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/98\", \"loss\": 1.811712622643, \"lr\": 0.000679865026, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/98\", \"loss\": 1.776156604290, \"lr\": 0.000679865026, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/98\", \"loss\": 1.827074170113, \"lr\": 0.000679865026, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/98\", \"loss\": 1.776335000992, \"lr\": 0.000679865026, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/98\", \"loss\": 1.786221027374, \"lr\": 0.000679865026, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/98\", \"loss\": 1.756617486477, \"lr\": 0.000679865026, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/98\", \"loss\": 1.821978807449, \"lr\": 0.000679865026, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/98\", \"loss\": 1.791435956955, \"lr\": 0.000679865026, \"top1_err\": 67.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/98\", \"loss\": 1.798633635044, \"lr\": 0.000679865026, \"top1_err\": 64.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.800720409927, \"lr\": 0.000679865026, \"top1_err\": 68.895999958496}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 63.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 65.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 63.800000762939, \"top1_err\": 63.800000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_36.199999237060545_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_36.199999237060545_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 00:59:15,468]\u001b[0m Trial 3 finished with value: 36.199999237060545 and parameters: {'learning_rate': 0.0006798650261761506, 'weight_decay': 1.1951638482121132e-07, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 1 with value: 50.64.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.0004046298844554519\n",
      "Weight Decay : 7.29789716820788e-08\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0004046298844554519\n",
      "    weight_decay: 7.29789716820788e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/30.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.699998931884764_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 12500, uSet:32500, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 25\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"loss\": 2.526754140854, \"lr\": 0.000404629884, \"top1_err\": 88.378906250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"loss\": 2.312828779221, \"lr\": 0.000404629884, \"top1_err\": 87.597656250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.912290624313, \"lr\": 0.000404629884, \"top1_err\": 88.504000004883}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 88.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 89.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.360000000000, \"top1_err\": 89.360000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"loss\": 2.276187181473, \"lr\": 0.000404629884, \"top1_err\": 85.937500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"loss\": 2.272160053253, \"lr\": 0.000404629884, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.274257799606, \"lr\": 0.000404629884, \"top1_err\": 86.743999938965}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 91.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 88.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 88.980000000000, \"top1_err\": 88.980000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"loss\": 2.266567111015, \"lr\": 0.000404629884, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"loss\": 2.272817730904, \"lr\": 0.000404629884, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.269883429031, \"lr\": 0.000404629884, \"top1_err\": 86.863999960938}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 87.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 88.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 88.480000000000, \"top1_err\": 88.480000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"loss\": 2.268429756165, \"lr\": 0.000404629884, \"top1_err\": 86.035156250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"loss\": 2.265642642975, \"lr\": 0.000404629884, \"top1_err\": 86.816406250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.265108703537, \"lr\": 0.000404629884, \"top1_err\": 85.967999995117}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 88.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 86.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 87.960000000000, \"top1_err\": 87.960000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"loss\": 2.243205785751, \"lr\": 0.000404629884, \"top1_err\": 84.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"loss\": 2.220570683479, \"lr\": 0.000404629884, \"top1_err\": 84.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.226987319107, \"lr\": 0.000404629884, \"top1_err\": 84.847999982910}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 90.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 88.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 87.960000000000, \"top1_err\": 90.080000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_12.040000000000006_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_12.040000000000006_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 01:00:22,340]\u001b[0m Trial 4 finished with value: 12.040000000000006 and parameters: {'learning_rate': 0.0004046298844554519, 'weight_decay': 7.29789716820788e-08, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 1 with value: 50.64.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 1059.1425399780273 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 50.64\n",
      "  Params: \n",
      "    learning_rate: 0.0001344031838522584\n",
      "    weight_decay: 5.044856083270199e-07\n",
      "    batch_size: 8\n",
      "    optimizer: SGD\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_50.64_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_nrcjriig.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform uncertainty sampling through subprocess\n",
      "len(uSetLoader): 4063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uSet Activations: 100%|████████████████████| 4063/4063 [00:18<00:00, 225.61it/s]\n",
      "u_ranks.shape: (32500,)\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  30000\n",
      "len(lSEt):  12500\n",
      "==================\n",
      "After including activeSet -- len(lSet): 15000 and len(uSet): 30000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  2500\n",
      "len(uSet):  30000\n",
      "len(lSet):  15000\n",
      "For uncertainty sampling, activeSet accuracy:  26.0\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.64_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.64_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.64_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 48.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 49.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 51.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 50.039999771118, \"top1_err\": 50.039999771118}\n",
      "Test Accuracy: 49.960\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/40.0/uncertainty/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:uncertainty;Seed:1]Test accuracy on cifar10 using 40.0% of data is 49.96000022888184\n",
      "\n",
      "Extracted Test Accuracy from subproces: 49.96000022888184\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/best_automl_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_budgetsize_results/auto_ml_results/lSet_1/start_1/CIFAR10/50.0/uncertainty/vgg_depth_16/vanilla/\n"
     ]
    }
   ],
   "source": [
    "!python3 $HOME_DIRECTORY/tools/main_aml.py --n_GPU $num_GPU \\\n",
    "--port $port --sampling_fn $sampling_fn --lSet_partition $lSet_partition \\\n",
    "--seed_id $base_seed \\\n",
    "--init_partition $init_partition --step_partition $step_partition \\\n",
    "--dataset $dataset --budget_size $budget_size \\\n",
    "--out_dir $out_dir \\\n",
    "--num_aml_trials $num_aml_trials --num_classes $num_classes \\\n",
    "--al_max_iter $al_iterations \\\n",
    "--model_type $model_type --model_depth $model_depth \\\n",
    "--clf_epochs $clf_epochs \\\n",
    "--eval_period 1 --checkpoint_period 1 \\\n",
    "--lSetPath $lSetPath --uSetPath $uSetPath --valSetPath $valSetPath \\\n",
    "--train_dir $train_dir --test_dir $test_dir \\\n",
    "--dropout_iterations 25 \\\n",
    "--cfg configs/$dataset/$model_style/$model_type/R-18_4gpu_unreg.yaml \\\n",
    "--vaal_z_dim 32 --vaal_vae_bs 64 --vaal_epochs 2 \\\n",
    "--vaal_vae_lr 5e-4 --vaal_disc_lr 5e-4 --vaal_beta 1.0 --vaal_adv_param 1.0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
