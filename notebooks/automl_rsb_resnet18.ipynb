{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0787532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43da9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIRECTORY=os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "os.chdir(HOME_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df13f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # sync ids with nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda32311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script params\n",
    "port=5219\n",
    "sampling_fn=\"random\"\n",
    "lSet_partition=1\n",
    "base_seed=1\n",
    "num_GPU=1\n",
    "al_iterations=4\n",
    "num_aml_trials=5 #50\n",
    "budget_size=5000 #2500\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "init_partition=10\n",
    "step_partition=10\n",
    "clf_epochs=5 #150\n",
    "num_classes=10\n",
    "swa_lr=5e-4\n",
    "swa_freq=50\n",
    "swa_epochs=5 #50\n",
    "\n",
    "log_iter=40\n",
    "\n",
    "#Data arguments\n",
    "train_dir=f\"{HOME_DIRECTORY}/data/{dataset}/train-{dataset}/\"\n",
    "test_dir=f\"{HOME_DIRECTORY}/data/{dataset}/test-{dataset}/\"\n",
    "lSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/lSet_{dataset}.npy\"\n",
    "uSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/uSet_{dataset}.npy\"\n",
    "valSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/valSet_{dataset}.npy\"\n",
    "\n",
    "out_dir=f\"{HOME_DIRECTORY}/sample_results_aml_rn18\"\n",
    "\n",
    "model_style=\"resnet_style\"\n",
    "model_type=\"resnet_2\"\n",
    "model_depth=18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a24cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= [NO ADVANCED REGULARIZATION TRICK ACTIVATED] =========\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_zpbaa38y.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:00:36,322]\u001b[0m A new study created in memory with name: no-name-e4ff46ce-36a8-4b60-96d9-8d658c824c8c\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 1.591404106434232e-05\n",
      "Weight Decay : 0.00028673212938351523\n",
      "Batch Size   : 8\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1.591404106434232e-05\n",
      "    weight_decay: 0.00028673212938351523\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:40000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 625\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/625\", \"loss\": 2.292534947395, \"lr\": 0.000015914041, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/625\", \"loss\": 2.161534786224, \"lr\": 0.000015914041, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/625\", \"loss\": 2.029745817184, \"lr\": 0.000015914041, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/625\", \"loss\": 1.914466142654, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/625\", \"loss\": 1.851829469204, \"lr\": 0.000015914041, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/625\", \"loss\": 1.884121656418, \"lr\": 0.000015914041, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/625\", \"loss\": 1.799612939358, \"lr\": 0.000015914041, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/625\", \"loss\": 1.819930016994, \"lr\": 0.000015914041, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/625\", \"loss\": 1.732919216156, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/625\", \"loss\": 1.746869146824, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/625\", \"loss\": 1.727177977562, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/625\", \"loss\": 1.603509068489, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.895055805588, \"lr\": 0.000015914041, \"top1_err\": 69.760000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 61.060001220703, \"top1_err\": 61.060001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/625\", \"loss\": 1.643732905388, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/625\", \"loss\": 1.582485496998, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/625\", \"loss\": 1.545060694218, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/625\", \"loss\": 1.638586103916, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/625\", \"loss\": 1.523359954357, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/625\", \"loss\": 1.515228748322, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/625\", \"loss\": 1.558936417103, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/625\", \"loss\": 1.414483487606, \"lr\": 0.000015914041, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/625\", \"loss\": 1.529986739159, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/625\", \"loss\": 1.521638572216, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/625\", \"loss\": 1.556341171265, \"lr\": 0.000015914041, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/625\", \"loss\": 1.570581376553, \"lr\": 0.000015914041, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.559999745274, \"lr\": 0.000015914041, \"top1_err\": 57.260000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 55.100000610352, \"top1_err\": 55.100000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/625\", \"loss\": 1.285637199879, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/625\", \"loss\": 1.423291563988, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/625\", \"loss\": 1.346863031387, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/625\", \"loss\": 1.373898386955, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/625\", \"loss\": 1.343439280987, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/625\", \"loss\": 1.433936059475, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/625\", \"loss\": 1.315882146358, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/625\", \"loss\": 1.409656822681, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/625\", \"loss\": 1.399997055531, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/625\", \"loss\": 1.427302062511, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/625\", \"loss\": 1.370916485786, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/625\", \"loss\": 1.234091639519, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.384689900589, \"lr\": 0.000015914041, \"top1_err\": 49.120000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 53.039999847412, \"top1_err\": 53.039999847412}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/625\", \"loss\": 1.141030073166, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/625\", \"loss\": 1.158747076988, \"lr\": 0.000015914041, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/625\", \"loss\": 1.165448904037, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/625\", \"loss\": 1.216302394867, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/625\", \"loss\": 1.188485264778, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/625\", \"loss\": 1.174982964993, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/625\", \"loss\": 1.248862922192, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/625\", \"loss\": 1.302262604237, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/625\", \"loss\": 1.205314099789, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/625\", \"loss\": 1.273514091969, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/625\", \"loss\": 1.097801029682, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/625\", \"loss\": 1.214296638966, \"lr\": 0.000015914041, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.235532487297, \"lr\": 0.000015914041, \"top1_err\": 43.140000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 50.140000762939, \"top1_err\": 50.140000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/625\", \"loss\": 1.094369232655, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/625\", \"loss\": 1.084942460060, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/625\", \"loss\": 1.079421877861, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/625\", \"loss\": 1.010788738728, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/625\", \"loss\": 1.022974014282, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/625\", \"loss\": 1.025925219059, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/625\", \"loss\": 1.041359364986, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/625\", \"loss\": 0.998030543327, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/625\", \"loss\": 1.076771557331, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/625\", \"loss\": 1.006589710712, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/625\", \"loss\": 0.993625551462, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/625\", \"loss\": 1.115236222744, \"lr\": 0.000015914041, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.082293325043, \"lr\": 0.000015914041, \"top1_err\": 37.400000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 50.140000762939, \"top1_err\": 51.700000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-22 01:05:29,664]\u001b[0m Trial 0 finished with value: 49.85999923706055 and parameters: {'learning_rate': 1.591404106434232e-05, 'weight_decay': 0.00028673212938351523, 'batch_size': 8, 'optimizer': 'ADAM'}. Best is trial 0 with value: 49.85999923706055.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 9.434876844402486e-05\n",
      "Weight Decay : 4.861955192019237e-08\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 9.434876844402486e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 4.861955192019237e-08\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:40000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 40\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.374636789703, \"lr\": 0.000094348768, \"top1_err\": 87.080000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 87.900000000000, \"top1_err\": 87.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.190796754837, \"lr\": 0.000094348768, \"top1_err\": 77.140000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 76.860000305176, \"top1_err\": 76.860000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.095905549622, \"lr\": 0.000094348768, \"top1_err\": 72.520000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 74.340000305176, \"top1_err\": 74.340000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.021473747253, \"lr\": 0.000094348768, \"top1_err\": 71.300000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 72.580000915527, \"top1_err\": 72.580000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.958286557388, \"lr\": 0.000094348768, \"top1_err\": 68.720000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 71.760001831055, \"top1_err\": 71.760001831055}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_28.239998168945306_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_28.239998168945306_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:06:03,093]\u001b[0m Trial 1 finished with value: 28.239998168945306 and parameters: {'learning_rate': 9.434876844402486e-05, 'weight_decay': 4.861955192019237e-08, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 0 with value: 49.85999923706055.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0016626918032117716\n",
      "Weight Decay : 2.0501421588969833e-08\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0016626918032117716\n",
      "    weight_decay: 2.0501421588969833e-08\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:40000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 10\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.420135342216, \"lr\": 0.001662691803, \"top1_err\": 78.559999621582}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 85.960000000000, \"top1_err\": 85.960000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.801237366104, \"lr\": 0.001662691803, \"top1_err\": 67.640000549316}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 83.900000000000, \"top1_err\": 83.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.690429419899, \"lr\": 0.001662691803, \"top1_err\": 63.100000048828}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 80.300000000000, \"top1_err\": 80.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.575429606438, \"lr\": 0.001662691803, \"top1_err\": 59.940000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 67.340001068115, \"top1_err\": 67.340001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.510572322464, \"lr\": 0.001662691803, \"top1_err\": 57.400000274658}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 61.600000457764, \"top1_err\": 61.600000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_38.39999954223633_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_38.39999954223633_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:06:34,855]\u001b[0m Trial 2 finished with value: 38.39999954223633 and parameters: {'learning_rate': 0.0016626918032117716, 'weight_decay': 2.0501421588969833e-08, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 0 with value: 49.85999923706055.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 5.4526699503310526e-05\n",
      "Weight Decay : 3.034756642144794e-07\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5.4526699503310526e-05\n",
      "    weight_decay: 3.034756642144794e-07\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:40000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 2.012971520424, \"lr\": 0.000054526700, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 1.713126718998, \"lr\": 0.000054526700, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.565679848194, \"lr\": 0.000054526700, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.769257034492, \"lr\": 0.000054526700, \"top1_err\": 66.040000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 61.780000915527, \"top1_err\": 61.780000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.445147454739, \"lr\": 0.000054526700, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.306203722954, \"lr\": 0.000054526700, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.380116045475, \"lr\": 0.000054526700, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.383798759079, \"lr\": 0.000054526700, \"top1_err\": 50.480000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 52.400001068115, \"top1_err\": 52.400001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.119772493839, \"lr\": 0.000054526700, \"top1_err\": 40.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.106518208981, \"lr\": 0.000054526700, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.091260194778, \"lr\": 0.000054526700, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.136149333572, \"lr\": 0.000054526700, \"top1_err\": 40.080000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 52.400001068115, \"top1_err\": 54.479999694824}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 0.869522064924, \"lr\": 0.000054526700, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 0.886884897947, \"lr\": 0.000054526700, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 0.947428822517, \"lr\": 0.000054526700, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.917061076546, \"lr\": 0.000054526700, \"top1_err\": 32.180000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 51.780000305176, \"top1_err\": 51.780000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 0.703111439943, \"lr\": 0.000054526700, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 0.652937620878, \"lr\": 0.000054526700, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 0.733156591654, \"lr\": 0.000054526700, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.713358482170, \"lr\": 0.000054526700, \"top1_err\": 23.740000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 51.780000305176, \"top1_err\": 55.280000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_48.21999969482422_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_48.21999969482422_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 01:07:52,788]\u001b[0m Trial 3 finished with value: 48.21999969482422 and parameters: {'learning_rate': 5.4526699503310526e-05, 'weight_decay': 3.034756642144794e-07, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 0 with value: 49.85999923706055.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.001936206097593722\n",
      "Weight Decay : 2.774472121519166e-08\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001936206097593722\n",
      "    weight_decay: 2.774472121519166e-08\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:40000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 2.128114938736, \"lr\": 0.001936206098, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 1.937042474747, \"lr\": 0.001936206098, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.827320456505, \"lr\": 0.001936206098, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.016293597794, \"lr\": 0.001936206098, \"top1_err\": 73.680000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 71.500000915527, \"top1_err\": 71.500000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.854718029499, \"lr\": 0.001936206098, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.700702011585, \"lr\": 0.001936206098, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.663452804089, \"lr\": 0.001936206098, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.748923833275, \"lr\": 0.001936206098, \"top1_err\": 65.340000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 71.100000915527, \"top1_err\": 71.100000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.608949184418, \"lr\": 0.001936206098, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.685985565186, \"lr\": 0.001936206098, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.559874415398, \"lr\": 0.001936206098, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.622486638641, \"lr\": 0.001936206098, \"top1_err\": 60.060000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 65.660001068115, \"top1_err\": 65.660001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 1.522788107395, \"lr\": 0.001936206098, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 1.525692343712, \"lr\": 0.001936206098, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 1.519904851913, \"lr\": 0.001936206098, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.524959228516, \"lr\": 0.001936206098, \"top1_err\": 57.700000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 61.880001220703, \"top1_err\": 61.880001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 1.493102729321, \"lr\": 0.001936206098, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 1.412407040596, \"lr\": 0.001936206098, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 1.419695019722, \"lr\": 0.001936206098, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.459573638916, \"lr\": 0.001936206098, \"top1_err\": 54.520000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 61.880001220703, \"top1_err\": 62.680000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_38.11999877929688_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_38.11999877929688_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 01:08:59,225]\u001b[0m Trial 4 finished with value: 38.11999877929688 and parameters: {'learning_rate': 0.001936206097593722, 'weight_decay': 2.774472121519166e-08, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 0 with value: 49.85999923706055.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 502.90322709083557 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 49.85999923706055\n",
      "  Params: \n",
      "    learning_rate: 1.591404106434232e-05\n",
      "    weight_decay: 0.00028673212938351523\n",
      "    batch_size: 8\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_h2xz2fr0.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: resnet_2\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  35000\n",
      "len(lSEt):  5000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 10000 and len(uSet): 35000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/activeSet.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  35000\n",
      "len(lSet):  10000\n",
      "For random sampling, activeSet accuracy:  48.7\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 51.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 51.329999923706, \"top1_err\": 51.329999923706}\n",
      "Test Accuracy: 48.670\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on CIFAR10 using 10.0% of data is 48.670000076293945\n",
      "\n",
      "Extracted Test Accuracy from subproces: 48.670000076293945\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_a71hyxq8.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:09:45,251]\u001b[0m A new study created in memory with name: no-name-15426ca6-401e-4532-9b64-ae897e6bcfe9\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.0004765226371071133\n",
      "Weight Decay : 1.0728909162988772e-08\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0004765226371071133\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.0728909162988772e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 40\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/40\", \"loss\": 2.397876739502, \"lr\": 0.000476522637, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/40\", \"loss\": 2.246254205704, \"lr\": 0.000476522637, \"top1_err\": 81.054687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/40\", \"loss\": 2.148745656013, \"lr\": 0.000476522637, \"top1_err\": 78.320312500000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/40\", \"loss\": 2.073463201523, \"lr\": 0.000476522637, \"top1_err\": 74.804687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.220183810043, \"lr\": 0.000476522637, \"top1_err\": 80.740000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 81.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 82.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 81.920000000000, \"top1_err\": 81.920000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/40\", \"loss\": 1.999783754349, \"lr\": 0.000476522637, \"top1_err\": 70.898437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/40\", \"loss\": 1.953448832035, \"lr\": 0.000476522637, \"top1_err\": 69.726562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/40\", \"loss\": 1.874432742596, \"lr\": 0.000476522637, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/40\", \"loss\": 1.862348914146, \"lr\": 0.000476522637, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.920671129227, \"lr\": 0.000476522637, \"top1_err\": 69.380000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 66.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 69.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 67.640002136230, \"top1_err\": 67.640002136230}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/40\", \"loss\": 1.801369786263, \"lr\": 0.000476522637, \"top1_err\": 65.039062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/40\", \"loss\": 1.742654323578, \"lr\": 0.000476522637, \"top1_err\": 62.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/40\", \"loss\": 1.727769613266, \"lr\": 0.000476522637, \"top1_err\": 63.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/40\", \"loss\": 1.725846886635, \"lr\": 0.000476522637, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.752590197372, \"lr\": 0.000476522637, \"top1_err\": 63.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 63.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 62.960000457764, \"top1_err\": 62.960000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/40\", \"loss\": 1.656918168068, \"lr\": 0.000476522637, \"top1_err\": 59.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/40\", \"loss\": 1.617978274822, \"lr\": 0.000476522637, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/40\", \"loss\": 1.600677251816, \"lr\": 0.000476522637, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/40\", \"loss\": 1.571686565876, \"lr\": 0.000476522637, \"top1_err\": 60.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.616180754852, \"lr\": 0.000476522637, \"top1_err\": 58.770000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 60.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 59.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 60.320001068115, \"top1_err\": 60.320001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/40\", \"loss\": 1.525383889675, \"lr\": 0.000476522637, \"top1_err\": 56.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/40\", \"loss\": 1.518078148365, \"lr\": 0.000476522637, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/40\", \"loss\": 1.525978267193, \"lr\": 0.000476522637, \"top1_err\": 54.882812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/40\", \"loss\": 1.486729681492, \"lr\": 0.000476522637, \"top1_err\": 54.492187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.519303463745, \"lr\": 0.000476522637, \"top1_err\": 55.600000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 57.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 56.220001373291, \"top1_err\": 56.220001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_43.77999862670899_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_43.77999862670899_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:10:27,191]\u001b[0m Trial 0 finished with value: 43.77999862670899 and parameters: {'learning_rate': 0.0004765226371071133, 'weight_decay': 1.0728909162988772e-08, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 0 with value: 43.77999862670899.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.00037772114532990444\n",
      "Weight Decay : 9.548356679177388e-08\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00037772114532990444\n",
      "    weight_decay: 9.548356679177388e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 20\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/20\", \"loss\": 1.889312744141, \"lr\": 0.000377721145, \"top1_err\": 69.726562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/20\", \"loss\": 1.574901998043, \"lr\": 0.000377721145, \"top1_err\": 59.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.802261210060, \"lr\": 0.000377721145, \"top1_err\": 66.279999993896}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 86.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 85.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 85.760000000000, \"top1_err\": 85.760000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/20\", \"loss\": 1.411947607994, \"lr\": 0.000377721145, \"top1_err\": 53.222656250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/20\", \"loss\": 1.312896549702, \"lr\": 0.000377721145, \"top1_err\": 48.925781250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.368540110779, \"lr\": 0.000377721145, \"top1_err\": 51.529999981689}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 77.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 80.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 78.040000000000, \"top1_err\": 78.040000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/20\", \"loss\": 1.194952845573, \"lr\": 0.000377721145, \"top1_err\": 44.335937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/20\", \"loss\": 1.145562171936, \"lr\": 0.000377721145, \"top1_err\": 41.210937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.169317958260, \"lr\": 0.000377721145, \"top1_err\": 42.540000054932}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 54.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 55.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 54.720001068115, \"top1_err\": 54.720001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/20\", \"loss\": 0.976608753204, \"lr\": 0.000377721145, \"top1_err\": 35.644531250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/20\", \"loss\": 0.958855032921, \"lr\": 0.000377721145, \"top1_err\": 34.570312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.969206018639, \"lr\": 0.000377721145, \"top1_err\": 35.089999926758}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 48.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 44.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 47.340000152588, \"top1_err\": 47.340000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/20\", \"loss\": 0.829087078571, \"lr\": 0.000377721145, \"top1_err\": 29.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/20\", \"loss\": 0.823868513107, \"lr\": 0.000377721145, \"top1_err\": 28.808593750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.818548748016, \"lr\": 0.000377721145, \"top1_err\": 28.979999929810}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 45.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 44.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 44.840000610352, \"top1_err\": 44.840000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_55.15999938964844_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_55.15999938964844_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:11:05,068]\u001b[0m Trial 1 finished with value: 55.15999938964844 and parameters: {'learning_rate': 0.00037772114532990444, 'weight_decay': 9.548356679177388e-08, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 1 with value: 55.15999938964844.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0010747960303912527\n",
      "Weight Decay : 5.295891165250158e-07\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0010747960303912527\n",
      "    weight_decay: 5.295891165250158e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/313\", \"loss\": 2.588258743286, \"lr\": 0.001074796030, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/313\", \"loss\": 2.112252593040, \"lr\": 0.001074796030, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/313\", \"loss\": 2.016672968864, \"lr\": 0.001074796030, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 1.928754866123, \"lr\": 0.001074796030, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/313\", \"loss\": 1.826980233192, \"lr\": 0.001074796030, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/313\", \"loss\": 1.982070386410, \"lr\": 0.001074796030, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/313\", \"loss\": 1.772906780243, \"lr\": 0.001074796030, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 1.819599866867, \"lr\": 0.001074796030, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/313\", \"loss\": 1.852047383785, \"lr\": 0.001074796030, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/313\", \"loss\": 1.916046857834, \"lr\": 0.001074796030, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/313\", \"loss\": 1.732671678066, \"lr\": 0.001074796030, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 1.789077877998, \"lr\": 0.001074796030, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/313\", \"loss\": 1.784779906273, \"lr\": 0.001074796030, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/313\", \"loss\": 1.805342257023, \"lr\": 0.001074796030, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/313\", \"loss\": 1.734406709671, \"lr\": 0.001074796030, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 1.679578959942, \"lr\": 0.001074796030, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/313\", \"loss\": 1.681903064251, \"lr\": 0.001074796030, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/313\", \"loss\": 1.566373467445, \"lr\": 0.001074796030, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/313\", \"loss\": 1.801432788372, \"lr\": 0.001074796030, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 1.743133723736, \"lr\": 0.001074796030, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/313\", \"loss\": 1.668493747711, \"lr\": 0.001074796030, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/313\", \"loss\": 1.616846859455, \"lr\": 0.001074796030, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/313\", \"loss\": 1.562272548676, \"lr\": 0.001074796030, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 1.438998937607, \"lr\": 0.001074796030, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/313\", \"loss\": 1.528685748577, \"lr\": 0.001074796030, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/313\", \"loss\": 1.596045911312, \"lr\": 0.001074796030, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/313\", \"loss\": 1.552593231201, \"lr\": 0.001074796030, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 1.479873001575, \"lr\": 0.001074796030, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/313\", \"loss\": 1.674995899200, \"lr\": 0.001074796030, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/313\", \"loss\": 1.593509793282, \"lr\": 0.001074796030, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/313\", \"loss\": 1.608013331890, \"lr\": 0.001074796030, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.757287662315, \"lr\": 0.001074796030, \"top1_err\": 65.020000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 61.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 62.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 61.900001068115, \"top1_err\": 61.900001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/313\", \"loss\": 1.421252429485, \"lr\": 0.001074796030, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/313\", \"loss\": 1.547898709774, \"lr\": 0.001074796030, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/313\", \"loss\": 1.477130711079, \"lr\": 0.001074796030, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 1.403377413750, \"lr\": 0.001074796030, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/313\", \"loss\": 1.538616001606, \"lr\": 0.001074796030, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/313\", \"loss\": 1.543918311596, \"lr\": 0.001074796030, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/313\", \"loss\": 1.426468968391, \"lr\": 0.001074796030, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 1.442511796951, \"lr\": 0.001074796030, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/313\", \"loss\": 1.398114979267, \"lr\": 0.001074796030, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/313\", \"loss\": 1.461380720139, \"lr\": 0.001074796030, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/313\", \"loss\": 1.434478342533, \"lr\": 0.001074796030, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 1.367258667946, \"lr\": 0.001074796030, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/313\", \"loss\": 1.415762245655, \"lr\": 0.001074796030, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/313\", \"loss\": 1.462560474873, \"lr\": 0.001074796030, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/313\", \"loss\": 1.489749431610, \"lr\": 0.001074796030, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 1.396101653576, \"lr\": 0.001074796030, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/313\", \"loss\": 1.380341827869, \"lr\": 0.001074796030, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/313\", \"loss\": 1.410288989544, \"lr\": 0.001074796030, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/313\", \"loss\": 1.446670174599, \"lr\": 0.001074796030, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 1.322015762329, \"lr\": 0.001074796030, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/313\", \"loss\": 1.350116729736, \"lr\": 0.001074796030, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/313\", \"loss\": 1.362356960773, \"lr\": 0.001074796030, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/313\", \"loss\": 1.362036406994, \"lr\": 0.001074796030, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 1.219507277012, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/313\", \"loss\": 1.421831965446, \"lr\": 0.001074796030, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/313\", \"loss\": 1.327791094780, \"lr\": 0.001074796030, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/313\", \"loss\": 1.282021939754, \"lr\": 0.001074796030, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 1.443683624268, \"lr\": 0.001074796030, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/313\", \"loss\": 1.319281935692, \"lr\": 0.001074796030, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/313\", \"loss\": 1.277474105358, \"lr\": 0.001074796030, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/313\", \"loss\": 1.235020220280, \"lr\": 0.001074796030, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.402466813660, \"lr\": 0.001074796030, \"top1_err\": 51.460000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 48.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 50.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 48.960000457764, \"top1_err\": 48.960000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/313\", \"loss\": 1.219695329666, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/313\", \"loss\": 1.176653146744, \"lr\": 0.001074796030, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/313\", \"loss\": 1.302622199059, \"lr\": 0.001074796030, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 1.157919049263, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/313\", \"loss\": 1.217721521854, \"lr\": 0.001074796030, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/313\", \"loss\": 1.272242069244, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/313\", \"loss\": 1.310549557209, \"lr\": 0.001074796030, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 1.274962306023, \"lr\": 0.001074796030, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/313\", \"loss\": 1.237968623638, \"lr\": 0.001074796030, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/313\", \"loss\": 1.124489843845, \"lr\": 0.001074796030, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/313\", \"loss\": 1.268920421600, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 1.270418941975, \"lr\": 0.001074796030, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/313\", \"loss\": 1.057383477688, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/313\", \"loss\": 1.333245515823, \"lr\": 0.001074796030, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/313\", \"loss\": 1.243589997292, \"lr\": 0.001074796030, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 1.099018156528, \"lr\": 0.001074796030, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/313\", \"loss\": 1.156665980816, \"lr\": 0.001074796030, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/313\", \"loss\": 1.184329926968, \"lr\": 0.001074796030, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/313\", \"loss\": 1.100819528103, \"lr\": 0.001074796030, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 1.266292273998, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/313\", \"loss\": 1.133143782616, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/313\", \"loss\": 1.192986130714, \"lr\": 0.001074796030, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/313\", \"loss\": 1.343704342842, \"lr\": 0.001074796030, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 1.101453721523, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/313\", \"loss\": 1.003474742174, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/313\", \"loss\": 1.108109295368, \"lr\": 0.001074796030, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/313\", \"loss\": 0.981518268585, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 1.072159945965, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/313\", \"loss\": 1.190620839596, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/313\", \"loss\": 1.240763485432, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/313\", \"loss\": 1.152374804020, \"lr\": 0.001074796030, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.184312450600, \"lr\": 0.001074796030, \"top1_err\": 42.470000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 39.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 44.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 42.180001373291, \"top1_err\": 42.180001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/313\", \"loss\": 0.945074766874, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/313\", \"loss\": 0.992302417755, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/313\", \"loss\": 0.967726379633, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 0.933700054884, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/313\", \"loss\": 1.143003523350, \"lr\": 0.001074796030, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/313\", \"loss\": 1.139322757721, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/313\", \"loss\": 1.212833464146, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 1.091531515121, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/313\", \"loss\": 1.089175701141, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/313\", \"loss\": 0.921811699867, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/313\", \"loss\": 1.105269432068, \"lr\": 0.001074796030, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 1.029606997967, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/313\", \"loss\": 1.056042909622, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/313\", \"loss\": 1.042181074619, \"lr\": 0.001074796030, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/313\", \"loss\": 0.845079988241, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 0.941798597574, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/313\", \"loss\": 1.016874760389, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/313\", \"loss\": 1.058236896992, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/313\", \"loss\": 1.014441788197, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 0.986592322588, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/313\", \"loss\": 0.944120794535, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/313\", \"loss\": 0.946141451597, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/313\", \"loss\": 1.059416949749, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 1.020171552896, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/313\", \"loss\": 1.085419893265, \"lr\": 0.001074796030, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/313\", \"loss\": 1.046597063541, \"lr\": 0.001074796030, \"top1_err\": 40.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/313\", \"loss\": 1.128514945507, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 0.941488385201, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/313\", \"loss\": 1.012957185507, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/313\", \"loss\": 1.030884981155, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/313\", \"loss\": 0.973966091871, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.026216248131, \"lr\": 0.001074796030, \"top1_err\": 36.650000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 38.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 38.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 39.180001068115, \"top1_err\": 39.180001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/313\", \"loss\": 0.941272467375, \"lr\": 0.001074796030, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/313\", \"loss\": 0.858384490013, \"lr\": 0.001074796030, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/313\", \"loss\": 0.950480550528, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 0.930256485939, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/313\", \"loss\": 0.930761307478, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/313\", \"loss\": 0.930734992027, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/313\", \"loss\": 0.950375437737, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 0.921813905239, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/313\", \"loss\": 0.847689658403, \"lr\": 0.001074796030, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/313\", \"loss\": 0.802381575108, \"lr\": 0.001074796030, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/313\", \"loss\": 0.780535817146, \"lr\": 0.001074796030, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 1.052183926105, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/313\", \"loss\": 0.944950491190, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/313\", \"loss\": 0.905664533377, \"lr\": 0.001074796030, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/313\", \"loss\": 0.926151156425, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 0.953407406807, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/313\", \"loss\": 0.962344706059, \"lr\": 0.001074796030, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/313\", \"loss\": 0.911989390850, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/313\", \"loss\": 0.785658150911, \"lr\": 0.001074796030, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 0.833329081535, \"lr\": 0.001074796030, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/313\", \"loss\": 0.803042024374, \"lr\": 0.001074796030, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/313\", \"loss\": 0.851444453001, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/313\", \"loss\": 0.818040460348, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 0.826867669821, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/313\", \"loss\": 0.866813212633, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/313\", \"loss\": 0.869005531073, \"lr\": 0.001074796030, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/313\", \"loss\": 0.793259978294, \"lr\": 0.001074796030, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 0.840338438749, \"lr\": 0.001074796030, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/313\", \"loss\": 0.901060283184, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/313\", \"loss\": 0.875321269035, \"lr\": 0.001074796030, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/313\", \"loss\": 0.998511642218, \"lr\": 0.001074796030, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.906433855820, \"lr\": 0.001074796030, \"top1_err\": 32.280000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 33.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 33.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 33.620001907349, \"top1_err\": 33.620001907349}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:13:17,063]\u001b[0m Trial 2 finished with value: 66.37999809265136 and parameters: {'learning_rate': 0.0010747960303912527, 'weight_decay': 5.295891165250158e-07, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 2 with value: 66.37999809265136.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.00011368769237816958\n",
      "Weight Decay : 4.761764947785391e-06\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00011368769237816958\n",
      "    weight_decay: 4.761764947785391e-06\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 20\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/20\", \"loss\": 1.962412118912, \"lr\": 0.000113687692, \"top1_err\": 72.167968750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/20\", \"loss\": 1.607448458672, \"lr\": 0.000113687692, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.823569755173, \"lr\": 0.000113687692, \"top1_err\": 67.080000061035}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 87.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 87.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 87.160000000000, \"top1_err\": 87.160000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/20\", \"loss\": 1.383146703243, \"lr\": 0.000113687692, \"top1_err\": 50.585937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/20\", \"loss\": 1.285251796246, \"lr\": 0.000113687692, \"top1_err\": 46.966911315918}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.350641977692, \"lr\": 0.000113687692, \"top1_err\": 49.269999975586}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 74.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 77.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 75.220000000000, \"top1_err\": 75.220000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/20\", \"loss\": 1.162724912167, \"lr\": 0.000113687692, \"top1_err\": 41.992187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/20\", \"loss\": 1.072418630123, \"lr\": 0.000113687692, \"top1_err\": 38.062959671021}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.113782094002, \"lr\": 0.000113687692, \"top1_err\": 39.800000006104}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 55.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 56.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 55.480001068115, \"top1_err\": 55.480001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/20\", \"loss\": 0.858817547560, \"lr\": 0.000113687692, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/20\", \"loss\": 0.850442767143, \"lr\": 0.000113687692, \"top1_err\": 28.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.852375807953, \"lr\": 0.000113687692, \"top1_err\": 28.930000006104}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 53.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 55.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 54.860000610352, \"top1_err\": 54.860000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/20\", \"loss\": 0.640321880579, \"lr\": 0.000113687692, \"top1_err\": 20.019531250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/20\", \"loss\": 0.620335638523, \"lr\": 0.000113687692, \"top1_err\": 19.789752006531}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.621247406578, \"lr\": 0.000113687692, \"top1_err\": 19.680000009155}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 48.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 48.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 49.680001525879, \"top1_err\": 49.680001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_50.31999847412109_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_50.31999847412109_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:14:04,824]\u001b[0m Trial 3 finished with value: 50.31999847412109 and parameters: {'learning_rate': 0.00011368769237816958, 'weight_decay': 4.761764947785391e-06, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 2 with value: 66.37999809265136.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.0008778496681978845\n",
      "Weight Decay : 1.5890153007830006e-07\n",
      "Batch Size   : 64\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0008778496681978845\n",
      "    weight_decay: 1.5890153007830006e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_49.85999923706055_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/157\", \"loss\": 2.477550148964, \"lr\": 0.000877849668, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/157\", \"loss\": 1.941002964973, \"lr\": 0.000877849668, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/157\", \"loss\": 1.919264674187, \"lr\": 0.000877849668, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 1.785605490208, \"lr\": 0.000877849668, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 1.705624520779, \"lr\": 0.000877849668, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/157\", \"loss\": 1.784237384796, \"lr\": 0.000877849668, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/157\", \"loss\": 1.707520544529, \"lr\": 0.000877849668, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 1.617062211037, \"lr\": 0.000877849668, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/157\", \"loss\": 1.607511699200, \"lr\": 0.000877849668, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 1.634022355080, \"lr\": 0.000877849668, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/157\", \"loss\": 1.566801488400, \"lr\": 0.000877849668, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 1.506925523281, \"lr\": 0.000877849668, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/157\", \"loss\": 1.605719387531, \"lr\": 0.000877849668, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/157\", \"loss\": 1.443910181522, \"lr\": 0.000877849668, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.649950981140, \"lr\": 0.000877849668, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.719096760178, \"lr\": 0.000877849668, \"top1_err\": 63.340000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 59.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 60.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 59.100001068115, \"top1_err\": 59.100001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/157\", \"loss\": 1.501295089722, \"lr\": 0.000877849668, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/157\", \"loss\": 1.565639138222, \"lr\": 0.000877849668, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/157\", \"loss\": 1.485820889473, \"lr\": 0.000877849668, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 1.409864664078, \"lr\": 0.000877849668, \"top1_err\": 51.562500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.448390126228, \"lr\": 0.000877849668, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/157\", \"loss\": 1.426336467266, \"lr\": 0.000877849668, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/157\", \"loss\": 1.428750813007, \"lr\": 0.000877849668, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 1.349424540997, \"lr\": 0.000877849668, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/157\", \"loss\": 1.428025484085, \"lr\": 0.000877849668, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.454184234142, \"lr\": 0.000877849668, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/157\", \"loss\": 1.293753266335, \"lr\": 0.000877849668, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 1.360728681087, \"lr\": 0.000877849668, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/157\", \"loss\": 1.391522347927, \"lr\": 0.000877849668, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/157\", \"loss\": 1.403588056564, \"lr\": 0.000877849668, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.326849460602, \"lr\": 0.000877849668, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.415062888145, \"lr\": 0.000877849668, \"top1_err\": 52.160000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 49.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 50.000000915527, \"top1_err\": 50.000000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/157\", \"loss\": 1.274844765663, \"lr\": 0.000877849668, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/157\", \"loss\": 1.308694183826, \"lr\": 0.000877849668, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/157\", \"loss\": 1.299524188042, \"lr\": 0.000877849668, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 1.375935494900, \"lr\": 0.000877849668, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.253923654556, \"lr\": 0.000877849668, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/157\", \"loss\": 1.233856081963, \"lr\": 0.000877849668, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/157\", \"loss\": 1.219120919704, \"lr\": 0.000877849668, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 1.222817897797, \"lr\": 0.000877849668, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/157\", \"loss\": 1.222072958946, \"lr\": 0.000877849668, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.152176439762, \"lr\": 0.000877849668, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/157\", \"loss\": 1.178116440773, \"lr\": 0.000877849668, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 1.113481044769, \"lr\": 0.000877849668, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/157\", \"loss\": 1.132204115391, \"lr\": 0.000877849668, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/157\", \"loss\": 1.171207726002, \"lr\": 0.000877849668, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.222756206989, \"lr\": 0.000877849668, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.231125277328, \"lr\": 0.000877849668, \"top1_err\": 44.580000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 42.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 43.660001220703, \"top1_err\": 43.660001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/157\", \"loss\": 1.046490967274, \"lr\": 0.000877849668, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/157\", \"loss\": 1.083549022675, \"lr\": 0.000877849668, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/157\", \"loss\": 1.114153921604, \"lr\": 0.000877849668, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 1.168955683708, \"lr\": 0.000877849668, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 0.995221167803, \"lr\": 0.000877849668, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/157\", \"loss\": 1.094330012798, \"lr\": 0.000877849668, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/157\", \"loss\": 1.077307105064, \"lr\": 0.000877849668, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 0.952608793974, \"lr\": 0.000877849668, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/157\", \"loss\": 0.990500122309, \"lr\": 0.000877849668, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 1.012529015541, \"lr\": 0.000877849668, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/157\", \"loss\": 1.050702631474, \"lr\": 0.000877849668, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 1.087073266506, \"lr\": 0.000877849668, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/157\", \"loss\": 1.086438179016, \"lr\": 0.000877849668, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/157\", \"loss\": 1.003773331642, \"lr\": 0.000877849668, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 0.979812592268, \"lr\": 0.000877849668, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.063426233387, \"lr\": 0.000877849668, \"top1_err\": 38.230000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 49.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 43.660001220703, \"top1_err\": 50.419999542236}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/157\", \"loss\": 0.953409016132, \"lr\": 0.000877849668, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/157\", \"loss\": 0.888165086508, \"lr\": 0.000877849668, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/157\", \"loss\": 0.963741332293, \"lr\": 0.000877849668, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 0.846191644669, \"lr\": 0.000877849668, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 0.948610782623, \"lr\": 0.000877849668, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/157\", \"loss\": 0.923786103725, \"lr\": 0.000877849668, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/157\", \"loss\": 0.942840218544, \"lr\": 0.000877849668, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 0.918246865273, \"lr\": 0.000877849668, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/157\", \"loss\": 1.008261054754, \"lr\": 0.000877849668, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 0.969949930906, \"lr\": 0.000877849668, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/157\", \"loss\": 0.922479540110, \"lr\": 0.000877849668, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 0.963462501764, \"lr\": 0.000877849668, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/157\", \"loss\": 0.956572979689, \"lr\": 0.000877849668, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/157\", \"loss\": 0.858830928802, \"lr\": 0.000877849668, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 0.954992324114, \"lr\": 0.000877849668, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.939461564255, \"lr\": 0.000877849668, \"top1_err\": 33.950000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 34.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 35.880001754761, \"top1_err\": 35.880001754761}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_64.11999824523926_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_64.11999824523926_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:15:29,037]\u001b[0m Trial 4 finished with value: 64.11999824523926 and parameters: {'learning_rate': 0.0008778496681978845, 'weight_decay': 1.5890153007830006e-07, 'batch_size': 64, 'optimizer': 'ADAM'}. Best is trial 2 with value: 66.37999809265136.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 343.78605914115906 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 66.37999809265136\n",
      "  Params: \n",
      "    learning_rate: 0.0010747960303912527\n",
      "    weight_decay: 5.295891165250158e-07\n",
      "    batch_size: 32\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_o4hf9zl9.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: resnet_2\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========BEFORE==========\n",
      "len(uSEt):  30000\n",
      "len(lSEt):  10000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 15000 and len(uSet): 30000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  30000\n",
      "len(lSet):  15000\n",
      "For random sampling, activeSet accuracy:  66.1\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 36.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 31.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 33.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 34.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 35.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 34.200001678467, \"top1_err\": 34.200001678467}\n",
      "Test Accuracy: 65.800\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on CIFAR10 using 20.0% of data is 65.7999983215332\n",
      "\n",
      "Extracted Test Accuracy from subproces: 65.7999983215332\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_76_zdml9.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:16:09,293]\u001b[0m A new study created in memory with name: no-name-8f364a14-624f-4871-86c3-fd436a421bc2\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 1.2761345396989285e-05\n",
      "Weight Decay : 1.4285695738787422e-08\n",
      "Batch Size   : 8\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 1.2761345396989285e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.4285695738787422e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 1875\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/1875\", \"loss\": 2.371674895287, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/1875\", \"loss\": 2.474741578102, \"lr\": 0.000012761345, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/1875\", \"loss\": 2.461674094200, \"lr\": 0.000012761345, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/1875\", \"loss\": 2.437284946442, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/1875\", \"loss\": 2.433280587196, \"lr\": 0.000012761345, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/1875\", \"loss\": 2.485674858093, \"lr\": 0.000012761345, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/1875\", \"loss\": 2.300726890564, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/1875\", \"loss\": 2.400069952011, \"lr\": 0.000012761345, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/1875\", \"loss\": 2.343576192856, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/1875\", \"loss\": 2.353564023972, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/1875\", \"loss\": 2.358477592468, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/1875\", \"loss\": 2.408502578735, \"lr\": 0.000012761345, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/1875\", \"loss\": 2.394734621048, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/1875\", \"loss\": 2.370062112808, \"lr\": 0.000012761345, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/1875\", \"loss\": 2.385741949081, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/1875\", \"loss\": 2.303616166115, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/1875\", \"loss\": 2.378765940666, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/1875\", \"loss\": 2.280918359756, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/1875\", \"loss\": 2.328210949898, \"lr\": 0.000012761345, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/1875\", \"loss\": 2.233765482903, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/1875\", \"loss\": 2.302680969238, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/1875\", \"loss\": 2.334100246429, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/1875\", \"loss\": 2.273060441017, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/1875\", \"loss\": 2.230570912361, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/1875\", \"loss\": 2.272488117218, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/1875\", \"loss\": 2.291740775108, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/1875\", \"loss\": 2.215539574623, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/1875\", \"loss\": 2.239046454430, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/1875\", \"loss\": 2.226097822189, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/1875\", \"loss\": 2.236121892929, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/1875\", \"loss\": 2.226305603981, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/1875\", \"loss\": 2.241816520691, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/1875\", \"loss\": 2.257701396942, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/1875\", \"loss\": 2.194567203522, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/1875\", \"loss\": 2.223281025887, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/1875\", \"loss\": 2.273219823837, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/1875\", \"loss\": 2.207115411758, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/1875\", \"loss\": 2.240385174751, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/1875\", \"loss\": 2.321137309074, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/1875\", \"loss\": 2.219140172005, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/1875\", \"loss\": 2.223455786705, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/1875\", \"loss\": 2.254845619202, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/1875\", \"loss\": 2.197879076004, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/1875\", \"loss\": 2.188476920128, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/1875\", \"loss\": 2.224774360657, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/1875\", \"loss\": 2.204803586006, \"lr\": 0.000012761345, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/1875\", \"loss\": 2.153464436531, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/1875\", \"loss\": 2.189076304436, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/1875\", \"loss\": 2.242133498192, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/1875\", \"loss\": 2.232320070267, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/1875\", \"loss\": 2.203569173813, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/1875\", \"loss\": 2.281328320503, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/1875\", \"loss\": 2.185473918915, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/1875\", \"loss\": 2.194979667664, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/1875\", \"loss\": 2.134470701218, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/1875\", \"loss\": 2.184084177017, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/1875\", \"loss\": 2.178166866302, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/1875\", \"loss\": 2.210452675819, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/1875\", \"loss\": 2.181250452995, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/1875\", \"loss\": 2.143405914307, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/1875\", \"loss\": 2.242027997971, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/1875\", \"loss\": 2.135115861893, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/1875\", \"loss\": 2.175364732742, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/1875\", \"loss\": 2.137242436409, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/1875\", \"loss\": 2.108791589737, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/1875\", \"loss\": 2.175580143929, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/1875\", \"loss\": 2.184930324554, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/1875\", \"loss\": 2.155077576637, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/1875\", \"loss\": 2.130636930466, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/1875\", \"loss\": 2.149406671524, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/1875\", \"loss\": 2.156235933304, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/1875\", \"loss\": 2.087324738503, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/1875\", \"loss\": 2.164718031883, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/1875\", \"loss\": 2.132352232933, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/1875\", \"loss\": 2.128514289856, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/1875\", \"loss\": 2.079449653625, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/1875\", \"loss\": 2.160063385963, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/1875\", \"loss\": 2.104118466377, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/1875\", \"loss\": 2.199422478676, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/1875\", \"loss\": 2.079619169235, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/1875\", \"loss\": 2.134470343590, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/1875\", \"loss\": 2.083937287331, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/1875\", \"loss\": 2.095385074615, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/1875\", \"loss\": 2.147712588310, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/1875\", \"loss\": 2.151930212975, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/1875\", \"loss\": 2.078889012337, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/1875\", \"loss\": 2.156499505043, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/1875\", \"loss\": 2.087964892387, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/1875\", \"loss\": 2.048625588417, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/1875\", \"loss\": 2.153791904449, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/1875\", \"loss\": 2.083191514015, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/1875\", \"loss\": 2.069588780403, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/1875\", \"loss\": 2.100990653038, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"940/1875\", \"loss\": 2.091830968857, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"950/1875\", \"loss\": 2.091987490654, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"960/1875\", \"loss\": 2.156249642372, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"970/1875\", \"loss\": 2.134759902954, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"980/1875\", \"loss\": 2.092095971107, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"990/1875\", \"loss\": 2.126946806908, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1000/1875\", \"loss\": 2.063312411308, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1010/1875\", \"loss\": 2.159174561501, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1020/1875\", \"loss\": 2.075982809067, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1030/1875\", \"loss\": 2.053623795509, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1040/1875\", \"loss\": 2.096530556679, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1050/1875\", \"loss\": 2.014584183693, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1060/1875\", \"loss\": 2.094507336617, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1070/1875\", \"loss\": 2.103221893311, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1080/1875\", \"loss\": 2.125067710876, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1090/1875\", \"loss\": 2.157058835030, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1100/1875\", \"loss\": 2.111049056053, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1110/1875\", \"loss\": 2.096513628960, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1120/1875\", \"loss\": 2.000930726528, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1130/1875\", \"loss\": 2.007922530174, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1140/1875\", \"loss\": 2.019340753555, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1150/1875\", \"loss\": 2.073408603668, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1160/1875\", \"loss\": 2.143158793449, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1170/1875\", \"loss\": 2.119522333145, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1180/1875\", \"loss\": 2.075643420219, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1190/1875\", \"loss\": 2.081378817558, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1200/1875\", \"loss\": 2.079989671707, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1210/1875\", \"loss\": 2.075961947441, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1220/1875\", \"loss\": 1.985104203224, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1230/1875\", \"loss\": 1.985371887684, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1240/1875\", \"loss\": 2.075957417488, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1250/1875\", \"loss\": 2.062506556511, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1260/1875\", \"loss\": 2.124341726303, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1270/1875\", \"loss\": 2.068767428398, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1280/1875\", \"loss\": 2.077289581299, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1290/1875\", \"loss\": 2.017755568027, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1300/1875\", \"loss\": 2.012274205685, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1310/1875\", \"loss\": 2.108949303627, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1320/1875\", \"loss\": 2.080832123756, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1330/1875\", \"loss\": 2.115504860878, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1340/1875\", \"loss\": 1.959099054337, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1350/1875\", \"loss\": 2.032978057861, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1360/1875\", \"loss\": 2.016113281250, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1370/1875\", \"loss\": 2.068601489067, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1380/1875\", \"loss\": 1.994444370270, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1390/1875\", \"loss\": 2.026494860649, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1400/1875\", \"loss\": 2.002742290497, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1410/1875\", \"loss\": 2.062261700630, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1420/1875\", \"loss\": 2.079143881798, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1430/1875\", \"loss\": 2.000329077244, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1440/1875\", \"loss\": 1.998983383179, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1450/1875\", \"loss\": 2.065964579582, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1460/1875\", \"loss\": 2.028731346130, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1470/1875\", \"loss\": 2.122810721397, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1480/1875\", \"loss\": 1.976513206959, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1490/1875\", \"loss\": 1.957980930805, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1500/1875\", \"loss\": 2.048564076424, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1510/1875\", \"loss\": 2.161472201347, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1520/1875\", \"loss\": 1.942671835423, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1530/1875\", \"loss\": 2.068800806999, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1540/1875\", \"loss\": 2.023257732391, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1550/1875\", \"loss\": 1.953100979328, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1560/1875\", \"loss\": 2.023993253708, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1570/1875\", \"loss\": 2.108189463615, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1580/1875\", \"loss\": 2.011820971966, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1590/1875\", \"loss\": 2.010133385658, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1600/1875\", \"loss\": 2.032750904560, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1610/1875\", \"loss\": 1.958486258984, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1620/1875\", \"loss\": 1.915720820427, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1630/1875\", \"loss\": 2.053833365440, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1640/1875\", \"loss\": 2.040320634842, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1650/1875\", \"loss\": 1.908757627010, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1660/1875\", \"loss\": 1.992494106293, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1670/1875\", \"loss\": 1.886135578156, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1680/1875\", \"loss\": 2.004835247993, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1690/1875\", \"loss\": 2.030894517899, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1700/1875\", \"loss\": 2.049056410789, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1710/1875\", \"loss\": 2.042708277702, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1720/1875\", \"loss\": 2.016378641129, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1730/1875\", \"loss\": 2.037881851196, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1740/1875\", \"loss\": 1.978383064270, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1750/1875\", \"loss\": 2.107832431793, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1760/1875\", \"loss\": 1.955842196941, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1770/1875\", \"loss\": 2.069945871830, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1780/1875\", \"loss\": 2.042426943779, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1790/1875\", \"loss\": 2.000286400318, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1800/1875\", \"loss\": 1.833712458611, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1810/1875\", \"loss\": 2.045957207680, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1820/1875\", \"loss\": 1.936608433723, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1830/1875\", \"loss\": 2.070831060410, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1840/1875\", \"loss\": 2.056961297989, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1850/1875\", \"loss\": 1.939335405827, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1860/1875\", \"loss\": 1.913121998310, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1870/1875\", \"loss\": 1.970465540886, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.136464230537, \"lr\": 0.000012761345, \"top1_err\": 77.246666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 72.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 70.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 71.600000915527, \"top1_err\": 71.600000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/1875\", \"loss\": 1.927361309528, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/1875\", \"loss\": 2.024431467056, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/1875\", \"loss\": 1.895014584064, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/1875\", \"loss\": 2.034518599510, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/1875\", \"loss\": 2.006954550743, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/1875\", \"loss\": 1.911589741707, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/1875\", \"loss\": 1.967513799667, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/1875\", \"loss\": 1.882285475731, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/1875\", \"loss\": 2.033093810081, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/1875\", \"loss\": 1.943500339985, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/1875\", \"loss\": 1.961822926998, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/1875\", \"loss\": 1.847054600716, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/1875\", \"loss\": 1.884375154972, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/1875\", \"loss\": 1.950237154961, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/1875\", \"loss\": 2.004693031311, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/1875\", \"loss\": 2.035915374756, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/1875\", \"loss\": 1.939560115337, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/1875\", \"loss\": 1.928990721703, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/1875\", \"loss\": 2.098370432854, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/1875\", \"loss\": 2.012583136559, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/1875\", \"loss\": 2.044779419899, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/1875\", \"loss\": 2.062423229218, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/1875\", \"loss\": 1.946932792664, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/1875\", \"loss\": 1.892581939697, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/1875\", \"loss\": 1.936201512814, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/1875\", \"loss\": 1.974717259407, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/1875\", \"loss\": 1.952864170074, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/1875\", \"loss\": 2.002616405487, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/1875\", \"loss\": 1.921444296837, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/1875\", \"loss\": 1.934777498245, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/1875\", \"loss\": 1.952232062817, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/1875\", \"loss\": 1.939153134823, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/1875\", \"loss\": 2.056543350220, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/1875\", \"loss\": 1.836739957333, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/1875\", \"loss\": 2.089798331261, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/1875\", \"loss\": 1.893378019333, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/1875\", \"loss\": 1.974065899849, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/1875\", \"loss\": 1.965716898441, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/1875\", \"loss\": 1.901763498783, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/1875\", \"loss\": 1.973941028118, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/1875\", \"loss\": 2.030712723732, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/1875\", \"loss\": 1.860835671425, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/1875\", \"loss\": 1.945086121559, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/1875\", \"loss\": 1.898388147354, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/1875\", \"loss\": 1.780574977398, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/1875\", \"loss\": 1.917199909687, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/1875\", \"loss\": 1.848479628563, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/1875\", \"loss\": 1.924401998520, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/1875\", \"loss\": 2.001742124557, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/1875\", \"loss\": 1.857802391052, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/1875\", \"loss\": 1.929388403893, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/1875\", \"loss\": 1.949016511440, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/1875\", \"loss\": 1.836445868015, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/1875\", \"loss\": 2.027830362320, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/1875\", \"loss\": 2.117702245712, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/1875\", \"loss\": 1.759764850140, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/1875\", \"loss\": 1.941192567348, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/1875\", \"loss\": 1.835231006145, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/1875\", \"loss\": 1.846239149570, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/1875\", \"loss\": 1.917422711849, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/1875\", \"loss\": 1.903127372265, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/1875\", \"loss\": 1.899381875992, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/1875\", \"loss\": 1.889394342899, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/1875\", \"loss\": 1.966649591923, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/1875\", \"loss\": 1.977380514145, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/1875\", \"loss\": 1.980576574802, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/1875\", \"loss\": 1.839405119419, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/1875\", \"loss\": 1.774971663952, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/1875\", \"loss\": 1.805382907391, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/1875\", \"loss\": 1.977703630924, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/1875\", \"loss\": 1.831325113773, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/1875\", \"loss\": 1.911600530148, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/1875\", \"loss\": 1.938710689545, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/1875\", \"loss\": 1.947733700275, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/1875\", \"loss\": 1.797691345215, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/1875\", \"loss\": 1.972279071808, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/1875\", \"loss\": 1.863442242146, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/1875\", \"loss\": 1.936340272427, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/1875\", \"loss\": 1.926117599010, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/1875\", \"loss\": 1.816601634026, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/1875\", \"loss\": 1.933567106724, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/1875\", \"loss\": 1.901967465878, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/1875\", \"loss\": 1.855599045753, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/1875\", \"loss\": 1.876088976860, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/1875\", \"loss\": 1.911415755749, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/1875\", \"loss\": 1.916900753975, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/1875\", \"loss\": 1.887107014656, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/1875\", \"loss\": 1.872782707214, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/1875\", \"loss\": 2.030497014523, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/1875\", \"loss\": 1.966386198997, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/1875\", \"loss\": 1.776463508606, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/1875\", \"loss\": 1.920140445232, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/1875\", \"loss\": 1.790156841278, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"940/1875\", \"loss\": 1.692744672298, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"950/1875\", \"loss\": 1.843544602394, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"960/1875\", \"loss\": 1.909768044949, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"970/1875\", \"loss\": 1.956320166588, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"980/1875\", \"loss\": 1.937683880329, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"990/1875\", \"loss\": 1.981697559357, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1000/1875\", \"loss\": 1.811281681061, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1010/1875\", \"loss\": 1.889945983887, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1020/1875\", \"loss\": 1.944627642632, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1030/1875\", \"loss\": 1.863763153553, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1040/1875\", \"loss\": 1.745734393597, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1050/1875\", \"loss\": 1.922982931137, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1060/1875\", \"loss\": 1.845041275024, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1070/1875\", \"loss\": 2.037384033203, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1080/1875\", \"loss\": 1.908702433109, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1090/1875\", \"loss\": 1.761365771294, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1100/1875\", \"loss\": 1.939183771610, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1110/1875\", \"loss\": 1.929635822773, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1120/1875\", \"loss\": 1.855937004089, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1130/1875\", \"loss\": 1.907042086124, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1140/1875\", \"loss\": 1.998032212257, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1150/1875\", \"loss\": 1.908971726894, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1160/1875\", \"loss\": 1.847677826881, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1170/1875\", \"loss\": 1.750136077404, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1180/1875\", \"loss\": 1.817888617516, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1190/1875\", \"loss\": 1.755731642246, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1200/1875\", \"loss\": 1.951119959354, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1210/1875\", \"loss\": 1.775856852531, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1220/1875\", \"loss\": 1.846791446209, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1230/1875\", \"loss\": 1.884268581867, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1240/1875\", \"loss\": 1.784602046013, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1250/1875\", \"loss\": 1.943164288998, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1260/1875\", \"loss\": 1.832624852657, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1270/1875\", \"loss\": 1.800402820110, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1280/1875\", \"loss\": 1.971276283264, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1290/1875\", \"loss\": 1.859054327011, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1300/1875\", \"loss\": 1.717074036598, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1310/1875\", \"loss\": 1.804844319820, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1320/1875\", \"loss\": 1.825379312038, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1330/1875\", \"loss\": 1.769057869911, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1340/1875\", \"loss\": 1.798989892006, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1350/1875\", \"loss\": 1.855784595013, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1360/1875\", \"loss\": 2.001181006432, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1370/1875\", \"loss\": 1.820475697517, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1380/1875\", \"loss\": 1.893265426159, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1390/1875\", \"loss\": 1.924282968044, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1400/1875\", \"loss\": 1.809628486633, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1410/1875\", \"loss\": 1.795854687691, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1420/1875\", \"loss\": 1.957768738270, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1430/1875\", \"loss\": 1.826136052608, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1440/1875\", \"loss\": 1.845332086086, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1450/1875\", \"loss\": 1.937928676605, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1460/1875\", \"loss\": 1.888265728951, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1470/1875\", \"loss\": 1.857466399670, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1480/1875\", \"loss\": 1.900994658470, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1490/1875\", \"loss\": 1.829102039337, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1500/1875\", \"loss\": 1.864738404751, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1510/1875\", \"loss\": 1.758718609810, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1520/1875\", \"loss\": 1.852646946907, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1530/1875\", \"loss\": 2.030878663063, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1540/1875\", \"loss\": 1.946815848351, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1550/1875\", \"loss\": 1.918768584728, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1560/1875\", \"loss\": 1.804745554924, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1570/1875\", \"loss\": 1.860692322254, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1580/1875\", \"loss\": 1.747226655483, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1590/1875\", \"loss\": 1.903637290001, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1600/1875\", \"loss\": 1.780671536922, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1610/1875\", \"loss\": 1.830329835415, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1620/1875\", \"loss\": 1.804673492908, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1630/1875\", \"loss\": 1.990426480770, \"lr\": 0.000012761345, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1640/1875\", \"loss\": 1.705406963825, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1650/1875\", \"loss\": 1.883198261261, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1660/1875\", \"loss\": 1.830462813377, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1670/1875\", \"loss\": 1.803939342499, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1680/1875\", \"loss\": 1.847009956837, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1690/1875\", \"loss\": 1.699856638908, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1700/1875\", \"loss\": 1.804927945137, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1710/1875\", \"loss\": 1.821953356266, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1720/1875\", \"loss\": 1.976173102856, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1730/1875\", \"loss\": 1.853363335133, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1740/1875\", \"loss\": 1.812063276768, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1750/1875\", \"loss\": 1.859377026558, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1760/1875\", \"loss\": 1.879888594151, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1770/1875\", \"loss\": 1.826694846153, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1780/1875\", \"loss\": 1.766455829144, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1790/1875\", \"loss\": 1.794729053974, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1800/1875\", \"loss\": 1.926550984383, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1810/1875\", \"loss\": 1.789090812206, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1820/1875\", \"loss\": 1.800066232681, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1830/1875\", \"loss\": 1.788050472736, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1840/1875\", \"loss\": 1.845807790756, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1850/1875\", \"loss\": 1.734978675842, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1860/1875\", \"loss\": 1.777423083782, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1870/1875\", \"loss\": 1.789401769638, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.906722415860, \"lr\": 0.000012761345, \"top1_err\": 69.360000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 64.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 64.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 64.420000305176, \"top1_err\": 64.420000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/1875\", \"loss\": 1.885779976845, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/1875\", \"loss\": 1.942616045475, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/1875\", \"loss\": 1.742794454098, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/1875\", \"loss\": 1.700017571449, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/1875\", \"loss\": 1.676184833050, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/1875\", \"loss\": 1.933026552200, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/1875\", \"loss\": 1.938515961170, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/1875\", \"loss\": 1.830644130707, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/1875\", \"loss\": 1.803339838982, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/1875\", \"loss\": 2.053102254868, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/1875\", \"loss\": 1.648258924484, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/1875\", \"loss\": 1.787864327431, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/1875\", \"loss\": 1.675682246685, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/1875\", \"loss\": 1.760239958763, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/1875\", \"loss\": 1.825963437557, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/1875\", \"loss\": 1.779098749161, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/1875\", \"loss\": 1.832242071629, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/1875\", \"loss\": 1.808426320553, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/1875\", \"loss\": 1.734600841999, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/1875\", \"loss\": 1.789303064346, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/1875\", \"loss\": 1.886002957821, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/1875\", \"loss\": 1.608777344227, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/1875\", \"loss\": 1.820813894272, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/1875\", \"loss\": 1.868961513042, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/1875\", \"loss\": 1.812623322010, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/1875\", \"loss\": 1.910093545914, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/1875\", \"loss\": 1.942560732365, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/1875\", \"loss\": 1.916051149368, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/1875\", \"loss\": 1.739213585854, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/1875\", \"loss\": 1.806676387787, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/1875\", \"loss\": 1.703351616859, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/1875\", \"loss\": 1.785470902920, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/1875\", \"loss\": 1.861303269863, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/1875\", \"loss\": 1.820253133774, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/1875\", \"loss\": 1.752655804157, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/1875\", \"loss\": 1.783367395401, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/1875\", \"loss\": 1.848249733448, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/1875\", \"loss\": 1.794153690338, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/1875\", \"loss\": 1.800941348076, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/1875\", \"loss\": 1.805599570274, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/1875\", \"loss\": 1.644830644131, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/1875\", \"loss\": 1.877806901932, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/1875\", \"loss\": 1.669131219387, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/1875\", \"loss\": 1.735615789890, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/1875\", \"loss\": 1.752585768700, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/1875\", \"loss\": 1.818207263947, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/1875\", \"loss\": 1.463627517223, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/1875\", \"loss\": 1.793818473816, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/1875\", \"loss\": 1.791443645954, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/1875\", \"loss\": 1.778625667095, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/1875\", \"loss\": 1.768992304802, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/1875\", \"loss\": 1.791684985161, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/1875\", \"loss\": 1.800094366074, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/1875\", \"loss\": 1.838876843452, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/1875\", \"loss\": 1.691866278648, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/1875\", \"loss\": 1.725956380367, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/1875\", \"loss\": 1.596359372139, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/1875\", \"loss\": 1.968480408192, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/1875\", \"loss\": 1.765827059746, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/1875\", \"loss\": 1.712198555470, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/1875\", \"loss\": 1.794251561165, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/1875\", \"loss\": 1.866232037544, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/1875\", \"loss\": 1.718709409237, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/1875\", \"loss\": 1.762314319611, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/1875\", \"loss\": 1.787398576736, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/1875\", \"loss\": 1.776889741421, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/1875\", \"loss\": 1.836661517620, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/1875\", \"loss\": 1.726628482342, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/1875\", \"loss\": 1.717147529125, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/1875\", \"loss\": 1.801374375820, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/1875\", \"loss\": 1.812123298645, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/1875\", \"loss\": 1.689595103264, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/1875\", \"loss\": 1.649953544140, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/1875\", \"loss\": 1.651672184467, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/1875\", \"loss\": 1.869914293289, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/1875\", \"loss\": 1.729618012905, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/1875\", \"loss\": 1.686894237995, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/1875\", \"loss\": 1.834665656090, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/1875\", \"loss\": 1.683641970158, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/1875\", \"loss\": 1.717580199242, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/1875\", \"loss\": 1.659277379513, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/1875\", \"loss\": 1.729957818985, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/1875\", \"loss\": 1.766565501690, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/1875\", \"loss\": 1.778205037117, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/1875\", \"loss\": 1.711846113205, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/1875\", \"loss\": 1.755667865276, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/1875\", \"loss\": 1.691783964634, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/1875\", \"loss\": 1.903158664703, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/1875\", \"loss\": 1.728657901287, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/1875\", \"loss\": 1.926434397697, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/1875\", \"loss\": 1.836440026760, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/1875\", \"loss\": 1.933491826057, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/1875\", \"loss\": 1.840309381485, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"940/1875\", \"loss\": 1.647741496563, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"950/1875\", \"loss\": 1.833174347878, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"960/1875\", \"loss\": 1.687334239483, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"970/1875\", \"loss\": 1.836408138275, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"980/1875\", \"loss\": 1.686610519886, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"990/1875\", \"loss\": 1.854863286018, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1000/1875\", \"loss\": 1.792054235935, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1010/1875\", \"loss\": 1.672370314598, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1020/1875\", \"loss\": 1.667418897152, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1030/1875\", \"loss\": 1.875178337097, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1040/1875\", \"loss\": 1.944832086563, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1050/1875\", \"loss\": 1.610543429852, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1060/1875\", \"loss\": 1.613978922367, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1070/1875\", \"loss\": 1.716032624245, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1080/1875\", \"loss\": 1.666904270649, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1090/1875\", \"loss\": 1.658298850060, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1100/1875\", \"loss\": 1.798819720745, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1110/1875\", \"loss\": 1.567226231098, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1120/1875\", \"loss\": 1.708118975163, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1130/1875\", \"loss\": 1.689129054546, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1140/1875\", \"loss\": 1.760318040848, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1150/1875\", \"loss\": 1.702847838402, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1160/1875\", \"loss\": 1.614143669605, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1170/1875\", \"loss\": 1.829854667187, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1180/1875\", \"loss\": 1.760827124119, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1190/1875\", \"loss\": 1.860053479671, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1200/1875\", \"loss\": 1.791414678097, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1210/1875\", \"loss\": 1.861042976379, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1220/1875\", \"loss\": 1.793285727501, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1230/1875\", \"loss\": 1.779670655727, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1240/1875\", \"loss\": 1.905146121979, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1250/1875\", \"loss\": 1.694612562656, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1260/1875\", \"loss\": 1.627968788147, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1270/1875\", \"loss\": 1.919408202171, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1280/1875\", \"loss\": 1.814333856106, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1290/1875\", \"loss\": 1.707168042660, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1300/1875\", \"loss\": 1.722865164280, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1310/1875\", \"loss\": 1.820667386055, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1320/1875\", \"loss\": 1.665537893772, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1330/1875\", \"loss\": 1.808872878551, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1340/1875\", \"loss\": 1.830541551113, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1350/1875\", \"loss\": 1.694144845009, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1360/1875\", \"loss\": 1.742949604988, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1370/1875\", \"loss\": 1.839498043060, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1380/1875\", \"loss\": 1.763960003853, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1390/1875\", \"loss\": 1.699699282646, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1400/1875\", \"loss\": 1.724236130714, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1410/1875\", \"loss\": 1.795668423176, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1420/1875\", \"loss\": 1.771926820278, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1430/1875\", \"loss\": 1.708487272263, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1440/1875\", \"loss\": 1.736430883408, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1450/1875\", \"loss\": 1.709272086620, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1460/1875\", \"loss\": 1.546166837215, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1470/1875\", \"loss\": 1.652057945728, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1480/1875\", \"loss\": 1.653941631317, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1490/1875\", \"loss\": 1.756985366344, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1500/1875\", \"loss\": 1.663853168488, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1510/1875\", \"loss\": 1.737238109112, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1520/1875\", \"loss\": 1.773819506168, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1530/1875\", \"loss\": 1.729964673519, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1540/1875\", \"loss\": 1.600020706654, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1550/1875\", \"loss\": 1.746906697750, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1560/1875\", \"loss\": 1.826024889946, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1570/1875\", \"loss\": 1.695555806160, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1580/1875\", \"loss\": 1.790074825287, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1590/1875\", \"loss\": 1.717010855675, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1600/1875\", \"loss\": 1.671059131622, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1610/1875\", \"loss\": 1.745617091656, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1620/1875\", \"loss\": 1.691093206406, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1630/1875\", \"loss\": 1.712545990944, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1640/1875\", \"loss\": 1.796678364277, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1650/1875\", \"loss\": 1.619970023632, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1660/1875\", \"loss\": 1.875687718391, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1670/1875\", \"loss\": 1.788907349110, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1680/1875\", \"loss\": 1.873821735382, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1690/1875\", \"loss\": 1.759036421776, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1700/1875\", \"loss\": 1.656705617905, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1710/1875\", \"loss\": 1.841087639332, \"lr\": 0.000012761345, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1720/1875\", \"loss\": 1.707754790783, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1730/1875\", \"loss\": 1.727498888969, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1740/1875\", \"loss\": 1.617133378983, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1750/1875\", \"loss\": 1.774149715900, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1760/1875\", \"loss\": 1.802739918232, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1770/1875\", \"loss\": 1.622338831425, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1780/1875\", \"loss\": 1.870814561844, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1790/1875\", \"loss\": 1.736642241478, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1800/1875\", \"loss\": 1.800466418266, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1810/1875\", \"loss\": 1.784445047379, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1820/1875\", \"loss\": 1.780149459839, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1830/1875\", \"loss\": 1.625598430634, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1840/1875\", \"loss\": 1.805965483189, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1850/1875\", \"loss\": 1.679612398148, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1860/1875\", \"loss\": 1.691268324852, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1870/1875\", \"loss\": 1.803481340408, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.779212155787, \"lr\": 0.000012761345, \"top1_err\": 64.253333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 59.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 61.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 60.300001220703, \"top1_err\": 60.300001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/1875\", \"loss\": 1.837325632572, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/1875\", \"loss\": 1.640641331673, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/1875\", \"loss\": 1.793464601040, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/1875\", \"loss\": 1.594187259674, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/1875\", \"loss\": 1.797087967396, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/1875\", \"loss\": 1.778896152973, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/1875\", \"loss\": 1.700870811939, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/1875\", \"loss\": 1.849524915218, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/1875\", \"loss\": 1.634068310261, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/1875\", \"loss\": 1.701297283173, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/1875\", \"loss\": 1.621831536293, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/1875\", \"loss\": 1.573545992374, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/1875\", \"loss\": 1.707027673721, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/1875\", \"loss\": 1.795378446579, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/1875\", \"loss\": 1.637310862541, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/1875\", \"loss\": 1.697689116001, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/1875\", \"loss\": 1.727893650532, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/1875\", \"loss\": 1.720064342022, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/1875\", \"loss\": 1.647789061069, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/1875\", \"loss\": 1.882052361965, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/1875\", \"loss\": 1.754528939724, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/1875\", \"loss\": 1.721010625362, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/1875\", \"loss\": 1.816365599632, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/1875\", \"loss\": 1.614638328552, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/1875\", \"loss\": 1.498056232929, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/1875\", \"loss\": 1.707018911839, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/1875\", \"loss\": 1.740521907806, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/1875\", \"loss\": 1.586685061455, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/1875\", \"loss\": 1.651009321213, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/1875\", \"loss\": 1.642000436783, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/1875\", \"loss\": 1.597133815289, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/1875\", \"loss\": 1.799662232399, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/1875\", \"loss\": 1.720835328102, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/1875\", \"loss\": 1.688291072845, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/1875\", \"loss\": 1.675672829151, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/1875\", \"loss\": 1.655754089355, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/1875\", \"loss\": 1.777101457119, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/1875\", \"loss\": 1.824333548546, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/1875\", \"loss\": 1.615822434425, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/1875\", \"loss\": 1.633535921574, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/1875\", \"loss\": 1.648356199265, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/1875\", \"loss\": 1.699818253517, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/1875\", \"loss\": 1.705588817596, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/1875\", \"loss\": 1.765067338943, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/1875\", \"loss\": 1.656393408775, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/1875\", \"loss\": 1.683435797691, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/1875\", \"loss\": 1.539293706417, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/1875\", \"loss\": 1.632499098778, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/1875\", \"loss\": 1.554042637348, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/1875\", \"loss\": 1.806431591511, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/1875\", \"loss\": 1.649764358997, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/1875\", \"loss\": 1.665386676788, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/1875\", \"loss\": 1.679152131081, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/1875\", \"loss\": 1.670212507248, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/1875\", \"loss\": 1.586210191250, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/1875\", \"loss\": 1.678620934486, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/1875\", \"loss\": 1.599563002586, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/1875\", \"loss\": 1.675166428089, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/1875\", \"loss\": 1.591379106045, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/1875\", \"loss\": 1.707513868809, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/1875\", \"loss\": 1.582051455975, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/1875\", \"loss\": 1.642036259174, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/1875\", \"loss\": 1.493500053883, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/1875\", \"loss\": 1.753753304482, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/1875\", \"loss\": 1.606672585011, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/1875\", \"loss\": 1.694311022758, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/1875\", \"loss\": 1.521728515625, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/1875\", \"loss\": 1.752805769444, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/1875\", \"loss\": 1.742984533310, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/1875\", \"loss\": 1.406637310982, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/1875\", \"loss\": 1.737330973148, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/1875\", \"loss\": 1.708399713039, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/1875\", \"loss\": 1.787023425102, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/1875\", \"loss\": 1.598427057266, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/1875\", \"loss\": 1.564870834351, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/1875\", \"loss\": 1.745209217072, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/1875\", \"loss\": 1.833647608757, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/1875\", \"loss\": 1.544924318790, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/1875\", \"loss\": 1.650554537773, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/1875\", \"loss\": 1.624924778938, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/1875\", \"loss\": 1.762296676636, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/1875\", \"loss\": 1.654906749725, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/1875\", \"loss\": 1.685983061790, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/1875\", \"loss\": 1.677519261837, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/1875\", \"loss\": 1.578359305859, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/1875\", \"loss\": 1.534914374352, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/1875\", \"loss\": 1.436785221100, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/1875\", \"loss\": 1.542138516903, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/1875\", \"loss\": 1.437464773655, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/1875\", \"loss\": 1.415003597736, \"lr\": 0.000012761345, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/1875\", \"loss\": 1.639583230019, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/1875\", \"loss\": 1.854557454586, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/1875\", \"loss\": 1.534154117107, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"940/1875\", \"loss\": 1.793819367886, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"950/1875\", \"loss\": 1.841926872730, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"960/1875\", \"loss\": 1.781036853790, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"970/1875\", \"loss\": 1.760172963142, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"980/1875\", \"loss\": 1.756501793861, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"990/1875\", \"loss\": 1.612889766693, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1000/1875\", \"loss\": 1.771654307842, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1010/1875\", \"loss\": 1.764797747135, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1020/1875\", \"loss\": 1.738895237446, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1030/1875\", \"loss\": 1.537917494774, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1040/1875\", \"loss\": 1.662292301655, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1050/1875\", \"loss\": 1.467376708984, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1060/1875\", \"loss\": 1.734513938427, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1070/1875\", \"loss\": 1.656038045883, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1080/1875\", \"loss\": 1.567074835300, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1090/1875\", \"loss\": 1.664108872414, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1100/1875\", \"loss\": 1.599274873734, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1110/1875\", \"loss\": 1.673709094524, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1120/1875\", \"loss\": 1.849581778049, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1130/1875\", \"loss\": 1.676657140255, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1140/1875\", \"loss\": 1.800042271614, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1150/1875\", \"loss\": 1.564732372761, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1160/1875\", \"loss\": 1.708767592907, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1170/1875\", \"loss\": 1.769825398922, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1180/1875\", \"loss\": 1.508290231228, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1190/1875\", \"loss\": 1.620803475380, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1200/1875\", \"loss\": 1.584982812405, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1210/1875\", \"loss\": 1.693942368031, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1220/1875\", \"loss\": 1.688011825085, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1230/1875\", \"loss\": 1.624571681023, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1240/1875\", \"loss\": 1.719791471958, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1250/1875\", \"loss\": 1.780824422836, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1260/1875\", \"loss\": 1.527102172375, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1270/1875\", \"loss\": 1.517162322998, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1280/1875\", \"loss\": 1.700753450394, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1290/1875\", \"loss\": 1.694401383400, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1300/1875\", \"loss\": 1.630444467068, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1310/1875\", \"loss\": 1.606048226357, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1320/1875\", \"loss\": 1.704127848148, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1330/1875\", \"loss\": 1.698428690434, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1340/1875\", \"loss\": 1.723790884018, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1350/1875\", \"loss\": 1.785743474960, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1360/1875\", \"loss\": 1.530146896839, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1370/1875\", \"loss\": 1.576455175877, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1380/1875\", \"loss\": 1.558207094669, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1390/1875\", \"loss\": 1.614172518253, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1400/1875\", \"loss\": 1.582313537598, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1410/1875\", \"loss\": 1.633945405483, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1420/1875\", \"loss\": 1.755812883377, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1430/1875\", \"loss\": 1.592351436615, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1440/1875\", \"loss\": 1.609244823456, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1450/1875\", \"loss\": 1.831727564335, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1460/1875\", \"loss\": 1.482579171658, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1470/1875\", \"loss\": 1.733651876450, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1480/1875\", \"loss\": 1.551750242710, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1490/1875\", \"loss\": 1.816241383553, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1500/1875\", \"loss\": 1.653718292713, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1510/1875\", \"loss\": 1.510342955589, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1520/1875\", \"loss\": 1.667338728905, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1530/1875\", \"loss\": 1.672989785671, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1540/1875\", \"loss\": 1.653730154037, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1550/1875\", \"loss\": 1.568168103695, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1560/1875\", \"loss\": 1.442673265934, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1570/1875\", \"loss\": 1.855038166046, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1580/1875\", \"loss\": 1.572042763233, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1590/1875\", \"loss\": 1.739192605019, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1600/1875\", \"loss\": 1.454897284508, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1610/1875\", \"loss\": 1.655686438084, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1620/1875\", \"loss\": 1.575580358505, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1630/1875\", \"loss\": 1.659668087959, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1640/1875\", \"loss\": 1.617523014545, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1650/1875\", \"loss\": 1.603855133057, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1660/1875\", \"loss\": 1.801017105579, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1670/1875\", \"loss\": 1.758630514145, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1680/1875\", \"loss\": 1.709937691689, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1690/1875\", \"loss\": 1.437655568123, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1700/1875\", \"loss\": 1.617653369904, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1710/1875\", \"loss\": 1.642230510712, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1720/1875\", \"loss\": 1.785332202911, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1730/1875\", \"loss\": 1.641918778419, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1740/1875\", \"loss\": 1.750783801079, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1750/1875\", \"loss\": 1.689231932163, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1760/1875\", \"loss\": 1.558682978153, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1770/1875\", \"loss\": 1.768832921982, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1780/1875\", \"loss\": 1.553559064865, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1790/1875\", \"loss\": 1.725699663162, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1800/1875\", \"loss\": 1.654237091541, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1810/1875\", \"loss\": 1.645205676556, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1820/1875\", \"loss\": 1.613231241703, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1830/1875\", \"loss\": 1.740919470787, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1840/1875\", \"loss\": 1.654096543789, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1850/1875\", \"loss\": 1.614414811134, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1860/1875\", \"loss\": 1.576034545898, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1870/1875\", \"loss\": 1.563363850117, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.685168436178, \"lr\": 0.000012761345, \"top1_err\": 61.040000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 58.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 56.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 56.580001220703, \"top1_err\": 56.580001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/1875\", \"loss\": 1.607239365578, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/1875\", \"loss\": 1.529128313065, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/1875\", \"loss\": 1.672282755375, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/1875\", \"loss\": 1.518154978752, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/1875\", \"loss\": 1.796879410744, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/1875\", \"loss\": 1.601189732552, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/1875\", \"loss\": 1.586144804955, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/1875\", \"loss\": 1.519754052162, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/1875\", \"loss\": 1.587672114372, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/1875\", \"loss\": 1.456390738487, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/1875\", \"loss\": 1.841019690037, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/1875\", \"loss\": 1.534456014633, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/1875\", \"loss\": 1.570024728775, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/1875\", \"loss\": 1.681391239166, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/1875\", \"loss\": 1.587620019913, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/1875\", \"loss\": 1.453519642353, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/1875\", \"loss\": 1.651641130447, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/1875\", \"loss\": 1.605370342731, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/1875\", \"loss\": 1.553682088852, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/1875\", \"loss\": 1.565972030163, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/1875\", \"loss\": 1.493828892708, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/1875\", \"loss\": 1.639918506145, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/1875\", \"loss\": 1.690004765987, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/1875\", \"loss\": 1.572009384632, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/1875\", \"loss\": 1.509910762310, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/1875\", \"loss\": 1.449214160442, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/1875\", \"loss\": 1.633229732513, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/1875\", \"loss\": 1.426434934139, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/1875\", \"loss\": 1.569718778133, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/1875\", \"loss\": 1.591136813164, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/1875\", \"loss\": 1.766005218029, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/1875\", \"loss\": 1.466132640839, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/1875\", \"loss\": 1.714683651924, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/1875\", \"loss\": 1.572175681591, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/1875\", \"loss\": 1.715591490269, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/1875\", \"loss\": 1.571633577347, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/1875\", \"loss\": 1.668601691723, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/1875\", \"loss\": 1.568088710308, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/1875\", \"loss\": 1.597038567066, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/1875\", \"loss\": 1.835189819336, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/1875\", \"loss\": 1.633298456669, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/1875\", \"loss\": 1.631914675236, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/1875\", \"loss\": 1.674307644367, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/1875\", \"loss\": 1.677480518818, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/1875\", \"loss\": 1.764546036720, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/1875\", \"loss\": 1.548890769482, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/1875\", \"loss\": 1.700756013393, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/1875\", \"loss\": 1.676134049892, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/1875\", \"loss\": 1.561373889446, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/1875\", \"loss\": 1.612522542477, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/1875\", \"loss\": 1.523392558098, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/1875\", \"loss\": 1.439767897129, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/1875\", \"loss\": 1.564386487007, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/1875\", \"loss\": 1.550683796406, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/1875\", \"loss\": 1.579018473625, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/1875\", \"loss\": 1.621200323105, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/1875\", \"loss\": 1.770368516445, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/1875\", \"loss\": 1.761236131191, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/1875\", \"loss\": 1.638978183270, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/1875\", \"loss\": 1.686058521271, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/1875\", \"loss\": 1.561530768871, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/1875\", \"loss\": 1.526423513889, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/1875\", \"loss\": 1.629754185677, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/1875\", \"loss\": 1.691027581692, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/1875\", \"loss\": 1.671150803566, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/1875\", \"loss\": 1.622471928596, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/1875\", \"loss\": 1.527785956860, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/1875\", \"loss\": 1.660413205624, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/1875\", \"loss\": 1.576885640621, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/1875\", \"loss\": 1.366581499577, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/1875\", \"loss\": 1.524453163147, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/1875\", \"loss\": 1.673564076424, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/1875\", \"loss\": 1.607564508915, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/1875\", \"loss\": 1.548044145107, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/1875\", \"loss\": 1.557055711746, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/1875\", \"loss\": 1.428900718689, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/1875\", \"loss\": 1.519836962223, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/1875\", \"loss\": 1.634478509426, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/1875\", \"loss\": 1.446194231510, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/1875\", \"loss\": 1.568535506725, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/1875\", \"loss\": 1.848845601082, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/1875\", \"loss\": 1.519807279110, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/1875\", \"loss\": 1.615607261658, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/1875\", \"loss\": 1.486447691917, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/1875\", \"loss\": 1.555776178837, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/1875\", \"loss\": 1.496782660484, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/1875\", \"loss\": 1.781514465809, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/1875\", \"loss\": 1.568892300129, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/1875\", \"loss\": 1.600411474705, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/1875\", \"loss\": 1.775112271309, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/1875\", \"loss\": 1.568629741669, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/1875\", \"loss\": 1.798202931881, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/1875\", \"loss\": 1.591174840927, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"940/1875\", \"loss\": 1.573914051056, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"950/1875\", \"loss\": 1.510788083076, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"960/1875\", \"loss\": 1.441963791847, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"970/1875\", \"loss\": 1.758434832096, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"980/1875\", \"loss\": 1.736380994320, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"990/1875\", \"loss\": 1.804242134094, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1000/1875\", \"loss\": 1.489504337311, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1010/1875\", \"loss\": 1.687722027302, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1020/1875\", \"loss\": 1.504328966141, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1030/1875\", \"loss\": 1.490247905254, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1040/1875\", \"loss\": 1.584446132183, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1050/1875\", \"loss\": 1.623836159706, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1060/1875\", \"loss\": 1.665265262127, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1070/1875\", \"loss\": 1.584752738476, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1080/1875\", \"loss\": 1.831909239292, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1090/1875\", \"loss\": 1.693291425705, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1100/1875\", \"loss\": 1.463950157166, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1110/1875\", \"loss\": 1.708337306976, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1120/1875\", \"loss\": 1.674100399017, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1130/1875\", \"loss\": 1.522969543934, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1140/1875\", \"loss\": 1.423245847225, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1150/1875\", \"loss\": 1.526847720146, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1160/1875\", \"loss\": 1.516581475735, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1170/1875\", \"loss\": 1.808437108994, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1180/1875\", \"loss\": 1.680415809155, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1190/1875\", \"loss\": 1.442620158195, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1200/1875\", \"loss\": 1.467951536179, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1210/1875\", \"loss\": 1.775589048862, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1220/1875\", \"loss\": 1.732668995857, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1230/1875\", \"loss\": 1.672722399235, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1240/1875\", \"loss\": 1.770770668983, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1250/1875\", \"loss\": 1.437047004700, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1260/1875\", \"loss\": 1.665641784668, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1270/1875\", \"loss\": 1.569556236267, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1280/1875\", \"loss\": 1.553577959538, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1290/1875\", \"loss\": 1.643185019493, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1300/1875\", \"loss\": 1.570311605930, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1310/1875\", \"loss\": 1.727271258831, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1320/1875\", \"loss\": 1.561145186424, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1330/1875\", \"loss\": 1.684545159340, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1340/1875\", \"loss\": 1.640008807182, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1350/1875\", \"loss\": 1.530849277973, \"lr\": 0.000012761345, \"top1_err\": 37.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1360/1875\", \"loss\": 1.709292411804, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1370/1875\", \"loss\": 1.608525276184, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1380/1875\", \"loss\": 1.491123318672, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1390/1875\", \"loss\": 1.556725621223, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1400/1875\", \"loss\": 1.580765545368, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1410/1875\", \"loss\": 1.609331130981, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1420/1875\", \"loss\": 1.571196317673, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1430/1875\", \"loss\": 1.558154165745, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1440/1875\", \"loss\": 1.602922379971, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1450/1875\", \"loss\": 1.662866890430, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1460/1875\", \"loss\": 1.553749203682, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1470/1875\", \"loss\": 1.582394301891, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1480/1875\", \"loss\": 1.618105113506, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1490/1875\", \"loss\": 1.460959374905, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1500/1875\", \"loss\": 1.405701220036, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1510/1875\", \"loss\": 1.561653852463, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1520/1875\", \"loss\": 1.710940420628, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1530/1875\", \"loss\": 1.568743526936, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1540/1875\", \"loss\": 1.505254447460, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1550/1875\", \"loss\": 1.466040134430, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1560/1875\", \"loss\": 1.765029728413, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1570/1875\", \"loss\": 1.478553831577, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1580/1875\", \"loss\": 1.446664810181, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1590/1875\", \"loss\": 1.385092377663, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1600/1875\", \"loss\": 1.734639346600, \"lr\": 0.000012761345, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1610/1875\", \"loss\": 1.597394704819, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1620/1875\", \"loss\": 1.508383989334, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1630/1875\", \"loss\": 1.419625163078, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1640/1875\", \"loss\": 1.466262638569, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1650/1875\", \"loss\": 1.510066688061, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1660/1875\", \"loss\": 1.598584830761, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1670/1875\", \"loss\": 1.509364426136, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1680/1875\", \"loss\": 1.814370214939, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1690/1875\", \"loss\": 1.660225331783, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1700/1875\", \"loss\": 1.551375985146, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1710/1875\", \"loss\": 1.585545659065, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1720/1875\", \"loss\": 1.466587543488, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1730/1875\", \"loss\": 1.697002947330, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1740/1875\", \"loss\": 1.622767150402, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1750/1875\", \"loss\": 1.697679460049, \"lr\": 0.000012761345, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1760/1875\", \"loss\": 1.683584272861, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1770/1875\", \"loss\": 1.623212158680, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1780/1875\", \"loss\": 1.479056239128, \"lr\": 0.000012761345, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1790/1875\", \"loss\": 1.681232213974, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1800/1875\", \"loss\": 1.645406961441, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1810/1875\", \"loss\": 1.657699942589, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1820/1875\", \"loss\": 1.695470392704, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1830/1875\", \"loss\": 1.651349067688, \"lr\": 0.000012761345, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1840/1875\", \"loss\": 1.522008419037, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1850/1875\", \"loss\": 1.328696191311, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1860/1875\", \"loss\": 1.391776025295, \"lr\": 0.000012761345, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1870/1875\", \"loss\": 1.504520177841, \"lr\": 0.000012761345, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.616144918442, \"lr\": 0.000012761345, \"top1_err\": 58.273333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 52.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 55.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 54.600000152588, \"top1_err\": 54.600000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_45.39999984741211_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_45.39999984741211_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:26:48,548]\u001b[0m Trial 0 finished with value: 45.39999984741211 and parameters: {'learning_rate': 1.2761345396989285e-05, 'weight_decay': 1.4285695738787422e-08, 'batch_size': 8, 'optimizer': 'SGD'}. Best is trial 0 with value: 45.39999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.00011899385537843203\n",
      "Weight Decay : 2.2293664988776105e-07\n",
      "Batch Size   : 16\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.00011899385537843203\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.2293664988776105e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 938\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/938\", \"loss\": 2.457118988037, \"lr\": 0.000118993855, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/938\", \"loss\": 2.350023508072, \"lr\": 0.000118993855, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/938\", \"loss\": 2.422716140747, \"lr\": 0.000118993855, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/938\", \"loss\": 2.242418527603, \"lr\": 0.000118993855, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/938\", \"loss\": 2.210082173347, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/938\", \"loss\": 2.228752493858, \"lr\": 0.000118993855, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/938\", \"loss\": 2.224196314812, \"lr\": 0.000118993855, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/938\", \"loss\": 2.163409948349, \"lr\": 0.000118993855, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/938\", \"loss\": 2.126937270164, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/938\", \"loss\": 2.142820477486, \"lr\": 0.000118993855, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/938\", \"loss\": 2.135887026787, \"lr\": 0.000118993855, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/938\", \"loss\": 2.087112784386, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/938\", \"loss\": 2.049905657768, \"lr\": 0.000118993855, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/938\", \"loss\": 2.106143951416, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/938\", \"loss\": 2.021621108055, \"lr\": 0.000118993855, \"top1_err\": 78.125000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/938\", \"loss\": 1.914660930634, \"lr\": 0.000118993855, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/938\", \"loss\": 1.978460371494, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/938\", \"loss\": 2.033011198044, \"lr\": 0.000118993855, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/938\", \"loss\": 1.982771337032, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/938\", \"loss\": 2.113540768623, \"lr\": 0.000118993855, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/938\", \"loss\": 2.032211899757, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/938\", \"loss\": 1.879085481167, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/938\", \"loss\": 2.027511477470, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/938\", \"loss\": 1.917579531670, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/938\", \"loss\": 1.979032933712, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/938\", \"loss\": 2.017661929131, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/938\", \"loss\": 1.931277930737, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/938\", \"loss\": 1.878425598145, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/938\", \"loss\": 1.887570977211, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/938\", \"loss\": 1.951434195042, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/938\", \"loss\": 1.900299251080, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/938\", \"loss\": 1.847741186619, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/938\", \"loss\": 1.870192348957, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/938\", \"loss\": 1.916149914265, \"lr\": 0.000118993855, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/938\", \"loss\": 1.779845595360, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/938\", \"loss\": 1.810896754265, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/938\", \"loss\": 1.905714273453, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/938\", \"loss\": 1.782472312450, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/938\", \"loss\": 1.813035726547, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/938\", \"loss\": 1.806524932384, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/938\", \"loss\": 1.743162453175, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/938\", \"loss\": 1.849464952946, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/938\", \"loss\": 1.724272727966, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/938\", \"loss\": 1.801426768303, \"lr\": 0.000118993855, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/938\", \"loss\": 1.871932446957, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/938\", \"loss\": 1.721067845821, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/938\", \"loss\": 1.716839790344, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/938\", \"loss\": 1.867739439011, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/938\", \"loss\": 1.831701159477, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/938\", \"loss\": 1.812042772770, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/938\", \"loss\": 1.814947664738, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/938\", \"loss\": 1.671987414360, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/938\", \"loss\": 1.816921472549, \"lr\": 0.000118993855, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/938\", \"loss\": 1.864301621914, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/938\", \"loss\": 1.838239789009, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/938\", \"loss\": 1.734482049942, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/938\", \"loss\": 1.625375866890, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/938\", \"loss\": 1.720720589161, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/938\", \"loss\": 1.746306300163, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/938\", \"loss\": 1.700126707554, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/938\", \"loss\": 1.623952448368, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/938\", \"loss\": 1.602149069309, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/938\", \"loss\": 1.783786356449, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/938\", \"loss\": 1.624906420708, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/938\", \"loss\": 1.680835604668, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/938\", \"loss\": 1.740000724792, \"lr\": 0.000118993855, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/938\", \"loss\": 1.672437489033, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/938\", \"loss\": 1.508851647377, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/938\", \"loss\": 1.682064712048, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/938\", \"loss\": 1.642603754997, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/938\", \"loss\": 1.684953868389, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/938\", \"loss\": 1.620558738708, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/938\", \"loss\": 1.599318981171, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/938\", \"loss\": 1.561963140965, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/938\", \"loss\": 1.608678996563, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/938\", \"loss\": 1.572059214115, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/938\", \"loss\": 1.638340711594, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/938\", \"loss\": 1.589391291142, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/938\", \"loss\": 1.674359261990, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/938\", \"loss\": 1.602109789848, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/938\", \"loss\": 1.515097498894, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/938\", \"loss\": 1.705910563469, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/938\", \"loss\": 1.728933751583, \"lr\": 0.000118993855, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/938\", \"loss\": 1.672397732735, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/938\", \"loss\": 1.563345730305, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/938\", \"loss\": 1.700111508369, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/938\", \"loss\": 1.707886278629, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/938\", \"loss\": 1.705937027931, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/938\", \"loss\": 1.686842083931, \"lr\": 0.000118993855, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/938\", \"loss\": 1.673589408398, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/938\", \"loss\": 1.584363698959, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/938\", \"loss\": 1.662124335766, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/938\", \"loss\": 1.488501429558, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.843057498042, \"lr\": 0.000118993855, \"top1_err\": 67.800000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 56.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 58.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 58.060001983643, \"top1_err\": 58.060001983643}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/938\", \"loss\": 1.526000499725, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/938\", \"loss\": 1.523263096809, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/938\", \"loss\": 1.644729018211, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/938\", \"loss\": 1.613621652126, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/938\", \"loss\": 1.707027077675, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/938\", \"loss\": 1.603118777275, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/938\", \"loss\": 1.657816350460, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/938\", \"loss\": 1.709592461586, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/938\", \"loss\": 1.556605279446, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/938\", \"loss\": 1.671311497688, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/938\", \"loss\": 1.776695489883, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/938\", \"loss\": 1.585427522659, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/938\", \"loss\": 1.446975767612, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/938\", \"loss\": 1.651154696941, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/938\", \"loss\": 1.618336141109, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/938\", \"loss\": 1.614028632641, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/938\", \"loss\": 1.591027796268, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/938\", \"loss\": 1.493627429008, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/938\", \"loss\": 1.538774669170, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/938\", \"loss\": 1.478707373142, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/938\", \"loss\": 1.562207758427, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/938\", \"loss\": 1.372956216335, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/938\", \"loss\": 1.466443717480, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/938\", \"loss\": 1.402232408524, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/938\", \"loss\": 1.554150819778, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/938\", \"loss\": 1.565887391567, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/938\", \"loss\": 1.570635974407, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/938\", \"loss\": 1.614967525005, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/938\", \"loss\": 1.395809471607, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/938\", \"loss\": 1.316512405872, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/938\", \"loss\": 1.416813671589, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/938\", \"loss\": 1.540265858173, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/938\", \"loss\": 1.540737628937, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/938\", \"loss\": 1.480303883553, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/938\", \"loss\": 1.502756655216, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/938\", \"loss\": 1.367259085178, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/938\", \"loss\": 1.522558033466, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/938\", \"loss\": 1.545435726643, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/938\", \"loss\": 1.515748381615, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/938\", \"loss\": 1.565885424614, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/938\", \"loss\": 1.485985040665, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/938\", \"loss\": 1.468909025192, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/938\", \"loss\": 1.383411467075, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/938\", \"loss\": 1.449925303459, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/938\", \"loss\": 1.690687477589, \"lr\": 0.000118993855, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/938\", \"loss\": 1.541056752205, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/938\", \"loss\": 1.388023972511, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/938\", \"loss\": 1.487663269043, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/938\", \"loss\": 1.548559963703, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/938\", \"loss\": 1.494560360909, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/938\", \"loss\": 1.597486674786, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/938\", \"loss\": 1.515447378159, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/938\", \"loss\": 1.447583854198, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/938\", \"loss\": 1.610125124454, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/938\", \"loss\": 1.353975653648, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/938\", \"loss\": 1.361564218998, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/938\", \"loss\": 1.511058688164, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/938\", \"loss\": 1.467467069626, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/938\", \"loss\": 1.329722940922, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/938\", \"loss\": 1.462698221207, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/938\", \"loss\": 1.523663043976, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/938\", \"loss\": 1.420147180557, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/938\", \"loss\": 1.454365193844, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/938\", \"loss\": 1.528957724571, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/938\", \"loss\": 1.318844437599, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/938\", \"loss\": 1.353928923607, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/938\", \"loss\": 1.376512765884, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/938\", \"loss\": 1.465714812279, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/938\", \"loss\": 1.411288857460, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/938\", \"loss\": 1.490047752857, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/938\", \"loss\": 1.413331866264, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/938\", \"loss\": 1.605113685131, \"lr\": 0.000118993855, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/938\", \"loss\": 1.478875935078, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/938\", \"loss\": 1.563262820244, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/938\", \"loss\": 1.183449745178, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/938\", \"loss\": 1.434792935848, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/938\", \"loss\": 1.482708454132, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/938\", \"loss\": 1.293993651867, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/938\", \"loss\": 1.328212797642, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/938\", \"loss\": 1.389541447163, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/938\", \"loss\": 1.543728590012, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/938\", \"loss\": 1.497878253460, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/938\", \"loss\": 1.511858701706, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/938\", \"loss\": 1.394641280174, \"lr\": 0.000118993855, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/938\", \"loss\": 1.406417846680, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/938\", \"loss\": 1.519025325775, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/938\", \"loss\": 1.335617959499, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/938\", \"loss\": 1.399478077888, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/938\", \"loss\": 1.438528060913, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/938\", \"loss\": 1.403908908367, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/938\", \"loss\": 1.295997142792, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/938\", \"loss\": 1.411813557148, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/938\", \"loss\": 1.311227917671, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.501285085996, \"lr\": 0.000118993855, \"top1_err\": 55.153333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 48.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 51.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 49.700000915527, \"top1_err\": 49.700000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/938\", \"loss\": 1.469936192036, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/938\", \"loss\": 1.320821166039, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/938\", \"loss\": 1.499275684357, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/938\", \"loss\": 1.616431534290, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/938\", \"loss\": 1.376861035824, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/938\", \"loss\": 1.264110147953, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/938\", \"loss\": 1.549025297165, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/938\", \"loss\": 1.313572227955, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/938\", \"loss\": 1.322371542454, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/938\", \"loss\": 1.356153309345, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/938\", \"loss\": 1.369551897049, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/938\", \"loss\": 1.294094622135, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/938\", \"loss\": 1.309612214565, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/938\", \"loss\": 1.472880303860, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/938\", \"loss\": 1.306226372719, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/938\", \"loss\": 1.294790148735, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/938\", \"loss\": 1.448479115963, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/938\", \"loss\": 1.262024044991, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/938\", \"loss\": 1.297043323517, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/938\", \"loss\": 1.319128930569, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/938\", \"loss\": 1.339319407940, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/938\", \"loss\": 1.175547480583, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/938\", \"loss\": 1.177960038185, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/938\", \"loss\": 1.182045638561, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/938\", \"loss\": 1.353006601334, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/938\", \"loss\": 1.302181124687, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/938\", \"loss\": 1.538891375065, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/938\", \"loss\": 1.243956327438, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/938\", \"loss\": 1.223441779613, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/938\", \"loss\": 1.265770375729, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/938\", \"loss\": 1.396183967590, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/938\", \"loss\": 1.465213418007, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/938\", \"loss\": 1.442292630672, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/938\", \"loss\": 1.262800037861, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/938\", \"loss\": 1.386287748814, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/938\", \"loss\": 1.256903827190, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/938\", \"loss\": 1.221360385418, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/938\", \"loss\": 1.386303365231, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/938\", \"loss\": 1.305870294571, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/938\", \"loss\": 1.365927338600, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/938\", \"loss\": 1.160231173038, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/938\", \"loss\": 1.274766385555, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/938\", \"loss\": 1.307995498180, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/938\", \"loss\": 1.449641168118, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/938\", \"loss\": 1.293096065521, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/938\", \"loss\": 1.270150899887, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/938\", \"loss\": 1.438799381256, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/938\", \"loss\": 1.298208415508, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/938\", \"loss\": 1.253570258617, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/938\", \"loss\": 1.366324245930, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/938\", \"loss\": 1.287788510323, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/938\", \"loss\": 1.449643492699, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/938\", \"loss\": 1.210242748260, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/938\", \"loss\": 1.285309731960, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/938\", \"loss\": 1.479985535145, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/938\", \"loss\": 1.286348283291, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/938\", \"loss\": 1.401653945446, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/938\", \"loss\": 1.342325389385, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/938\", \"loss\": 1.207080304623, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/938\", \"loss\": 1.317381799221, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/938\", \"loss\": 1.492289364338, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/938\", \"loss\": 1.429235756397, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/938\", \"loss\": 1.265736341476, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/938\", \"loss\": 1.347018063068, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/938\", \"loss\": 1.283371627331, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/938\", \"loss\": 1.396684408188, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/938\", \"loss\": 1.375657081604, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/938\", \"loss\": 1.342449784279, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/938\", \"loss\": 1.466306090355, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/938\", \"loss\": 1.417856395245, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/938\", \"loss\": 1.491219699383, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/938\", \"loss\": 1.539216756821, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/938\", \"loss\": 1.296414673328, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/938\", \"loss\": 1.278314590454, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/938\", \"loss\": 1.386546969414, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/938\", \"loss\": 1.405246555805, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/938\", \"loss\": 1.210591375828, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/938\", \"loss\": 1.324605286121, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/938\", \"loss\": 1.260365545750, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/938\", \"loss\": 1.356318712234, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/938\", \"loss\": 1.280032575130, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/938\", \"loss\": 1.312691271305, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/938\", \"loss\": 1.317407429218, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/938\", \"loss\": 1.385555207729, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/938\", \"loss\": 1.137442529202, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/938\", \"loss\": 1.331334650517, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/938\", \"loss\": 1.157868385315, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/938\", \"loss\": 1.398286461830, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/938\", \"loss\": 1.317480087280, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/938\", \"loss\": 1.428349018097, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/938\", \"loss\": 1.242912113667, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/938\", \"loss\": 1.203659534454, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/938\", \"loss\": 1.336142539978, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.347630865351, \"lr\": 0.000118993855, \"top1_err\": 48.726666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 45.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 47.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 44.780001831055, \"top1_err\": 44.780001831055}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/938\", \"loss\": 1.288434565067, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/938\", \"loss\": 1.341076970100, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/938\", \"loss\": 1.228005945683, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/938\", \"loss\": 1.276324152946, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/938\", \"loss\": 1.272067427635, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/938\", \"loss\": 1.015339642763, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/938\", \"loss\": 1.273023128510, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/938\", \"loss\": 1.110272645950, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/938\", \"loss\": 1.317853510380, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/938\", \"loss\": 1.306132972240, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/938\", \"loss\": 1.381856858730, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/938\", \"loss\": 1.320737600327, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/938\", \"loss\": 1.197691023350, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/938\", \"loss\": 1.178048968315, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/938\", \"loss\": 1.128265380859, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/938\", \"loss\": 1.267292499542, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/938\", \"loss\": 1.278208792210, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/938\", \"loss\": 1.138844549656, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/938\", \"loss\": 1.403077542782, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/938\", \"loss\": 1.075130701065, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/938\", \"loss\": 1.258958876133, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/938\", \"loss\": 1.363973736763, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/938\", \"loss\": 1.334678530693, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/938\", \"loss\": 1.122088432312, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/938\", \"loss\": 1.270455896854, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/938\", \"loss\": 1.219449937344, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/938\", \"loss\": 1.145069658756, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/938\", \"loss\": 1.149959266186, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/938\", \"loss\": 1.210172653198, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/938\", \"loss\": 1.092168748379, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/938\", \"loss\": 1.131143152714, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/938\", \"loss\": 1.103428006172, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/938\", \"loss\": 1.114521265030, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/938\", \"loss\": 1.181586325169, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/938\", \"loss\": 1.189018964767, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/938\", \"loss\": 1.440344154835, \"lr\": 0.000118993855, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/938\", \"loss\": 1.262999415398, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/938\", \"loss\": 1.095297873020, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/938\", \"loss\": 1.240820705891, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/938\", \"loss\": 1.091348826885, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/938\", \"loss\": 1.302433490753, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/938\", \"loss\": 1.268647253513, \"lr\": 0.000118993855, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/938\", \"loss\": 1.148685634136, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/938\", \"loss\": 1.046775817871, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/938\", \"loss\": 1.081875085831, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/938\", \"loss\": 1.137792587280, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/938\", \"loss\": 1.249606013298, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/938\", \"loss\": 1.405535161495, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/938\", \"loss\": 1.480644166470, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/938\", \"loss\": 1.140170156956, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/938\", \"loss\": 1.259883522987, \"lr\": 0.000118993855, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/938\", \"loss\": 1.170767188072, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/938\", \"loss\": 1.092950224876, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/938\", \"loss\": 1.013800501823, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/938\", \"loss\": 1.250995934010, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/938\", \"loss\": 1.336290836334, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/938\", \"loss\": 1.349452972412, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/938\", \"loss\": 1.097852468491, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/938\", \"loss\": 1.307296216488, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/938\", \"loss\": 1.156174778938, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/938\", \"loss\": 1.295315265656, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/938\", \"loss\": 1.201972663403, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/938\", \"loss\": 1.236008942127, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/938\", \"loss\": 1.106106698513, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/938\", \"loss\": 1.168791055679, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/938\", \"loss\": 1.088490068913, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/938\", \"loss\": 1.096849739552, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/938\", \"loss\": 1.114061415195, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/938\", \"loss\": 1.079227685928, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/938\", \"loss\": 1.049127101898, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/938\", \"loss\": 1.390667796135, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/938\", \"loss\": 1.038461089134, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/938\", \"loss\": 1.253401219845, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/938\", \"loss\": 1.118479907513, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/938\", \"loss\": 1.275445222855, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/938\", \"loss\": 1.268955111504, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/938\", \"loss\": 1.148209631443, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/938\", \"loss\": 1.088430702686, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/938\", \"loss\": 1.173157274723, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/938\", \"loss\": 1.195761322975, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/938\", \"loss\": 1.068483769894, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/938\", \"loss\": 1.118320226669, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/938\", \"loss\": 1.220495820045, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/938\", \"loss\": 1.348089277744, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/938\", \"loss\": 1.271957457066, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/938\", \"loss\": 1.100201606750, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/938\", \"loss\": 1.210909068584, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/938\", \"loss\": 1.136158525944, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/938\", \"loss\": 1.108881115913, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/938\", \"loss\": 1.227837026119, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/938\", \"loss\": 1.327501833439, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/938\", \"loss\": 1.221469283104, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/938\", \"loss\": 1.136620044708, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.233411267503, \"lr\": 0.000118993855, \"top1_err\": 44.133333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 42.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 44.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 43.880001373291, \"top1_err\": 43.880001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/938\", \"loss\": 1.106095969677, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/938\", \"loss\": 1.193090617657, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/938\", \"loss\": 1.228379666805, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/938\", \"loss\": 0.875610679388, \"lr\": 0.000118993855, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/938\", \"loss\": 1.030116289854, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/938\", \"loss\": 1.170394301414, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/938\", \"loss\": 1.196079790592, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/938\", \"loss\": 0.953028470278, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/938\", \"loss\": 0.938467592001, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/938\", \"loss\": 1.192560970783, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/938\", \"loss\": 1.021435856819, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/938\", \"loss\": 1.171169161797, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/938\", \"loss\": 1.113040030003, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/938\", \"loss\": 0.976149260998, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/938\", \"loss\": 1.166887521744, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/938\", \"loss\": 1.036055386066, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/938\", \"loss\": 1.264093399048, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/938\", \"loss\": 1.063309073448, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/938\", \"loss\": 1.147314071655, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/938\", \"loss\": 1.341279566288, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/938\", \"loss\": 1.139686167240, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/938\", \"loss\": 1.204139649868, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/938\", \"loss\": 1.061160862446, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/938\", \"loss\": 1.243852913380, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/938\", \"loss\": 1.075549006462, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/938\", \"loss\": 1.023855149746, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/938\", \"loss\": 0.973202109337, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/938\", \"loss\": 1.124754548073, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/938\", \"loss\": 1.325698316097, \"lr\": 0.000118993855, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/938\", \"loss\": 1.173332929611, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/938\", \"loss\": 1.093636453152, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/938\", \"loss\": 1.202531099319, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/938\", \"loss\": 1.176892578602, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/938\", \"loss\": 0.959166109562, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/938\", \"loss\": 1.045719474554, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/938\", \"loss\": 1.086360216141, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/938\", \"loss\": 1.235756278038, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/938\", \"loss\": 0.937270045280, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/938\", \"loss\": 0.979631572962, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/938\", \"loss\": 1.007259130478, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/938\", \"loss\": 1.112762749195, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/938\", \"loss\": 1.059787690639, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/938\", \"loss\": 1.141823410988, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/938\", \"loss\": 1.201756715775, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/938\", \"loss\": 1.013410210609, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/938\", \"loss\": 1.241636991501, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/938\", \"loss\": 1.121434628963, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/938\", \"loss\": 1.019125133753, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/938\", \"loss\": 1.302363574505, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/938\", \"loss\": 1.041237711906, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/938\", \"loss\": 1.071064531803, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/938\", \"loss\": 1.119409680367, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/938\", \"loss\": 1.193793714046, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/938\", \"loss\": 1.254576504230, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/938\", \"loss\": 1.143945157528, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/938\", \"loss\": 1.216260910034, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/938\", \"loss\": 1.001445919275, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/938\", \"loss\": 1.083244323730, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/938\", \"loss\": 1.123887300491, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/938\", \"loss\": 0.848843365908, \"lr\": 0.000118993855, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/938\", \"loss\": 1.404458105564, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/938\", \"loss\": 1.169414758682, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/938\", \"loss\": 1.091080129147, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/938\", \"loss\": 1.119260072708, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/938\", \"loss\": 1.250371634960, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/938\", \"loss\": 1.153351664543, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/938\", \"loss\": 1.190565943718, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/938\", \"loss\": 1.189462542534, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/938\", \"loss\": 1.101211369038, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/938\", \"loss\": 0.943442195654, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/938\", \"loss\": 0.999019980431, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/938\", \"loss\": 1.054782211781, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/938\", \"loss\": 1.062436997890, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/938\", \"loss\": 1.046562433243, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/938\", \"loss\": 0.876063615084, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/938\", \"loss\": 1.016998708248, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/938\", \"loss\": 1.199635565281, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/938\", \"loss\": 1.177111208439, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/938\", \"loss\": 0.994776308537, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/938\", \"loss\": 1.082196533680, \"lr\": 0.000118993855, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/938\", \"loss\": 1.046204447746, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/938\", \"loss\": 0.941114783287, \"lr\": 0.000118993855, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/938\", \"loss\": 1.014118432999, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/938\", \"loss\": 1.171121478081, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/938\", \"loss\": 1.090314447880, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/938\", \"loss\": 1.000748336315, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/938\", \"loss\": 1.249905586243, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/938\", \"loss\": 1.163520693779, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/938\", \"loss\": 1.127724885941, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/938\", \"loss\": 1.216379463673, \"lr\": 0.000118993855, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/938\", \"loss\": 1.145615100861, \"lr\": 0.000118993855, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/938\", \"loss\": 1.045176804066, \"lr\": 0.000118993855, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/938\", \"loss\": 1.115708112717, \"lr\": 0.000118993855, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.122022377364, \"lr\": 0.000118993855, \"top1_err\": 40.086666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 41.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 41.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 41.000001068115, \"top1_err\": 41.000001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_58.99999893188477_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_58.99999893188477_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:32:46,931]\u001b[0m Trial 1 finished with value: 58.99999893188477 and parameters: {'learning_rate': 0.00011899385537843203, 'weight_decay': 2.2293664988776105e-07, 'batch_size': 16, 'optimizer': 'SGD'}. Best is trial 1 with value: 58.99999893188477.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 3.529744810375054e-05\n",
      "Weight Decay : 8.552243451626917e-05\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 3.529744810375054e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 8.552243451626917e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 118\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/118\", \"loss\": 2.478874921799, \"lr\": 0.000035297448, \"top1_err\": 90.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/118\", \"loss\": 2.427047133446, \"lr\": 0.000035297448, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/118\", \"loss\": 2.432278275490, \"lr\": 0.000035297448, \"top1_err\": 91.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/118\", \"loss\": 2.368846416473, \"lr\": 0.000035297448, \"top1_err\": 89.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/118\", \"loss\": 2.321448802948, \"lr\": 0.000035297448, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/118\", \"loss\": 2.310140132904, \"lr\": 0.000035297448, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/118\", \"loss\": 2.306184053421, \"lr\": 0.000035297448, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/118\", \"loss\": 2.267379403114, \"lr\": 0.000035297448, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/118\", \"loss\": 2.263889670372, \"lr\": 0.000035297448, \"top1_err\": 79.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/118\", \"loss\": 2.258327722549, \"lr\": 0.000035297448, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/118\", \"loss\": 2.233739852905, \"lr\": 0.000035297448, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.328884912745, \"lr\": 0.000035297448, \"top1_err\": 85.233333329264}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 82.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 78.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 79.580000000000, \"top1_err\": 79.580000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/118\", \"loss\": 2.215705871582, \"lr\": 0.000035297448, \"top1_err\": 78.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/118\", \"loss\": 2.218436717987, \"lr\": 0.000035297448, \"top1_err\": 78.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/118\", \"loss\": 2.196274399757, \"lr\": 0.000035297448, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/118\", \"loss\": 2.186134576797, \"lr\": 0.000035297448, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/118\", \"loss\": 2.174936294556, \"lr\": 0.000035297448, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/118\", \"loss\": 2.158652544022, \"lr\": 0.000035297448, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/118\", \"loss\": 2.167428612709, \"lr\": 0.000035297448, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/118\", \"loss\": 2.141850113869, \"lr\": 0.000035297448, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/118\", \"loss\": 2.149914026260, \"lr\": 0.000035297448, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/118\", \"loss\": 2.141057729721, \"lr\": 0.000035297448, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/118\", \"loss\": 2.144163370132, \"lr\": 0.000035297448, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.170438321431, \"lr\": 0.000035297448, \"top1_err\": 77.033333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 75.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 75.440000305176, \"top1_err\": 75.440000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/118\", \"loss\": 2.117560863495, \"lr\": 0.000035297448, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/118\", \"loss\": 2.118837475777, \"lr\": 0.000035297448, \"top1_err\": 73.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/118\", \"loss\": 2.086187839508, \"lr\": 0.000035297448, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/118\", \"loss\": 2.100562214851, \"lr\": 0.000035297448, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/118\", \"loss\": 2.085032820702, \"lr\": 0.000035297448, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/118\", \"loss\": 2.072759389877, \"lr\": 0.000035297448, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/118\", \"loss\": 2.076817989349, \"lr\": 0.000035297448, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/118\", \"loss\": 2.085620045662, \"lr\": 0.000035297448, \"top1_err\": 73.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/118\", \"loss\": 2.079829216003, \"lr\": 0.000035297448, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/118\", \"loss\": 2.047620177269, \"lr\": 0.000035297448, \"top1_err\": 73.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/118\", \"loss\": 2.064247727394, \"lr\": 0.000035297448, \"top1_err\": 73.828125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.083312780762, \"lr\": 0.000035297448, \"top1_err\": 73.979999995931}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 73.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 74.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 73.300000915527, \"top1_err\": 73.300000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/118\", \"loss\": 2.038640141487, \"lr\": 0.000035297448, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/118\", \"loss\": 2.040736556053, \"lr\": 0.000035297448, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/118\", \"loss\": 2.030405640602, \"lr\": 0.000035297448, \"top1_err\": 73.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/118\", \"loss\": 2.009478569031, \"lr\": 0.000035297448, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/118\", \"loss\": 2.030062794685, \"lr\": 0.000035297448, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/118\", \"loss\": 1.977103054523, \"lr\": 0.000035297448, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/118\", \"loss\": 2.009356498718, \"lr\": 0.000035297448, \"top1_err\": 72.656250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/118\", \"loss\": 2.009302973747, \"lr\": 0.000035297448, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/118\", \"loss\": 2.009596109390, \"lr\": 0.000035297448, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/118\", \"loss\": 2.005921840668, \"lr\": 0.000035297448, \"top1_err\": 73.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/118\", \"loss\": 1.995851457119, \"lr\": 0.000035297448, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.012400661977, \"lr\": 0.000035297448, \"top1_err\": 71.686666662598}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 71.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 72.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 71.920000610352, \"top1_err\": 71.920000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/118\", \"loss\": 1.956584990025, \"lr\": 0.000035297448, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/118\", \"loss\": 1.972751140594, \"lr\": 0.000035297448, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/118\", \"loss\": 1.983120799065, \"lr\": 0.000035297448, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/118\", \"loss\": 1.993339121342, \"lr\": 0.000035297448, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/118\", \"loss\": 1.938577055931, \"lr\": 0.000035297448, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/118\", \"loss\": 1.965052783489, \"lr\": 0.000035297448, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/118\", \"loss\": 1.965759277344, \"lr\": 0.000035297448, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/118\", \"loss\": 1.943402051926, \"lr\": 0.000035297448, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/118\", \"loss\": 1.969237089157, \"lr\": 0.000035297448, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/118\", \"loss\": 1.903720974922, \"lr\": 0.000035297448, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/118\", \"loss\": 1.946029901505, \"lr\": 0.000035297448, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.954658585421, \"lr\": 0.000035297448, \"top1_err\": 69.946666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 70.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 71.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 70.860000305176, \"top1_err\": 70.860000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_29.139999694824212_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_29.139999694824212_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:33:52,414]\u001b[0m Trial 2 finished with value: 29.139999694824212 and parameters: {'learning_rate': 3.529744810375054e-05, 'weight_decay': 8.552243451626917e-05, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 1 with value: 58.99999893188477.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.00013086153945855546\n",
      "Weight Decay : 1.8698565734595045e-08\n",
      "Batch Size   : 128\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00013086153945855546\n",
      "    weight_decay: 1.8698565734595045e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 118\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/118\", \"loss\": 2.124611616135, \"lr\": 0.000130861539, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/118\", \"loss\": 1.751504361629, \"lr\": 0.000130861539, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/118\", \"loss\": 1.665858387947, \"lr\": 0.000130861539, \"top1_err\": 58.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/118\", \"loss\": 1.591514766216, \"lr\": 0.000130861539, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/118\", \"loss\": 1.504172086716, \"lr\": 0.000130861539, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/118\", \"loss\": 1.552362918854, \"lr\": 0.000130861539, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/118\", \"loss\": 1.506336688995, \"lr\": 0.000130861539, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/118\", \"loss\": 1.406826913357, \"lr\": 0.000130861539, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/118\", \"loss\": 1.399497866631, \"lr\": 0.000130861539, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/118\", \"loss\": 1.394782364368, \"lr\": 0.000130861539, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/118\", \"loss\": 1.417402148247, \"lr\": 0.000130861539, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.561463879712, \"lr\": 0.000130861539, \"top1_err\": 57.540000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 49.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 49.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 49.400000305176, \"top1_err\": 49.400000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/118\", \"loss\": 1.227866113186, \"lr\": 0.000130861539, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/118\", \"loss\": 1.262586653233, \"lr\": 0.000130861539, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/118\", \"loss\": 1.141815066338, \"lr\": 0.000130861539, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/118\", \"loss\": 1.121574103832, \"lr\": 0.000130861539, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/118\", \"loss\": 1.227616786957, \"lr\": 0.000130861539, \"top1_err\": 45.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/118\", \"loss\": 1.171457946301, \"lr\": 0.000130861539, \"top1_err\": 42.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/118\", \"loss\": 1.193382859230, \"lr\": 0.000130861539, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/118\", \"loss\": 1.151093542576, \"lr\": 0.000130861539, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/118\", \"loss\": 1.157079935074, \"lr\": 0.000130861539, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/118\", \"loss\": 1.102512121201, \"lr\": 0.000130861539, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/118\", \"loss\": 1.122588038445, \"lr\": 0.000130861539, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.169661861738, \"lr\": 0.000130861539, \"top1_err\": 42.446666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 42.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 45.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 43.740001220703, \"top1_err\": 43.740001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/118\", \"loss\": 0.995885282755, \"lr\": 0.000130861539, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/118\", \"loss\": 0.928693354130, \"lr\": 0.000130861539, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/118\", \"loss\": 0.856254488230, \"lr\": 0.000130861539, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/118\", \"loss\": 0.959237068892, \"lr\": 0.000130861539, \"top1_err\": 33.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/118\", \"loss\": 0.920575171709, \"lr\": 0.000130861539, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/118\", \"loss\": 0.949176460505, \"lr\": 0.000130861539, \"top1_err\": 32.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/118\", \"loss\": 0.860014140606, \"lr\": 0.000130861539, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/118\", \"loss\": 0.878998547792, \"lr\": 0.000130861539, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/118\", \"loss\": 0.987789154053, \"lr\": 0.000130861539, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/118\", \"loss\": 0.976919323206, \"lr\": 0.000130861539, \"top1_err\": 34.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/118\", \"loss\": 0.940866112709, \"lr\": 0.000130861539, \"top1_err\": 33.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 0.938812302017, \"lr\": 0.000130861539, \"top1_err\": 33.460000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 39.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 40.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 40.560001373291, \"top1_err\": 40.560001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/118\", \"loss\": 0.771203756332, \"lr\": 0.000130861539, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/118\", \"loss\": 0.764570593834, \"lr\": 0.000130861539, \"top1_err\": 25.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/118\", \"loss\": 0.755194336176, \"lr\": 0.000130861539, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/118\", \"loss\": 0.733958482742, \"lr\": 0.000130861539, \"top1_err\": 23.828125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/118\", \"loss\": 0.762258261442, \"lr\": 0.000130861539, \"top1_err\": 26.171875000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/118\", \"loss\": 0.724563360214, \"lr\": 0.000130861539, \"top1_err\": 25.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/118\", \"loss\": 0.796068966389, \"lr\": 0.000130861539, \"top1_err\": 26.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/118\", \"loss\": 0.797468781471, \"lr\": 0.000130861539, \"top1_err\": 26.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/118\", \"loss\": 0.727263301611, \"lr\": 0.000130861539, \"top1_err\": 26.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/118\", \"loss\": 0.720019817352, \"lr\": 0.000130861539, \"top1_err\": 24.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/118\", \"loss\": 0.810005277395, \"lr\": 0.000130861539, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.759037385972, \"lr\": 0.000130861539, \"top1_err\": 26.793333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 38.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 39.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 38.540001373291, \"top1_err\": 38.540001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/118\", \"loss\": 0.579336851835, \"lr\": 0.000130861539, \"top1_err\": 19.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/118\", \"loss\": 0.597654283047, \"lr\": 0.000130861539, \"top1_err\": 19.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/118\", \"loss\": 0.597830265760, \"lr\": 0.000130861539, \"top1_err\": 19.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/118\", \"loss\": 0.557883232832, \"lr\": 0.000130861539, \"top1_err\": 18.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/118\", \"loss\": 0.593648701906, \"lr\": 0.000130861539, \"top1_err\": 21.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/118\", \"loss\": 0.613490819931, \"lr\": 0.000130861539, \"top1_err\": 22.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/118\", \"loss\": 0.624125421047, \"lr\": 0.000130861539, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/118\", \"loss\": 0.574793577194, \"lr\": 0.000130861539, \"top1_err\": 19.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/118\", \"loss\": 0.660976618528, \"lr\": 0.000130861539, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/118\", \"loss\": 0.621339857578, \"lr\": 0.000130861539, \"top1_err\": 21.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/118\", \"loss\": 0.677568167448, \"lr\": 0.000130861539, \"top1_err\": 20.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.607774676545, \"lr\": 0.000130861539, \"top1_err\": 20.700000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 37.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 36.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 36.140001602173, \"top1_err\": 36.140001602173}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:35:04,965]\u001b[0m Trial 3 finished with value: 63.85999839782715 and parameters: {'learning_rate': 0.00013086153945855546, 'weight_decay': 1.8698565734595045e-08, 'batch_size': 128, 'optimizer': 'ADAM'}. Best is trial 3 with value: 63.85999839782715.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 7.671529475814331e-05\n",
      "Weight Decay : 2.5862372104018316e-06\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 7.671529475814331e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.5862372104018316e-06\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_66.37999809265136_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 59\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/59\", \"loss\": 2.454147338867, \"lr\": 0.000076715295, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/59\", \"loss\": 2.407711148262, \"lr\": 0.000076715295, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/59\", \"loss\": 2.343316435814, \"lr\": 0.000076715295, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/59\", \"loss\": 2.285722017288, \"lr\": 0.000076715295, \"top1_err\": 83.398437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/59\", \"loss\": 2.263456940651, \"lr\": 0.000076715295, \"top1_err\": 80.273437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.335416455078, \"lr\": 0.000076715295, \"top1_err\": 85.473333349609}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 80.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 78.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 79.740000000000, \"top1_err\": 79.740000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/59\", \"loss\": 2.209553956985, \"lr\": 0.000076715295, \"top1_err\": 78.710937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/59\", \"loss\": 2.189738512039, \"lr\": 0.000076715295, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/59\", \"loss\": 2.163738131523, \"lr\": 0.000076715295, \"top1_err\": 75.585937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/59\", \"loss\": 2.150070786476, \"lr\": 0.000076715295, \"top1_err\": 76.757812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/59\", \"loss\": 2.136205554008, \"lr\": 0.000076715295, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.164748901113, \"lr\": 0.000076715295, \"top1_err\": 77.020000020345}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 76.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 77.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 75.500000305176, \"top1_err\": 75.500000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/59\", \"loss\": 2.109708189964, \"lr\": 0.000076715295, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/59\", \"loss\": 2.087326645851, \"lr\": 0.000076715295, \"top1_err\": 75.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/59\", \"loss\": 2.070354700089, \"lr\": 0.000076715295, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/59\", \"loss\": 2.067443609238, \"lr\": 0.000076715295, \"top1_err\": 72.851562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/59\", \"loss\": 2.051992774010, \"lr\": 0.000076715295, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.073548102697, \"lr\": 0.000076715295, \"top1_err\": 73.973333369954}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 73.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 76.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 73.340000305176, \"top1_err\": 73.340000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/59\", \"loss\": 2.030075550079, \"lr\": 0.000076715295, \"top1_err\": 69.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/59\", \"loss\": 2.005611181259, \"lr\": 0.000076715295, \"top1_err\": 70.898437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/59\", \"loss\": 2.012297511101, \"lr\": 0.000076715295, \"top1_err\": 71.289062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/59\", \"loss\": 1.989083051682, \"lr\": 0.000076715295, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/59\", \"loss\": 1.994211614132, \"lr\": 0.000076715295, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.999541618729, \"lr\": 0.000076715295, \"top1_err\": 70.993333325195}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 71.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 73.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 71.860000915527, \"top1_err\": 71.860000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/59\", \"loss\": 1.962396204472, \"lr\": 0.000076715295, \"top1_err\": 68.164062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/59\", \"loss\": 1.968474626541, \"lr\": 0.000076715295, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/59\", \"loss\": 1.936014115810, \"lr\": 0.000076715295, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/59\", \"loss\": 1.940848648548, \"lr\": 0.000076715295, \"top1_err\": 70.507812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/59\", \"loss\": 1.923297107220, \"lr\": 0.000076715295, \"top1_err\": 68.945312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.940952663231, \"lr\": 0.000076715295, \"top1_err\": 69.619999979655}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 70.250007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 71.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 70.300001220703, \"top1_err\": 70.300001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_29.699998779296877_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_29.699998779296877_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:35:58,258]\u001b[0m Trial 4 finished with value: 29.699998779296877 and parameters: {'learning_rate': 7.671529475814331e-05, 'weight_decay': 2.5862372104018316e-06, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 3 with value: 63.85999839782715.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 1188.9649217128754 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 63.85999839782715\n",
      "  Params: \n",
      "    learning_rate: 0.00013086153945855546\n",
      "    weight_decay: 1.8698565734595045e-08\n",
      "    batch_size: 128\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_eltjs48g.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: resnet_2\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  25000\n",
      "len(lSEt):  15000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 20000 and len(uSet): 25000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  25000\n",
      "len(lSet):  20000\n",
      "For random sampling, activeSet accuracy:  63.2\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 37.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 35.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 33.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 37.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 36.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 35.810001792908, \"top1_err\": 35.810001792908}\n",
      "Test Accuracy: 64.190\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on CIFAR10 using 30.0% of data is 64.18999820709229\n",
      "\n",
      "Extracted Test Accuracy from subproces: 64.18999820709229\n",
      "Finished test net subprocess call\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_eyqixzyv.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:36:40,358]\u001b[0m A new study created in memory with name: no-name-80a38c34-8e2b-4c7f-bec9-88c5721b3b06\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.00022393016137387868\n",
      "Weight Decay : 3.948993902421533e-08\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.00022393016137387868\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 3.948993902421533e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.438089489937, \"lr\": 0.000223930161, \"top1_err\": 90.429687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.312142372131, \"lr\": 0.000223930161, \"top1_err\": 83.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.228940963745, \"lr\": 0.000223930161, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 2.178638219833, \"lr\": 0.000223930161, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 2.155637860298, \"lr\": 0.000223930161, \"top1_err\": 78.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 2.082853198051, \"lr\": 0.000223930161, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 2.055734515190, \"lr\": 0.000223930161, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.189218938255, \"lr\": 0.000223930161, \"top1_err\": 78.970000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 73.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 72.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 72.540000000000, \"top1_err\": 72.540000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 1.971271276474, \"lr\": 0.000223930161, \"top1_err\": 69.726562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 1.961121439934, \"lr\": 0.000223930161, \"top1_err\": 71.289062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 1.955514311790, \"lr\": 0.000223930161, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 1.938765227795, \"lr\": 0.000223930161, \"top1_err\": 68.945312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 1.890779972076, \"lr\": 0.000223930161, \"top1_err\": 66.992187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 1.878086686134, \"lr\": 0.000223930161, \"top1_err\": 67.382812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 1.864972233772, \"lr\": 0.000223930161, \"top1_err\": 67.382812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.909409915924, \"lr\": 0.000223930161, \"top1_err\": 68.950000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 67.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 65.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 66.540000610352, \"top1_err\": 66.540000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 1.815938055515, \"lr\": 0.000223930161, \"top1_err\": 66.210937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 1.813040614128, \"lr\": 0.000223930161, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 1.763827323914, \"lr\": 0.000223930161, \"top1_err\": 64.648437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 1.728595316410, \"lr\": 0.000223930161, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 1.753154635429, \"lr\": 0.000223930161, \"top1_err\": 65.234375000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 1.709064304829, \"lr\": 0.000223930161, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 1.699077725410, \"lr\": 0.000223930161, \"top1_err\": 61.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.747684920502, \"lr\": 0.000223930161, \"top1_err\": 63.760000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 64.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 61.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 62.140000305176, \"top1_err\": 62.140000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 1.669434070587, \"lr\": 0.000223930161, \"top1_err\": 61.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 1.649983048439, \"lr\": 0.000223930161, \"top1_err\": 59.179687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 1.694091379642, \"lr\": 0.000223930161, \"top1_err\": 60.351562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 1.615218460560, \"lr\": 0.000223930161, \"top1_err\": 58.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 1.595261037350, \"lr\": 0.000223930161, \"top1_err\": 56.054687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 1.604561090469, \"lr\": 0.000223930161, \"top1_err\": 58.789062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 1.584911286831, \"lr\": 0.000223930161, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.624165291405, \"lr\": 0.000223930161, \"top1_err\": 59.020000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 58.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 58.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 58.540000762939, \"top1_err\": 58.540000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 1.514444530010, \"lr\": 0.000223930161, \"top1_err\": 52.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 1.544367253780, \"lr\": 0.000223930161, \"top1_err\": 55.273437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 1.536451578140, \"lr\": 0.000223930161, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 1.561898410320, \"lr\": 0.000223930161, \"top1_err\": 57.226562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 1.544695794582, \"lr\": 0.000223930161, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 1.518462538719, \"lr\": 0.000223930161, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 1.523156762123, \"lr\": 0.000223930161, \"top1_err\": 54.882812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.532911178398, \"lr\": 0.000223930161, \"top1_err\": 55.905000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 54.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 56.040001525879, \"top1_err\": 56.040001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_43.95999847412109_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-0/checkpoints/vlBest_acc_43.95999847412109_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:38:05,584]\u001b[0m Trial 0 finished with value: 43.95999847412109 and parameters: {'learning_rate': 0.00022393016137387868, 'weight_decay': 3.948993902421533e-08, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 0 with value: 43.95999847412109.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.00015981678818517418\n",
      "Weight Decay : 3.4566036820467953e-07\n",
      "Batch Size   : 8\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.00015981678818517418\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 3.4566036820467953e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 2500\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/2500\", \"loss\": 2.379326343536, \"lr\": 0.000159816788, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/2500\", \"loss\": 2.316837787628, \"lr\": 0.000159816788, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/2500\", \"loss\": 2.290377140045, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/2500\", \"loss\": 2.336131691933, \"lr\": 0.000159816788, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/2500\", \"loss\": 2.244536161423, \"lr\": 0.000159816788, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/2500\", \"loss\": 2.241513490677, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/2500\", \"loss\": 2.149051666260, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/2500\", \"loss\": 2.234337925911, \"lr\": 0.000159816788, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/2500\", \"loss\": 2.173808813095, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/2500\", \"loss\": 2.126090288162, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/2500\", \"loss\": 2.137880682945, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/2500\", \"loss\": 2.085551261902, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/2500\", \"loss\": 2.146823406219, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/2500\", \"loss\": 2.067374229431, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/2500\", \"loss\": 2.094063878059, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/2500\", \"loss\": 2.007993221283, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/2500\", \"loss\": 1.996384263039, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/2500\", \"loss\": 1.785744488239, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/2500\", \"loss\": 2.097046136856, \"lr\": 0.000159816788, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/2500\", \"loss\": 2.042038321495, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/2500\", \"loss\": 1.964480757713, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/2500\", \"loss\": 2.011863470078, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/2500\", \"loss\": 1.978983342648, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/2500\", \"loss\": 1.891825795174, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/2500\", \"loss\": 2.020945131779, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/2500\", \"loss\": 1.904853641987, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/2500\", \"loss\": 1.767831683159, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/2500\", \"loss\": 1.978278815746, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/2500\", \"loss\": 1.901138424873, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/2500\", \"loss\": 1.974733054638, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/2500\", \"loss\": 2.017734766006, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/2500\", \"loss\": 2.054849267006, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/2500\", \"loss\": 1.848465085030, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/2500\", \"loss\": 1.820971310139, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/2500\", \"loss\": 1.727865397930, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/2500\", \"loss\": 1.863120973110, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/2500\", \"loss\": 1.807127952576, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/2500\", \"loss\": 1.835284113884, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/2500\", \"loss\": 1.953916370869, \"lr\": 0.000159816788, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/2500\", \"loss\": 1.829703330994, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/2500\", \"loss\": 1.857843697071, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/2500\", \"loss\": 1.835297882557, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/2500\", \"loss\": 1.729049861431, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/2500\", \"loss\": 2.012976527214, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/2500\", \"loss\": 1.756741762161, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/2500\", \"loss\": 1.816225349903, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/2500\", \"loss\": 1.828986763954, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/2500\", \"loss\": 1.789833128452, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/2500\", \"loss\": 1.648491322994, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/2500\", \"loss\": 1.941594958305, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/2500\", \"loss\": 1.862482070923, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/2500\", \"loss\": 1.761223673820, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/2500\", \"loss\": 1.635049462318, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/2500\", \"loss\": 1.682874381542, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/2500\", \"loss\": 1.748452901840, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/2500\", \"loss\": 1.714211583138, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/2500\", \"loss\": 1.752218961716, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/2500\", \"loss\": 1.775887668133, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/2500\", \"loss\": 1.725901186466, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/2500\", \"loss\": 1.813216984272, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/2500\", \"loss\": 1.822223603725, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/2500\", \"loss\": 1.802491128445, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/2500\", \"loss\": 1.853478074074, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/2500\", \"loss\": 1.723741471767, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/2500\", \"loss\": 1.754361569881, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/2500\", \"loss\": 1.975254595280, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/2500\", \"loss\": 1.755839824677, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/2500\", \"loss\": 1.937216818333, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/2500\", \"loss\": 1.638197541237, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/2500\", \"loss\": 1.704338312149, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/2500\", \"loss\": 1.723674952984, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/2500\", \"loss\": 1.611240625381, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/2500\", \"loss\": 1.618312776089, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/2500\", \"loss\": 1.768041312695, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/2500\", \"loss\": 1.803818464279, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/2500\", \"loss\": 1.649121761322, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/2500\", \"loss\": 1.745906710625, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/2500\", \"loss\": 1.610416114330, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/2500\", \"loss\": 1.644180834293, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/2500\", \"loss\": 1.646090745926, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/2500\", \"loss\": 1.661257147789, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/2500\", \"loss\": 1.918255150318, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/2500\", \"loss\": 1.571929752827, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/2500\", \"loss\": 1.650136113167, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/2500\", \"loss\": 1.555252969265, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/2500\", \"loss\": 1.709474503994, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/2500\", \"loss\": 1.804485857487, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/2500\", \"loss\": 1.655931890011, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/2500\", \"loss\": 1.699908912182, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/2500\", \"loss\": 1.496936023235, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/2500\", \"loss\": 1.640490949154, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/2500\", \"loss\": 1.620364964008, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/2500\", \"loss\": 1.601747035980, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"940/2500\", \"loss\": 1.687330901623, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"950/2500\", \"loss\": 1.605156838894, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"960/2500\", \"loss\": 1.690932691097, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"970/2500\", \"loss\": 1.650650382042, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"980/2500\", \"loss\": 1.818564176559, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"990/2500\", \"loss\": 1.617075443268, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1000/2500\", \"loss\": 1.661047399044, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1010/2500\", \"loss\": 1.575044155121, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1020/2500\", \"loss\": 1.385323047638, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1030/2500\", \"loss\": 1.482741296291, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1040/2500\", \"loss\": 1.654739141464, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1050/2500\", \"loss\": 1.742890775204, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1060/2500\", \"loss\": 1.629039883614, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1070/2500\", \"loss\": 1.526196658611, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1080/2500\", \"loss\": 1.709610641003, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1090/2500\", \"loss\": 1.557464778423, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1100/2500\", \"loss\": 1.493384242058, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1110/2500\", \"loss\": 1.512221455574, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1120/2500\", \"loss\": 1.546508193016, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1130/2500\", \"loss\": 1.672169804573, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1140/2500\", \"loss\": 1.444121122360, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1150/2500\", \"loss\": 1.583531677723, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1160/2500\", \"loss\": 1.447544693947, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1170/2500\", \"loss\": 1.742554306984, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1180/2500\", \"loss\": 1.474279820919, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1190/2500\", \"loss\": 1.845746338367, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1200/2500\", \"loss\": 1.801508069038, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1210/2500\", \"loss\": 1.561133861542, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1220/2500\", \"loss\": 1.456799209118, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1230/2500\", \"loss\": 1.546443879604, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1240/2500\", \"loss\": 1.602194309235, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1250/2500\", \"loss\": 1.711386144161, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1260/2500\", \"loss\": 1.498800575733, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1270/2500\", \"loss\": 1.776236355305, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1280/2500\", \"loss\": 1.501735925674, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1290/2500\", \"loss\": 1.567189812660, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1300/2500\", \"loss\": 1.443519532681, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1310/2500\", \"loss\": 1.741709113121, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1320/2500\", \"loss\": 1.743349969387, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1330/2500\", \"loss\": 1.437478780746, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1340/2500\", \"loss\": 1.538978338242, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1350/2500\", \"loss\": 1.531274259090, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1360/2500\", \"loss\": 1.481328308582, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1370/2500\", \"loss\": 1.431022763252, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1380/2500\", \"loss\": 1.540958583355, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1390/2500\", \"loss\": 1.651985585690, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1400/2500\", \"loss\": 1.597269535065, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1410/2500\", \"loss\": 1.790564358234, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1420/2500\", \"loss\": 1.481696367264, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1430/2500\", \"loss\": 1.597721099854, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1440/2500\", \"loss\": 1.493319749832, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1450/2500\", \"loss\": 1.814701974392, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1460/2500\", \"loss\": 1.504177391529, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1470/2500\", \"loss\": 1.543936371803, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1480/2500\", \"loss\": 1.562804698944, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1490/2500\", \"loss\": 1.635389149189, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1500/2500\", \"loss\": 1.716946959496, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1510/2500\", \"loss\": 1.558615088463, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1520/2500\", \"loss\": 1.395051777363, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1530/2500\", \"loss\": 1.603897809982, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1540/2500\", \"loss\": 1.464867055416, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1550/2500\", \"loss\": 1.677666902542, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1560/2500\", \"loss\": 1.813802719116, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1570/2500\", \"loss\": 1.627013444901, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1580/2500\", \"loss\": 1.494594812393, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1590/2500\", \"loss\": 1.448498368263, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1600/2500\", \"loss\": 1.606156706810, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1610/2500\", \"loss\": 1.422528862953, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1620/2500\", \"loss\": 1.223149597645, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1630/2500\", \"loss\": 1.589742302895, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1640/2500\", \"loss\": 1.537948369980, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1650/2500\", \"loss\": 1.658063888550, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1660/2500\", \"loss\": 1.641482651234, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1670/2500\", \"loss\": 1.507960140705, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1680/2500\", \"loss\": 1.462929129601, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1690/2500\", \"loss\": 1.730658292770, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1700/2500\", \"loss\": 1.637964606285, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1710/2500\", \"loss\": 1.596431970596, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1720/2500\", \"loss\": 1.408997297287, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1730/2500\", \"loss\": 1.499796092510, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1740/2500\", \"loss\": 1.681887447834, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1750/2500\", \"loss\": 1.680918812752, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1760/2500\", \"loss\": 1.320967018604, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1770/2500\", \"loss\": 1.565528690815, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1780/2500\", \"loss\": 1.464315831661, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1790/2500\", \"loss\": 1.321964323521, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1800/2500\", \"loss\": 1.522050499916, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1810/2500\", \"loss\": 1.273763477802, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1820/2500\", \"loss\": 1.697353363037, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1830/2500\", \"loss\": 1.639057815075, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1840/2500\", \"loss\": 1.539131104946, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1850/2500\", \"loss\": 1.455349445343, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1860/2500\", \"loss\": 1.428464949131, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1870/2500\", \"loss\": 1.381914973259, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1880/2500\", \"loss\": 1.835618853569, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1890/2500\", \"loss\": 1.432446599007, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1900/2500\", \"loss\": 1.572068393230, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1910/2500\", \"loss\": 1.518881142139, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1920/2500\", \"loss\": 1.329781770706, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1930/2500\", \"loss\": 1.400263011456, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1940/2500\", \"loss\": 1.486786484718, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1950/2500\", \"loss\": 1.598310947418, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1960/2500\", \"loss\": 1.354392170906, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1970/2500\", \"loss\": 1.293526768684, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1980/2500\", \"loss\": 1.585167407990, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1990/2500\", \"loss\": 1.450705528259, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2000/2500\", \"loss\": 1.462367713451, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2010/2500\", \"loss\": 1.476409852505, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2020/2500\", \"loss\": 1.494248747826, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2030/2500\", \"loss\": 1.539964497089, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2040/2500\", \"loss\": 1.406341850758, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2050/2500\", \"loss\": 1.690974116325, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2060/2500\", \"loss\": 1.469306886196, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2070/2500\", \"loss\": 1.473426640034, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2080/2500\", \"loss\": 1.464479148388, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2090/2500\", \"loss\": 1.447361230850, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2100/2500\", \"loss\": 1.420772790909, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2110/2500\", \"loss\": 1.197555780411, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2120/2500\", \"loss\": 1.466630518436, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2130/2500\", \"loss\": 1.265570938587, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2140/2500\", \"loss\": 1.440412819386, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2150/2500\", \"loss\": 1.358267724514, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2160/2500\", \"loss\": 1.683162868023, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2170/2500\", \"loss\": 1.557288587093, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2180/2500\", \"loss\": 1.450211405754, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2190/2500\", \"loss\": 1.390305280685, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2200/2500\", \"loss\": 1.539899885654, \"lr\": 0.000159816788, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2210/2500\", \"loss\": 1.480892598629, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2220/2500\", \"loss\": 1.480021834373, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2230/2500\", \"loss\": 1.677031517029, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2240/2500\", \"loss\": 1.760509371758, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2250/2500\", \"loss\": 1.642581284046, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2260/2500\", \"loss\": 1.595523178577, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2270/2500\", \"loss\": 1.453211367130, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2280/2500\", \"loss\": 1.619801342487, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2290/2500\", \"loss\": 1.545861244202, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2300/2500\", \"loss\": 1.458331227303, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2310/2500\", \"loss\": 1.300078809261, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2320/2500\", \"loss\": 1.343875288963, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2330/2500\", \"loss\": 1.385675311089, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2340/2500\", \"loss\": 1.672987282276, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2350/2500\", \"loss\": 1.686144649982, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2360/2500\", \"loss\": 1.623385369778, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2370/2500\", \"loss\": 1.555071055889, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2380/2500\", \"loss\": 1.582964360714, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2390/2500\", \"loss\": 1.448999166489, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2400/2500\", \"loss\": 1.276611387730, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2410/2500\", \"loss\": 1.408898115158, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2420/2500\", \"loss\": 1.378777801991, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2430/2500\", \"loss\": 1.597529768944, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2440/2500\", \"loss\": 1.578883886337, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2450/2500\", \"loss\": 1.642918646336, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2460/2500\", \"loss\": 1.479342341423, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2470/2500\", \"loss\": 1.433105707169, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2480/2500\", \"loss\": 1.223798453808, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2490/2500\", \"loss\": 1.600406765938, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"2500/2500\", \"loss\": 1.728336334229, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.678861265445, \"lr\": 0.000159816788, \"top1_err\": 61.780000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 48.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 49.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 48.440000610352, \"top1_err\": 48.440000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/2500\", \"loss\": 1.356104910374, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/2500\", \"loss\": 1.337098002434, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/2500\", \"loss\": 1.600642919540, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/2500\", \"loss\": 1.417241394520, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/2500\", \"loss\": 1.471286654472, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/2500\", \"loss\": 1.585663795471, \"lr\": 0.000159816788, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/2500\", \"loss\": 1.273551702499, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/2500\", \"loss\": 1.449811935425, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/2500\", \"loss\": 1.428876698017, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/2500\", \"loss\": 1.354414701462, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/2500\", \"loss\": 1.288770914078, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/2500\", \"loss\": 1.464234054089, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/2500\", \"loss\": 1.445239365101, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/2500\", \"loss\": 1.284161806107, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/2500\", \"loss\": 1.254023253918, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/2500\", \"loss\": 1.289374172688, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/2500\", \"loss\": 1.514909267426, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/2500\", \"loss\": 1.533564865589, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/2500\", \"loss\": 1.476196765900, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/2500\", \"loss\": 1.642636597157, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/2500\", \"loss\": 1.272525787354, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/2500\", \"loss\": 1.414786577225, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/2500\", \"loss\": 1.601391315460, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/2500\", \"loss\": 1.790441632271, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/2500\", \"loss\": 1.331032872200, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/2500\", \"loss\": 1.472416102886, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/2500\", \"loss\": 1.560609459877, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/2500\", \"loss\": 1.393351852894, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/2500\", \"loss\": 1.342339158058, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/2500\", \"loss\": 1.434475183487, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/2500\", \"loss\": 1.492122292519, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/2500\", \"loss\": 1.302756905556, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/2500\", \"loss\": 1.353682041168, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/2500\", \"loss\": 1.546608209610, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/2500\", \"loss\": 1.303673446178, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/2500\", \"loss\": 1.179868876934, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/2500\", \"loss\": 1.218151986599, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/2500\", \"loss\": 1.447778165340, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/2500\", \"loss\": 1.396733880043, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/2500\", \"loss\": 1.588462114334, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/2500\", \"loss\": 1.231617212296, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/2500\", \"loss\": 1.275895416737, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/2500\", \"loss\": 1.276951909065, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/2500\", \"loss\": 1.519607841969, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/2500\", \"loss\": 1.511341691017, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/2500\", \"loss\": 1.342088699341, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/2500\", \"loss\": 1.515097379684, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/2500\", \"loss\": 1.265452980995, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/2500\", \"loss\": 1.311012923717, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/2500\", \"loss\": 1.533333599567, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/2500\", \"loss\": 1.611227810383, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/2500\", \"loss\": 1.428529918194, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/2500\", \"loss\": 1.509350955486, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/2500\", \"loss\": 1.260008037090, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/2500\", \"loss\": 1.376030862331, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/2500\", \"loss\": 1.247870624065, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/2500\", \"loss\": 1.468344211578, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/2500\", \"loss\": 1.471193790436, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/2500\", \"loss\": 1.164009332657, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/2500\", \"loss\": 1.362119376659, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/2500\", \"loss\": 1.362303376198, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/2500\", \"loss\": 1.183011472225, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/2500\", \"loss\": 1.295642375946, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/2500\", \"loss\": 1.404396474361, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/2500\", \"loss\": 1.259235024452, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/2500\", \"loss\": 1.285068750381, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/2500\", \"loss\": 1.546564102173, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/2500\", \"loss\": 1.179696559906, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/2500\", \"loss\": 1.510953843594, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/2500\", \"loss\": 1.395870327950, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/2500\", \"loss\": 1.118495404720, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/2500\", \"loss\": 1.564956545830, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/2500\", \"loss\": 1.317178666592, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/2500\", \"loss\": 1.231947243214, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/2500\", \"loss\": 1.254663050175, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/2500\", \"loss\": 1.480629205704, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/2500\", \"loss\": 1.418406605721, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/2500\", \"loss\": 1.391026914120, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/2500\", \"loss\": 1.274101972580, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/2500\", \"loss\": 1.480664730072, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/2500\", \"loss\": 1.360446393490, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/2500\", \"loss\": 1.381522119045, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/2500\", \"loss\": 1.287036001682, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/2500\", \"loss\": 1.691634297371, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/2500\", \"loss\": 1.335053086281, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/2500\", \"loss\": 1.188772559166, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/2500\", \"loss\": 1.249962389469, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/2500\", \"loss\": 1.214613437653, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/2500\", \"loss\": 1.293450176716, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/2500\", \"loss\": 1.366861939430, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/2500\", \"loss\": 1.387238979340, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/2500\", \"loss\": 1.257164716721, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/2500\", \"loss\": 1.288813769817, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"940/2500\", \"loss\": 1.288633286953, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"950/2500\", \"loss\": 1.188729226589, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"960/2500\", \"loss\": 1.573915600777, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"970/2500\", \"loss\": 1.223293066025, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"980/2500\", \"loss\": 1.275413334370, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"990/2500\", \"loss\": 1.277833998203, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1000/2500\", \"loss\": 1.209466576576, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1010/2500\", \"loss\": 1.191704392433, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1020/2500\", \"loss\": 1.484385430813, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1030/2500\", \"loss\": 1.396178007126, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1040/2500\", \"loss\": 1.496950984001, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1050/2500\", \"loss\": 1.265331923962, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1060/2500\", \"loss\": 1.436914503574, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1070/2500\", \"loss\": 1.343679487705, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1080/2500\", \"loss\": 1.337657213211, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1090/2500\", \"loss\": 1.513683736324, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1100/2500\", \"loss\": 1.375636458397, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1110/2500\", \"loss\": 1.279505491257, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1120/2500\", \"loss\": 1.270276486874, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1130/2500\", \"loss\": 1.113570928574, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1140/2500\", \"loss\": 1.160665810108, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1150/2500\", \"loss\": 1.477412343025, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1160/2500\", \"loss\": 1.453066885471, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1170/2500\", \"loss\": 1.312374472618, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1180/2500\", \"loss\": 1.100861668587, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1190/2500\", \"loss\": 1.483190655708, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1200/2500\", \"loss\": 1.541681408882, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1210/2500\", \"loss\": 1.305228590965, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1220/2500\", \"loss\": 1.111150026321, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1230/2500\", \"loss\": 1.454886615276, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1240/2500\", \"loss\": 1.058016479015, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1250/2500\", \"loss\": 1.229724466801, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1260/2500\", \"loss\": 1.070656657219, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1270/2500\", \"loss\": 1.273251831532, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1280/2500\", \"loss\": 1.312906801701, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1290/2500\", \"loss\": 1.094332337379, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1300/2500\", \"loss\": 1.430376887321, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1310/2500\", \"loss\": 1.050670385361, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1320/2500\", \"loss\": 1.174461185932, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1330/2500\", \"loss\": 1.114068269730, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1340/2500\", \"loss\": 1.218578696251, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1350/2500\", \"loss\": 1.365757882595, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1360/2500\", \"loss\": 1.154731154442, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1370/2500\", \"loss\": 1.236891984940, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1380/2500\", \"loss\": 1.367071628571, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1390/2500\", \"loss\": 1.331956565380, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1400/2500\", \"loss\": 1.412595331669, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1410/2500\", \"loss\": 1.349684715271, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1420/2500\", \"loss\": 1.193362295628, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1430/2500\", \"loss\": 1.293492853642, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1440/2500\", \"loss\": 1.047045707703, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1450/2500\", \"loss\": 1.324408769608, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1460/2500\", \"loss\": 1.083406329155, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1470/2500\", \"loss\": 1.241292774677, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1480/2500\", \"loss\": 1.682270467281, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1490/2500\", \"loss\": 1.204622387886, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1500/2500\", \"loss\": 1.225049614906, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1510/2500\", \"loss\": 1.365471839905, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1520/2500\", \"loss\": 1.267772972584, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1530/2500\", \"loss\": 1.451479017735, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1540/2500\", \"loss\": 1.191269457340, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1550/2500\", \"loss\": 1.291435897350, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1560/2500\", \"loss\": 0.928931534290, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1570/2500\", \"loss\": 1.331792712212, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1580/2500\", \"loss\": 1.164251923561, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1590/2500\", \"loss\": 1.356010556221, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1600/2500\", \"loss\": 1.331852614880, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1610/2500\", \"loss\": 1.159561455250, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1620/2500\", \"loss\": 1.399634659290, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1630/2500\", \"loss\": 1.120556592941, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1640/2500\", \"loss\": 1.402820289135, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1650/2500\", \"loss\": 1.215262472630, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1660/2500\", \"loss\": 1.271925687790, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1670/2500\", \"loss\": 1.270849227905, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1680/2500\", \"loss\": 1.231465041637, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1690/2500\", \"loss\": 1.543909132481, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1700/2500\", \"loss\": 1.327655613422, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1710/2500\", \"loss\": 1.234446048737, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1720/2500\", \"loss\": 1.158138096333, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1730/2500\", \"loss\": 1.348586142063, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1740/2500\", \"loss\": 1.085054397583, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1750/2500\", \"loss\": 1.224414229393, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1760/2500\", \"loss\": 1.122973680496, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1770/2500\", \"loss\": 1.191786408424, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1780/2500\", \"loss\": 1.168689489365, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1790/2500\", \"loss\": 1.081850469112, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1800/2500\", \"loss\": 1.272917330265, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1810/2500\", \"loss\": 1.181701958179, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1820/2500\", \"loss\": 1.274285256863, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1830/2500\", \"loss\": 1.253314614296, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1840/2500\", \"loss\": 1.457253515720, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1850/2500\", \"loss\": 1.114935159683, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1860/2500\", \"loss\": 1.148041725159, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1870/2500\", \"loss\": 1.229462444782, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1880/2500\", \"loss\": 1.014930963516, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1890/2500\", \"loss\": 1.218515217304, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1900/2500\", \"loss\": 1.193282902241, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1910/2500\", \"loss\": 1.148041307926, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1920/2500\", \"loss\": 1.082794487476, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1930/2500\", \"loss\": 1.215279936790, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1940/2500\", \"loss\": 1.252033591270, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1950/2500\", \"loss\": 1.219727218151, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1960/2500\", \"loss\": 1.234812438488, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1970/2500\", \"loss\": 1.205704331398, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1980/2500\", \"loss\": 1.139216303825, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1990/2500\", \"loss\": 1.306335926056, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2000/2500\", \"loss\": 1.406435549259, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2010/2500\", \"loss\": 1.276850223541, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2020/2500\", \"loss\": 1.500936269760, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2030/2500\", \"loss\": 1.329827845097, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2040/2500\", \"loss\": 1.244243979454, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2050/2500\", \"loss\": 1.456639468670, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2060/2500\", \"loss\": 1.417089104652, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2070/2500\", \"loss\": 1.342759251595, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2080/2500\", \"loss\": 1.470080554485, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2090/2500\", \"loss\": 1.165368139744, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2100/2500\", \"loss\": 1.241852104664, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2110/2500\", \"loss\": 1.295913279057, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2120/2500\", \"loss\": 1.300038039684, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2130/2500\", \"loss\": 1.229787349701, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2140/2500\", \"loss\": 1.135944426060, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2150/2500\", \"loss\": 1.387011587620, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2160/2500\", \"loss\": 1.211869180202, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2170/2500\", \"loss\": 1.263190984726, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2180/2500\", \"loss\": 1.322230935097, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2190/2500\", \"loss\": 1.438322305679, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2200/2500\", \"loss\": 1.451553344727, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2210/2500\", \"loss\": 1.179125070572, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2220/2500\", \"loss\": 1.262710690498, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2230/2500\", \"loss\": 1.434711098671, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2240/2500\", \"loss\": 1.141904771328, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2250/2500\", \"loss\": 1.227766036987, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2260/2500\", \"loss\": 1.153126060963, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2270/2500\", \"loss\": 1.501479268074, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2280/2500\", \"loss\": 1.209722697735, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2290/2500\", \"loss\": 0.894579321146, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2300/2500\", \"loss\": 1.316626369953, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2310/2500\", \"loss\": 1.303844690323, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2320/2500\", \"loss\": 1.162362694740, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2330/2500\", \"loss\": 1.357153952122, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2340/2500\", \"loss\": 1.450247287750, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2350/2500\", \"loss\": 1.229658663273, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2360/2500\", \"loss\": 1.144263148308, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2370/2500\", \"loss\": 0.984847754240, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2380/2500\", \"loss\": 1.064943134785, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2390/2500\", \"loss\": 0.922556787729, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2400/2500\", \"loss\": 1.410763800144, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2410/2500\", \"loss\": 1.214858829975, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2420/2500\", \"loss\": 1.259425997734, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2430/2500\", \"loss\": 1.150863289833, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2440/2500\", \"loss\": 1.284188628197, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2450/2500\", \"loss\": 1.685084581375, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2460/2500\", \"loss\": 1.134447455406, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2470/2500\", \"loss\": 1.194744288921, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2480/2500\", \"loss\": 1.250993490219, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2490/2500\", \"loss\": 1.378780305386, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"2500/2500\", \"loss\": 1.146633803844, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.336730993271, \"lr\": 0.000159816788, \"top1_err\": 47.980000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 41.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 39.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 40.760001068115, \"top1_err\": 40.760001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/2500\", \"loss\": 1.100263476372, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/2500\", \"loss\": 1.340836167336, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/2500\", \"loss\": 1.095365345478, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/2500\", \"loss\": 1.117133378983, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/2500\", \"loss\": 1.098648250103, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/2500\", \"loss\": 1.113829612732, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/2500\", \"loss\": 1.016590476036, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/2500\", \"loss\": 1.125148832798, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/2500\", \"loss\": 1.026755750179, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/2500\", \"loss\": 0.986547946930, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/2500\", \"loss\": 1.291190743446, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/2500\", \"loss\": 1.156947612762, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/2500\", \"loss\": 1.207211911678, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/2500\", \"loss\": 1.123877823353, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/2500\", \"loss\": 1.119324505329, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/2500\", \"loss\": 1.132901370525, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/2500\", \"loss\": 1.005848586559, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/2500\", \"loss\": 1.315559267998, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/2500\", \"loss\": 1.225944817066, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/2500\", \"loss\": 0.943175822496, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/2500\", \"loss\": 1.031677782536, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/2500\", \"loss\": 1.119816541672, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/2500\", \"loss\": 1.270733296871, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/2500\", \"loss\": 1.276306569576, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/2500\", \"loss\": 1.171449899673, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/2500\", \"loss\": 1.179334282875, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/2500\", \"loss\": 0.976032078266, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/2500\", \"loss\": 1.105776488781, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/2500\", \"loss\": 1.293799817562, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/2500\", \"loss\": 1.033328056335, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/2500\", \"loss\": 1.201349437237, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/2500\", \"loss\": 1.142303466797, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/2500\", \"loss\": 1.106755495071, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/2500\", \"loss\": 1.233499467373, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/2500\", \"loss\": 1.185969591141, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/2500\", \"loss\": 1.264006197453, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/2500\", \"loss\": 1.183299183846, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/2500\", \"loss\": 1.245499789715, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/2500\", \"loss\": 1.206955492496, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/2500\", \"loss\": 0.906379312277, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/2500\", \"loss\": 1.122494757175, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/2500\", \"loss\": 1.211748659611, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/2500\", \"loss\": 1.055571198463, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/2500\", \"loss\": 0.956302613020, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/2500\", \"loss\": 1.131247818470, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/2500\", \"loss\": 1.115262448788, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/2500\", \"loss\": 1.146643161774, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/2500\", \"loss\": 1.148133397102, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/2500\", \"loss\": 0.882440447807, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/2500\", \"loss\": 1.219001948833, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/2500\", \"loss\": 0.916545093060, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/2500\", \"loss\": 1.063116014004, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/2500\", \"loss\": 1.178247749805, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/2500\", \"loss\": 1.332995891571, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/2500\", \"loss\": 0.929686516523, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/2500\", \"loss\": 0.865302979946, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/2500\", \"loss\": 1.123249471188, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/2500\", \"loss\": 0.976038664579, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/2500\", \"loss\": 1.185371160507, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/2500\", \"loss\": 1.041667997837, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/2500\", \"loss\": 1.217420995235, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/2500\", \"loss\": 1.408716320992, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/2500\", \"loss\": 1.007265865803, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/2500\", \"loss\": 1.137144446373, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/2500\", \"loss\": 1.036596655846, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/2500\", \"loss\": 1.216759264469, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/2500\", \"loss\": 1.231305062771, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/2500\", \"loss\": 1.054294556379, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/2500\", \"loss\": 1.055521011353, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/2500\", \"loss\": 1.207868933678, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/2500\", \"loss\": 1.269912838936, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/2500\", \"loss\": 0.949872553349, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/2500\", \"loss\": 1.243564486504, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/2500\", \"loss\": 1.218730747700, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/2500\", \"loss\": 1.173714935780, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/2500\", \"loss\": 1.281596601009, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/2500\", \"loss\": 1.096570014954, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/2500\", \"loss\": 0.966152310371, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/2500\", \"loss\": 1.276427984238, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/2500\", \"loss\": 1.129581749439, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/2500\", \"loss\": 1.012599974871, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/2500\", \"loss\": 1.251507341862, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/2500\", \"loss\": 1.232754468918, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/2500\", \"loss\": 1.253244042397, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/2500\", \"loss\": 0.954903542995, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/2500\", \"loss\": 1.165106534958, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/2500\", \"loss\": 1.076662063599, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/2500\", \"loss\": 1.061009109020, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/2500\", \"loss\": 0.980878919363, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/2500\", \"loss\": 1.161387205124, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/2500\", \"loss\": 0.791272193193, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/2500\", \"loss\": 1.029474049807, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/2500\", \"loss\": 1.235143482685, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"940/2500\", \"loss\": 1.142371654510, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"950/2500\", \"loss\": 1.116747796535, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"960/2500\", \"loss\": 1.171195387840, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"970/2500\", \"loss\": 0.949020534754, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"980/2500\", \"loss\": 1.036348581314, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"990/2500\", \"loss\": 1.137866139412, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1000/2500\", \"loss\": 0.899457573891, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1010/2500\", \"loss\": 1.160839259624, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1020/2500\", \"loss\": 0.882856547832, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1030/2500\", \"loss\": 1.111863017082, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1040/2500\", \"loss\": 1.051653355360, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1050/2500\", \"loss\": 1.107261061668, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1060/2500\", \"loss\": 1.210815310478, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1070/2500\", \"loss\": 1.083715379238, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1080/2500\", \"loss\": 0.844164371490, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1090/2500\", \"loss\": 1.330451965332, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1100/2500\", \"loss\": 0.836697250605, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1110/2500\", \"loss\": 0.979428499937, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1120/2500\", \"loss\": 1.137046098709, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1130/2500\", \"loss\": 1.239717960358, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1140/2500\", \"loss\": 1.209465026855, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1150/2500\", \"loss\": 0.948483884335, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1160/2500\", \"loss\": 1.177414000034, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1170/2500\", \"loss\": 1.358143508434, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1180/2500\", \"loss\": 1.169425308704, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1190/2500\", \"loss\": 1.014985799789, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1200/2500\", \"loss\": 1.098061919212, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1210/2500\", \"loss\": 1.150172591209, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1220/2500\", \"loss\": 0.999992221594, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1230/2500\", \"loss\": 1.148621082306, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1240/2500\", \"loss\": 0.789041697979, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1250/2500\", \"loss\": 1.108686625957, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1260/2500\", \"loss\": 0.928402721882, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1270/2500\", \"loss\": 0.961822181940, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1280/2500\", \"loss\": 1.051143348217, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1290/2500\", \"loss\": 1.270559728146, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1300/2500\", \"loss\": 1.039969742298, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1310/2500\", \"loss\": 0.976215213537, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1320/2500\", \"loss\": 1.134403169155, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1330/2500\", \"loss\": 0.979340642691, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1340/2500\", \"loss\": 1.315383791924, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1350/2500\", \"loss\": 0.970879763365, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1360/2500\", \"loss\": 1.031514883041, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1370/2500\", \"loss\": 1.302140235901, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1380/2500\", \"loss\": 0.859269499779, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1390/2500\", \"loss\": 0.985404163599, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1400/2500\", \"loss\": 1.065249025822, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1410/2500\", \"loss\": 1.146247029305, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1420/2500\", \"loss\": 1.320663213730, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1430/2500\", \"loss\": 0.998958766460, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1440/2500\", \"loss\": 1.048499286175, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1450/2500\", \"loss\": 1.362099170685, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1460/2500\", \"loss\": 0.945327877998, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1470/2500\", \"loss\": 0.975953966379, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1480/2500\", \"loss\": 1.023000776768, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1490/2500\", \"loss\": 1.125033915043, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1500/2500\", \"loss\": 0.956275284290, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1510/2500\", \"loss\": 1.192274451256, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1520/2500\", \"loss\": 1.074171990156, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1530/2500\", \"loss\": 1.246006429195, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1540/2500\", \"loss\": 1.087793946266, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1550/2500\", \"loss\": 1.022646427155, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1560/2500\", \"loss\": 1.105888307095, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1570/2500\", \"loss\": 1.151164889336, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1580/2500\", \"loss\": 1.115945279598, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1590/2500\", \"loss\": 0.965641736984, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1600/2500\", \"loss\": 1.084642827511, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1610/2500\", \"loss\": 1.238244771957, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1620/2500\", \"loss\": 1.075278103352, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1630/2500\", \"loss\": 0.981625050306, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1640/2500\", \"loss\": 1.074145734310, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1650/2500\", \"loss\": 0.923780918121, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1660/2500\", \"loss\": 1.297653257847, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1670/2500\", \"loss\": 1.192551136017, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1680/2500\", \"loss\": 0.817318230867, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1690/2500\", \"loss\": 1.205772995949, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1700/2500\", \"loss\": 0.982481360435, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1710/2500\", \"loss\": 0.908222556114, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1720/2500\", \"loss\": 1.022042036057, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1730/2500\", \"loss\": 1.115776181221, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1740/2500\", \"loss\": 1.043294131756, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1750/2500\", \"loss\": 0.890614926815, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1760/2500\", \"loss\": 1.093126058578, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1770/2500\", \"loss\": 1.179351747036, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1780/2500\", \"loss\": 1.124084889889, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1790/2500\", \"loss\": 1.408460557461, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1800/2500\", \"loss\": 1.214504539967, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1810/2500\", \"loss\": 1.081626534462, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1820/2500\", \"loss\": 1.224410474300, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1830/2500\", \"loss\": 1.017547488213, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1840/2500\", \"loss\": 1.145661294460, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1850/2500\", \"loss\": 1.264380812645, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1860/2500\", \"loss\": 1.242018938065, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1870/2500\", \"loss\": 1.124319881201, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1880/2500\", \"loss\": 1.016810357571, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1890/2500\", \"loss\": 0.996199160814, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1900/2500\", \"loss\": 1.032085597515, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1910/2500\", \"loss\": 1.231531202793, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1920/2500\", \"loss\": 1.243325889111, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1930/2500\", \"loss\": 1.127295374870, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1940/2500\", \"loss\": 0.771233588457, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1950/2500\", \"loss\": 1.152029573917, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1960/2500\", \"loss\": 0.983105242252, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1970/2500\", \"loss\": 1.073166251183, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1980/2500\", \"loss\": 0.915968030691, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1990/2500\", \"loss\": 0.915302753448, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2000/2500\", \"loss\": 0.975828498602, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2010/2500\", \"loss\": 0.894596517086, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2020/2500\", \"loss\": 1.118393778801, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2030/2500\", \"loss\": 0.972704023123, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2040/2500\", \"loss\": 1.161039888859, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2050/2500\", \"loss\": 0.967051684856, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2060/2500\", \"loss\": 1.051716208458, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2070/2500\", \"loss\": 1.020471245050, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2080/2500\", \"loss\": 0.954278528690, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2090/2500\", \"loss\": 0.948953866959, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2100/2500\", \"loss\": 0.981401234865, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2110/2500\", \"loss\": 1.193425178528, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2120/2500\", \"loss\": 1.149562299252, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2130/2500\", \"loss\": 1.215848326683, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2140/2500\", \"loss\": 1.102252125740, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2150/2500\", \"loss\": 0.874438971281, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2160/2500\", \"loss\": 0.967294245958, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2170/2500\", \"loss\": 1.263953268528, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2180/2500\", \"loss\": 0.999047338963, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2190/2500\", \"loss\": 0.889654904604, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2200/2500\", \"loss\": 0.923719555140, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2210/2500\", \"loss\": 0.950764089823, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2220/2500\", \"loss\": 1.126425623894, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2230/2500\", \"loss\": 0.891020774841, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2240/2500\", \"loss\": 1.116623342037, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2250/2500\", \"loss\": 1.060380905867, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2260/2500\", \"loss\": 1.296375989914, \"lr\": 0.000159816788, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2270/2500\", \"loss\": 1.266809999943, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2280/2500\", \"loss\": 1.221173703671, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2290/2500\", \"loss\": 1.125072598457, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2300/2500\", \"loss\": 1.051313698292, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2310/2500\", \"loss\": 1.005069315434, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2320/2500\", \"loss\": 1.340788125992, \"lr\": 0.000159816788, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2330/2500\", \"loss\": 0.995104342699, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2340/2500\", \"loss\": 1.144897460938, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2350/2500\", \"loss\": 1.044364511967, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2360/2500\", \"loss\": 1.216442823410, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2370/2500\", \"loss\": 1.048479080200, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2380/2500\", \"loss\": 0.990223437548, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2390/2500\", \"loss\": 1.216145157814, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2400/2500\", \"loss\": 1.254466116428, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2410/2500\", \"loss\": 1.342614412308, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2420/2500\", \"loss\": 0.878712087870, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2430/2500\", \"loss\": 1.095382750034, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2440/2500\", \"loss\": 0.847583025694, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2450/2500\", \"loss\": 1.116098821163, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2460/2500\", \"loss\": 1.048236668110, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2470/2500\", \"loss\": 1.023025929928, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2480/2500\", \"loss\": 0.924150854349, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2490/2500\", \"loss\": 0.948219746351, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"2500/2500\", \"loss\": 1.022093594074, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.125824108601, \"lr\": 0.000159816788, \"top1_err\": 39.570000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 34.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 35.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 35.180001754761, \"top1_err\": 35.180001754761}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/2500\", \"loss\": 1.025915741920, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/2500\", \"loss\": 0.886996835470, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/2500\", \"loss\": 0.875646501780, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/2500\", \"loss\": 1.066113829613, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/2500\", \"loss\": 0.959595501423, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/2500\", \"loss\": 0.939554721117, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/2500\", \"loss\": 0.926129102707, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/2500\", \"loss\": 1.081752419472, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/2500\", \"loss\": 1.053960919380, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/2500\", \"loss\": 0.901789128780, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/2500\", \"loss\": 0.886845171452, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/2500\", \"loss\": 0.927341878414, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/2500\", \"loss\": 0.953509420156, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/2500\", \"loss\": 1.039778172970, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/2500\", \"loss\": 0.878520727158, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/2500\", \"loss\": 1.011336505413, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/2500\", \"loss\": 0.894474744797, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/2500\", \"loss\": 1.076309680939, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/2500\", \"loss\": 0.796708464622, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/2500\", \"loss\": 0.971825569868, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/2500\", \"loss\": 0.985917985439, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/2500\", \"loss\": 1.237832784653, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/2500\", \"loss\": 0.938917726278, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/2500\", \"loss\": 1.039393842220, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/2500\", \"loss\": 1.023000776768, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/2500\", \"loss\": 0.860510975122, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/2500\", \"loss\": 0.961931884289, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/2500\", \"loss\": 0.976971507072, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/2500\", \"loss\": 1.014753639698, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/2500\", \"loss\": 0.982551485300, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/2500\", \"loss\": 1.094951629639, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/2500\", \"loss\": 0.771510422230, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/2500\", \"loss\": 1.234358370304, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/2500\", \"loss\": 0.971728503704, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/2500\", \"loss\": 0.871742427349, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/2500\", \"loss\": 0.842136889696, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/2500\", \"loss\": 0.993702322245, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/2500\", \"loss\": 1.087377130985, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/2500\", \"loss\": 0.975952535868, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/2500\", \"loss\": 0.993410229683, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/2500\", \"loss\": 1.009277760983, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/2500\", \"loss\": 0.946059942245, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/2500\", \"loss\": 0.977037936449, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/2500\", \"loss\": 0.717445045710, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/2500\", \"loss\": 1.014951854944, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/2500\", \"loss\": 1.113351523876, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/2500\", \"loss\": 1.227585911751, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/2500\", \"loss\": 1.036853492260, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/2500\", \"loss\": 1.029633343220, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/2500\", \"loss\": 0.770670086145, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/2500\", \"loss\": 0.920190095901, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/2500\", \"loss\": 0.789539545774, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/2500\", \"loss\": 0.875966638327, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/2500\", \"loss\": 0.927041083574, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/2500\", \"loss\": 1.153748393059, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/2500\", \"loss\": 0.903930425644, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/2500\", \"loss\": 1.071780562401, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/2500\", \"loss\": 0.912485033274, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/2500\", \"loss\": 0.804786205292, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/2500\", \"loss\": 1.089937567711, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/2500\", \"loss\": 0.980488657951, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/2500\", \"loss\": 0.815123140812, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/2500\", \"loss\": 1.087086677551, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/2500\", \"loss\": 1.009160518646, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/2500\", \"loss\": 0.721896231174, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/2500\", \"loss\": 0.884097903967, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/2500\", \"loss\": 0.952370285988, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/2500\", \"loss\": 1.240860462189, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/2500\", \"loss\": 0.796470910311, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/2500\", \"loss\": 1.144924163818, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/2500\", \"loss\": 1.175644338131, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/2500\", \"loss\": 0.913615167141, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/2500\", \"loss\": 0.909036129713, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/2500\", \"loss\": 0.864432901144, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/2500\", \"loss\": 0.769696116447, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/2500\", \"loss\": 0.897072106600, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/2500\", \"loss\": 0.868783205748, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/2500\", \"loss\": 0.730783522129, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/2500\", \"loss\": 0.971385985613, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/2500\", \"loss\": 1.082796394825, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/2500\", \"loss\": 1.026215851307, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/2500\", \"loss\": 0.717444837093, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/2500\", \"loss\": 0.783040106297, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/2500\", \"loss\": 0.854583948851, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/2500\", \"loss\": 1.002663552761, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/2500\", \"loss\": 1.146641016006, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/2500\", \"loss\": 0.950356930494, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/2500\", \"loss\": 0.881171733141, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/2500\", \"loss\": 0.758254081011, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/2500\", \"loss\": 1.025218784809, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/2500\", \"loss\": 0.952584326267, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/2500\", \"loss\": 0.942460656166, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/2500\", \"loss\": 0.918481439352, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"940/2500\", \"loss\": 0.969286352396, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"950/2500\", \"loss\": 0.983769625425, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"960/2500\", \"loss\": 0.942145466805, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"970/2500\", \"loss\": 0.962723284960, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"980/2500\", \"loss\": 0.682731479406, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"990/2500\", \"loss\": 0.825251132250, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1000/2500\", \"loss\": 1.173375666142, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1010/2500\", \"loss\": 0.980672985315, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1020/2500\", \"loss\": 0.876233607531, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1030/2500\", \"loss\": 0.976639419794, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1040/2500\", \"loss\": 0.972887694836, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1050/2500\", \"loss\": 0.958206444979, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1060/2500\", \"loss\": 0.719247430563, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1070/2500\", \"loss\": 1.013923019171, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1080/2500\", \"loss\": 0.972230494022, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1090/2500\", \"loss\": 0.872146874666, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1100/2500\", \"loss\": 0.982124865055, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1110/2500\", \"loss\": 0.758158355951, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1120/2500\", \"loss\": 0.976419031620, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1130/2500\", \"loss\": 1.081496119499, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1140/2500\", \"loss\": 0.706267267466, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1150/2500\", \"loss\": 0.829918295145, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1160/2500\", \"loss\": 0.765800088644, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1170/2500\", \"loss\": 0.972941756248, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1180/2500\", \"loss\": 0.897964090109, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1190/2500\", \"loss\": 0.956725895405, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1200/2500\", \"loss\": 1.028238564730, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1210/2500\", \"loss\": 0.902380108833, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1220/2500\", \"loss\": 0.783570379019, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1230/2500\", \"loss\": 1.006816118956, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1240/2500\", \"loss\": 0.968014508486, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1250/2500\", \"loss\": 0.839678257704, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1260/2500\", \"loss\": 0.801772952080, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1270/2500\", \"loss\": 0.827642619610, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1280/2500\", \"loss\": 0.943523317575, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1290/2500\", \"loss\": 0.903075605631, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1300/2500\", \"loss\": 1.004383832216, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1310/2500\", \"loss\": 0.966203540564, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1320/2500\", \"loss\": 0.812652707100, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1330/2500\", \"loss\": 0.889216929674, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1340/2500\", \"loss\": 0.790198326111, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1350/2500\", \"loss\": 0.865848869085, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1360/2500\", \"loss\": 0.885212600231, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1370/2500\", \"loss\": 0.873824685812, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1380/2500\", \"loss\": 1.025672435760, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1390/2500\", \"loss\": 1.008731216192, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1400/2500\", \"loss\": 0.683632105589, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1410/2500\", \"loss\": 1.009917408228, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1420/2500\", \"loss\": 1.021854639053, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1430/2500\", \"loss\": 0.986681640148, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1440/2500\", \"loss\": 0.896223127842, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1450/2500\", \"loss\": 0.819845914841, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1460/2500\", \"loss\": 0.901279747486, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1470/2500\", \"loss\": 0.957591950893, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1480/2500\", \"loss\": 1.013246357441, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1490/2500\", \"loss\": 0.850861489773, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1500/2500\", \"loss\": 0.737179934978, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1510/2500\", \"loss\": 0.990024566650, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1520/2500\", \"loss\": 0.781600415707, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1530/2500\", \"loss\": 0.787580609322, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1540/2500\", \"loss\": 0.833091080189, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1550/2500\", \"loss\": 0.961277008057, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1560/2500\", \"loss\": 0.829990506172, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1570/2500\", \"loss\": 0.854706674814, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1580/2500\", \"loss\": 0.805176794529, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1590/2500\", \"loss\": 0.940773665905, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1600/2500\", \"loss\": 0.881458729506, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1610/2500\", \"loss\": 0.924035549164, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1620/2500\", \"loss\": 0.927695810795, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1630/2500\", \"loss\": 0.756888777018, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1640/2500\", \"loss\": 1.049194931984, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1650/2500\", \"loss\": 1.040907830000, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1660/2500\", \"loss\": 1.051190644503, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1670/2500\", \"loss\": 0.863426685333, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1680/2500\", \"loss\": 0.865751385689, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1690/2500\", \"loss\": 0.955368965864, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1700/2500\", \"loss\": 0.965496897697, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1710/2500\", \"loss\": 0.893482387066, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1720/2500\", \"loss\": 0.886748522520, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1730/2500\", \"loss\": 0.839368671179, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1740/2500\", \"loss\": 0.904918104410, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1750/2500\", \"loss\": 1.037015795708, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1760/2500\", \"loss\": 0.785591274500, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1770/2500\", \"loss\": 1.021111249924, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1780/2500\", \"loss\": 0.844712108374, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1790/2500\", \"loss\": 1.207341134548, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1800/2500\", \"loss\": 1.039215147495, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1810/2500\", \"loss\": 1.253089189529, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1820/2500\", \"loss\": 0.801120191813, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1830/2500\", \"loss\": 1.036699861288, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1840/2500\", \"loss\": 0.785654485226, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1850/2500\", \"loss\": 1.083681702614, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1860/2500\", \"loss\": 1.053545296192, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1870/2500\", \"loss\": 0.833984732628, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1880/2500\", \"loss\": 0.758672297001, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1890/2500\", \"loss\": 0.886435419321, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1900/2500\", \"loss\": 1.137042403221, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1910/2500\", \"loss\": 1.003704696894, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1920/2500\", \"loss\": 0.601946443319, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1930/2500\", \"loss\": 0.692449390888, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1940/2500\", \"loss\": 0.804758638144, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1950/2500\", \"loss\": 0.981270879507, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1960/2500\", \"loss\": 0.671103954315, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1970/2500\", \"loss\": 1.133629798889, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1980/2500\", \"loss\": 0.808758199215, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1990/2500\", \"loss\": 1.108604133129, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2000/2500\", \"loss\": 1.237875163555, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2010/2500\", \"loss\": 0.909381926060, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2020/2500\", \"loss\": 0.697051972151, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2030/2500\", \"loss\": 0.754246920347, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2040/2500\", \"loss\": 1.134442508221, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2050/2500\", \"loss\": 0.873574823141, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2060/2500\", \"loss\": 0.713285058737, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2070/2500\", \"loss\": 1.074535548687, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2080/2500\", \"loss\": 1.194441974163, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2090/2500\", \"loss\": 0.891190052032, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2100/2500\", \"loss\": 0.813759922981, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2110/2500\", \"loss\": 0.820956796408, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2120/2500\", \"loss\": 0.749795973301, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2130/2500\", \"loss\": 1.046842992306, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2140/2500\", \"loss\": 0.876065701246, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2150/2500\", \"loss\": 0.950252383947, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2160/2500\", \"loss\": 1.145027577877, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2170/2500\", \"loss\": 0.726231306791, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2180/2500\", \"loss\": 0.861625522375, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2190/2500\", \"loss\": 1.264535069466, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2200/2500\", \"loss\": 0.962222129107, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2210/2500\", \"loss\": 0.826212823391, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2220/2500\", \"loss\": 0.864645302296, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2230/2500\", \"loss\": 0.833388775587, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2240/2500\", \"loss\": 0.598723918200, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2250/2500\", \"loss\": 0.927950263023, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2260/2500\", \"loss\": 0.925171405077, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2270/2500\", \"loss\": 0.860251665115, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2280/2500\", \"loss\": 0.915810257196, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2290/2500\", \"loss\": 1.019625782967, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2300/2500\", \"loss\": 1.145499706268, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2310/2500\", \"loss\": 0.956976115704, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2320/2500\", \"loss\": 1.006154865026, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2330/2500\", \"loss\": 0.813922286034, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2340/2500\", \"loss\": 0.705291181803, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2350/2500\", \"loss\": 0.610060542822, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2360/2500\", \"loss\": 0.791391313076, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2370/2500\", \"loss\": 1.120029509068, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2380/2500\", \"loss\": 1.001644372940, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2390/2500\", \"loss\": 0.813678115606, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2400/2500\", \"loss\": 0.695071667433, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2410/2500\", \"loss\": 0.991088271141, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2420/2500\", \"loss\": 0.722571849823, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2430/2500\", \"loss\": 1.181301712990, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2440/2500\", \"loss\": 0.719884425402, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2450/2500\", \"loss\": 0.863668769598, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2460/2500\", \"loss\": 0.811162382364, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2470/2500\", \"loss\": 1.072533965111, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2480/2500\", \"loss\": 1.131699979305, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2490/2500\", \"loss\": 0.880633711815, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"2500/2500\", \"loss\": 0.960724622011, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.965459409833, \"lr\": 0.000159816788, \"top1_err\": 33.830000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 32.250002861023}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 33.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 32.940001373291, \"top1_err\": 32.940001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/2500\", \"loss\": 0.695639640093, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/2500\", \"loss\": 0.798737227917, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/2500\", \"loss\": 0.868736147881, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/2500\", \"loss\": 0.839699864388, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/2500\", \"loss\": 0.687899053097, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/2500\", \"loss\": 0.596368193626, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/2500\", \"loss\": 0.612850666046, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/2500\", \"loss\": 0.632061362267, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/2500\", \"loss\": 0.643074899912, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/2500\", \"loss\": 0.543570667505, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/2500\", \"loss\": 0.723318845034, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/2500\", \"loss\": 0.512002974749, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/2500\", \"loss\": 0.494235783815, \"lr\": 0.000159816788, \"top1_err\": 12.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/2500\", \"loss\": 0.729546248913, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/2500\", \"loss\": 0.824083119631, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/2500\", \"loss\": 0.666486322880, \"lr\": 0.000159816788, \"top1_err\": 12.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/2500\", \"loss\": 0.694326430559, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/2500\", \"loss\": 0.836164414883, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/2500\", \"loss\": 0.856433302164, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/2500\", \"loss\": 0.876134634018, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/2500\", \"loss\": 0.706488490105, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/2500\", \"loss\": 1.036630839109, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/2500\", \"loss\": 0.989480942488, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/2500\", \"loss\": 0.857555210590, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/2500\", \"loss\": 0.603782683611, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/2500\", \"loss\": 0.850047379732, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/2500\", \"loss\": 0.723320037127, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/2500\", \"loss\": 0.624168038368, \"lr\": 0.000159816788, \"top1_err\": 12.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/2500\", \"loss\": 0.794683516026, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/2500\", \"loss\": 0.657267451286, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/2500\", \"loss\": 0.584759503603, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/2500\", \"loss\": 0.696450442076, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/2500\", \"loss\": 0.631955921650, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/2500\", \"loss\": 0.641899138689, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/2500\", \"loss\": 0.732683986425, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/2500\", \"loss\": 0.563945949078, \"lr\": 0.000159816788, \"top1_err\": 12.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/2500\", \"loss\": 0.674982339144, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/2500\", \"loss\": 0.834842085838, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/2500\", \"loss\": 0.819533735514, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/2500\", \"loss\": 0.798239141703, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/2500\", \"loss\": 0.808527410030, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/2500\", \"loss\": 0.984609931707, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/2500\", \"loss\": 0.655737221241, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/2500\", \"loss\": 0.646132856607, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/2500\", \"loss\": 0.602899253368, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/2500\", \"loss\": 0.804264903069, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/2500\", \"loss\": 0.754618674517, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/2500\", \"loss\": 0.719221353531, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/2500\", \"loss\": 0.888192534447, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/2500\", \"loss\": 0.976401627064, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/2500\", \"loss\": 0.867794215679, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/2500\", \"loss\": 0.898011565208, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/2500\", \"loss\": 0.771213769913, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/2500\", \"loss\": 0.901126563549, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/2500\", \"loss\": 0.737307012081, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/2500\", \"loss\": 0.747295022011, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/2500\", \"loss\": 0.785698831081, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/2500\", \"loss\": 0.808602690697, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/2500\", \"loss\": 0.744477540255, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/2500\", \"loss\": 0.665246188641, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/2500\", \"loss\": 0.716103583574, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/2500\", \"loss\": 0.883530974388, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/2500\", \"loss\": 0.965225994587, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/2500\", \"loss\": 0.791444599628, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/2500\", \"loss\": 0.715216219425, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/2500\", \"loss\": 0.820969372988, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/2500\", \"loss\": 0.581351041794, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/2500\", \"loss\": 1.031453073025, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/2500\", \"loss\": 0.803047299385, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/2500\", \"loss\": 0.782978266478, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/2500\", \"loss\": 0.748133420944, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/2500\", \"loss\": 0.815872907639, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/2500\", \"loss\": 0.815915197134, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/2500\", \"loss\": 0.605354726315, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/2500\", \"loss\": 1.003436118364, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/2500\", \"loss\": 0.741354703903, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/2500\", \"loss\": 0.906214147806, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/2500\", \"loss\": 0.751629799604, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/2500\", \"loss\": 0.756646305323, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/2500\", \"loss\": 0.808157473803, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/2500\", \"loss\": 0.755083262920, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/2500\", \"loss\": 0.826325207949, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/2500\", \"loss\": 0.685854643583, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/2500\", \"loss\": 0.770467460155, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/2500\", \"loss\": 0.673719912767, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/2500\", \"loss\": 0.741526454687, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/2500\", \"loss\": 1.053875416517, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/2500\", \"loss\": 0.830544173717, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/2500\", \"loss\": 0.609481930733, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/2500\", \"loss\": 0.768725514412, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/2500\", \"loss\": 0.808498799801, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/2500\", \"loss\": 0.923291206360, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/2500\", \"loss\": 0.872518986464, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"940/2500\", \"loss\": 1.019603192806, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"950/2500\", \"loss\": 0.783197283745, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"960/2500\", \"loss\": 0.832712262869, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"970/2500\", \"loss\": 0.877610325813, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"980/2500\", \"loss\": 0.849888443947, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"990/2500\", \"loss\": 0.902520328760, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1000/2500\", \"loss\": 0.531842172146, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1010/2500\", \"loss\": 0.789944529533, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1020/2500\", \"loss\": 0.748602271080, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1030/2500\", \"loss\": 0.898918360472, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1040/2500\", \"loss\": 0.804061055183, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1050/2500\", \"loss\": 0.847202628851, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1060/2500\", \"loss\": 0.815230578184, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1070/2500\", \"loss\": 1.065834105015, \"lr\": 0.000159816788, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1080/2500\", \"loss\": 0.907470315695, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1090/2500\", \"loss\": 0.907432407141, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1100/2500\", \"loss\": 0.758521050215, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1110/2500\", \"loss\": 1.238457560539, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1120/2500\", \"loss\": 0.774055540562, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1130/2500\", \"loss\": 0.878565073013, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1140/2500\", \"loss\": 0.779150158167, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1150/2500\", \"loss\": 0.888658225536, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1160/2500\", \"loss\": 0.681882172823, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1170/2500\", \"loss\": 0.900710314512, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1180/2500\", \"loss\": 0.877105295658, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1190/2500\", \"loss\": 0.819033533335, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1200/2500\", \"loss\": 0.978074014187, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1210/2500\", \"loss\": 0.847856432199, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1220/2500\", \"loss\": 0.881649553776, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1230/2500\", \"loss\": 0.600755006075, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1240/2500\", \"loss\": 0.500488907099, \"lr\": 0.000159816788, \"top1_err\": 12.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1250/2500\", \"loss\": 0.842125862837, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1260/2500\", \"loss\": 0.916673004627, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1270/2500\", \"loss\": 0.706018239260, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1280/2500\", \"loss\": 0.735637903214, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1290/2500\", \"loss\": 0.826551675797, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1300/2500\", \"loss\": 0.671037912369, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1310/2500\", \"loss\": 0.670842587948, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1320/2500\", \"loss\": 0.853965967894, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1330/2500\", \"loss\": 0.744973510504, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1340/2500\", \"loss\": 0.886217981577, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1350/2500\", \"loss\": 0.704702556133, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1360/2500\", \"loss\": 0.989393532276, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1370/2500\", \"loss\": 0.648507684469, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1380/2500\", \"loss\": 0.714923411608, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1390/2500\", \"loss\": 0.758387953043, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1400/2500\", \"loss\": 1.052010476589, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1410/2500\", \"loss\": 0.780086100101, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1420/2500\", \"loss\": 0.846533864737, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1430/2500\", \"loss\": 0.910144448280, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1440/2500\", \"loss\": 0.916712462902, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1450/2500\", \"loss\": 0.823260635138, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1460/2500\", \"loss\": 0.996465891600, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1470/2500\", \"loss\": 0.831046015024, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1480/2500\", \"loss\": 0.628531098366, \"lr\": 0.000159816788, \"top1_err\": 12.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1490/2500\", \"loss\": 0.802872240543, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1500/2500\", \"loss\": 0.928555786610, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1510/2500\", \"loss\": 0.745147168636, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1520/2500\", \"loss\": 0.862564027309, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1530/2500\", \"loss\": 0.868919938803, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1540/2500\", \"loss\": 0.749687224627, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1550/2500\", \"loss\": 0.875727832317, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1560/2500\", \"loss\": 0.828687399626, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1570/2500\", \"loss\": 0.967384099960, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1580/2500\", \"loss\": 0.822019040585, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1590/2500\", \"loss\": 0.763753622770, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1600/2500\", \"loss\": 1.007177889347, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1610/2500\", \"loss\": 0.923733413219, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1620/2500\", \"loss\": 0.915879964828, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1630/2500\", \"loss\": 0.673576176167, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1640/2500\", \"loss\": 0.797264873981, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1650/2500\", \"loss\": 0.891476303339, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1660/2500\", \"loss\": 1.059603095055, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1670/2500\", \"loss\": 1.239282429218, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1680/2500\", \"loss\": 0.651056051254, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1690/2500\", \"loss\": 0.620741486549, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1700/2500\", \"loss\": 0.696683734655, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1710/2500\", \"loss\": 0.711364388466, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1720/2500\", \"loss\": 0.675156146288, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1730/2500\", \"loss\": 1.089567422867, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1740/2500\", \"loss\": 0.721242547035, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1750/2500\", \"loss\": 0.534992396832, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1760/2500\", \"loss\": 0.951538980007, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1770/2500\", \"loss\": 0.920524209738, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1780/2500\", \"loss\": 0.886479765177, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1790/2500\", \"loss\": 0.644004017115, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1800/2500\", \"loss\": 0.812692910433, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1810/2500\", \"loss\": 0.894079506397, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1820/2500\", \"loss\": 0.835462182760, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1830/2500\", \"loss\": 0.791264444590, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1840/2500\", \"loss\": 0.532170891762, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1850/2500\", \"loss\": 0.779495894909, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1860/2500\", \"loss\": 0.649096369743, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1870/2500\", \"loss\": 0.861529231071, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1880/2500\", \"loss\": 0.892853677273, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1890/2500\", \"loss\": 0.820186614990, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1900/2500\", \"loss\": 1.130192935467, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1910/2500\", \"loss\": 0.932695895433, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1920/2500\", \"loss\": 0.792048305273, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1930/2500\", \"loss\": 0.911585509777, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1940/2500\", \"loss\": 0.683034718037, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1950/2500\", \"loss\": 0.978544235229, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1960/2500\", \"loss\": 0.914555698633, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1970/2500\", \"loss\": 0.933990418911, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1980/2500\", \"loss\": 0.617137908936, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1990/2500\", \"loss\": 0.864475071430, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2000/2500\", \"loss\": 0.702269881964, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2010/2500\", \"loss\": 0.716687083244, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2020/2500\", \"loss\": 0.804710984230, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2030/2500\", \"loss\": 0.871050447226, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2040/2500\", \"loss\": 0.831152200699, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2050/2500\", \"loss\": 0.633019059896, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2060/2500\", \"loss\": 0.629770591855, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2070/2500\", \"loss\": 0.979053229094, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2080/2500\", \"loss\": 0.841438233852, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2090/2500\", \"loss\": 0.694908261299, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2100/2500\", \"loss\": 0.969559192657, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2110/2500\", \"loss\": 0.796444356441, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2120/2500\", \"loss\": 0.715187668800, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2130/2500\", \"loss\": 0.620332479477, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2140/2500\", \"loss\": 0.687726765871, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2150/2500\", \"loss\": 0.982981979847, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2160/2500\", \"loss\": 0.711385965347, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2170/2500\", \"loss\": 0.548368304968, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2180/2500\", \"loss\": 0.687143027782, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2190/2500\", \"loss\": 0.617311954498, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2200/2500\", \"loss\": 0.842554122210, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2210/2500\", \"loss\": 0.876259028912, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2220/2500\", \"loss\": 0.837840199471, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2230/2500\", \"loss\": 0.668350696564, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2240/2500\", \"loss\": 0.934143573046, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2250/2500\", \"loss\": 0.821560591459, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2260/2500\", \"loss\": 1.021086275578, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2270/2500\", \"loss\": 0.791645109653, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2280/2500\", \"loss\": 0.622090578079, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2290/2500\", \"loss\": 0.708250731230, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2300/2500\", \"loss\": 0.770910531282, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2310/2500\", \"loss\": 0.878795385361, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2320/2500\", \"loss\": 0.868473231792, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2330/2500\", \"loss\": 0.942340582609, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2340/2500\", \"loss\": 0.626071721315, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2350/2500\", \"loss\": 0.957096219063, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2360/2500\", \"loss\": 0.740976661444, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2370/2500\", \"loss\": 1.220794141293, \"lr\": 0.000159816788, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2380/2500\", \"loss\": 0.575428813696, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2390/2500\", \"loss\": 0.624297469854, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2400/2500\", \"loss\": 0.393330410123, \"lr\": 0.000159816788, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2410/2500\", \"loss\": 0.716873139143, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2420/2500\", \"loss\": 0.864484935999, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2430/2500\", \"loss\": 0.901650100946, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2440/2500\", \"loss\": 0.844186097383, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2450/2500\", \"loss\": 0.734592735767, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2460/2500\", \"loss\": 0.789119482040, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2470/2500\", \"loss\": 0.681796371937, \"lr\": 0.000159816788, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2480/2500\", \"loss\": 0.868419855833, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2490/2500\", \"loss\": 1.056044101715, \"lr\": 0.000159816788, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"2500/2500\", \"loss\": 0.768786340952, \"lr\": 0.000159816788, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.840013355356, \"lr\": 0.000159816788, \"top1_err\": 29.480000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 30.250000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 30.250000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 30.920001678467, \"top1_err\": 30.920001678467}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_69.0799983215332_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-1/checkpoints/vlBest_acc_69.0799983215332_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:51:39,976]\u001b[0m Trial 1 finished with value: 69.0799983215332 and parameters: {'learning_rate': 0.00015981678818517418, 'weight_decay': 3.4566036820467953e-07, 'batch_size': 8, 'optimizer': 'SGD'}. Best is trial 1 with value: 69.0799983215332.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0002282201923804006\n",
      "Weight Decay : 0.0008449079244088544\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0002282201923804006\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0008449079244088544\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.437466025352, \"lr\": 0.000228220192, \"top1_err\": 90.429687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.310403466225, \"lr\": 0.000228220192, \"top1_err\": 83.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.226317167282, \"lr\": 0.000228220192, \"top1_err\": 80.273437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 2.175957202911, \"lr\": 0.000228220192, \"top1_err\": 76.757812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 2.151478409767, \"lr\": 0.000228220192, \"top1_err\": 77.929687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 2.078990101814, \"lr\": 0.000228220192, \"top1_err\": 74.804687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 2.049338936806, \"lr\": 0.000228220192, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.186560133171, \"lr\": 0.000228220192, \"top1_err\": 78.890000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 73.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 72.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 72.460000305176, \"top1_err\": 72.460000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 1.965383827686, \"lr\": 0.000228220192, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 1.959059298038, \"lr\": 0.000228220192, \"top1_err\": 71.679687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 1.955858588219, \"lr\": 0.000228220192, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 1.932725131512, \"lr\": 0.000228220192, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 1.887879729271, \"lr\": 0.000228220192, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 1.872707426548, \"lr\": 0.000228220192, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 1.860725581646, \"lr\": 0.000228220192, \"top1_err\": 67.773437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.904379650879, \"lr\": 0.000228220192, \"top1_err\": 68.830000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 67.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 66.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 66.520000305176, \"top1_err\": 66.520000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 1.809153378010, \"lr\": 0.000228220192, \"top1_err\": 64.648437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 1.805740356445, \"lr\": 0.000228220192, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 1.756806552410, \"lr\": 0.000228220192, \"top1_err\": 64.257812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 1.725525319576, \"lr\": 0.000228220192, \"top1_err\": 62.304687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 1.746604084969, \"lr\": 0.000228220192, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 1.701171100140, \"lr\": 0.000228220192, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 1.691195189953, \"lr\": 0.000228220192, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.740702096939, \"lr\": 0.000228220192, \"top1_err\": 63.495000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 64.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 61.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 61.760000915527, \"top1_err\": 61.760000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 1.658022701740, \"lr\": 0.000228220192, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 1.639004945755, \"lr\": 0.000228220192, \"top1_err\": 59.179687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 1.684564530849, \"lr\": 0.000228220192, \"top1_err\": 59.960937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 1.605832993984, \"lr\": 0.000228220192, \"top1_err\": 58.007812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 1.584996223450, \"lr\": 0.000228220192, \"top1_err\": 57.226562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 1.597275435925, \"lr\": 0.000228220192, \"top1_err\": 58.007812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 1.567279458046, \"lr\": 0.000228220192, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.614147854805, \"lr\": 0.000228220192, \"top1_err\": 58.630000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 59.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 57.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 58.600000610352, \"top1_err\": 58.600000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 1.504722595215, \"lr\": 0.000228220192, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 1.534383594990, \"lr\": 0.000228220192, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 1.528186559677, \"lr\": 0.000228220192, \"top1_err\": 55.664062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 1.554477989674, \"lr\": 0.000228220192, \"top1_err\": 56.835937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 1.539473295212, \"lr\": 0.000228220192, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 1.510750710964, \"lr\": 0.000228220192, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 1.511019825935, \"lr\": 0.000228220192, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.524033454514, \"lr\": 0.000228220192, \"top1_err\": 55.480000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 54.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 56.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 55.680000762939, \"top1_err\": 55.680000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_44.31999923706055_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-2/checkpoints/vlBest_acc_44.31999923706055_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:52:43,956]\u001b[0m Trial 2 finished with value: 44.31999923706055 and parameters: {'learning_rate': 0.0002282201923804006, 'weight_decay': 0.0008449079244088544, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 1 with value: 69.0799983215332.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.00032208953581698357\n",
      "Weight Decay : 9.453892741256792e-05\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00032208953581698357\n",
      "    weight_decay: 9.453892741256792e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 625\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/625\", \"loss\": 2.211740851402, \"lr\": 0.000322089536, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/625\", \"loss\": 2.083079457283, \"lr\": 0.000322089536, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/625\", \"loss\": 1.890912890434, \"lr\": 0.000322089536, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/625\", \"loss\": 1.760918796062, \"lr\": 0.000322089536, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/625\", \"loss\": 1.875103533268, \"lr\": 0.000322089536, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/625\", \"loss\": 1.841744124889, \"lr\": 0.000322089536, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/625\", \"loss\": 1.753707587719, \"lr\": 0.000322089536, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/625\", \"loss\": 1.794854700565, \"lr\": 0.000322089536, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/625\", \"loss\": 1.596888899803, \"lr\": 0.000322089536, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/625\", \"loss\": 1.697455406189, \"lr\": 0.000322089536, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/625\", \"loss\": 1.708793103695, \"lr\": 0.000322089536, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/625\", \"loss\": 1.766961514950, \"lr\": 0.000322089536, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/625\", \"loss\": 1.658406734467, \"lr\": 0.000322089536, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/625\", \"loss\": 1.622607588768, \"lr\": 0.000322089536, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/625\", \"loss\": 1.621852993965, \"lr\": 0.000322089536, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/625\", \"loss\": 1.558791100979, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/625\", \"loss\": 1.576910972595, \"lr\": 0.000322089536, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/625\", \"loss\": 1.585556030273, \"lr\": 0.000322089536, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/625\", \"loss\": 1.586572289467, \"lr\": 0.000322089536, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/625\", \"loss\": 1.554432809353, \"lr\": 0.000322089536, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/625\", \"loss\": 1.523375988007, \"lr\": 0.000322089536, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/625\", \"loss\": 1.529322445393, \"lr\": 0.000322089536, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/625\", \"loss\": 1.532651185989, \"lr\": 0.000322089536, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/625\", \"loss\": 1.519378602505, \"lr\": 0.000322089536, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/625\", \"loss\": 1.471370697021, \"lr\": 0.000322089536, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/625\", \"loss\": 1.406714439392, \"lr\": 0.000322089536, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/625\", \"loss\": 1.523703277111, \"lr\": 0.000322089536, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/625\", \"loss\": 1.424215137959, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/625\", \"loss\": 1.419223010540, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/625\", \"loss\": 1.479589402676, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/625\", \"loss\": 1.452457666397, \"lr\": 0.000322089536, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/625\", \"loss\": 1.376626849174, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/625\", \"loss\": 1.457077801228, \"lr\": 0.000322089536, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/625\", \"loss\": 1.344507098198, \"lr\": 0.000322089536, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/625\", \"loss\": 1.448594748974, \"lr\": 0.000322089536, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/625\", \"loss\": 1.397608160973, \"lr\": 0.000322089536, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/625\", \"loss\": 1.511751115322, \"lr\": 0.000322089536, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/625\", \"loss\": 1.475512206554, \"lr\": 0.000322089536, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/625\", \"loss\": 1.524403810501, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/625\", \"loss\": 1.395360827446, \"lr\": 0.000322089536, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/625\", \"loss\": 1.281033039093, \"lr\": 0.000322089536, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/625\", \"loss\": 1.504082679749, \"lr\": 0.000322089536, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/625\", \"loss\": 1.414697766304, \"lr\": 0.000322089536, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/625\", \"loss\": 1.343606412411, \"lr\": 0.000322089536, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/625\", \"loss\": 1.308338642120, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/625\", \"loss\": 1.384831190109, \"lr\": 0.000322089536, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/625\", \"loss\": 1.283794999123, \"lr\": 0.000322089536, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/625\", \"loss\": 1.332908511162, \"lr\": 0.000322089536, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/625\", \"loss\": 1.353806853294, \"lr\": 0.000322089536, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/625\", \"loss\": 1.339220285416, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/625\", \"loss\": 1.297631204128, \"lr\": 0.000322089536, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/625\", \"loss\": 1.352461099625, \"lr\": 0.000322089536, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/625\", \"loss\": 1.164139926434, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/625\", \"loss\": 1.158213913441, \"lr\": 0.000322089536, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/625\", \"loss\": 1.413059771061, \"lr\": 0.000322089536, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/625\", \"loss\": 1.228450417519, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/625\", \"loss\": 1.267519891262, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/625\", \"loss\": 1.212184369564, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/625\", \"loss\": 1.354456722736, \"lr\": 0.000322089536, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/625\", \"loss\": 1.286345899105, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/625\", \"loss\": 1.189270853996, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/625\", \"loss\": 1.175095796585, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.496908756542, \"lr\": 0.000322089536, \"top1_err\": 54.690000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 45.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 45.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 45.120001831055, \"top1_err\": 45.120001831055}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/625\", \"loss\": 1.144270837307, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/625\", \"loss\": 1.250068247318, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/625\", \"loss\": 1.098253190517, \"lr\": 0.000322089536, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/625\", \"loss\": 1.106580972672, \"lr\": 0.000322089536, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/625\", \"loss\": 1.242615640163, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/625\", \"loss\": 1.268439352512, \"lr\": 0.000322089536, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/625\", \"loss\": 1.190900325775, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/625\", \"loss\": 1.197230756283, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/625\", \"loss\": 1.111813902855, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/625\", \"loss\": 1.155735552311, \"lr\": 0.000322089536, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/625\", \"loss\": 1.104449629784, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/625\", \"loss\": 1.224595844746, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/625\", \"loss\": 1.252745449543, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/625\", \"loss\": 1.212453305721, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/625\", \"loss\": 1.095244109631, \"lr\": 0.000322089536, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/625\", \"loss\": 1.041272819042, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/625\", \"loss\": 1.105274856091, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/625\", \"loss\": 1.133546769619, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/625\", \"loss\": 1.195727467537, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/625\", \"loss\": 1.028915882111, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/625\", \"loss\": 1.161598742008, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/625\", \"loss\": 1.105898499489, \"lr\": 0.000322089536, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/625\", \"loss\": 1.207608580589, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/625\", \"loss\": 1.143734276295, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/625\", \"loss\": 1.177451491356, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/625\", \"loss\": 1.075418889523, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/625\", \"loss\": 1.146542429924, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/625\", \"loss\": 1.002498716116, \"lr\": 0.000322089536, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/625\", \"loss\": 0.988468676805, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/625\", \"loss\": 1.116533517838, \"lr\": 0.000322089536, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/625\", \"loss\": 1.040398120880, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/625\", \"loss\": 0.963456600904, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/625\", \"loss\": 1.046707212925, \"lr\": 0.000322089536, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/625\", \"loss\": 0.924333095551, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/625\", \"loss\": 0.969713658094, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/625\", \"loss\": 1.079563558102, \"lr\": 0.000322089536, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/625\", \"loss\": 1.080218493938, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/625\", \"loss\": 1.071221530437, \"lr\": 0.000322089536, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/625\", \"loss\": 0.959214925766, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/625\", \"loss\": 1.037304461002, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/625\", \"loss\": 0.990297764540, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/625\", \"loss\": 1.040085792542, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/625\", \"loss\": 0.989740282297, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/625\", \"loss\": 1.057374000549, \"lr\": 0.000322089536, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/625\", \"loss\": 0.965685963631, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/625\", \"loss\": 0.922017782927, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/625\", \"loss\": 1.037056982517, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/625\", \"loss\": 0.921235769987, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/625\", \"loss\": 0.915634244680, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/625\", \"loss\": 0.985403418541, \"lr\": 0.000322089536, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/625\", \"loss\": 0.879215776920, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/625\", \"loss\": 1.132807970047, \"lr\": 0.000322089536, \"top1_err\": 39.062500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/625\", \"loss\": 0.954321146011, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/625\", \"loss\": 0.975706219673, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/625\", \"loss\": 1.060146510601, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/625\", \"loss\": 1.053800642490, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/625\", \"loss\": 0.972229629755, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/625\", \"loss\": 0.930537313223, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/625\", \"loss\": 0.983540922403, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/625\", \"loss\": 0.908479511738, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/625\", \"loss\": 0.914879709482, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/625\", \"loss\": 1.030901432037, \"lr\": 0.000322089536, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.060398330498, \"lr\": 0.000322089536, \"top1_err\": 38.045000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 33.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 31.720001220703, \"top1_err\": 31.720001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/625\", \"loss\": 0.830249100924, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/625\", \"loss\": 0.804055571556, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/625\", \"loss\": 0.879374295473, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/625\", \"loss\": 0.877930611372, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/625\", \"loss\": 0.806781083345, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/625\", \"loss\": 0.905271619558, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/625\", \"loss\": 0.861952573061, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/625\", \"loss\": 0.800904095173, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/625\", \"loss\": 0.889903306961, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/625\", \"loss\": 0.841882139444, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/625\", \"loss\": 0.844657808542, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/625\", \"loss\": 0.865673750639, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/625\", \"loss\": 0.823089748621, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/625\", \"loss\": 0.863799959421, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/625\", \"loss\": 0.844754070044, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/625\", \"loss\": 0.829801321030, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/625\", \"loss\": 0.752837926149, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/625\", \"loss\": 0.891702204943, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/625\", \"loss\": 0.890774548054, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/625\", \"loss\": 0.774777948856, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/625\", \"loss\": 1.069038271904, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/625\", \"loss\": 0.800042182207, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/625\", \"loss\": 0.804319381714, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/625\", \"loss\": 0.865970909595, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/625\", \"loss\": 0.868879795074, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/625\", \"loss\": 0.809658139944, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/625\", \"loss\": 0.788289844990, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/625\", \"loss\": 0.822017759085, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/625\", \"loss\": 0.802861928940, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/625\", \"loss\": 1.021166771650, \"lr\": 0.000322089536, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/625\", \"loss\": 0.837132245302, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/625\", \"loss\": 0.716199904680, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/625\", \"loss\": 0.762230724096, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/625\", \"loss\": 0.798984825611, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/625\", \"loss\": 0.717372417450, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/625\", \"loss\": 0.923835277557, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/625\", \"loss\": 0.826087713242, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/625\", \"loss\": 0.923270642757, \"lr\": 0.000322089536, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/625\", \"loss\": 0.898956686258, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/625\", \"loss\": 0.802020847797, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/625\", \"loss\": 0.840242713690, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/625\", \"loss\": 0.847315281630, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/625\", \"loss\": 0.842192411423, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/625\", \"loss\": 0.857035279274, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/625\", \"loss\": 0.884953379631, \"lr\": 0.000322089536, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/625\", \"loss\": 0.804601728916, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/625\", \"loss\": 0.816934525967, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/625\", \"loss\": 0.747792869806, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/625\", \"loss\": 0.737904250622, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/625\", \"loss\": 0.727996587753, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/625\", \"loss\": 0.769006222486, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/625\", \"loss\": 0.736795127392, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/625\", \"loss\": 0.918142110109, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/625\", \"loss\": 0.813322007656, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/625\", \"loss\": 0.823005765676, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/625\", \"loss\": 0.739053040743, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/625\", \"loss\": 0.848584115505, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/625\", \"loss\": 0.791953682899, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/625\", \"loss\": 0.816042661667, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/625\", \"loss\": 0.841773360968, \"lr\": 0.000322089536, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/625\", \"loss\": 0.790632903576, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/625\", \"loss\": 0.699941754341, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 0.845102691364, \"lr\": 0.000322089536, \"top1_err\": 29.825000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 28.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 28.500002861023}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 28.440002059937, \"top1_err\": 28.440002059937}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/625\", \"loss\": 0.701851099730, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/625\", \"loss\": 0.556802392006, \"lr\": 0.000322089536, \"top1_err\": 15.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/625\", \"loss\": 0.622127801180, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/625\", \"loss\": 0.757383227348, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/625\", \"loss\": 0.693311095238, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/625\", \"loss\": 0.730921119452, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/625\", \"loss\": 0.708195239305, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/625\", \"loss\": 0.762972056866, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/625\", \"loss\": 0.688595592976, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/625\", \"loss\": 0.670875042677, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/625\", \"loss\": 0.678284049034, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/625\", \"loss\": 0.801406770945, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/625\", \"loss\": 0.589004784822, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/625\", \"loss\": 0.676867842674, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/625\", \"loss\": 0.722321033478, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/625\", \"loss\": 0.618936896324, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/625\", \"loss\": 0.671831369400, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/625\", \"loss\": 0.836518496275, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/625\", \"loss\": 0.685062408447, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/625\", \"loss\": 0.794567257166, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/625\", \"loss\": 0.668475300074, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/625\", \"loss\": 0.761819124222, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/625\", \"loss\": 0.641007572412, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/625\", \"loss\": 0.765892803669, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/625\", \"loss\": 0.738500893116, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/625\", \"loss\": 0.715677201748, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/625\", \"loss\": 0.709021985531, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/625\", \"loss\": 0.649817973375, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/625\", \"loss\": 0.703981935978, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/625\", \"loss\": 0.760945320129, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/625\", \"loss\": 0.693428874016, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/625\", \"loss\": 0.635520398617, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/625\", \"loss\": 0.658651292324, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/625\", \"loss\": 0.651673167944, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/625\", \"loss\": 0.678635537624, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/625\", \"loss\": 0.811723023653, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/625\", \"loss\": 0.671488225460, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/625\", \"loss\": 0.707024127245, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/625\", \"loss\": 0.709756076336, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/625\", \"loss\": 0.771932035685, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/625\", \"loss\": 0.758037388325, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/625\", \"loss\": 0.642755746841, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/625\", \"loss\": 0.740899384022, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/625\", \"loss\": 0.709831088781, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/625\", \"loss\": 0.760428160429, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/625\", \"loss\": 0.643803119659, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/625\", \"loss\": 0.633377850056, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/625\", \"loss\": 0.774759024382, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/625\", \"loss\": 0.554421544075, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/625\", \"loss\": 0.786486268044, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/625\", \"loss\": 0.595472693443, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/625\", \"loss\": 0.730352133512, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/625\", \"loss\": 0.535509735346, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/625\", \"loss\": 0.781097322702, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/625\", \"loss\": 0.576574057341, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/625\", \"loss\": 0.669965475798, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/625\", \"loss\": 0.748021006584, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/625\", \"loss\": 0.746780753136, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/625\", \"loss\": 0.643537729979, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/625\", \"loss\": 0.668179094791, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/625\", \"loss\": 0.671344071627, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/625\", \"loss\": 0.761216402054, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.708686425066, \"lr\": 0.000322089536, \"top1_err\": 25.085000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 27.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 24.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 25.180001678467, \"top1_err\": 25.180001678467}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/625\", \"loss\": 0.570832699537, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/625\", \"loss\": 0.513631165028, \"lr\": 0.000322089536, \"top1_err\": 15.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/625\", \"loss\": 0.496841490269, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/625\", \"loss\": 0.473895668983, \"lr\": 0.000322089536, \"top1_err\": 17.187500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/625\", \"loss\": 0.545797109604, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/625\", \"loss\": 0.685539692640, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/625\", \"loss\": 0.528580814600, \"lr\": 0.000322089536, \"top1_err\": 14.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/625\", \"loss\": 0.496388837695, \"lr\": 0.000322089536, \"top1_err\": 17.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/625\", \"loss\": 0.490011066198, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/625\", \"loss\": 0.529974460602, \"lr\": 0.000322089536, \"top1_err\": 17.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/625\", \"loss\": 0.532762467861, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/625\", \"loss\": 0.606606245041, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/625\", \"loss\": 0.676882356405, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/625\", \"loss\": 0.652703464031, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/625\", \"loss\": 0.566386401653, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/625\", \"loss\": 0.681786328554, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/625\", \"loss\": 0.662053316832, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/625\", \"loss\": 0.538591951132, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/625\", \"loss\": 0.595656812191, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/625\", \"loss\": 0.556391328573, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/625\", \"loss\": 0.591135948896, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/625\", \"loss\": 0.473836407065, \"lr\": 0.000322089536, \"top1_err\": 14.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/625\", \"loss\": 0.559794038534, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/625\", \"loss\": 0.626058578491, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/625\", \"loss\": 0.594674438238, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/625\", \"loss\": 0.683557271957, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/625\", \"loss\": 0.681781888008, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/625\", \"loss\": 0.611159890890, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/625\", \"loss\": 0.662601530552, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/625\", \"loss\": 0.636221051216, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/625\", \"loss\": 0.597161114216, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/625\", \"loss\": 0.643925189972, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/625\", \"loss\": 0.513088673353, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/625\", \"loss\": 0.595578074455, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/625\", \"loss\": 0.648708701134, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/625\", \"loss\": 0.665479183197, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/625\", \"loss\": 0.645915329456, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/625\", \"loss\": 0.583398044109, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/625\", \"loss\": 0.510860919952, \"lr\": 0.000322089536, \"top1_err\": 15.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/625\", \"loss\": 0.667176216841, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/625\", \"loss\": 0.665925413370, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/625\", \"loss\": 0.688119888306, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/625\", \"loss\": 0.584378659725, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/625\", \"loss\": 0.651133358479, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/625\", \"loss\": 0.596580594778, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/625\", \"loss\": 0.637965768576, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/625\", \"loss\": 0.588399618864, \"lr\": 0.000322089536, \"top1_err\": 15.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/625\", \"loss\": 0.669475018978, \"lr\": 0.000322089536, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/625\", \"loss\": 0.680577814579, \"lr\": 0.000322089536, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/625\", \"loss\": 0.559467613697, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/625\", \"loss\": 0.627832561731, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/625\", \"loss\": 0.641204744577, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/625\", \"loss\": 0.673259645700, \"lr\": 0.000322089536, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/625\", \"loss\": 0.600373059511, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/625\", \"loss\": 0.587589591742, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/625\", \"loss\": 0.688686341047, \"lr\": 0.000322089536, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/625\", \"loss\": 0.632956475019, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/625\", \"loss\": 0.598821640015, \"lr\": 0.000322089536, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/625\", \"loss\": 0.721536993980, \"lr\": 0.000322089536, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/625\", \"loss\": 0.562692642212, \"lr\": 0.000322089536, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/625\", \"loss\": 0.696495234966, \"lr\": 0.000322089536, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/625\", \"loss\": 0.480088695884, \"lr\": 0.000322089536, \"top1_err\": 15.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.615733976960, \"lr\": 0.000322089536, \"top1_err\": 21.495000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 22.250002861023}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 23.750000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 23.400002059937, \"top1_err\": 23.400002059937}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_76.59999794006347_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_76.59999794006347_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:56:56,348]\u001b[0m Trial 3 finished with value: 76.59999794006347 and parameters: {'learning_rate': 0.00032208953581698357, 'weight_decay': 9.453892741256792e-05, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 3 with value: 76.59999794006347.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 1.441382172242656e-05\n",
      "Weight Decay : 4.150842426469941e-07\n",
      "Batch Size   : 64\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 1.441382172242656e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 4.150842426469941e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_63.85999839782715_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/313\", \"loss\": 2.487718343735, \"lr\": 0.000014413822, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/313\", \"loss\": 2.468829870224, \"lr\": 0.000014413822, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/313\", \"loss\": 2.446822404861, \"lr\": 0.000014413822, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 2.407191514969, \"lr\": 0.000014413822, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/313\", \"loss\": 2.405077934265, \"lr\": 0.000014413822, \"top1_err\": 91.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/313\", \"loss\": 2.396260499954, \"lr\": 0.000014413822, \"top1_err\": 91.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/313\", \"loss\": 2.340283393860, \"lr\": 0.000014413822, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 2.396889448166, \"lr\": 0.000014413822, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/313\", \"loss\": 2.382622718811, \"lr\": 0.000014413822, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/313\", \"loss\": 2.342121958733, \"lr\": 0.000014413822, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/313\", \"loss\": 2.325950145721, \"lr\": 0.000014413822, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 2.337617397308, \"lr\": 0.000014413822, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/313\", \"loss\": 2.333906769753, \"lr\": 0.000014413822, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/313\", \"loss\": 2.343943834305, \"lr\": 0.000014413822, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/313\", \"loss\": 2.327464461327, \"lr\": 0.000014413822, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 2.278092026711, \"lr\": 0.000014413822, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/313\", \"loss\": 2.321663737297, \"lr\": 0.000014413822, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/313\", \"loss\": 2.304857134819, \"lr\": 0.000014413822, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/313\", \"loss\": 2.258458495140, \"lr\": 0.000014413822, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 2.282127499580, \"lr\": 0.000014413822, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/313\", \"loss\": 2.264254450798, \"lr\": 0.000014413822, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/313\", \"loss\": 2.240269184113, \"lr\": 0.000014413822, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/313\", \"loss\": 2.241472840309, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 2.225960731506, \"lr\": 0.000014413822, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/313\", \"loss\": 2.234469294548, \"lr\": 0.000014413822, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/313\", \"loss\": 2.239240884781, \"lr\": 0.000014413822, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/313\", \"loss\": 2.237630486488, \"lr\": 0.000014413822, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 2.227900981903, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/313\", \"loss\": 2.215102910995, \"lr\": 0.000014413822, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/313\", \"loss\": 2.232775568962, \"lr\": 0.000014413822, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/313\", \"loss\": 2.212790012360, \"lr\": 0.000014413822, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.312924395752, \"lr\": 0.000014413822, \"top1_err\": 84.255000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 78.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 80.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 79.200000000000, \"top1_err\": 79.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/313\", \"loss\": 2.196280360222, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/313\", \"loss\": 2.200488924980, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/313\", \"loss\": 2.198668956757, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 2.190160870552, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/313\", \"loss\": 2.174478054047, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/313\", \"loss\": 2.192122817039, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/313\", \"loss\": 2.202282428741, \"lr\": 0.000014413822, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 2.182684421539, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/313\", \"loss\": 2.222772717476, \"lr\": 0.000014413822, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/313\", \"loss\": 2.178754687309, \"lr\": 0.000014413822, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/313\", \"loss\": 2.164906144142, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 2.172321081161, \"lr\": 0.000014413822, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/313\", \"loss\": 2.190535902977, \"lr\": 0.000014413822, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/313\", \"loss\": 2.186414003372, \"lr\": 0.000014413822, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/313\", \"loss\": 2.139957189560, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 2.153524398804, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/313\", \"loss\": 2.138493537903, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/313\", \"loss\": 2.144532561302, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/313\", \"loss\": 2.169723153114, \"lr\": 0.000014413822, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 2.141977071762, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/313\", \"loss\": 2.147728443146, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/313\", \"loss\": 2.149302601814, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/313\", \"loss\": 2.142521381378, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 2.108935713768, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/313\", \"loss\": 2.121715664864, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/313\", \"loss\": 2.118611454964, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/313\", \"loss\": 2.110319972038, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 2.134426951408, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/313\", \"loss\": 2.112361788750, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/313\", \"loss\": 2.122989773750, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/313\", \"loss\": 2.129871129990, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.159548159409, \"lr\": 0.000014413822, \"top1_err\": 76.690000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 76.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 74.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 75.420000000000, \"top1_err\": 75.420000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/313\", \"loss\": 2.095528602600, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/313\", \"loss\": 2.091655135155, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/313\", \"loss\": 2.095489025116, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 2.079361081123, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/313\", \"loss\": 2.081640958786, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/313\", \"loss\": 2.111384868622, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/313\", \"loss\": 2.115678787231, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 2.101359605789, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/313\", \"loss\": 2.082985401154, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/313\", \"loss\": 2.094101309776, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/313\", \"loss\": 2.078596949577, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 2.048701405525, \"lr\": 0.000014413822, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/313\", \"loss\": 2.046180009842, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/313\", \"loss\": 2.056948184967, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/313\", \"loss\": 2.072965383530, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 2.071229577065, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/313\", \"loss\": 2.088766455650, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/313\", \"loss\": 2.096037626266, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/313\", \"loss\": 2.033075690269, \"lr\": 0.000014413822, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 2.067103028297, \"lr\": 0.000014413822, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/313\", \"loss\": 2.026785016060, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/313\", \"loss\": 2.062909841537, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/313\", \"loss\": 2.050662040710, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 2.069268584251, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/313\", \"loss\": 2.058179974556, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/313\", \"loss\": 2.037129282951, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/313\", \"loss\": 2.037650704384, \"lr\": 0.000014413822, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 2.032189846039, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/313\", \"loss\": 2.028939247131, \"lr\": 0.000014413822, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/313\", \"loss\": 2.046679139137, \"lr\": 0.000014413822, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/313\", \"loss\": 2.034913659096, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.070772651291, \"lr\": 0.000014413822, \"top1_err\": 74.210000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 74.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 72.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 73.260000915527, \"top1_err\": 73.260000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/313\", \"loss\": 2.020835161209, \"lr\": 0.000014413822, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/313\", \"loss\": 2.024399280548, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/313\", \"loss\": 2.024044156075, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 2.033816337585, \"lr\": 0.000014413822, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/313\", \"loss\": 2.005753815174, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/313\", \"loss\": 2.046478152275, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/313\", \"loss\": 2.049412727356, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 2.034630298615, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/313\", \"loss\": 2.041027784348, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/313\", \"loss\": 2.020412921906, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/313\", \"loss\": 2.044622302055, \"lr\": 0.000014413822, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 2.014532685280, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/313\", \"loss\": 1.979904830456, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/313\", \"loss\": 1.983612596989, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/313\", \"loss\": 1.995054781437, \"lr\": 0.000014413822, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 1.968643188477, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/313\", \"loss\": 1.979936480522, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/313\", \"loss\": 2.006048619747, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/313\", \"loss\": 1.975223600864, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 1.987757861614, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/313\", \"loss\": 1.965027570724, \"lr\": 0.000014413822, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/313\", \"loss\": 1.955783605576, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/313\", \"loss\": 1.996276676655, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 1.968165695667, \"lr\": 0.000014413822, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/313\", \"loss\": 1.997328758240, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/313\", \"loss\": 1.964936077595, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/313\", \"loss\": 1.969625532627, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 1.980698347092, \"lr\": 0.000014413822, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/313\", \"loss\": 2.001740217209, \"lr\": 0.000014413822, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/313\", \"loss\": 1.954613745213, \"lr\": 0.000014413822, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/313\", \"loss\": 1.986785531044, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.000363548660, \"lr\": 0.000014413822, \"top1_err\": 71.495000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 71.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 72.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 71.500001220703, \"top1_err\": 71.500001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/313\", \"loss\": 1.941426873207, \"lr\": 0.000014413822, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/313\", \"loss\": 1.946275353432, \"lr\": 0.000014413822, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/313\", \"loss\": 1.975739896297, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 1.947887003422, \"lr\": 0.000014413822, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/313\", \"loss\": 1.925799787045, \"lr\": 0.000014413822, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/313\", \"loss\": 1.974982321262, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/313\", \"loss\": 1.981169819832, \"lr\": 0.000014413822, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 1.963297307491, \"lr\": 0.000014413822, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/313\", \"loss\": 1.953433156013, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/313\", \"loss\": 1.961344957352, \"lr\": 0.000014413822, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/313\", \"loss\": 1.989992320538, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 1.997597396374, \"lr\": 0.000014413822, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/313\", \"loss\": 1.945498824120, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/313\", \"loss\": 1.931275248528, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/313\", \"loss\": 1.999795854092, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 1.918541610241, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/313\", \"loss\": 1.953587055206, \"lr\": 0.000014413822, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/313\", \"loss\": 1.949012517929, \"lr\": 0.000014413822, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/313\", \"loss\": 1.955703616142, \"lr\": 0.000014413822, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 1.951777458191, \"lr\": 0.000014413822, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/313\", \"loss\": 1.913561105728, \"lr\": 0.000014413822, \"top1_err\": 67.187500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/313\", \"loss\": 1.950592517853, \"lr\": 0.000014413822, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/313\", \"loss\": 1.916836738586, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 1.897033035755, \"lr\": 0.000014413822, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/313\", \"loss\": 1.893063366413, \"lr\": 0.000014413822, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/313\", \"loss\": 1.927349507809, \"lr\": 0.000014413822, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/313\", \"loss\": 1.908626019955, \"lr\": 0.000014413822, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 1.945396840572, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/313\", \"loss\": 1.920977771282, \"lr\": 0.000014413822, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/313\", \"loss\": 1.919886946678, \"lr\": 0.000014413822, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/313\", \"loss\": 1.905150771141, \"lr\": 0.000014413822, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.942993748856, \"lr\": 0.000014413822, \"top1_err\": 69.640000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 68.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 69.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 70.080000305176, \"top1_err\": 70.080000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_29.919999694824213_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-4/checkpoints/vlBest_acc_29.919999694824213_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:59:01,075]\u001b[0m Trial 4 finished with value: 29.919999694824213 and parameters: {'learning_rate': 1.441382172242656e-05, 'weight_decay': 4.150842426469941e-07, 'batch_size': 64, 'optimizer': 'SGD'}. Best is trial 3 with value: 76.59999794006347.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 1340.7161571979523 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 76.59999794006347\n",
      "  Params: \n",
      "    learning_rate: 0.00032208953581698357\n",
      "    weight_decay: 9.453892741256792e-05\n",
      "    batch_size: 32\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/trial-3/checkpoints/vlBest_acc_76.59999794006347_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_tgtw9e8v.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: resnet_2\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  20000\n",
      "len(lSEt):  20000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 25000 and len(uSet): 20000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/activeSet.txt in text format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  20000\n",
      "len(lSet):  25000\n",
      "For random sampling, activeSet accuracy:  77.2\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_76.59999794006347_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_76.59999794006347_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/checkpoints/vlBest_acc_76.59999794006347_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 24.000000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 22.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 21.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 23.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 23.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 22.700001907349, \"top1_err\": 22.700001907349}\n",
      "Test Accuracy: 77.300\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/resnet_2_depth_18/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on CIFAR10 using 40.0% of data is 77.29999809265136\n",
      "\n",
      "Extracted Test Accuracy from subproces: 77.29999809265136\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/50.0/random/resnet_2_depth_18/vanilla/\n"
     ]
    }
   ],
   "source": [
    "!python3 $HOME_DIRECTORY/tools/main_aml.py --n_GPU $num_GPU \\\n",
    "--port $port --sampling_fn $sampling_fn --lSet_partition $lSet_partition \\\n",
    "--seed_id $base_seed \\\n",
    "--init_partition $init_partition --step_partition $step_partition \\\n",
    "--dataset $dataset --budget_size $budget_size \\\n",
    "--out_dir $out_dir \\\n",
    "--num_aml_trials $num_aml_trials --num_classes $num_classes \\\n",
    "--al_max_iter $al_iterations \\\n",
    "--model_type $model_type --model_depth $model_depth \\\n",
    "--clf_epochs $clf_epochs \\\n",
    "--eval_period 1 --checkpoint_period 1 \\\n",
    "--lSetPath $lSetPath --uSetPath $uSetPath --valSetPath $valSetPath \\\n",
    "--train_dir $train_dir --test_dir $test_dir \\\n",
    "--dropout_iterations 25 \\\n",
    "--cfg configs/$dataset/$model_style/$model_type/R-18_4gpu_unreg.yaml \\\n",
    "--vaal_z_dim 32 --vaal_vae_bs 64 --vaal_epochs 2 \\\n",
    "--vaal_vae_lr 5e-4 --vaal_disc_lr 5e-4 --vaal_beta 1.0 --vaal_adv_param 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ee282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
