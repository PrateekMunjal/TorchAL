{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559020b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989b4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIRECTORY=os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "os.chdir(HOME_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be85e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # sync ids with nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4d99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script params\n",
    "port=5013\n",
    "sampling_fn=\"random\"\n",
    "lSet_partition=1\n",
    "base_seed=1\n",
    "num_GPU=1\n",
    "al_iterations=4\n",
    "num_aml_trials=5 #50\n",
    "budget_size=5000 #2500\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "init_partition=10\n",
    "step_partition=10\n",
    "clf_epochs=5 #150\n",
    "num_classes=10\n",
    "\n",
    "log_iter=40\n",
    "\n",
    "#Data arguments\n",
    "train_dir=f\"{HOME_DIRECTORY}/data/{dataset}/train-{dataset}/\"\n",
    "test_dir=f\"{HOME_DIRECTORY}/data/{dataset}/test-{dataset}/\"\n",
    "lSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/lSet_{dataset}.npy\"\n",
    "uSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/uSet_{dataset}.npy\"\n",
    "valSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/valSet_{dataset}.npy\"\n",
    "\n",
    "out_dir=f\"{HOME_DIRECTORY}/sample_results_aml_transfer\"\n",
    "\n",
    "model_style=\"vgg_style\"\n",
    "model_type=\"vgg\"\n",
    "model_depth=16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f42500",
   "metadata": {},
   "source": [
    "## Using active sets found using VGG16 for finetuning Resnet18. \n",
    "\n",
    "- We need to perform following steps to run the transfer experiment. \n",
    "- These steps are important as we wanted each results directory to contains results for single experimental setting. \n",
    "- With this we avoid any unintentional errors which can be caused by saving/overwriting models, logs, checkpoints of more than one experiment in same results folder.\n",
    "- Inorder to run transferability.\n",
    "    * Step1: Locate the path of active sets from source network. In our case it is <current_directory>/sample_results_aml\n",
    "    * Step2: To alleviate any bias in hyper-parameters selection when training the target architecture we again make use of AutoML running a random search over 50 trials. So in our new results directory (where we copy the active sets sampled using source architecture) we only have \"best_automl_results\" directory.\n",
    "    * Step3: Incase any checkpoints exist in results directory, make sure to remove them.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc909d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1\n",
    "activeset_dir=f\"{HOME_DIRECTORY}/sample_results_aml\"\n",
    "!mkdir -p $out_dir\n",
    "!scp -r $activeset_dir/best_automl_results $out_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9cc8bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints\n"
     ]
    }
   ],
   "source": [
    "#step2: if there exist checkpoints remove them\n",
    "dirlist = []\n",
    "extraFiles = []\n",
    "for root, dirs, files in os.walk(out_dir+\"/\"):\n",
    "    for d in dirs:\n",
    "        #append the dir name to the list\n",
    "        if os.path.basename(d)==\"checkpoints\":\n",
    "            dirlist.append(os.path.join(root,d))\n",
    "    for f in files:\n",
    "        #append the dir name to the list\n",
    "        if os.path.splitext(f)[1] not in [\".npy\"]:\n",
    "            extraFiles.append(os.path.join(root,f))\n",
    "\n",
    "dirlist.sort()            \n",
    "extraFiles.sort()            \n",
    "    \n",
    "#print all the dir names\n",
    "for d in dirlist:\n",
    "    print(\"Found\", d)\n",
    "    \n",
    "    \n",
    "# one can remove extrafiles too - however as they don't effect model learning - we omit to delete them in this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4619649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "Removed  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "Removed  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# We don't want to remove checkpoints for initial lab data, so we remove rest.\n",
    "best_base_path=None\n",
    "for i,d in enumerate(dirlist):\n",
    "    if i==0:\n",
    "        best_base_path=d\n",
    "        continue\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d+\"/\")\n",
    "        print(\"Removed \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc05feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to run the transfer experiment except to setup automl results for base 10% model. \n",
    "# Our codebase assumes that we have run automl even for initial model.\n",
    "\n",
    "automl_base_path=f\"{out_dir}/auto_ml_results/lSet_{lSet_partition}/start_{base_seed}/{dataset}/10.0/vgg_depth_16/vanilla/trial-0/\" \n",
    "!mkdir -p $automl_base_path\n",
    "!scp -r $best_base_path $automl_base_path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed330dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= [NO ADVANCED REGULARIZATION TRICK ACTIVATED] =========\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints\n",
      "Auto ml already exists; So skip doing automl for this!\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla: 1\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/\n",
      "--------------------\n",
      "Skipping best model inference as index sets already exists at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 52.499996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 51.979999771118, \"top1_err\": 51.979999771118}\n",
      "Test Accuracy: 48.020\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 10.0% of data is 48.020000228881834\n",
      "\n",
      "Extracted Test Accuracy from subproces: 48.020000228881834\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_sysxwd1h.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-04-02 21:15:15,874]\u001b[0m A new study created in memory with name: no-name-c8549399-e7f8-413e-b52f-196bdadfc379\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.0002824415655407379\n",
      "Weight Decay : 0.0007089834954929964\n",
      "Batch Size   : 16\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0002824415655407379\n",
      "    weight_decay: 0.0007089834954929964\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 625\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/625\", \"loss\": 2.487498044968, \"lr\": 0.000282441566, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/625\", \"loss\": 2.102945446968, \"lr\": 0.000282441566, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/625\", \"loss\": 1.986389040947, \"lr\": 0.000282441566, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/625\", \"loss\": 1.936379492283, \"lr\": 0.000282441566, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/625\", \"loss\": 2.043925523758, \"lr\": 0.000282441566, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/625\", \"loss\": 1.851932048798, \"lr\": 0.000282441566, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/625\", \"loss\": 1.820424437523, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/625\", \"loss\": 1.792563259602, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/625\", \"loss\": 1.841814815998, \"lr\": 0.000282441566, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/625\", \"loss\": 1.926536381245, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/625\", \"loss\": 1.862981557846, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/625\", \"loss\": 1.728744864464, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/625\", \"loss\": 1.692593038082, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/625\", \"loss\": 1.712879955769, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/625\", \"loss\": 1.762384712696, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/625\", \"loss\": 1.722576916218, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/625\", \"loss\": 1.668366312981, \"lr\": 0.000282441566, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/625\", \"loss\": 1.735080420971, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/625\", \"loss\": 1.789940297604, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/625\", \"loss\": 1.835164189339, \"lr\": 0.000282441566, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/625\", \"loss\": 1.679578602314, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/625\", \"loss\": 1.834026694298, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/625\", \"loss\": 1.865221679211, \"lr\": 0.000282441566, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/625\", \"loss\": 1.625279903412, \"lr\": 0.000282441566, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/625\", \"loss\": 1.716701507568, \"lr\": 0.000282441566, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/625\", \"loss\": 1.709989547729, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/625\", \"loss\": 1.614008784294, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/625\", \"loss\": 1.616493701935, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/625\", \"loss\": 1.680139064789, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/625\", \"loss\": 1.703658699989, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/625\", \"loss\": 1.596159875393, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/625\", \"loss\": 1.540514230728, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/625\", \"loss\": 1.577087104321, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/625\", \"loss\": 1.688944518566, \"lr\": 0.000282441566, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/625\", \"loss\": 1.414684295654, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/625\", \"loss\": 1.678225159645, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/625\", \"loss\": 1.808985471725, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/625\", \"loss\": 1.450091123581, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/625\", \"loss\": 1.708755075932, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/625\", \"loss\": 1.640445947647, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/625\", \"loss\": 1.449619412422, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/625\", \"loss\": 1.514803767204, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/625\", \"loss\": 1.624931216240, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/625\", \"loss\": 1.466425418854, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/625\", \"loss\": 1.759669601917, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/625\", \"loss\": 1.413461327553, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/625\", \"loss\": 1.379142463207, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/625\", \"loss\": 1.428180873394, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/625\", \"loss\": 1.502583205700, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/625\", \"loss\": 1.339190423489, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/625\", \"loss\": 1.618017554283, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/625\", \"loss\": 1.467140734196, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/625\", \"loss\": 1.447299182415, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/625\", \"loss\": 1.342341840267, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/625\", \"loss\": 1.296297430992, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/625\", \"loss\": 1.354371190071, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/625\", \"loss\": 1.571552038193, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/625\", \"loss\": 1.549919068813, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/625\", \"loss\": 1.663504719734, \"lr\": 0.000282441566, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/625\", \"loss\": 1.422724783421, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/625\", \"loss\": 1.494319856167, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/625\", \"loss\": 1.456159055233, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.668220716572, \"lr\": 0.000282441566, \"top1_err\": 61.070000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 49.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 51.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 49.940000915527, \"top1_err\": 49.940000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/625\", \"loss\": 1.265085756779, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/625\", \"loss\": 1.294122099876, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/625\", \"loss\": 1.508380174637, \"lr\": 0.000282441566, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/625\", \"loss\": 1.300501525402, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/625\", \"loss\": 1.443937003613, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/625\", \"loss\": 1.425841331482, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/625\", \"loss\": 1.410689890385, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/625\", \"loss\": 1.291649520397, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/625\", \"loss\": 1.280844509602, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/625\", \"loss\": 1.334158658981, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/625\", \"loss\": 1.633210897446, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/625\", \"loss\": 1.338382184505, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/625\", \"loss\": 1.371224820614, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/625\", \"loss\": 1.524597823620, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/625\", \"loss\": 1.394957959652, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/625\", \"loss\": 1.482317447662, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/625\", \"loss\": 1.435456991196, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/625\", \"loss\": 1.364590466022, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/625\", \"loss\": 1.417264342308, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/625\", \"loss\": 1.416581392288, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/625\", \"loss\": 1.341576337814, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/625\", \"loss\": 1.443322956562, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/625\", \"loss\": 1.214626729488, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/625\", \"loss\": 1.410278141499, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/625\", \"loss\": 1.423467516899, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/625\", \"loss\": 1.268772780895, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/625\", \"loss\": 1.240565419197, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/625\", \"loss\": 1.420344591141, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/625\", \"loss\": 1.352007806301, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/625\", \"loss\": 1.385997176170, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/625\", \"loss\": 1.232457876205, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/625\", \"loss\": 1.252605378628, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/625\", \"loss\": 1.242336034775, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/625\", \"loss\": 1.400408208370, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/625\", \"loss\": 1.240910708904, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/625\", \"loss\": 1.269426167011, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/625\", \"loss\": 1.296802818775, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/625\", \"loss\": 1.515165984631, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/625\", \"loss\": 1.162063360214, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/625\", \"loss\": 1.283316493034, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/625\", \"loss\": 1.304433703423, \"lr\": 0.000282441566, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/625\", \"loss\": 1.137194633484, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/625\", \"loss\": 1.178696870804, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/625\", \"loss\": 1.276153743267, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/625\", \"loss\": 1.285822689533, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/625\", \"loss\": 1.456516206264, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/625\", \"loss\": 1.384746193886, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/625\", \"loss\": 1.128631830215, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/625\", \"loss\": 1.207654356956, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/625\", \"loss\": 1.146986782551, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/625\", \"loss\": 1.226954698563, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/625\", \"loss\": 1.287277698517, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/625\", \"loss\": 1.092800796032, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/625\", \"loss\": 1.336806535721, \"lr\": 0.000282441566, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/625\", \"loss\": 1.412681519985, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/625\", \"loss\": 1.353084325790, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/625\", \"loss\": 1.134277760983, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/625\", \"loss\": 1.159267663956, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/625\", \"loss\": 1.254479467869, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/625\", \"loss\": 1.151545763016, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/625\", \"loss\": 1.236476957798, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/625\", \"loss\": 1.260498166084, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.332662545300, \"lr\": 0.000282441566, \"top1_err\": 48.350000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 47.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 46.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 46.200001373291, \"top1_err\": 46.200001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/625\", \"loss\": 1.090258598328, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/625\", \"loss\": 1.260090649128, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/625\", \"loss\": 1.097555994987, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/625\", \"loss\": 1.136366486549, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/625\", \"loss\": 1.367497801781, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/625\", \"loss\": 1.134849786758, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/625\", \"loss\": 1.216724872589, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/625\", \"loss\": 1.171772837639, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/625\", \"loss\": 1.095257520676, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/625\", \"loss\": 0.999435186386, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/625\", \"loss\": 0.953728318214, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/625\", \"loss\": 1.000553369522, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/625\", \"loss\": 1.177861750126, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/625\", \"loss\": 1.315961420536, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/625\", \"loss\": 1.192010283470, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/625\", \"loss\": 1.206524431705, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/625\", \"loss\": 1.156176805496, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/625\", \"loss\": 1.021135628223, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/625\", \"loss\": 1.107691764832, \"lr\": 0.000282441566, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/625\", \"loss\": 1.009833931923, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/625\", \"loss\": 1.041412889957, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/625\", \"loss\": 1.200326144695, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/625\", \"loss\": 1.193438708782, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/625\", \"loss\": 1.156423270702, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/625\", \"loss\": 1.047267735004, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/625\", \"loss\": 0.921134352684, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/625\", \"loss\": 1.146676838398, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/625\", \"loss\": 1.091936826706, \"lr\": 0.000282441566, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/625\", \"loss\": 1.025674313307, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/625\", \"loss\": 1.059350550175, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/625\", \"loss\": 0.907921642065, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/625\", \"loss\": 1.011880815029, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/625\", \"loss\": 1.002556324005, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/625\", \"loss\": 1.006019413471, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/625\", \"loss\": 1.137400150299, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/625\", \"loss\": 1.017511188984, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/625\", \"loss\": 0.986574709415, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/625\", \"loss\": 1.138493716717, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/625\", \"loss\": 1.083685457706, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/625\", \"loss\": 0.996559798717, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/625\", \"loss\": 1.195520758629, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/625\", \"loss\": 1.103838324547, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/625\", \"loss\": 1.019285529852, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/625\", \"loss\": 1.150962173939, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/625\", \"loss\": 1.316447854042, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/625\", \"loss\": 1.122060000896, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/625\", \"loss\": 1.006086349487, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/625\", \"loss\": 1.092878699303, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/625\", \"loss\": 0.990000903606, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/625\", \"loss\": 0.892661213875, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/625\", \"loss\": 1.074929475784, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/625\", \"loss\": 0.876463264227, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/625\", \"loss\": 0.883967310190, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/625\", \"loss\": 0.991335600615, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/625\", \"loss\": 0.995637327433, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/625\", \"loss\": 0.932704925537, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/625\", \"loss\": 1.064938604832, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/625\", \"loss\": 1.196141362190, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/625\", \"loss\": 1.170462727547, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/625\", \"loss\": 0.899822711945, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/625\", \"loss\": 0.966480642557, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/625\", \"loss\": 1.065116167068, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.104706631517, \"lr\": 0.000282441566, \"top1_err\": 39.230000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 37.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 40.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 39.100001068115, \"top1_err\": 39.100001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/625\", \"loss\": 0.810601264238, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/625\", \"loss\": 0.943388283253, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/625\", \"loss\": 0.809070229530, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/625\", \"loss\": 0.995009183884, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/625\", \"loss\": 0.994838535786, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/625\", \"loss\": 0.867176711559, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/625\", \"loss\": 0.820675462484, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/625\", \"loss\": 0.883221745491, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/625\", \"loss\": 0.916880667210, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/625\", \"loss\": 1.067635327578, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/625\", \"loss\": 1.055007815361, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/625\", \"loss\": 1.025602161884, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/625\", \"loss\": 1.038248598576, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/625\", \"loss\": 1.194355249405, \"lr\": 0.000282441566, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/625\", \"loss\": 1.011035054922, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/625\", \"loss\": 0.893885165453, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/625\", \"loss\": 1.032744884491, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/625\", \"loss\": 0.865298002958, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/625\", \"loss\": 0.820852100849, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/625\", \"loss\": 0.839535713196, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/625\", \"loss\": 0.946854114532, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/625\", \"loss\": 0.804209798574, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/625\", \"loss\": 0.861601442099, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/625\", \"loss\": 0.906047791243, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/625\", \"loss\": 0.892631083727, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/625\", \"loss\": 0.948948293924, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/625\", \"loss\": 1.042609155178, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/625\", \"loss\": 1.104664385319, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/625\", \"loss\": 0.833579361439, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/625\", \"loss\": 0.939829349518, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/625\", \"loss\": 0.755008816719, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/625\", \"loss\": 0.910920768976, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/625\", \"loss\": 0.830976843834, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/625\", \"loss\": 0.916432797909, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/625\", \"loss\": 0.867108702660, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/625\", \"loss\": 1.009805768728, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/625\", \"loss\": 0.983312368393, \"lr\": 0.000282441566, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/625\", \"loss\": 0.941371768713, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/625\", \"loss\": 1.018070697784, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/625\", \"loss\": 1.056339085102, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/625\", \"loss\": 1.029277592897, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/625\", \"loss\": 0.870228141546, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/625\", \"loss\": 0.827963113785, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/625\", \"loss\": 0.910000234842, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/625\", \"loss\": 0.782053291798, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/625\", \"loss\": 1.102185428143, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/625\", \"loss\": 0.815055578947, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/625\", \"loss\": 0.833158314228, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/625\", \"loss\": 0.955124288797, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/625\", \"loss\": 0.877468436956, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/625\", \"loss\": 0.689062118530, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/625\", \"loss\": 0.906556248665, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/625\", \"loss\": 1.019072890282, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/625\", \"loss\": 0.951562613249, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/625\", \"loss\": 0.914206057787, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/625\", \"loss\": 0.765886276960, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/625\", \"loss\": 0.868060290813, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/625\", \"loss\": 0.874034911394, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/625\", \"loss\": 0.945966124535, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/625\", \"loss\": 1.019204914570, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/625\", \"loss\": 0.690387517214, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/625\", \"loss\": 0.888583242893, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.956227072477, \"lr\": 0.000282441566, \"top1_err\": 33.530000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 35.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 33.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 34.300001449585, \"top1_err\": 34.300001449585}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/625\", \"loss\": 0.896694123745, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/625\", \"loss\": 0.870995879173, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/625\", \"loss\": 0.681862235069, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/625\", \"loss\": 0.849318891764, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/625\", \"loss\": 0.917171269655, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/625\", \"loss\": 0.738202273846, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/625\", \"loss\": 0.889933884144, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/625\", \"loss\": 0.814288675785, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/625\", \"loss\": 0.863830745220, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/625\", \"loss\": 0.875680327415, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/625\", \"loss\": 0.891432672739, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/625\", \"loss\": 0.933742761612, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/625\", \"loss\": 0.879250854254, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/625\", \"loss\": 0.852076649666, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/625\", \"loss\": 0.781989604235, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/625\", \"loss\": 0.746015220881, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/625\", \"loss\": 0.733337163925, \"lr\": 0.000282441566, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/625\", \"loss\": 0.807135134935, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/625\", \"loss\": 0.639028519392, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/625\", \"loss\": 0.850482791662, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/625\", \"loss\": 0.764134407043, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/625\", \"loss\": 0.707937687635, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/625\", \"loss\": 0.976278185844, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/625\", \"loss\": 0.885279148817, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/625\", \"loss\": 0.868181198835, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/625\", \"loss\": 0.906428009272, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/625\", \"loss\": 0.921745777130, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/625\", \"loss\": 0.966752290726, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/625\", \"loss\": 0.872523546219, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/625\", \"loss\": 0.891356796026, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/625\", \"loss\": 0.803724497557, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/625\", \"loss\": 0.845863908529, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/625\", \"loss\": 0.862984180450, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/625\", \"loss\": 0.916049033403, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/625\", \"loss\": 0.839842408895, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/625\", \"loss\": 0.825479388237, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/625\", \"loss\": 0.681096374989, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/625\", \"loss\": 0.682044357061, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/625\", \"loss\": 0.817031919956, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/625\", \"loss\": 0.730931520462, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/625\", \"loss\": 0.736346244812, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/625\", \"loss\": 0.778316974640, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/625\", \"loss\": 0.898995071650, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/625\", \"loss\": 1.032624661922, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/625\", \"loss\": 0.822572588921, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/625\", \"loss\": 0.929720818996, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/625\", \"loss\": 0.805442869663, \"lr\": 0.000282441566, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/625\", \"loss\": 0.892319977283, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/625\", \"loss\": 0.969768017530, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/625\", \"loss\": 0.863013476133, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/625\", \"loss\": 0.731737941504, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/625\", \"loss\": 0.710927307606, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/625\", \"loss\": 0.853618323803, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/625\", \"loss\": 0.767145842314, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/625\", \"loss\": 0.672016382217, \"lr\": 0.000282441566, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/625\", \"loss\": 0.816312640905, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/625\", \"loss\": 1.007884263992, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/625\", \"loss\": 0.937329173088, \"lr\": 0.000282441566, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/625\", \"loss\": 0.871006578207, \"lr\": 0.000282441566, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/625\", \"loss\": 0.876600503922, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/625\", \"loss\": 0.910774856806, \"lr\": 0.000282441566, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/625\", \"loss\": 0.758012384176, \"lr\": 0.000282441566, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.871795267534, \"lr\": 0.000282441566, \"top1_err\": 30.710000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 30.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 30.250000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 30.360001983643, \"top1_err\": 30.360001983643}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_69.63999801635742_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_69.63999801635742_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:21:18,632]\u001b[0m Trial 0 finished with value: 69.63999801635742 and parameters: {'learning_rate': 0.0002824415655407379, 'weight_decay': 0.0007089834954929964, 'batch_size': 16, 'optimizer': 'ADAM'}. Best is trial 0 with value: 69.63999801635742.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 1.7173018018342467e-05\n",
      "Weight Decay : 4.6352551645024626e-08\n",
      "Batch Size   : 128\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1.7173018018342467e-05\n",
      "    weight_decay: 4.6352551645024626e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.353222012520, \"lr\": 0.000017173018, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.220623493195, \"lr\": 0.000017173018, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.017298340797, \"lr\": 0.000017173018, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 1.932670056820, \"lr\": 0.000017173018, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 1.853903591633, \"lr\": 0.000017173018, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 1.781483471394, \"lr\": 0.000017173018, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 1.755469799042, \"lr\": 0.000017173018, \"top1_err\": 63.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.959221468735, \"lr\": 0.000017173018, \"top1_err\": 71.410000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 63.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 63.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 63.880000305176, \"top1_err\": 63.880000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 1.624330937862, \"lr\": 0.000017173018, \"top1_err\": 58.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 1.592673122883, \"lr\": 0.000017173018, \"top1_err\": 56.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 1.566939592361, \"lr\": 0.000017173018, \"top1_err\": 56.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 1.578225672245, \"lr\": 0.000017173018, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 1.520844638348, \"lr\": 0.000017173018, \"top1_err\": 55.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 1.473759651184, \"lr\": 0.000017173018, \"top1_err\": 55.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 1.473523855209, \"lr\": 0.000017173018, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.537771980476, \"lr\": 0.000017173018, \"top1_err\": 55.830000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 55.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 55.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 54.700001068115, \"top1_err\": 54.700001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 1.365715563297, \"lr\": 0.000017173018, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 1.416546523571, \"lr\": 0.000017173018, \"top1_err\": 51.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 1.370960593224, \"lr\": 0.000017173018, \"top1_err\": 51.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 1.313799262047, \"lr\": 0.000017173018, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 1.349287927151, \"lr\": 0.000017173018, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 1.319203376770, \"lr\": 0.000017173018, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 1.286851763725, \"lr\": 0.000017173018, \"top1_err\": 46.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.344717523003, \"lr\": 0.000017173018, \"top1_err\": 48.360000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 51.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 52.499996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 52.180000610352, \"top1_err\": 52.180000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 1.170252323151, \"lr\": 0.000017173018, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 1.250185132027, \"lr\": 0.000017173018, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 1.152108490467, \"lr\": 0.000017173018, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 1.224202096462, \"lr\": 0.000017173018, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 1.185946285725, \"lr\": 0.000017173018, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 1.220463216305, \"lr\": 0.000017173018, \"top1_err\": 41.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 1.224018216133, \"lr\": 0.000017173018, \"top1_err\": 42.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.188712765121, \"lr\": 0.000017173018, \"top1_err\": 41.770000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 52.999996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 52.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 52.180000610352, \"top1_err\": 53.139999847412}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 1.040947079659, \"lr\": 0.000017173018, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 1.052237868309, \"lr\": 0.000017173018, \"top1_err\": 37.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 0.997382551432, \"lr\": 0.000017173018, \"top1_err\": 33.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 1.082656741142, \"lr\": 0.000017173018, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 1.061526477337, \"lr\": 0.000017173018, \"top1_err\": 37.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 1.035908520222, \"lr\": 0.000017173018, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 1.006599426270, \"lr\": 0.000017173018, \"top1_err\": 33.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.045239148712, \"lr\": 0.000017173018, \"top1_err\": 35.840000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 51.749998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 48.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 50.200000305176, \"top1_err\": 50.200000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_49.799999694824216_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_49.799999694824216_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:22:18,704]\u001b[0m Trial 1 finished with value: 49.799999694824216 and parameters: {'learning_rate': 1.7173018018342467e-05, 'weight_decay': 4.6352551645024626e-08, 'batch_size': 128, 'optimizer': 'ADAM'}. Best is trial 0 with value: 69.63999801635742.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0013432671421910968\n",
      "Weight Decay : 2.967131050805595e-07\n",
      "Batch Size   : 32\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0013432671421910968\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.967131050805595e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/313\", \"loss\": 2.303700447083, \"lr\": 0.001343267142, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/313\", \"loss\": 2.165551781654, \"lr\": 0.001343267142, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/313\", \"loss\": 2.089950561523, \"lr\": 0.001343267142, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 1.964989542961, \"lr\": 0.001343267142, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/313\", \"loss\": 1.901862859726, \"lr\": 0.001343267142, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/313\", \"loss\": 1.913487732410, \"lr\": 0.001343267142, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/313\", \"loss\": 1.793658912182, \"lr\": 0.001343267142, \"top1_err\": 70.312500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 1.826228857040, \"lr\": 0.001343267142, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/313\", \"loss\": 1.734584569931, \"lr\": 0.001343267142, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/313\", \"loss\": 1.834585130215, \"lr\": 0.001343267142, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/313\", \"loss\": 1.683756828308, \"lr\": 0.001343267142, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 1.719023704529, \"lr\": 0.001343267142, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/313\", \"loss\": 1.779433429241, \"lr\": 0.001343267142, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/313\", \"loss\": 1.707967162132, \"lr\": 0.001343267142, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/313\", \"loss\": 1.598718285561, \"lr\": 0.001343267142, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 1.559977531433, \"lr\": 0.001343267142, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/313\", \"loss\": 1.661567032337, \"lr\": 0.001343267142, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/313\", \"loss\": 1.469233036041, \"lr\": 0.001343267142, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/313\", \"loss\": 1.654974222183, \"lr\": 0.001343267142, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 1.624233007431, \"lr\": 0.001343267142, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/313\", \"loss\": 1.453005790710, \"lr\": 0.001343267142, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/313\", \"loss\": 1.538555860519, \"lr\": 0.001343267142, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/313\", \"loss\": 1.492973983288, \"lr\": 0.001343267142, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 1.417201697826, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/313\", \"loss\": 1.511005401611, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/313\", \"loss\": 1.522858560085, \"lr\": 0.001343267142, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/313\", \"loss\": 1.475885093212, \"lr\": 0.001343267142, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 1.395274281502, \"lr\": 0.001343267142, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/313\", \"loss\": 1.542005360126, \"lr\": 0.001343267142, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/313\", \"loss\": 1.527959465981, \"lr\": 0.001343267142, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/313\", \"loss\": 1.452170908451, \"lr\": 0.001343267142, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.694049804497, \"lr\": 0.001343267142, \"top1_err\": 63.060000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 54.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 57.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 55.280000305176, \"top1_err\": 55.280000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/313\", \"loss\": 1.306361615658, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/313\", \"loss\": 1.446513175964, \"lr\": 0.001343267142, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/313\", \"loss\": 1.311547517776, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 1.287958800793, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/313\", \"loss\": 1.418056249619, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/313\", \"loss\": 1.372461497784, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/313\", \"loss\": 1.305202841759, \"lr\": 0.001343267142, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 1.261266350746, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/313\", \"loss\": 1.336885392666, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/313\", \"loss\": 1.423842132092, \"lr\": 0.001343267142, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/313\", \"loss\": 1.357309043407, \"lr\": 0.001343267142, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 1.296216189861, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/313\", \"loss\": 1.279790997505, \"lr\": 0.001343267142, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/313\", \"loss\": 1.307754158974, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/313\", \"loss\": 1.443704128265, \"lr\": 0.001343267142, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 1.306973099709, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/313\", \"loss\": 1.317487895489, \"lr\": 0.001343267142, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/313\", \"loss\": 1.231328606606, \"lr\": 0.001343267142, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/313\", \"loss\": 1.428629398346, \"lr\": 0.001343267142, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 1.251167178154, \"lr\": 0.001343267142, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/313\", \"loss\": 1.232835829258, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/313\", \"loss\": 1.281673133373, \"lr\": 0.001343267142, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/313\", \"loss\": 1.290120303631, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 1.260376513004, \"lr\": 0.001343267142, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/313\", \"loss\": 1.332866728306, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/313\", \"loss\": 1.366060435772, \"lr\": 0.001343267142, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/313\", \"loss\": 1.294715106487, \"lr\": 0.001343267142, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 1.339171409607, \"lr\": 0.001343267142, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/313\", \"loss\": 1.308484077454, \"lr\": 0.001343267142, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/313\", \"loss\": 1.266104996204, \"lr\": 0.001343267142, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/313\", \"loss\": 1.293074250221, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.325527509689, \"lr\": 0.001343267142, \"top1_err\": 48.230000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 48.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 46.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 46.480000305176, \"top1_err\": 46.480000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/313\", \"loss\": 1.173429548740, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/313\", \"loss\": 1.070766508579, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/313\", \"loss\": 1.107881546021, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 1.030784994364, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/313\", \"loss\": 1.137623250484, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/313\", \"loss\": 1.002423316240, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/313\", \"loss\": 1.204202353954, \"lr\": 0.001343267142, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 1.165109932423, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/313\", \"loss\": 1.130754113197, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/313\", \"loss\": 1.003758817911, \"lr\": 0.001343267142, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/313\", \"loss\": 1.000818252563, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 1.104238390923, \"lr\": 0.001343267142, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/313\", \"loss\": 1.044001698494, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/313\", \"loss\": 1.190460026264, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/313\", \"loss\": 1.032357245684, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 1.050041735172, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/313\", \"loss\": 1.087738215923, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/313\", \"loss\": 1.105292558670, \"lr\": 0.001343267142, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/313\", \"loss\": 1.053517639637, \"lr\": 0.001343267142, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 1.125394761562, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/313\", \"loss\": 1.119689762592, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/313\", \"loss\": 1.115199327469, \"lr\": 0.001343267142, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/313\", \"loss\": 1.148734748363, \"lr\": 0.001343267142, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 1.007321953773, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/313\", \"loss\": 0.983571648598, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/313\", \"loss\": 1.079943001270, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/313\", \"loss\": 1.080835103989, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 1.024420171976, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/313\", \"loss\": 1.182348847389, \"lr\": 0.001343267142, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/313\", \"loss\": 1.171830832958, \"lr\": 0.001343267142, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/313\", \"loss\": 1.095223009586, \"lr\": 0.001343267142, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.100182277679, \"lr\": 0.001343267142, \"top1_err\": 39.150000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 49.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 51.999998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 46.480000305176, \"top1_err\": 50.459999542236}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/313\", \"loss\": 0.902679115534, \"lr\": 0.001343267142, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/313\", \"loss\": 0.883127272129, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/313\", \"loss\": 0.849965661764, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 0.766824901104, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/313\", \"loss\": 1.039647042751, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/313\", \"loss\": 0.968040436506, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/313\", \"loss\": 1.016819328070, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 0.906574934721, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/313\", \"loss\": 0.966336697340, \"lr\": 0.001343267142, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/313\", \"loss\": 0.792955815792, \"lr\": 0.001343267142, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/313\", \"loss\": 0.968228757381, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 0.995814085007, \"lr\": 0.001343267142, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/313\", \"loss\": 1.035133659840, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/313\", \"loss\": 0.950828433037, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/313\", \"loss\": 0.806898295879, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 0.792599618435, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/313\", \"loss\": 0.786363154650, \"lr\": 0.001343267142, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/313\", \"loss\": 0.908325552940, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/313\", \"loss\": 0.882234424353, \"lr\": 0.001343267142, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 0.800539702177, \"lr\": 0.001343267142, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/313\", \"loss\": 0.919567465782, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/313\", \"loss\": 0.954626113176, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/313\", \"loss\": 0.942656576633, \"lr\": 0.001343267142, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 0.979155600071, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/313\", \"loss\": 0.868506848812, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/313\", \"loss\": 0.904659390450, \"lr\": 0.001343267142, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/313\", \"loss\": 0.940963536501, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 0.823596328497, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/313\", \"loss\": 0.859801828861, \"lr\": 0.001343267142, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/313\", \"loss\": 0.800991207361, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/313\", \"loss\": 0.900283187628, \"lr\": 0.001343267142, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.916399432278, \"lr\": 0.001343267142, \"top1_err\": 32.870000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 44.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 43.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 44.980000457764, \"top1_err\": 44.980000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/313\", \"loss\": 0.816393911839, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/313\", \"loss\": 0.746245622635, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/313\", \"loss\": 0.696202456951, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 0.791070699692, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/313\", \"loss\": 0.802056163549, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/313\", \"loss\": 0.730287432671, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/313\", \"loss\": 0.739471971989, \"lr\": 0.001343267142, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 0.727034360170, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/313\", \"loss\": 0.668531954288, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/313\", \"loss\": 0.767820388079, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/313\", \"loss\": 0.615549832582, \"lr\": 0.001343267142, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 0.898012161255, \"lr\": 0.001343267142, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/313\", \"loss\": 0.802953392267, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/313\", \"loss\": 0.776050955057, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/313\", \"loss\": 0.797972917557, \"lr\": 0.001343267142, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 0.713731616735, \"lr\": 0.001343267142, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/313\", \"loss\": 0.781663805246, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/313\", \"loss\": 0.858740538359, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/313\", \"loss\": 0.732442468405, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 0.837442398071, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/313\", \"loss\": 0.762720197439, \"lr\": 0.001343267142, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/313\", \"loss\": 0.886941820383, \"lr\": 0.001343267142, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/313\", \"loss\": 0.709144264460, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 0.713671296835, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/313\", \"loss\": 0.925513297319, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/313\", \"loss\": 0.669028937817, \"lr\": 0.001343267142, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/313\", \"loss\": 0.844533741474, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 0.764539420605, \"lr\": 0.001343267142, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/313\", \"loss\": 0.816371381283, \"lr\": 0.001343267142, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/313\", \"loss\": 0.809442967176, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/313\", \"loss\": 0.851549267769, \"lr\": 0.001343267142, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.778703664494, \"lr\": 0.001343267142, \"top1_err\": 26.710000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 36.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 37.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 37.420001373291, \"top1_err\": 37.420001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_62.579998626708985_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_62.579998626708985_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:25:22,302]\u001b[0m Trial 2 finished with value: 62.579998626708985 and parameters: {'learning_rate': 0.0013432671421910968, 'weight_decay': 2.967131050805595e-07, 'batch_size': 32, 'optimizer': 'SGD'}. Best is trial 0 with value: 69.63999801635742.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 2.475122939858522e-05\n",
      "Weight Decay : 0.0004539691689422361\n",
      "Batch Size   : 128\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 2.475122939858522e-05\n",
      "    weight_decay: 0.0004539691689422361\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.319003462791, \"lr\": 0.000024751229, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.143252134323, \"lr\": 0.000024751229, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 1.936350226402, \"lr\": 0.000024751229, \"top1_err\": 69.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 1.851598739624, \"lr\": 0.000024751229, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 1.762915432453, \"lr\": 0.000024751229, \"top1_err\": 63.671875000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 1.687951266766, \"lr\": 0.000024751229, \"top1_err\": 59.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 1.654937207699, \"lr\": 0.000024751229, \"top1_err\": 60.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.880606513405, \"lr\": 0.000024751229, \"top1_err\": 68.670000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 60.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 61.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 61.220001220703, \"top1_err\": 61.220001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 1.525608241558, \"lr\": 0.000024751229, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 1.471901357174, \"lr\": 0.000024751229, \"top1_err\": 52.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 1.490201413631, \"lr\": 0.000024751229, \"top1_err\": 55.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 1.463707506657, \"lr\": 0.000024751229, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 1.445072531700, \"lr\": 0.000024751229, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 1.386688768864, \"lr\": 0.000024751229, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 1.410138607025, \"lr\": 0.000024751229, \"top1_err\": 51.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.446580594063, \"lr\": 0.000024751229, \"top1_err\": 52.840000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 51.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 53.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 52.000000152588, \"top1_err\": 52.000000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 1.282673478127, \"lr\": 0.000024751229, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 1.294283211231, \"lr\": 0.000024751229, \"top1_err\": 44.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 1.270158290863, \"lr\": 0.000024751229, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 1.207394599915, \"lr\": 0.000024751229, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 1.267600476742, \"lr\": 0.000024751229, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 1.206460654736, \"lr\": 0.000024751229, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 1.191546618938, \"lr\": 0.000024751229, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.242555528259, \"lr\": 0.000024751229, \"top1_err\": 44.710000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 51.749998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 54.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 52.000000152588, \"top1_err\": 53.260000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 1.039122581482, \"lr\": 0.000024751229, \"top1_err\": 35.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 1.095533251762, \"lr\": 0.000024751229, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 1.012501537800, \"lr\": 0.000024751229, \"top1_err\": 34.765625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 1.095762431622, \"lr\": 0.000024751229, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 1.076965451241, \"lr\": 0.000024751229, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 1.077452182770, \"lr\": 0.000024751229, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 1.058661580086, \"lr\": 0.000024751229, \"top1_err\": 37.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.052194005775, \"lr\": 0.000024751229, \"top1_err\": 36.520000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 51.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 52.000000152588, \"top1_err\": 52.080000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 0.860325098038, \"lr\": 0.000024751229, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 0.918012380600, \"lr\": 0.000024751229, \"top1_err\": 32.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 0.816809773445, \"lr\": 0.000024751229, \"top1_err\": 25.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 0.869008213282, \"lr\": 0.000024751229, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 0.870561212301, \"lr\": 0.000024751229, \"top1_err\": 30.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 0.854915589094, \"lr\": 0.000024751229, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 0.805385589600, \"lr\": 0.000024751229, \"top1_err\": 26.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.860845483875, \"lr\": 0.000024751229, \"top1_err\": 28.180000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 52.999996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 49.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 51.040000000000, \"top1_err\": 51.040000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_48.96_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_48.96_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:26:20,688]\u001b[0m Trial 3 finished with value: 48.96 and parameters: {'learning_rate': 2.475122939858522e-05, 'weight_decay': 0.0004539691689422361, 'batch_size': 128, 'optimizer': 'ADAM'}. Best is trial 0 with value: 69.63999801635742.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.00017840026420264102\n",
      "Weight Decay : 3.024681984210527e-05\n",
      "Batch Size   : 256\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00017840026420264102\n",
      "    weight_decay: 3.024681984210527e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 40\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/40\", \"loss\": 1.940609395504, \"lr\": 0.000178400264, \"top1_err\": 69.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/40\", \"loss\": 1.669527053833, \"lr\": 0.000178400264, \"top1_err\": 63.085937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/40\", \"loss\": 1.512638032436, \"lr\": 0.000178400264, \"top1_err\": 57.617187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/40\", \"loss\": 1.501245975494, \"lr\": 0.000178400264, \"top1_err\": 56.835937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.669252838707, \"lr\": 0.000178400264, \"top1_err\": 62.280000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 67.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 67.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 67.860000915527, \"top1_err\": 67.860000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/40\", \"loss\": 1.397048234940, \"lr\": 0.000178400264, \"top1_err\": 50.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/40\", \"loss\": 1.332463741302, \"lr\": 0.000178400264, \"top1_err\": 48.632812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/40\", \"loss\": 1.253494381905, \"lr\": 0.000178400264, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/40\", \"loss\": 1.197057962418, \"lr\": 0.000178400264, \"top1_err\": 44.726562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.301867362595, \"lr\": 0.000178400264, \"top1_err\": 48.010000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 52.249998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 53.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 52.120000000000, \"top1_err\": 52.120000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/40\", \"loss\": 1.188001573086, \"lr\": 0.000178400264, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/40\", \"loss\": 1.112065613270, \"lr\": 0.000178400264, \"top1_err\": 40.820312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/40\", \"loss\": 1.063609540462, \"lr\": 0.000178400264, \"top1_err\": 39.648437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/40\", \"loss\": 1.058360874653, \"lr\": 0.000178400264, \"top1_err\": 37.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.108440277672, \"lr\": 0.000178400264, \"top1_err\": 40.330000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 47.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 48.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 48.340000610352, \"top1_err\": 48.340000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/40\", \"loss\": 0.947846204042, \"lr\": 0.000178400264, \"top1_err\": 35.351562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/40\", \"loss\": 0.907216906548, \"lr\": 0.000178400264, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/40\", \"loss\": 0.874090582132, \"lr\": 0.000178400264, \"top1_err\": 30.859375000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/40\", \"loss\": 0.861692011356, \"lr\": 0.000178400264, \"top1_err\": 31.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.906476488972, \"lr\": 0.000178400264, \"top1_err\": 32.590000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 49.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 48.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 48.340000610352, \"top1_err\": 48.720000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/40\", \"loss\": 0.783222556114, \"lr\": 0.000178400264, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/40\", \"loss\": 0.733641564846, \"lr\": 0.000178400264, \"top1_err\": 26.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/40\", \"loss\": 0.748966038227, \"lr\": 0.000178400264, \"top1_err\": 26.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/40\", \"loss\": 0.710527867079, \"lr\": 0.000178400264, \"top1_err\": 25.195312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.749564231110, \"lr\": 0.000178400264, \"top1_err\": 26.450000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 46.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 45.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 46.600000915527, \"top1_err\": 46.600000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_53.399999084472654_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_53.399999084472654_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:27:07,522]\u001b[0m Trial 4 finished with value: 53.399999084472654 and parameters: {'learning_rate': 0.00017840026420264102, 'weight_decay': 3.024681984210527e-05, 'batch_size': 256, 'optimizer': 'ADAM'}. Best is trial 0 with value: 69.63999801635742.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 711.6480300426483 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 69.63999801635742\n",
      "  Params: \n",
      "    learning_rate: 0.0002824415655407379\n",
      "    weight_decay: 0.0007089834954929964\n",
      "    batch_size: 16\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_69.63999801635742_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "--------------------\n",
      "Skipping best model inference as index sets already exists at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_69.63999801635742_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_69.63999801635742_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_69.63999801635742_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 29.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 29.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 29.750000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 30.250000953674}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 29.900001640320, \"top1_err\": 29.900001640320}\n",
      "Test Accuracy: 70.100\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 20.0% of data is 70.09999835968017\n",
      "\n",
      "Extracted Test Accuracy from subproces: 70.09999835968017\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempArgsFile: /tmp/auto_ml_sp_xc_6byjj.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-04-02 21:27:43,441]\u001b[0m A new study created in memory with name: no-name-a261e82b-56f3-4da0-a9bf-ba604e16f49a\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 9.433221945517051e-05\n",
      "Weight Decay : 1.1408396024476828e-08\n",
      "Batch Size   : 64\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 9.433221945517051e-05\n",
      "    weight_decay: 1.1408396024476828e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.01999969482422_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 235\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/235\", \"loss\": 2.239642858505, \"lr\": 0.000094332219, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/235\", \"loss\": 1.911073267460, \"lr\": 0.000094332219, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/235\", \"loss\": 1.840431511402, \"lr\": 0.000094332219, \"top1_err\": 64.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/235\", \"loss\": 1.613003611565, \"lr\": 0.000094332219, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/235\", \"loss\": 1.637816905975, \"lr\": 0.000094332219, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/235\", \"loss\": 1.624482452869, \"lr\": 0.000094332219, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/235\", \"loss\": 1.599111735821, \"lr\": 0.000094332219, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/235\", \"loss\": 1.579758703709, \"lr\": 0.000094332219, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/235\", \"loss\": 1.492549777031, \"lr\": 0.000094332219, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/235\", \"loss\": 1.451228976250, \"lr\": 0.000094332219, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/235\", \"loss\": 1.478031754494, \"lr\": 0.000094332219, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/235\", \"loss\": 1.545342922211, \"lr\": 0.000094332219, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/235\", \"loss\": 1.473363518715, \"lr\": 0.000094332219, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/235\", \"loss\": 1.476839721203, \"lr\": 0.000094332219, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/235\", \"loss\": 1.411384880543, \"lr\": 0.000094332219, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/235\", \"loss\": 1.358695328236, \"lr\": 0.000094332219, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/235\", \"loss\": 1.421543121338, \"lr\": 0.000094332219, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/235\", \"loss\": 1.315878391266, \"lr\": 0.000094332219, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/235\", \"loss\": 1.362750351429, \"lr\": 0.000094332219, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/235\", \"loss\": 1.431640744209, \"lr\": 0.000094332219, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/235\", \"loss\": 1.453054010868, \"lr\": 0.000094332219, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/235\", \"loss\": 1.396854281425, \"lr\": 0.000094332219, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/235\", \"loss\": 1.412956595421, \"lr\": 0.000094332219, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.539695407422, \"lr\": 0.000094332219, \"top1_err\": 56.739999997965}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 46.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 48.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 48.760000762939, \"top1_err\": 48.760000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/235\", \"loss\": 1.147922813892, \"lr\": 0.000094332219, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/235\", \"loss\": 1.202331721783, \"lr\": 0.000094332219, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/235\", \"loss\": 1.194348037243, \"lr\": 0.000094332219, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/235\", \"loss\": 1.160755753517, \"lr\": 0.000094332219, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/235\", \"loss\": 1.208268105984, \"lr\": 0.000094332219, \"top1_err\": 48.437500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/235\", \"loss\": 1.145214259624, \"lr\": 0.000094332219, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/235\", \"loss\": 1.126533687115, \"lr\": 0.000094332219, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/235\", \"loss\": 1.089479088783, \"lr\": 0.000094332219, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/235\", \"loss\": 1.153819501400, \"lr\": 0.000094332219, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/235\", \"loss\": 1.237859249115, \"lr\": 0.000094332219, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/235\", \"loss\": 1.106352090836, \"lr\": 0.000094332219, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/235\", \"loss\": 1.213644862175, \"lr\": 0.000094332219, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/235\", \"loss\": 1.217731714249, \"lr\": 0.000094332219, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/235\", \"loss\": 1.095956921577, \"lr\": 0.000094332219, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/235\", \"loss\": 1.110560178757, \"lr\": 0.000094332219, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/235\", \"loss\": 1.122856616974, \"lr\": 0.000094332219, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/235\", \"loss\": 1.062164366245, \"lr\": 0.000094332219, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/235\", \"loss\": 1.158383905888, \"lr\": 0.000094332219, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/235\", \"loss\": 1.160710036755, \"lr\": 0.000094332219, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/235\", \"loss\": 1.078135788441, \"lr\": 0.000094332219, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/235\", \"loss\": 1.125984132290, \"lr\": 0.000094332219, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/235\", \"loss\": 1.106453418732, \"lr\": 0.000094332219, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/235\", \"loss\": 1.043595135212, \"lr\": 0.000094332219, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.153990295982, \"lr\": 0.000094332219, \"top1_err\": 41.813333329264}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 41.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 42.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 42.020002136230, \"top1_err\": 42.020002136230}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/235\", \"loss\": 0.975249499083, \"lr\": 0.000094332219, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/235\", \"loss\": 0.947243958712, \"lr\": 0.000094332219, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/235\", \"loss\": 0.858580946922, \"lr\": 0.000094332219, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/235\", \"loss\": 0.930802553892, \"lr\": 0.000094332219, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/235\", \"loss\": 0.879248917103, \"lr\": 0.000094332219, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/235\", \"loss\": 0.811406284571, \"lr\": 0.000094332219, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/235\", \"loss\": 1.058434844017, \"lr\": 0.000094332219, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/235\", \"loss\": 0.927359521389, \"lr\": 0.000094332219, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/235\", \"loss\": 0.953871369362, \"lr\": 0.000094332219, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/235\", \"loss\": 0.956388682127, \"lr\": 0.000094332219, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/235\", \"loss\": 0.993442982435, \"lr\": 0.000094332219, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/235\", \"loss\": 0.961988955736, \"lr\": 0.000094332219, \"top1_err\": 30.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/235\", \"loss\": 0.884687900543, \"lr\": 0.000094332219, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/235\", \"loss\": 0.923815459013, \"lr\": 0.000094332219, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/235\", \"loss\": 0.863232046366, \"lr\": 0.000094332219, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/235\", \"loss\": 0.832199990749, \"lr\": 0.000094332219, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/235\", \"loss\": 1.089733839035, \"lr\": 0.000094332219, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/235\", \"loss\": 0.981728553772, \"lr\": 0.000094332219, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/235\", \"loss\": 0.956792235374, \"lr\": 0.000094332219, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/235\", \"loss\": 0.929815649986, \"lr\": 0.000094332219, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/235\", \"loss\": 0.961010515690, \"lr\": 0.000094332219, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/235\", \"loss\": 0.875853449106, \"lr\": 0.000094332219, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/235\", \"loss\": 0.857152879238, \"lr\": 0.000094332219, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 0.931045034027, \"lr\": 0.000094332219, \"top1_err\": 33.513333331299}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 38.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 39.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 38.380001525879, \"top1_err\": 38.380001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/235\", \"loss\": 0.706771254539, \"lr\": 0.000094332219, \"top1_err\": 25.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/235\", \"loss\": 0.713416516781, \"lr\": 0.000094332219, \"top1_err\": 25.781250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/235\", \"loss\": 0.775578498840, \"lr\": 0.000094332219, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/235\", \"loss\": 0.734754443169, \"lr\": 0.000094332219, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/235\", \"loss\": 0.689079076052, \"lr\": 0.000094332219, \"top1_err\": 24.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/235\", \"loss\": 0.759683817625, \"lr\": 0.000094332219, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/235\", \"loss\": 0.694846302271, \"lr\": 0.000094332219, \"top1_err\": 24.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/235\", \"loss\": 0.689661055803, \"lr\": 0.000094332219, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/235\", \"loss\": 0.823118686676, \"lr\": 0.000094332219, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/235\", \"loss\": 0.713052630424, \"lr\": 0.000094332219, \"top1_err\": 22.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/235\", \"loss\": 0.642506688833, \"lr\": 0.000094332219, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/235\", \"loss\": 0.718714237213, \"lr\": 0.000094332219, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/235\", \"loss\": 0.781818836927, \"lr\": 0.000094332219, \"top1_err\": 25.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/235\", \"loss\": 0.776448518038, \"lr\": 0.000094332219, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/235\", \"loss\": 0.732554942369, \"lr\": 0.000094332219, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/235\", \"loss\": 0.786153852940, \"lr\": 0.000094332219, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/235\", \"loss\": 0.692278027534, \"lr\": 0.000094332219, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/235\", \"loss\": 0.722892999649, \"lr\": 0.000094332219, \"top1_err\": 24.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/235\", \"loss\": 0.777903318405, \"lr\": 0.000094332219, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/235\", \"loss\": 0.705499202013, \"lr\": 0.000094332219, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/235\", \"loss\": 0.793531507254, \"lr\": 0.000094332219, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/235\", \"loss\": 0.789436668158, \"lr\": 0.000094332219, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/235\", \"loss\": 0.690089762211, \"lr\": 0.000094332219, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.744560793972, \"lr\": 0.000094332219, \"top1_err\": 26.373333326213}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 35.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 35.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 35.700001525879, \"top1_err\": 35.700001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/235\", \"loss\": 0.523541539907, \"lr\": 0.000094332219, \"top1_err\": 17.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/235\", \"loss\": 0.547694772482, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/235\", \"loss\": 0.517212122679, \"lr\": 0.000094332219, \"top1_err\": 19.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/235\", \"loss\": 0.517936646938, \"lr\": 0.000094332219, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/235\", \"loss\": 0.552590429783, \"lr\": 0.000094332219, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/235\", \"loss\": 0.631640523672, \"lr\": 0.000094332219, \"top1_err\": 22.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/235\", \"loss\": 0.571639597416, \"lr\": 0.000094332219, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/235\", \"loss\": 0.546604067087, \"lr\": 0.000094332219, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/235\", \"loss\": 0.579970449209, \"lr\": 0.000094332219, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/235\", \"loss\": 0.588240057230, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/235\", \"loss\": 0.634845197201, \"lr\": 0.000094332219, \"top1_err\": 21.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/235\", \"loss\": 0.562255620956, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/235\", \"loss\": 0.564265608788, \"lr\": 0.000094332219, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/235\", \"loss\": 0.593514651060, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/235\", \"loss\": 0.544670581818, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/235\", \"loss\": 0.678844630718, \"lr\": 0.000094332219, \"top1_err\": 22.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/235\", \"loss\": 0.682654231787, \"lr\": 0.000094332219, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/235\", \"loss\": 0.619896948338, \"lr\": 0.000094332219, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/235\", \"loss\": 0.562810868025, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/235\", \"loss\": 0.623771697283, \"lr\": 0.000094332219, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/235\", \"loss\": 0.616796106100, \"lr\": 0.000094332219, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/235\", \"loss\": 0.704062908888, \"lr\": 0.000094332219, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/235\", \"loss\": 0.623651146889, \"lr\": 0.000094332219, \"top1_err\": 20.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.596215123399, \"lr\": 0.000094332219, \"top1_err\": 20.566666664632}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 34.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 36.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 35.700001525879, \"top1_err\": 35.840001907349}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_64.2999984741211_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_64.2999984741211_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-04-02 21:30:09,577]\u001b[0m Trial 0 finished with value: 64.2999984741211 and parameters: {'learning_rate': 9.433221945517051e-05, 'weight_decay': 1.1408396024476828e-08, 'batch_size': 64, 'optimizer': 'ADAM'}. Best is trial 0 with value: 64.2999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.005278183157140649\n",
      "Weight Decay : 1.6155850528417117e-06\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.005278183157140649\n",
      "    weight_decay: 1.6155850528417117e-06\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.01999969482422_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 30\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/30\", \"loss\": 2.441111683846, \"lr\": 0.005278183157, \"top1_err\": 82.226562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/30\", \"loss\": 2.026534318924, \"lr\": 0.005278183157, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/30\", \"loss\": 1.894057452679, \"lr\": 0.005278183157, \"top1_err\": 69.238281250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.174881356366, \"lr\": 0.005278183157, \"top1_err\": 75.666666650391}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 72.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 73.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 73.120000610352, \"top1_err\": 73.120000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/30\", \"loss\": 1.748494744301, \"lr\": 0.005278183157, \"top1_err\": 65.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/30\", \"loss\": 1.685321986675, \"lr\": 0.005278183157, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/30\", \"loss\": 1.606228590012, \"lr\": 0.005278183157, \"top1_err\": 60.742187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.685229941877, \"lr\": 0.005278183157, \"top1_err\": 63.106666638184}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 66.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 64.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 65.480000457764, \"top1_err\": 65.480000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/30\", \"loss\": 1.559151470661, \"lr\": 0.005278183157, \"top1_err\": 58.007812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/30\", \"loss\": 1.508223712444, \"lr\": 0.005278183157, \"top1_err\": 56.738281250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/30\", \"loss\": 1.480858445168, \"lr\": 0.005278183157, \"top1_err\": 54.101562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.537573970540, \"lr\": 0.005278183157, \"top1_err\": 56.979999955241}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 73.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 75.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 65.480000457764, \"top1_err\": 73.520000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/30\", \"loss\": 1.454952299595, \"lr\": 0.005278183157, \"top1_err\": 53.613281250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/30\", \"loss\": 1.404739677906, \"lr\": 0.005278183157, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/30\", \"loss\": 1.363358914852, \"lr\": 0.005278183157, \"top1_err\": 51.464843750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.414543315188, \"lr\": 0.005278183157, \"top1_err\": 52.673333325195}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 55.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 56.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 56.060000152588, \"top1_err\": 56.060000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/30\", \"loss\": 1.341116607189, \"lr\": 0.005278183157, \"top1_err\": 49.414062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/30\", \"loss\": 1.320623457432, \"lr\": 0.005278183157, \"top1_err\": 46.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/30\", \"loss\": 1.291991293430, \"lr\": 0.005278183157, \"top1_err\": 46.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.318296794573, \"lr\": 0.005278183157, \"top1_err\": 48.073333337402}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 51.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 54.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 52.340000152588, \"top1_err\": 52.340000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_47.65999984741211_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_47.65999984741211_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:30:58,705]\u001b[0m Trial 1 finished with value: 47.65999984741211 and parameters: {'learning_rate': 0.005278183157140649, 'weight_decay': 1.6155850528417117e-06, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 0 with value: 64.2999984741211.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0010518592956918393\n",
      "Weight Decay : 3.620505391925248e-06\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0010518592956918393\n",
      "    weight_decay: 3.620505391925248e-06\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.01999969482422_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 469\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/469\", \"loss\": 2.379956245422, \"lr\": 0.001051859296, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/469\", \"loss\": 2.132039308548, \"lr\": 0.001051859296, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/469\", \"loss\": 2.020023703575, \"lr\": 0.001051859296, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/469\", \"loss\": 2.109911561012, \"lr\": 0.001051859296, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/469\", \"loss\": 1.935783982277, \"lr\": 0.001051859296, \"top1_err\": 71.875000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/469\", \"loss\": 1.889963924885, \"lr\": 0.001051859296, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/469\", \"loss\": 1.855815887451, \"lr\": 0.001051859296, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/469\", \"loss\": 1.827930510044, \"lr\": 0.001051859296, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/469\", \"loss\": 1.770474791527, \"lr\": 0.001051859296, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/469\", \"loss\": 1.813218772411, \"lr\": 0.001051859296, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/469\", \"loss\": 1.755576312542, \"lr\": 0.001051859296, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/469\", \"loss\": 1.807251036167, \"lr\": 0.001051859296, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/469\", \"loss\": 1.795749366283, \"lr\": 0.001051859296, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/469\", \"loss\": 1.706432282925, \"lr\": 0.001051859296, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/469\", \"loss\": 1.653011500835, \"lr\": 0.001051859296, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/469\", \"loss\": 1.815281569958, \"lr\": 0.001051859296, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/469\", \"loss\": 1.649229347706, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/469\", \"loss\": 1.583663046360, \"lr\": 0.001051859296, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/469\", \"loss\": 1.631323456764, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/469\", \"loss\": 1.601056456566, \"lr\": 0.001051859296, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/469\", \"loss\": 1.689416766167, \"lr\": 0.001051859296, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/469\", \"loss\": 1.678662836552, \"lr\": 0.001051859296, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/469\", \"loss\": 1.726941645145, \"lr\": 0.001051859296, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/469\", \"loss\": 1.722033500671, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/469\", \"loss\": 1.564728498459, \"lr\": 0.001051859296, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/469\", \"loss\": 1.627024650574, \"lr\": 0.001051859296, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/469\", \"loss\": 1.656201124191, \"lr\": 0.001051859296, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/469\", \"loss\": 1.845430552959, \"lr\": 0.001051859296, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/469\", \"loss\": 1.408320307732, \"lr\": 0.001051859296, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/469\", \"loss\": 1.607443273067, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/469\", \"loss\": 1.409521818161, \"lr\": 0.001051859296, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/469\", \"loss\": 1.666162908077, \"lr\": 0.001051859296, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/469\", \"loss\": 1.550719022751, \"lr\": 0.001051859296, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/469\", \"loss\": 1.524613916874, \"lr\": 0.001051859296, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/469\", \"loss\": 1.523008286953, \"lr\": 0.001051859296, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/469\", \"loss\": 1.472373485565, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/469\", \"loss\": 1.466545820236, \"lr\": 0.001051859296, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/469\", \"loss\": 1.410639941692, \"lr\": 0.001051859296, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/469\", \"loss\": 1.450927972794, \"lr\": 0.001051859296, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/469\", \"loss\": 1.642639517784, \"lr\": 0.001051859296, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/469\", \"loss\": 1.557202935219, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/469\", \"loss\": 1.623679220676, \"lr\": 0.001051859296, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/469\", \"loss\": 1.543667793274, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/469\", \"loss\": 1.557160735130, \"lr\": 0.001051859296, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/469\", \"loss\": 1.443947136402, \"lr\": 0.001051859296, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/469\", \"loss\": 1.507055699825, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.692036131541, \"lr\": 0.001051859296, \"top1_err\": 61.806666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 57.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 61.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 58.940001373291, \"top1_err\": 58.940001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/469\", \"loss\": 1.397055983543, \"lr\": 0.001051859296, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/469\", \"loss\": 1.330522119999, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/469\", \"loss\": 1.435904979706, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/469\", \"loss\": 1.542153000832, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/469\", \"loss\": 1.485694706440, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/469\", \"loss\": 1.486780226231, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/469\", \"loss\": 1.484425604343, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/469\", \"loss\": 1.417089700699, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/469\", \"loss\": 1.413865923882, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/469\", \"loss\": 1.273893475533, \"lr\": 0.001051859296, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/469\", \"loss\": 1.388227880001, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/469\", \"loss\": 1.332349181175, \"lr\": 0.001051859296, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/469\", \"loss\": 1.467313766479, \"lr\": 0.001051859296, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/469\", \"loss\": 1.419050455093, \"lr\": 0.001051859296, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/469\", \"loss\": 1.199541091919, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/469\", \"loss\": 1.315700292587, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/469\", \"loss\": 1.246622860432, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/469\", \"loss\": 1.301116704941, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/469\", \"loss\": 1.417809605598, \"lr\": 0.001051859296, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/469\", \"loss\": 1.392501175404, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/469\", \"loss\": 1.351856112480, \"lr\": 0.001051859296, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/469\", \"loss\": 1.219319403172, \"lr\": 0.001051859296, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/469\", \"loss\": 1.498421609402, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/469\", \"loss\": 1.249560773373, \"lr\": 0.001051859296, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/469\", \"loss\": 1.353319942951, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/469\", \"loss\": 1.358014762402, \"lr\": 0.001051859296, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/469\", \"loss\": 1.248463273048, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/469\", \"loss\": 1.156282901764, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/469\", \"loss\": 1.127992570400, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/469\", \"loss\": 1.299271941185, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/469\", \"loss\": 1.279436290264, \"lr\": 0.001051859296, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/469\", \"loss\": 1.312188684940, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/469\", \"loss\": 1.233257055283, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/469\", \"loss\": 1.083780884743, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/469\", \"loss\": 1.305728197098, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/469\", \"loss\": 1.364888012409, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/469\", \"loss\": 1.417293667793, \"lr\": 0.001051859296, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/469\", \"loss\": 1.109102964401, \"lr\": 0.001051859296, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/469\", \"loss\": 1.210715413094, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/469\", \"loss\": 1.084039151669, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/469\", \"loss\": 1.168703854084, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/469\", \"loss\": 1.176229357719, \"lr\": 0.001051859296, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/469\", \"loss\": 1.245130598545, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/469\", \"loss\": 1.123516499996, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/469\", \"loss\": 1.178579151630, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/469\", \"loss\": 1.083391487598, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.315125077057, \"lr\": 0.001051859296, \"top1_err\": 47.346666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 42.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 43.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 42.680001831055, \"top1_err\": 42.680001831055}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/469\", \"loss\": 1.165716767311, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/469\", \"loss\": 1.132021129131, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/469\", \"loss\": 1.158559799194, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/469\", \"loss\": 1.153112053871, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/469\", \"loss\": 1.084492266178, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/469\", \"loss\": 0.996157854795, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/469\", \"loss\": 1.109613716602, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/469\", \"loss\": 0.964666992426, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/469\", \"loss\": 1.108301877975, \"lr\": 0.001051859296, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/469\", \"loss\": 1.146617591381, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/469\", \"loss\": 1.053098082542, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/469\", \"loss\": 0.970791369677, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/469\", \"loss\": 1.031603068113, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/469\", \"loss\": 1.138604164124, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/469\", \"loss\": 1.028645515442, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/469\", \"loss\": 1.105028331280, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/469\", \"loss\": 1.147902250290, \"lr\": 0.001051859296, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/469\", \"loss\": 1.092588901520, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/469\", \"loss\": 1.174226880074, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/469\", \"loss\": 0.979969143867, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/469\", \"loss\": 0.839450448751, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/469\", \"loss\": 1.108093202114, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/469\", \"loss\": 1.047281742096, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/469\", \"loss\": 1.173716306686, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/469\", \"loss\": 1.116966724396, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/469\", \"loss\": 1.044301569462, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/469\", \"loss\": 0.966987043619, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/469\", \"loss\": 1.243830919266, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/469\", \"loss\": 1.127302169800, \"lr\": 0.001051859296, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/469\", \"loss\": 0.949358373880, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/469\", \"loss\": 1.073954105377, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/469\", \"loss\": 1.087016463280, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/469\", \"loss\": 1.208348751068, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/469\", \"loss\": 1.262374579906, \"lr\": 0.001051859296, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/469\", \"loss\": 1.189663589001, \"lr\": 0.001051859296, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/469\", \"loss\": 1.184919476509, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/469\", \"loss\": 1.005897432566, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/469\", \"loss\": 1.014040142298, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/469\", \"loss\": 0.983868807554, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/469\", \"loss\": 0.988708615303, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/469\", \"loss\": 0.997929841280, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/469\", \"loss\": 1.139384090900, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/469\", \"loss\": 0.956441730261, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/469\", \"loss\": 0.989598602057, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/469\", \"loss\": 0.979707837105, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/469\", \"loss\": 1.009648025036, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.097326394463, \"lr\": 0.001051859296, \"top1_err\": 39.653333329264}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 40.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 40.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 39.700001678467, \"top1_err\": 39.700001678467}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/469\", \"loss\": 0.943256169558, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/469\", \"loss\": 0.986069738865, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/469\", \"loss\": 0.895374268293, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/469\", \"loss\": 0.966413170099, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/469\", \"loss\": 1.032221317291, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/469\", \"loss\": 1.033431768417, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/469\", \"loss\": 1.048343062401, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/469\", \"loss\": 0.933973699808, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/469\", \"loss\": 0.822152376175, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/469\", \"loss\": 0.921246439219, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/469\", \"loss\": 0.954281628132, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/469\", \"loss\": 0.914425700903, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/469\", \"loss\": 0.858578741550, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/469\", \"loss\": 0.910102725029, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/469\", \"loss\": 0.935196459293, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/469\", \"loss\": 0.979888290167, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/469\", \"loss\": 1.053891897202, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/469\", \"loss\": 1.085978269577, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/469\", \"loss\": 0.985571980476, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/469\", \"loss\": 1.014318197966, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/469\", \"loss\": 0.901512056589, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/469\", \"loss\": 0.819768190384, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/469\", \"loss\": 0.822437196970, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/469\", \"loss\": 1.111370265484, \"lr\": 0.001051859296, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/469\", \"loss\": 0.903984487057, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/469\", \"loss\": 1.002519875765, \"lr\": 0.001051859296, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/469\", \"loss\": 0.931474626064, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/469\", \"loss\": 0.963718473911, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/469\", \"loss\": 1.011928409338, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/469\", \"loss\": 0.823095202446, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/469\", \"loss\": 0.967028886080, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/469\", \"loss\": 0.916297733784, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/469\", \"loss\": 0.903150171041, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/469\", \"loss\": 0.839526027441, \"lr\": 0.001051859296, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/469\", \"loss\": 0.965246945620, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/469\", \"loss\": 0.908023834229, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/469\", \"loss\": 0.886079192162, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/469\", \"loss\": 0.947890281677, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/469\", \"loss\": 0.856012195349, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/469\", \"loss\": 1.093103885651, \"lr\": 0.001051859296, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/469\", \"loss\": 0.884628027678, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/469\", \"loss\": 1.047040283680, \"lr\": 0.001051859296, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/469\", \"loss\": 0.921378612518, \"lr\": 0.001051859296, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/469\", \"loss\": 0.923648446798, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/469\", \"loss\": 0.838106989861, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/469\", \"loss\": 0.955206364393, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.951825593122, \"lr\": 0.001051859296, \"top1_err\": 33.946666662598}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 40.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 43.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 39.700001678467, \"top1_err\": 41.920000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/469\", \"loss\": 0.872068226337, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/469\", \"loss\": 0.819720447063, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/469\", \"loss\": 0.860259354115, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/469\", \"loss\": 0.814491301775, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/469\", \"loss\": 0.777649194002, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/469\", \"loss\": 0.789888501167, \"lr\": 0.001051859296, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/469\", \"loss\": 0.837760776281, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/469\", \"loss\": 0.817775338888, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/469\", \"loss\": 0.933189570904, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/469\", \"loss\": 0.765755414963, \"lr\": 0.001051859296, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/469\", \"loss\": 0.788691550493, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/469\", \"loss\": 0.828325152397, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/469\", \"loss\": 0.816690951586, \"lr\": 0.001051859296, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/469\", \"loss\": 0.929343551397, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/469\", \"loss\": 0.887831300497, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/469\", \"loss\": 0.859192132950, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/469\", \"loss\": 0.832428634167, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/469\", \"loss\": 0.841143339872, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/469\", \"loss\": 0.850680559874, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/469\", \"loss\": 0.752278804779, \"lr\": 0.001051859296, \"top1_err\": 23.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/469\", \"loss\": 0.876341015100, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/469\", \"loss\": 0.926253318787, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/469\", \"loss\": 0.884160667658, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/469\", \"loss\": 0.855996042490, \"lr\": 0.001051859296, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/469\", \"loss\": 0.851601243019, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/469\", \"loss\": 0.640108734369, \"lr\": 0.001051859296, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/469\", \"loss\": 0.813721418381, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/469\", \"loss\": 0.817879229784, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/469\", \"loss\": 0.846806287766, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/469\", \"loss\": 0.690883994102, \"lr\": 0.001051859296, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/469\", \"loss\": 1.037106156349, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/469\", \"loss\": 0.767517447472, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/469\", \"loss\": 0.954965472221, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/469\", \"loss\": 0.927325665951, \"lr\": 0.001051859296, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/469\", \"loss\": 0.713841140270, \"lr\": 0.001051859296, \"top1_err\": 26.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/469\", \"loss\": 0.865484863520, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/469\", \"loss\": 0.844709366560, \"lr\": 0.001051859296, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/469\", \"loss\": 0.812184214592, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/469\", \"loss\": 0.824276238680, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/469\", \"loss\": 0.806964099407, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/469\", \"loss\": 0.742782920599, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/469\", \"loss\": 0.765884697437, \"lr\": 0.001051859296, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/469\", \"loss\": 0.827325433493, \"lr\": 0.001051859296, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/469\", \"loss\": 0.807142853737, \"lr\": 0.001051859296, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/469\", \"loss\": 0.766135156155, \"lr\": 0.001051859296, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/469\", \"loss\": 0.750098347664, \"lr\": 0.001051859296, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.839351358891, \"lr\": 0.001051859296, \"top1_err\": 29.659999997965}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 33.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 33.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 33.460002059937, \"top1_err\": 33.460002059937}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_66.53999794006347_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_66.53999794006347_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:35:28,316]\u001b[0m Trial 2 finished with value: 66.53999794006347 and parameters: {'learning_rate': 0.0010518592956918393, 'weight_decay': 3.620505391925248e-06, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 2 with value: 66.53999794006347.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 1.730339335441768e-05\n",
      "Weight Decay : 0.00013263903821982088\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 1.730339335441768e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.00013263903821982088\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.01999969482422_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 118\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/118\", \"loss\": 2.484899759293, \"lr\": 0.000017303393, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/118\", \"loss\": 2.440128564835, \"lr\": 0.000017303393, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/118\", \"loss\": 2.465047955513, \"lr\": 0.000017303393, \"top1_err\": 91.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/118\", \"loss\": 2.413598060608, \"lr\": 0.000017303393, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/118\", \"loss\": 2.373288631439, \"lr\": 0.000017303393, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/118\", \"loss\": 2.377030014992, \"lr\": 0.000017303393, \"top1_err\": 87.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/118\", \"loss\": 2.380133509636, \"lr\": 0.000017303393, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/118\", \"loss\": 2.326075792313, \"lr\": 0.000017303393, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/118\", \"loss\": 2.345286369324, \"lr\": 0.000017303393, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/118\", \"loss\": 2.343541145325, \"lr\": 0.000017303393, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/118\", \"loss\": 2.298532128334, \"lr\": 0.000017303393, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.383724094772, \"lr\": 0.000017303393, \"top1_err\": 88.560000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 84.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 83.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 83.540000000000, \"top1_err\": 83.540000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/118\", \"loss\": 2.294404745102, \"lr\": 0.000017303393, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/118\", \"loss\": 2.304887413979, \"lr\": 0.000017303393, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/118\", \"loss\": 2.297039031982, \"lr\": 0.000017303393, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/118\", \"loss\": 2.270192980766, \"lr\": 0.000017303393, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/118\", \"loss\": 2.260692715645, \"lr\": 0.000017303393, \"top1_err\": 80.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/118\", \"loss\": 2.270678758621, \"lr\": 0.000017303393, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/118\", \"loss\": 2.263039708138, \"lr\": 0.000017303393, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/118\", \"loss\": 2.244821071625, \"lr\": 0.000017303393, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/118\", \"loss\": 2.226181268692, \"lr\": 0.000017303393, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/118\", \"loss\": 2.229517221451, \"lr\": 0.000017303393, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/118\", \"loss\": 2.227612614632, \"lr\": 0.000017303393, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.258970803324, \"lr\": 0.000017303393, \"top1_err\": 81.299999991862}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 80.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 78.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 79.500000000000, \"top1_err\": 79.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/118\", \"loss\": 2.219439148903, \"lr\": 0.000017303393, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/118\", \"loss\": 2.215436100960, \"lr\": 0.000017303393, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/118\", \"loss\": 2.198757529259, \"lr\": 0.000017303393, \"top1_err\": 79.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/118\", \"loss\": 2.202622532845, \"lr\": 0.000017303393, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/118\", \"loss\": 2.202093601227, \"lr\": 0.000017303393, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/118\", \"loss\": 2.183490395546, \"lr\": 0.000017303393, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/118\", \"loss\": 2.191007494926, \"lr\": 0.000017303393, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/118\", \"loss\": 2.183743715286, \"lr\": 0.000017303393, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/118\", \"loss\": 2.197608828545, \"lr\": 0.000017303393, \"top1_err\": 80.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/118\", \"loss\": 2.158815979958, \"lr\": 0.000017303393, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/118\", \"loss\": 2.179086208344, \"lr\": 0.000017303393, \"top1_err\": 78.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.192910978444, \"lr\": 0.000017303393, \"top1_err\": 77.926666658529}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 77.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 76.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 77.340000305176, \"top1_err\": 77.340000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/118\", \"loss\": 2.156780242920, \"lr\": 0.000017303393, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/118\", \"loss\": 2.168877840042, \"lr\": 0.000017303393, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/118\", \"loss\": 2.160421013832, \"lr\": 0.000017303393, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/118\", \"loss\": 2.146698474884, \"lr\": 0.000017303393, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/118\", \"loss\": 2.152570486069, \"lr\": 0.000017303393, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/118\", \"loss\": 2.132942557335, \"lr\": 0.000017303393, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/118\", \"loss\": 2.142604351044, \"lr\": 0.000017303393, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/118\", \"loss\": 2.137240052223, \"lr\": 0.000017303393, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/118\", \"loss\": 2.145346999168, \"lr\": 0.000017303393, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/118\", \"loss\": 2.144362807274, \"lr\": 0.000017303393, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/118\", \"loss\": 2.120172142982, \"lr\": 0.000017303393, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.143169197464, \"lr\": 0.000017303393, \"top1_err\": 75.820000008138}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 76.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 76.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 75.740000000000, \"top1_err\": 75.740000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/118\", \"loss\": 2.121891617775, \"lr\": 0.000017303393, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/118\", \"loss\": 2.109262108803, \"lr\": 0.000017303393, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/118\", \"loss\": 2.119397163391, \"lr\": 0.000017303393, \"top1_err\": 75.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/118\", \"loss\": 2.136068701744, \"lr\": 0.000017303393, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/118\", \"loss\": 2.090670108795, \"lr\": 0.000017303393, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/118\", \"loss\": 2.106455922127, \"lr\": 0.000017303393, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/118\", \"loss\": 2.101277351379, \"lr\": 0.000017303393, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/118\", \"loss\": 2.087389230728, \"lr\": 0.000017303393, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/118\", \"loss\": 2.097419857979, \"lr\": 0.000017303393, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/118\", \"loss\": 2.060627579689, \"lr\": 0.000017303393, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/118\", \"loss\": 2.089368939400, \"lr\": 0.000017303393, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.099471539434, \"lr\": 0.000017303393, \"top1_err\": 74.233333341471}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 74.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 74.980000305176, \"top1_err\": 74.980000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_25.01999969482422_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_25.01999969482422_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:37:06,418]\u001b[0m Trial 3 finished with value: 25.01999969482422 and parameters: {'learning_rate': 1.730339335441768e-05, 'weight_decay': 0.00013263903821982088, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 2 with value: 66.53999794006347.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.00013566169644370826\n",
      "Weight Decay : 1.6359968046862252e-05\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.00013566169644370826\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.6359968046862252e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.01999969482422_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:30000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 59\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/59\", \"loss\": 2.445225477219, \"lr\": 0.000135661696, \"top1_err\": 90.429687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/59\", \"loss\": 2.368791699409, \"lr\": 0.000135661696, \"top1_err\": 88.476562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/59\", \"loss\": 2.286662220955, \"lr\": 0.000135661696, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/59\", \"loss\": 2.220303535461, \"lr\": 0.000135661696, \"top1_err\": 80.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/59\", \"loss\": 2.187991499901, \"lr\": 0.000135661696, \"top1_err\": 77.929687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.284662649409, \"lr\": 0.000135661696, \"top1_err\": 83.026666654460}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 77.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 76.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 77.200000000000, \"top1_err\": 77.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/59\", \"loss\": 2.132977843285, \"lr\": 0.000135661696, \"top1_err\": 76.367187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/59\", \"loss\": 2.103022933006, \"lr\": 0.000135661696, \"top1_err\": 74.804687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/59\", \"loss\": 2.079382300377, \"lr\": 0.000135661696, \"top1_err\": 72.070312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/59\", \"loss\": 2.060882449150, \"lr\": 0.000135661696, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/59\", \"loss\": 2.029929280281, \"lr\": 0.000135661696, \"top1_err\": 72.070312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.077196622467, \"lr\": 0.000135661696, \"top1_err\": 74.000000016276}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 72.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 72.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 72.480000915527, \"top1_err\": 72.480000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/59\", \"loss\": 2.002953648567, \"lr\": 0.000135661696, \"top1_err\": 70.117187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/59\", \"loss\": 1.977741122246, \"lr\": 0.000135661696, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/59\", \"loss\": 1.952674150467, \"lr\": 0.000135661696, \"top1_err\": 70.898437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/59\", \"loss\": 1.944766640663, \"lr\": 0.000135661696, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/59\", \"loss\": 1.927488923073, \"lr\": 0.000135661696, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.959549204445, \"lr\": 0.000135661696, \"top1_err\": 69.986666703288}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 70.250007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 72.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 70.020001373291, \"top1_err\": 70.020001373291}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/59\", \"loss\": 1.907000303268, \"lr\": 0.000135661696, \"top1_err\": 68.164062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/59\", \"loss\": 1.871816515923, \"lr\": 0.000135661696, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/59\", \"loss\": 1.880675554276, \"lr\": 0.000135661696, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/59\", \"loss\": 1.875462234020, \"lr\": 0.000135661696, \"top1_err\": 67.773437500000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/59\", \"loss\": 1.859436452389, \"lr\": 0.000135661696, \"top1_err\": 67.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.869750711695, \"lr\": 0.000135661696, \"top1_err\": 67.053333304850}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 67.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 66.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 66.960000000000, \"top1_err\": 66.960000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/59\", \"loss\": 1.801979362965, \"lr\": 0.000135661696, \"top1_err\": 63.085937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/59\", \"loss\": 1.823284924030, \"lr\": 0.000135661696, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/59\", \"loss\": 1.787553131580, \"lr\": 0.000135661696, \"top1_err\": 63.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/59\", \"loss\": 1.800300598145, \"lr\": 0.000135661696, \"top1_err\": 65.820312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/59\", \"loss\": 1.768281817436, \"lr\": 0.000135661696, \"top1_err\": 62.304687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.794329829915, \"lr\": 0.000135661696, \"top1_err\": 64.526666650391}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 63.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 63.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 64.660000457764, \"top1_err\": 64.660000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_35.33999954223633_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_35.33999954223633_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:37:59,234]\u001b[0m Trial 4 finished with value: 35.33999954223633 and parameters: {'learning_rate': 0.00013566169644370826, 'weight_decay': 1.6359968046862252e-05, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 2 with value: 66.53999794006347.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 615.7933948040009 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 66.53999794006347\n",
      "  Params: \n",
      "    learning_rate: 0.0010518592956918393\n",
      "    weight_decay: 3.620505391925248e-06\n",
      "    batch_size: 32\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_66.53999794006347_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "--------------------\n",
      "Skipping best model inference as index sets already exists at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_66.53999794006347_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_66.53999794006347_model_epoch_0006.pyth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_66.53999794006347_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 34.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 31.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 31.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 35.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 32.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 32.970001716614, \"top1_err\": 32.970001716614}\n",
      "Test Accuracy: 67.030\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 30.0% of data is 67.02999828338622\n",
      "\n",
      "Extracted Test Accuracy from subproces: 67.02999828338622\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_zl7m_ymv.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-04-02 21:38:36,706]\u001b[0m A new study created in memory with name: no-name-9a901197-628e-498a-a7ea-9e8b5ded536e\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.000119921878299938\n",
      "Weight Decay : 2.58818753146218e-07\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.000119921878299938\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.58818753146218e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_65.63999855041504_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.456584215164, \"lr\": 0.000119921878, \"top1_err\": 90.429687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.362147927284, \"lr\": 0.000119921878, \"top1_err\": 85.742187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.306618094444, \"lr\": 0.000119921878, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 2.259499311447, \"lr\": 0.000119921878, \"top1_err\": 80.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 2.229176759720, \"lr\": 0.000119921878, \"top1_err\": 80.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 2.177154541016, \"lr\": 0.000119921878, \"top1_err\": 77.929687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 2.154016256332, \"lr\": 0.000119921878, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.260672137833, \"lr\": 0.000119921878, \"top1_err\": 81.765000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 75.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 76.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 75.700000305176, \"top1_err\": 75.700000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 2.099070310593, \"lr\": 0.000119921878, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 2.083666443825, \"lr\": 0.000119921878, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 2.071195244789, \"lr\": 0.000119921878, \"top1_err\": 74.414062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 2.076560735703, \"lr\": 0.000119921878, \"top1_err\": 72.460937500000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 2.024028301239, \"lr\": 0.000119921878, \"top1_err\": 70.507812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 2.016820073128, \"lr\": 0.000119921878, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 1.998603820801, \"lr\": 0.000119921878, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.042852738953, \"lr\": 0.000119921878, \"top1_err\": 72.545000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 72.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 70.250007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 71.560001220703, \"top1_err\": 71.560001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 1.961535215378, \"lr\": 0.000119921878, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 1.962772309780, \"lr\": 0.000119921878, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 1.929030656815, \"lr\": 0.000119921878, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 1.900344312191, \"lr\": 0.000119921878, \"top1_err\": 68.164062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 1.932686924934, \"lr\": 0.000119921878, \"top1_err\": 70.898437500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 1.890635907650, \"lr\": 0.000119921878, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 1.886282742023, \"lr\": 0.000119921878, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.917883426666, \"lr\": 0.000119921878, \"top1_err\": 69.280000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 69.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 67.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 68.400000305176, \"top1_err\": 68.400000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 1.857880771160, \"lr\": 0.000119921878, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 1.837817549706, \"lr\": 0.000119921878, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 1.876717388630, \"lr\": 0.000119921878, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 1.800824940205, \"lr\": 0.000119921878, \"top1_err\": 63.476562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 1.811857283115, \"lr\": 0.000119921878, \"top1_err\": 66.992187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 1.804669618607, \"lr\": 0.000119921878, \"top1_err\": 63.867187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 1.790883839130, \"lr\": 0.000119921878, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.819689368057, \"lr\": 0.000119921878, \"top1_err\": 65.295000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 67.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 65.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 65.440000152588, \"top1_err\": 65.440000152588}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 1.735797524452, \"lr\": 0.000119921878, \"top1_err\": 60.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 1.755988776684, \"lr\": 0.000119921878, \"top1_err\": 63.085937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 1.759416103363, \"lr\": 0.000119921878, \"top1_err\": 63.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 1.757727205753, \"lr\": 0.000119921878, \"top1_err\": 63.476562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 1.731920778751, \"lr\": 0.000119921878, \"top1_err\": 63.085937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 1.723658382893, \"lr\": 0.000119921878, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 1.721793293953, \"lr\": 0.000119921878, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.738088968849, \"lr\": 0.000119921878, \"top1_err\": 62.515000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 60.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 63.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 63.160001525879, \"top1_err\": 63.160001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_36.839998474121096_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_36.839998474121096_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:39:50,945]\u001b[0m Trial 0 finished with value: 36.839998474121096 and parameters: {'learning_rate': 0.000119921878299938, 'weight_decay': 2.58818753146218e-07, 'batch_size': 256, 'optimizer': 'SGD'}. Best is trial 0 with value: 36.839998474121096.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.0001369501376040869\n",
      "Weight Decay : 1.0140805319256237e-05\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0001369501376040869\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.0140805319256237e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_65.63999855041504_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/157\", \"loss\": 2.460408210754, \"lr\": 0.000136950138, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/157\", \"loss\": 2.340492725372, \"lr\": 0.000136950138, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/157\", \"loss\": 2.298067450523, \"lr\": 0.000136950138, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 2.225696921349, \"lr\": 0.000136950138, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 2.197688341141, \"lr\": 0.000136950138, \"top1_err\": 77.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/157\", \"loss\": 2.168910264969, \"lr\": 0.000136950138, \"top1_err\": 78.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/157\", \"loss\": 2.140913963318, \"lr\": 0.000136950138, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 2.112171649933, \"lr\": 0.000136950138, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/157\", \"loss\": 2.105296730995, \"lr\": 0.000136950138, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 2.098731160164, \"lr\": 0.000136950138, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/157\", \"loss\": 2.046889781952, \"lr\": 0.000136950138, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 2.010944366455, \"lr\": 0.000136950138, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/157\", \"loss\": 2.010826349258, \"lr\": 0.000136950138, \"top1_err\": 69.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/157\", \"loss\": 1.992634892464, \"lr\": 0.000136950138, \"top1_err\": 72.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.979951858521, \"lr\": 0.000136950138, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.138744404602, \"lr\": 0.000136950138, \"top1_err\": 77.170000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 70.750003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 71.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 71.720000610352, \"top1_err\": 71.720000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/157\", \"loss\": 1.921158790588, \"lr\": 0.000136950138, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/157\", \"loss\": 1.901569843292, \"lr\": 0.000136950138, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/157\", \"loss\": 1.920166373253, \"lr\": 0.000136950138, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 1.899578690529, \"lr\": 0.000136950138, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.907908916473, \"lr\": 0.000136950138, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/157\", \"loss\": 1.889134049416, \"lr\": 0.000136950138, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/157\", \"loss\": 1.899179577827, \"lr\": 0.000136950138, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 1.830600559711, \"lr\": 0.000136950138, \"top1_err\": 64.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/157\", \"loss\": 1.821608245373, \"lr\": 0.000136950138, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.809299349785, \"lr\": 0.000136950138, \"top1_err\": 63.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/157\", \"loss\": 1.830506622791, \"lr\": 0.000136950138, \"top1_err\": 64.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 1.762552738190, \"lr\": 0.000136950138, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/157\", \"loss\": 1.792023718357, \"lr\": 0.000136950138, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/157\", \"loss\": 1.762847363949, \"lr\": 0.000136950138, \"top1_err\": 63.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.745348095894, \"lr\": 0.000136950138, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.843777475357, \"lr\": 0.000136950138, \"top1_err\": 66.710000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 65.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 63.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 63.880000457764, \"top1_err\": 63.880000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/157\", \"loss\": 1.741834223270, \"lr\": 0.000136950138, \"top1_err\": 63.281250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/157\", \"loss\": 1.726366937160, \"lr\": 0.000136950138, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/157\", \"loss\": 1.786230385303, \"lr\": 0.000136950138, \"top1_err\": 65.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 1.737286925316, \"lr\": 0.000136950138, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.699402093887, \"lr\": 0.000136950138, \"top1_err\": 64.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/157\", \"loss\": 1.682186901569, \"lr\": 0.000136950138, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/157\", \"loss\": 1.642478108406, \"lr\": 0.000136950138, \"top1_err\": 60.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 1.663934171200, \"lr\": 0.000136950138, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/157\", \"loss\": 1.700718402863, \"lr\": 0.000136950138, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.666742563248, \"lr\": 0.000136950138, \"top1_err\": 61.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/157\", \"loss\": 1.610827744007, \"lr\": 0.000136950138, \"top1_err\": 57.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 1.649508714676, \"lr\": 0.000136950138, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/157\", \"loss\": 1.618727982044, \"lr\": 0.000136950138, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/157\", \"loss\": 1.615442752838, \"lr\": 0.000136950138, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.645718693733, \"lr\": 0.000136950138, \"top1_err\": 58.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.674813011932, \"lr\": 0.000136950138, \"top1_err\": 60.975000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 61.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 59.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 59.800001220703, \"top1_err\": 59.800001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/157\", \"loss\": 1.575102269650, \"lr\": 0.000136950138, \"top1_err\": 60.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/157\", \"loss\": 1.592840492725, \"lr\": 0.000136950138, \"top1_err\": 60.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/157\", \"loss\": 1.586506664753, \"lr\": 0.000136950138, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 1.591542840004, \"lr\": 0.000136950138, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 1.599233746529, \"lr\": 0.000136950138, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/157\", \"loss\": 1.599138319492, \"lr\": 0.000136950138, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/157\", \"loss\": 1.544360160828, \"lr\": 0.000136950138, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 1.565920293331, \"lr\": 0.000136950138, \"top1_err\": 55.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/157\", \"loss\": 1.535807728767, \"lr\": 0.000136950138, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 1.503676593304, \"lr\": 0.000136950138, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/157\", \"loss\": 1.523568153381, \"lr\": 0.000136950138, \"top1_err\": 55.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 1.548681020737, \"lr\": 0.000136950138, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/157\", \"loss\": 1.505465090275, \"lr\": 0.000136950138, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/157\", \"loss\": 1.518605172634, \"lr\": 0.000136950138, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 1.447876691818, \"lr\": 0.000136950138, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.552926816750, \"lr\": 0.000136950138, \"top1_err\": 56.855000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 57.250003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 54.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 55.900001068115, \"top1_err\": 55.900001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/157\", \"loss\": 1.404354929924, \"lr\": 0.000136950138, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/157\", \"loss\": 1.448277771473, \"lr\": 0.000136950138, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/157\", \"loss\": 1.456352829933, \"lr\": 0.000136950138, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 1.513119757175, \"lr\": 0.000136950138, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 1.461552500725, \"lr\": 0.000136950138, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/157\", \"loss\": 1.482864737511, \"lr\": 0.000136950138, \"top1_err\": 55.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/157\", \"loss\": 1.482228577137, \"lr\": 0.000136950138, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 1.496970117092, \"lr\": 0.000136950138, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/157\", \"loss\": 1.463810026646, \"lr\": 0.000136950138, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 1.504590094090, \"lr\": 0.000136950138, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/157\", \"loss\": 1.463611841202, \"lr\": 0.000136950138, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 1.441654205322, \"lr\": 0.000136950138, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/157\", \"loss\": 1.448636233807, \"lr\": 0.000136950138, \"top1_err\": 52.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/157\", \"loss\": 1.467786908150, \"lr\": 0.000136950138, \"top1_err\": 51.953125000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 1.460173547268, \"lr\": 0.000136950138, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.466573028374, \"lr\": 0.000136950138, \"top1_err\": 53.590000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 50.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 54.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 53.680001068115, \"top1_err\": 53.680001068115}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_46.31999893188477_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_46.31999893188477_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:41:30,696]\u001b[0m Trial 1 finished with value: 46.31999893188477 and parameters: {'learning_rate': 0.0001369501376040869, 'weight_decay': 1.0140805319256237e-05, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 1 with value: 46.31999893188477.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.00048402017629182623\n",
      "Weight Decay : 1.7200748880381157e-07\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.00048402017629182623\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.7200748880381157e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_65.63999855041504_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/157\", \"loss\": 2.414502263069, \"lr\": 0.000484020176, \"top1_err\": 90.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/157\", \"loss\": 2.230999827385, \"lr\": 0.000484020176, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/157\", \"loss\": 2.134023666382, \"lr\": 0.000484020176, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 2.075499653816, \"lr\": 0.000484020176, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 2.021786570549, \"lr\": 0.000484020176, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/157\", \"loss\": 1.980189979076, \"lr\": 0.000484020176, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/157\", \"loss\": 1.929433703423, \"lr\": 0.000484020176, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 1.854401350021, \"lr\": 0.000484020176, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/157\", \"loss\": 1.845496177673, \"lr\": 0.000484020176, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 1.824592292309, \"lr\": 0.000484020176, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/157\", \"loss\": 1.774893403053, \"lr\": 0.000484020176, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 1.711376368999, \"lr\": 0.000484020176, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/157\", \"loss\": 1.720650911331, \"lr\": 0.000484020176, \"top1_err\": 60.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/157\", \"loss\": 1.632853150368, \"lr\": 0.000484020176, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.662736952305, \"lr\": 0.000484020176, \"top1_err\": 60.156250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.908823861504, \"lr\": 0.000484020176, \"top1_err\": 69.540000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 58.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 58.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 58.860002441406, \"top1_err\": 58.860002441406}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/157\", \"loss\": 1.594489336014, \"lr\": 0.000484020176, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/157\", \"loss\": 1.542789280415, \"lr\": 0.000484020176, \"top1_err\": 58.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/157\", \"loss\": 1.563821434975, \"lr\": 0.000484020176, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 1.580551564693, \"lr\": 0.000484020176, \"top1_err\": 58.984375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.512341678143, \"lr\": 0.000484020176, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/157\", \"loss\": 1.531628906727, \"lr\": 0.000484020176, \"top1_err\": 55.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/157\", \"loss\": 1.534609615803, \"lr\": 0.000484020176, \"top1_err\": 58.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 1.450381338596, \"lr\": 0.000484020176, \"top1_err\": 49.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/157\", \"loss\": 1.452706515789, \"lr\": 0.000484020176, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.465929210186, \"lr\": 0.000484020176, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/157\", \"loss\": 1.445199191570, \"lr\": 0.000484020176, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 1.429784238338, \"lr\": 0.000484020176, \"top1_err\": 51.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/157\", \"loss\": 1.465221464634, \"lr\": 0.000484020176, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/157\", \"loss\": 1.404887080193, \"lr\": 0.000484020176, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.366628289223, \"lr\": 0.000484020176, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.488028525543, \"lr\": 0.000484020176, \"top1_err\": 54.705000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 51.499998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 53.499996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 51.960000000000, \"top1_err\": 51.960000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/157\", \"loss\": 1.357416570187, \"lr\": 0.000484020176, \"top1_err\": 50.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/157\", \"loss\": 1.357766449451, \"lr\": 0.000484020176, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/157\", \"loss\": 1.407869458199, \"lr\": 0.000484020176, \"top1_err\": 51.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 1.382146298885, \"lr\": 0.000484020176, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.324058175087, \"lr\": 0.000484020176, \"top1_err\": 50.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/157\", \"loss\": 1.324560701847, \"lr\": 0.000484020176, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/157\", \"loss\": 1.294608175755, \"lr\": 0.000484020176, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 1.303140521049, \"lr\": 0.000484020176, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/157\", \"loss\": 1.371789634228, \"lr\": 0.000484020176, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.340598642826, \"lr\": 0.000484020176, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/157\", \"loss\": 1.270006775856, \"lr\": 0.000484020176, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 1.308068871498, \"lr\": 0.000484020176, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/157\", \"loss\": 1.268271684647, \"lr\": 0.000484020176, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/157\", \"loss\": 1.244346976280, \"lr\": 0.000484020176, \"top1_err\": 44.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.339112520218, \"lr\": 0.000484020176, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.321483072853, \"lr\": 0.000484020176, \"top1_err\": 48.215000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 52.749996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 52.249998092651}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 51.960000000000, \"top1_err\": 52.339999847412}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/157\", \"loss\": 1.253302693367, \"lr\": 0.000484020176, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/157\", \"loss\": 1.277104258537, \"lr\": 0.000484020176, \"top1_err\": 47.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/157\", \"loss\": 1.235432088375, \"lr\": 0.000484020176, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 1.232706785202, \"lr\": 0.000484020176, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 1.253830790520, \"lr\": 0.000484020176, \"top1_err\": 46.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/157\", \"loss\": 1.225955784321, \"lr\": 0.000484020176, \"top1_err\": 45.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/157\", \"loss\": 1.202955663204, \"lr\": 0.000484020176, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 1.223066270351, \"lr\": 0.000484020176, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/157\", \"loss\": 1.224489510059, \"lr\": 0.000484020176, \"top1_err\": 42.578125000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 1.169777333736, \"lr\": 0.000484020176, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/157\", \"loss\": 1.189130783081, \"lr\": 0.000484020176, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 1.183535933495, \"lr\": 0.000484020176, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/157\", \"loss\": 1.168315231800, \"lr\": 0.000484020176, \"top1_err\": 42.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/157\", \"loss\": 1.155574619770, \"lr\": 0.000484020176, \"top1_err\": 44.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 1.138928771019, \"lr\": 0.000484020176, \"top1_err\": 42.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.208513458252, \"lr\": 0.000484020176, \"top1_err\": 44.275000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 47.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 44.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 47.200000457764, \"top1_err\": 47.200000457764}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/157\", \"loss\": 1.017595589161, \"lr\": 0.000484020176, \"top1_err\": 35.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/157\", \"loss\": 1.079607188702, \"lr\": 0.000484020176, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/157\", \"loss\": 1.080886006355, \"lr\": 0.000484020176, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 1.149574756622, \"lr\": 0.000484020176, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 1.102288782597, \"lr\": 0.000484020176, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/157\", \"loss\": 1.095912158489, \"lr\": 0.000484020176, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/157\", \"loss\": 1.124855399132, \"lr\": 0.000484020176, \"top1_err\": 39.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 1.067560315132, \"lr\": 0.000484020176, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/157\", \"loss\": 1.089399814606, \"lr\": 0.000484020176, \"top1_err\": 39.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 1.124293327332, \"lr\": 0.000484020176, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/157\", \"loss\": 1.099958419800, \"lr\": 0.000484020176, \"top1_err\": 40.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 1.093631207943, \"lr\": 0.000484020176, \"top1_err\": 37.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/157\", \"loss\": 1.096447885036, \"lr\": 0.000484020176, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/157\", \"loss\": 1.151572227478, \"lr\": 0.000484020176, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 1.106928288937, \"lr\": 0.000484020176, \"top1_err\": 38.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.104991647911, \"lr\": 0.000484020176, \"top1_err\": 39.810000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 43.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 43.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 43.280001525879, \"top1_err\": 43.280001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_56.71999847412109_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_56.71999847412109_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:43:15,928]\u001b[0m Trial 2 finished with value: 56.71999847412109 and parameters: {'learning_rate': 0.00048402017629182623, 'weight_decay': 1.7200748880381157e-07, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 2 with value: 56.71999847412109.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 1.6182716359624528e-05\n",
      "Weight Decay : 1.7697235282784876e-08\n",
      "Batch Size   : 64\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 1.6182716359624528e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.7697235282784876e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_65.63999855041504_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/313\", \"loss\": 2.487299680710, \"lr\": 0.000016182716, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/313\", \"loss\": 2.467148065567, \"lr\": 0.000016182716, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/313\", \"loss\": 2.442663669586, \"lr\": 0.000016182716, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 2.402582406998, \"lr\": 0.000016182716, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/313\", \"loss\": 2.398384571075, \"lr\": 0.000016182716, \"top1_err\": 91.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/313\", \"loss\": 2.387630343437, \"lr\": 0.000016182716, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/313\", \"loss\": 2.332895994186, \"lr\": 0.000016182716, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 2.389589786530, \"lr\": 0.000016182716, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/313\", \"loss\": 2.372350573540, \"lr\": 0.000016182716, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/313\", \"loss\": 2.332010149956, \"lr\": 0.000016182716, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/313\", \"loss\": 2.317396163940, \"lr\": 0.000016182716, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 2.323766112328, \"lr\": 0.000016182716, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/313\", \"loss\": 2.320943117142, \"lr\": 0.000016182716, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/313\", \"loss\": 2.330558061600, \"lr\": 0.000016182716, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/313\", \"loss\": 2.312872409821, \"lr\": 0.000016182716, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 2.263988018036, \"lr\": 0.000016182716, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/313\", \"loss\": 2.307568788528, \"lr\": 0.000016182716, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/313\", \"loss\": 2.292361259460, \"lr\": 0.000016182716, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/313\", \"loss\": 2.248303771019, \"lr\": 0.000016182716, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 2.272743463516, \"lr\": 0.000016182716, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/313\", \"loss\": 2.249438166618, \"lr\": 0.000016182716, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/313\", \"loss\": 2.232394337654, \"lr\": 0.000016182716, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/313\", \"loss\": 2.231756925583, \"lr\": 0.000016182716, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 2.212737560272, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/313\", \"loss\": 2.219649672508, \"lr\": 0.000016182716, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/313\", \"loss\": 2.226194620132, \"lr\": 0.000016182716, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/313\", \"loss\": 2.220631003380, \"lr\": 0.000016182716, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 2.212510466576, \"lr\": 0.000016182716, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/313\", \"loss\": 2.200307726860, \"lr\": 0.000016182716, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/313\", \"loss\": 2.217036366463, \"lr\": 0.000016182716, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/313\", \"loss\": 2.197853326797, \"lr\": 0.000016182716, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.302058209610, \"lr\": 0.000016182716, \"top1_err\": 83.545000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 77.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 79.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 78.840000000000, \"top1_err\": 78.840000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/313\", \"loss\": 2.181675195694, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/313\", \"loss\": 2.182763814926, \"lr\": 0.000016182716, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/313\", \"loss\": 2.186825156212, \"lr\": 0.000016182716, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 2.176581740379, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/313\", \"loss\": 2.158143997192, \"lr\": 0.000016182716, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/313\", \"loss\": 2.177808046341, \"lr\": 0.000016182716, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/313\", \"loss\": 2.186073303223, \"lr\": 0.000016182716, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 2.165385842323, \"lr\": 0.000016182716, \"top1_err\": 78.125000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/313\", \"loss\": 2.207848191261, \"lr\": 0.000016182716, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/313\", \"loss\": 2.161540746689, \"lr\": 0.000016182716, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/313\", \"loss\": 2.149467110634, \"lr\": 0.000016182716, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 2.158060193062, \"lr\": 0.000016182716, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/313\", \"loss\": 2.177661299706, \"lr\": 0.000016182716, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/313\", \"loss\": 2.171051383018, \"lr\": 0.000016182716, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/313\", \"loss\": 2.122116327286, \"lr\": 0.000016182716, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 2.136612296104, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/313\", \"loss\": 2.122490406036, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/313\", \"loss\": 2.129144668579, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/313\", \"loss\": 2.152553081512, \"lr\": 0.000016182716, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 2.123183488846, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/313\", \"loss\": 2.127032279968, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/313\", \"loss\": 2.132015109062, \"lr\": 0.000016182716, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/313\", \"loss\": 2.127166271210, \"lr\": 0.000016182716, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 2.091220378876, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/313\", \"loss\": 2.104413628578, \"lr\": 0.000016182716, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/313\", \"loss\": 2.099645972252, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/313\", \"loss\": 2.094439387321, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 2.119695067406, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/313\", \"loss\": 2.087401032448, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/313\", \"loss\": 2.101984024048, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/313\", \"loss\": 2.108689546585, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.142175062943, \"lr\": 0.000016182716, \"top1_err\": 76.315000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 76.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 73.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 75.040000000000, \"top1_err\": 75.040000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/313\", \"loss\": 2.075712919235, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/313\", \"loss\": 2.071185350418, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/313\", \"loss\": 2.074465274811, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 2.054334878922, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/313\", \"loss\": 2.062839388847, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/313\", \"loss\": 2.095836043358, \"lr\": 0.000016182716, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/313\", \"loss\": 2.090774416924, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 2.080740332603, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/313\", \"loss\": 2.058283567429, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/313\", \"loss\": 2.068784356117, \"lr\": 0.000016182716, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/313\", \"loss\": 2.055022120476, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 2.025650739670, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/313\", \"loss\": 2.023806571960, \"lr\": 0.000016182716, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/313\", \"loss\": 2.030259132385, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/313\", \"loss\": 2.047560572624, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 2.041475296021, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/313\", \"loss\": 2.064135909081, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/313\", \"loss\": 2.076334953308, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/313\", \"loss\": 2.007206439972, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 2.047694563866, \"lr\": 0.000016182716, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/313\", \"loss\": 1.998485088348, \"lr\": 0.000016182716, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/313\", \"loss\": 2.040306568146, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/313\", \"loss\": 2.026621580124, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 2.044289827347, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/313\", \"loss\": 2.034938812256, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/313\", \"loss\": 2.018433332443, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/313\", \"loss\": 2.009015202522, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 2.002980411053, \"lr\": 0.000016182716, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/313\", \"loss\": 2.001307070255, \"lr\": 0.000016182716, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/313\", \"loss\": 2.022548437119, \"lr\": 0.000016182716, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/313\", \"loss\": 2.015775799751, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.047957823181, \"lr\": 0.000016182716, \"top1_err\": 73.635000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 72.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 72.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 72.960001220703, \"top1_err\": 72.960001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/313\", \"loss\": 1.993490874767, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/313\", \"loss\": 1.994964897633, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/313\", \"loss\": 1.999174892902, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 2.004219472408, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/313\", \"loss\": 1.978083133698, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/313\", \"loss\": 2.022879958153, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/313\", \"loss\": 2.022716760635, \"lr\": 0.000016182716, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 2.009507775307, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/313\", \"loss\": 2.018254160881, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/313\", \"loss\": 1.999516785145, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/313\", \"loss\": 2.021291613579, \"lr\": 0.000016182716, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 1.985503077507, \"lr\": 0.000016182716, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/313\", \"loss\": 1.954944372177, \"lr\": 0.000016182716, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/313\", \"loss\": 1.957439303398, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/313\", \"loss\": 1.970011174679, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 1.938646435738, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/313\", \"loss\": 1.948467195034, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/313\", \"loss\": 1.986413419247, \"lr\": 0.000016182716, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/313\", \"loss\": 1.943730473518, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 1.964921712875, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/313\", \"loss\": 1.939030408859, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/313\", \"loss\": 1.926061928272, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/313\", \"loss\": 1.976339817047, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 1.945553421974, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/313\", \"loss\": 1.969015181065, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/313\", \"loss\": 1.943792104721, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/313\", \"loss\": 1.942992031574, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 1.954100191593, \"lr\": 0.000016182716, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/313\", \"loss\": 1.979605674744, \"lr\": 0.000016182716, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/313\", \"loss\": 1.921886384487, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/313\", \"loss\": 1.958014011383, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.974218999863, \"lr\": 0.000016182716, \"top1_err\": 70.600000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 71.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 70.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 70.740001525879, \"top1_err\": 70.740001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/313\", \"loss\": 1.907598972321, \"lr\": 0.000016182716, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/313\", \"loss\": 1.914230108261, \"lr\": 0.000016182716, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/313\", \"loss\": 1.939238607883, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 1.914982855320, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/313\", \"loss\": 1.896474003792, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/313\", \"loss\": 1.941852152348, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/313\", \"loss\": 1.957189083099, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 1.934082448483, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/313\", \"loss\": 1.928982138634, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/313\", \"loss\": 1.927451670170, \"lr\": 0.000016182716, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/313\", \"loss\": 1.962343811989, \"lr\": 0.000016182716, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 1.966199100018, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/313\", \"loss\": 1.921091377735, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/313\", \"loss\": 1.901719033718, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/313\", \"loss\": 1.975164115429, \"lr\": 0.000016182716, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 1.891726553440, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/313\", \"loss\": 1.922910928726, \"lr\": 0.000016182716, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/313\", \"loss\": 1.919085323811, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/313\", \"loss\": 1.936595320702, \"lr\": 0.000016182716, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 1.924015164375, \"lr\": 0.000016182716, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/313\", \"loss\": 1.881299614906, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/313\", \"loss\": 1.919609010220, \"lr\": 0.000016182716, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/313\", \"loss\": 1.879632294178, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 1.865912020206, \"lr\": 0.000016182716, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/313\", \"loss\": 1.857834279537, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/313\", \"loss\": 1.903890132904, \"lr\": 0.000016182716, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/313\", \"loss\": 1.869763255119, \"lr\": 0.000016182716, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 1.923035979271, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/313\", \"loss\": 1.892674744129, \"lr\": 0.000016182716, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/313\", \"loss\": 1.890142083168, \"lr\": 0.000016182716, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/313\", \"loss\": 1.876911103725, \"lr\": 0.000016182716, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.914350325966, \"lr\": 0.000016182716, \"top1_err\": 68.645000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 66.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 70.250007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 69.100001220703, \"top1_err\": 69.100001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_30.89999877929688_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_30.89999877929688_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:46:17,421]\u001b[0m Trial 3 finished with value: 30.89999877929688 and parameters: {'learning_rate': 1.6182716359624528e-05, 'weight_decay': 1.7697235282784876e-08, 'batch_size': 64, 'optimizer': 'SGD'}. Best is trial 2 with value: 56.71999847412109.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 5.688271836020098e-05\n",
      "Weight Decay : 1.9330737818565223e-05\n",
      "Batch Size   : 32\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 5.688271836020098e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.9330737818565223e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_65.63999855041504_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:25000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 625\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/625\", \"loss\": 2.431504845619, \"lr\": 0.000056882718, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/625\", \"loss\": 2.427742242813, \"lr\": 0.000056882718, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/625\", \"loss\": 2.382665753365, \"lr\": 0.000056882718, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/625\", \"loss\": 2.318369269371, \"lr\": 0.000056882718, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/625\", \"loss\": 2.317548155785, \"lr\": 0.000056882718, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/625\", \"loss\": 2.264648795128, \"lr\": 0.000056882718, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/625\", \"loss\": 2.230915188789, \"lr\": 0.000056882718, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/625\", \"loss\": 2.252534151077, \"lr\": 0.000056882718, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/625\", \"loss\": 2.210735440254, \"lr\": 0.000056882718, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/625\", \"loss\": 2.192499399185, \"lr\": 0.000056882718, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/625\", \"loss\": 2.188117742538, \"lr\": 0.000056882718, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/625\", \"loss\": 2.189942479134, \"lr\": 0.000056882718, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/625\", \"loss\": 2.166941046715, \"lr\": 0.000056882718, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/625\", \"loss\": 2.120988368988, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/625\", \"loss\": 2.186898350716, \"lr\": 0.000056882718, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/625\", \"loss\": 2.112352252007, \"lr\": 0.000056882718, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/625\", \"loss\": 2.165718078613, \"lr\": 0.000056882718, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/625\", \"loss\": 2.125407695770, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/625\", \"loss\": 2.119813799858, \"lr\": 0.000056882718, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/625\", \"loss\": 2.071274995804, \"lr\": 0.000056882718, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/625\", \"loss\": 2.088620901108, \"lr\": 0.000056882718, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/625\", \"loss\": 2.049376487732, \"lr\": 0.000056882718, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/625\", \"loss\": 2.081893444061, \"lr\": 0.000056882718, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/625\", \"loss\": 2.059185981750, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/625\", \"loss\": 2.052906513214, \"lr\": 0.000056882718, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/625\", \"loss\": 2.046119928360, \"lr\": 0.000056882718, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/625\", \"loss\": 2.020211219788, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/625\", \"loss\": 2.017799139023, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/625\", \"loss\": 1.974420726299, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/625\", \"loss\": 2.047578096390, \"lr\": 0.000056882718, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/625\", \"loss\": 1.967949986458, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/625\", \"loss\": 1.999442040920, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/625\", \"loss\": 2.028948783875, \"lr\": 0.000056882718, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/625\", \"loss\": 1.969384253025, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/625\", \"loss\": 2.020842552185, \"lr\": 0.000056882718, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/625\", \"loss\": 1.964283406734, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/625\", \"loss\": 1.951757609844, \"lr\": 0.000056882718, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/625\", \"loss\": 1.974463641644, \"lr\": 0.000056882718, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/625\", \"loss\": 1.992338895798, \"lr\": 0.000056882718, \"top1_err\": 70.312500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/625\", \"loss\": 1.977787911892, \"lr\": 0.000056882718, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/625\", \"loss\": 1.914044678211, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/625\", \"loss\": 1.915921747684, \"lr\": 0.000056882718, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/625\", \"loss\": 1.928180456161, \"lr\": 0.000056882718, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/625\", \"loss\": 1.934891223907, \"lr\": 0.000056882718, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/625\", \"loss\": 1.859828293324, \"lr\": 0.000056882718, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/625\", \"loss\": 1.904137849808, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/625\", \"loss\": 1.876038670540, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/625\", \"loss\": 1.874497532845, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/625\", \"loss\": 1.845607459545, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/625\", \"loss\": 1.821153342724, \"lr\": 0.000056882718, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/625\", \"loss\": 1.890803217888, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/625\", \"loss\": 1.931729316711, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/625\", \"loss\": 1.872131109238, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/625\", \"loss\": 1.805186450481, \"lr\": 0.000056882718, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/625\", \"loss\": 1.947191894054, \"lr\": 0.000056882718, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/625\", \"loss\": 1.806152939796, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/625\", \"loss\": 1.880042374134, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/625\", \"loss\": 1.818343520164, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/625\", \"loss\": 1.849887609482, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/625\", \"loss\": 1.892595589161, \"lr\": 0.000056882718, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/625\", \"loss\": 1.836309552193, \"lr\": 0.000056882718, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/625\", \"loss\": 1.855317771435, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.035507668495, \"lr\": 0.000056882718, \"top1_err\": 73.860000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"10/25\", \"top1_err\": 64.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"1/5\", \"iter\": \"20/25\", \"top1_err\": 67.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 65.360000305176, \"top1_err\": 65.360000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/625\", \"loss\": 1.788928627968, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/625\", \"loss\": 1.855574846268, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/625\", \"loss\": 1.765965521336, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/625\", \"loss\": 1.764540731907, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/625\", \"loss\": 1.742566525936, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/625\", \"loss\": 1.796002209187, \"lr\": 0.000056882718, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/625\", \"loss\": 1.735083699226, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/625\", \"loss\": 1.757095813751, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/625\", \"loss\": 1.743333280087, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/625\", \"loss\": 1.789885163307, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/625\", \"loss\": 1.702113568783, \"lr\": 0.000056882718, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/625\", \"loss\": 1.844360113144, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/625\", \"loss\": 1.789558410645, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/625\", \"loss\": 1.842211782932, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/625\", \"loss\": 1.685570240021, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/625\", \"loss\": 1.706361830235, \"lr\": 0.000056882718, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/625\", \"loss\": 1.778594136238, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/625\", \"loss\": 1.767759501934, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/625\", \"loss\": 1.747471272945, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/625\", \"loss\": 1.718299448490, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/625\", \"loss\": 1.776658177376, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/625\", \"loss\": 1.681325376034, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/625\", \"loss\": 1.797924578190, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/625\", \"loss\": 1.740017235279, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/625\", \"loss\": 1.751759290695, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/625\", \"loss\": 1.792571544647, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/625\", \"loss\": 1.759811282158, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/625\", \"loss\": 1.723850131035, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/625\", \"loss\": 1.668511688709, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/625\", \"loss\": 1.720582425594, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/625\", \"loss\": 1.636391818523, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/625\", \"loss\": 1.682671070099, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/625\", \"loss\": 1.656729340553, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/625\", \"loss\": 1.609306514263, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/625\", \"loss\": 1.653923630714, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/625\", \"loss\": 1.682724952698, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/625\", \"loss\": 1.757507026196, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/625\", \"loss\": 1.719160079956, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/625\", \"loss\": 1.627236187458, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/625\", \"loss\": 1.714200854301, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/625\", \"loss\": 1.679673194885, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/625\", \"loss\": 1.629501223564, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/625\", \"loss\": 1.736269831657, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/625\", \"loss\": 1.635196387768, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/625\", \"loss\": 1.624903917313, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/625\", \"loss\": 1.725324988365, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/625\", \"loss\": 1.615701258183, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/625\", \"loss\": 1.540742576122, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/625\", \"loss\": 1.612775981426, \"lr\": 0.000056882718, \"top1_err\": 67.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/625\", \"loss\": 1.709666609764, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/625\", \"loss\": 1.626350522041, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/625\", \"loss\": 1.722684144974, \"lr\": 0.000056882718, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/625\", \"loss\": 1.663271605968, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/625\", \"loss\": 1.581610918045, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/625\", \"loss\": 1.644124805927, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/625\", \"loss\": 1.663298189640, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/625\", \"loss\": 1.630486786366, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/625\", \"loss\": 1.566084563732, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/625\", \"loss\": 1.560022413731, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/625\", \"loss\": 1.592757165432, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/625\", \"loss\": 1.635300636292, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/625\", \"loss\": 1.606767177582, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.701234317780, \"lr\": 0.000056882718, \"top1_err\": 61.935000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"10/25\", \"top1_err\": 60.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"2/5\", \"iter\": \"20/25\", \"top1_err\": 59.000003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 58.400001220703, \"top1_err\": 58.400001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/625\", \"loss\": 1.631057798862, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/625\", \"loss\": 1.563308954239, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/625\", \"loss\": 1.547637045383, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/625\", \"loss\": 1.662696242332, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/625\", \"loss\": 1.597784042358, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/625\", \"loss\": 1.606470227242, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/625\", \"loss\": 1.486081838608, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/625\", \"loss\": 1.610962927341, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/625\", \"loss\": 1.631058633327, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/625\", \"loss\": 1.604886472225, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/625\", \"loss\": 1.744554102421, \"lr\": 0.000056882718, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/625\", \"loss\": 1.604541182518, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/625\", \"loss\": 1.559441030025, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/625\", \"loss\": 1.590831875801, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/625\", \"loss\": 1.624756395817, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/625\", \"loss\": 1.570191442966, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/625\", \"loss\": 1.491231679916, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/625\", \"loss\": 1.541936159134, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/625\", \"loss\": 1.545335829258, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/625\", \"loss\": 1.610803484917, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/625\", \"loss\": 1.586160480976, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/625\", \"loss\": 1.530643403530, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/625\", \"loss\": 1.527779340744, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/625\", \"loss\": 1.479698479176, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/625\", \"loss\": 1.566957712173, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/625\", \"loss\": 1.524181365967, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/625\", \"loss\": 1.473803222179, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/625\", \"loss\": 1.438153445721, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/625\", \"loss\": 1.511162698269, \"lr\": 0.000056882718, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/625\", \"loss\": 1.526600122452, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/625\", \"loss\": 1.583906292915, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/625\", \"loss\": 1.483614742756, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/625\", \"loss\": 1.523624002934, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/625\", \"loss\": 1.480287551880, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/625\", \"loss\": 1.513548910618, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/625\", \"loss\": 1.568659603596, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/625\", \"loss\": 1.501883149147, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/625\", \"loss\": 1.481274902821, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/625\", \"loss\": 1.555407702923, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/625\", \"loss\": 1.520252883434, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/625\", \"loss\": 1.504880368710, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/625\", \"loss\": 1.521269321442, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/625\", \"loss\": 1.447073221207, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/625\", \"loss\": 1.474109113216, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/625\", \"loss\": 1.517446994781, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/625\", \"loss\": 1.458332836628, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/625\", \"loss\": 1.610433459282, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/625\", \"loss\": 1.475449144840, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/625\", \"loss\": 1.457122921944, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/625\", \"loss\": 1.475260972977, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/625\", \"loss\": 1.494886577129, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/625\", \"loss\": 1.489816248417, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/625\", \"loss\": 1.520097732544, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/625\", \"loss\": 1.486342310905, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/625\", \"loss\": 1.476519882679, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/625\", \"loss\": 1.453695714474, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/625\", \"loss\": 1.555310606956, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/625\", \"loss\": 1.459370911121, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/625\", \"loss\": 1.566969990730, \"lr\": 0.000056882718, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/625\", \"loss\": 1.516179144382, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/625\", \"loss\": 1.520144641399, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/625\", \"loss\": 1.516049444675, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.542326683044, \"lr\": 0.000056882718, \"top1_err\": 56.490000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"10/25\", \"top1_err\": 57.500003814697}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"3/5\", \"iter\": \"20/25\", \"top1_err\": 53.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 54.720000915527, \"top1_err\": 54.720000915527}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/625\", \"loss\": 1.449449300766, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/625\", \"loss\": 1.394943952560, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/625\", \"loss\": 1.446690797806, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/625\", \"loss\": 1.508131384850, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/625\", \"loss\": 1.393295943737, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/625\", \"loss\": 1.564555227757, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/625\", \"loss\": 1.504138112068, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/625\", \"loss\": 1.450181484222, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/625\", \"loss\": 1.423049569130, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/625\", \"loss\": 1.478795230389, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/625\", \"loss\": 1.424489080906, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/625\", \"loss\": 1.650262713432, \"lr\": 0.000056882718, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/625\", \"loss\": 1.465717375278, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/625\", \"loss\": 1.471530318260, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/625\", \"loss\": 1.377438843250, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/625\", \"loss\": 1.410951435566, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/625\", \"loss\": 1.432076632977, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/625\", \"loss\": 1.644972562790, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/625\", \"loss\": 1.332320153713, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/625\", \"loss\": 1.535547375679, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/625\", \"loss\": 1.491165518761, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/625\", \"loss\": 1.544143259525, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/625\", \"loss\": 1.442144453526, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/625\", \"loss\": 1.463712871075, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/625\", \"loss\": 1.381188094616, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/625\", \"loss\": 1.393229246140, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/625\", \"loss\": 1.422639548779, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/625\", \"loss\": 1.364158272743, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/625\", \"loss\": 1.484408676624, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/625\", \"loss\": 1.521821677685, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/625\", \"loss\": 1.418532252312, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/625\", \"loss\": 1.377589941025, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/625\", \"loss\": 1.406508803368, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/625\", \"loss\": 1.323346197605, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/625\", \"loss\": 1.412126839161, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/625\", \"loss\": 1.463434278965, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/625\", \"loss\": 1.347966372967, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/625\", \"loss\": 1.394912421703, \"lr\": 0.000056882718, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/625\", \"loss\": 1.338712573051, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/625\", \"loss\": 1.402143299580, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/625\", \"loss\": 1.364847123623, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/625\", \"loss\": 1.457606375217, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/625\", \"loss\": 1.368809044361, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/625\", \"loss\": 1.402079820633, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/625\", \"loss\": 1.394842624664, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/625\", \"loss\": 1.438446462154, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/625\", \"loss\": 1.422193288803, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/625\", \"loss\": 1.469531297684, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/625\", \"loss\": 1.397164344788, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/625\", \"loss\": 1.391897618771, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/625\", \"loss\": 1.353172004223, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/625\", \"loss\": 1.425683021545, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/625\", \"loss\": 1.395951211452, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/625\", \"loss\": 1.442773997784, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/625\", \"loss\": 1.402113080025, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/625\", \"loss\": 1.380083024502, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/625\", \"loss\": 1.380198419094, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/625\", \"loss\": 1.339942812920, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/625\", \"loss\": 1.231266736984, \"lr\": 0.000056882718, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/625\", \"loss\": 1.388044595718, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/625\", \"loss\": 1.468923330307, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/625\", \"loss\": 1.382389783859, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.433547635841, \"lr\": 0.000056882718, \"top1_err\": 52.195000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"10/25\", \"top1_err\": 52.499996185303}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"4/5\", \"iter\": \"20/25\", \"top1_err\": 51.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 51.620000610352, \"top1_err\": 51.620000610352}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/625\", \"loss\": 1.295211851597, \"lr\": 0.000056882718, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/625\", \"loss\": 1.245901107788, \"lr\": 0.000056882718, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/625\", \"loss\": 1.279365181923, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/625\", \"loss\": 1.339224815369, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/625\", \"loss\": 1.356579542160, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/625\", \"loss\": 1.294205904007, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/625\", \"loss\": 1.348835706711, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/625\", \"loss\": 1.347583293915, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/625\", \"loss\": 1.280998229980, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/625\", \"loss\": 1.319383263588, \"lr\": 0.000056882718, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/625\", \"loss\": 1.433853089809, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/625\", \"loss\": 1.297137737274, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/625\", \"loss\": 1.447151601315, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/625\", \"loss\": 1.312363505363, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/625\", \"loss\": 1.331160843372, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/625\", \"loss\": 1.452440977097, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/625\", \"loss\": 1.306510388851, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/625\", \"loss\": 1.419783174992, \"lr\": 0.000056882718, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/625\", \"loss\": 1.267230570316, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/625\", \"loss\": 1.284141361713, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/625\", \"loss\": 1.439258098602, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/625\", \"loss\": 1.312525928020, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/625\", \"loss\": 1.403409004211, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/625\", \"loss\": 1.391855537891, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/625\", \"loss\": 1.356154561043, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/625\", \"loss\": 1.440769791603, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/625\", \"loss\": 1.462140381336, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/625\", \"loss\": 1.447188615799, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/625\", \"loss\": 1.436099648476, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/625\", \"loss\": 1.390639781952, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/625\", \"loss\": 1.278931379318, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/625\", \"loss\": 1.344009339809, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/625\", \"loss\": 1.359952211380, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/625\", \"loss\": 1.382896780968, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/625\", \"loss\": 1.275977909565, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/625\", \"loss\": 1.429156422615, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/625\", \"loss\": 1.489903509617, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/625\", \"loss\": 1.317402303219, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/625\", \"loss\": 1.366036593914, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/625\", \"loss\": 1.423458278179, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/625\", \"loss\": 1.276442110538, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/625\", \"loss\": 1.410614132881, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/625\", \"loss\": 1.320392727852, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/625\", \"loss\": 1.278271615505, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/625\", \"loss\": 1.282965421677, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/625\", \"loss\": 1.291502714157, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/625\", \"loss\": 1.397057235241, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/625\", \"loss\": 1.393301486969, \"lr\": 0.000056882718, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/625\", \"loss\": 1.383690893650, \"lr\": 0.000056882718, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/625\", \"loss\": 1.251679062843, \"lr\": 0.000056882718, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/625\", \"loss\": 1.372246026993, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/625\", \"loss\": 1.295473933220, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/625\", \"loss\": 1.391509830952, \"lr\": 0.000056882718, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/625\", \"loss\": 1.359292805195, \"lr\": 0.000056882718, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/625\", \"loss\": 1.419725537300, \"lr\": 0.000056882718, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/625\", \"loss\": 1.331700086594, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/625\", \"loss\": 1.345583915710, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/625\", \"loss\": 1.292272090912, \"lr\": 0.000056882718, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/625\", \"loss\": 1.245461583138, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/625\", \"loss\": 1.344514369965, \"lr\": 0.000056882718, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/625\", \"loss\": 1.307939231396, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/625\", \"loss\": 1.321453571320, \"lr\": 0.000056882718, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.358839022732, \"lr\": 0.000056882718, \"top1_err\": 49.815000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"10/25\", \"top1_err\": 48.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_iter\", \"epoch\": \"5/5\", \"iter\": \"20/25\", \"top1_err\": 48.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 49.020000305176, \"top1_err\": 49.020000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/transfer_experiment/resnet_2_depth_18/val_acc_epochs_y.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_50.979999694824215_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_50.979999694824215_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-04-02 21:51:35,169]\u001b[0m Trial 4 finished with value: 50.979999694824215 and parameters: {'learning_rate': 5.688271836020098e-05, 'weight_decay': 1.9330737818565223e-05, 'batch_size': 32, 'optimizer': 'SGD'}. Best is trial 2 with value: 56.71999847412109.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 778.4632680416107 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 56.71999847412109\n",
      "  Params: \n",
      "    learning_rate: 0.00048402017629182623\n",
      "    weight_decay: 1.7200748880381157e-07\n",
      "    batch_size: 128\n",
      "    optimizer: SGD\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_56.71999847412109_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "--------------------\n",
      "Skipping best model inference as index sets already exists at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.71999847412109_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.71999847412109_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: resnet_2\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 11,173,962\n",
      "Flops: 256,185,344\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_56.71999847412109_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 45.500001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 42.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 42.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 44.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 45.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 43.870001602173, \"top1_err\": 43.870001602173}\n",
      "Test Accuracy: 56.130\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 40.0% of data is 56.12999839782715\n",
      "\n",
      "Extracted Test Accuracy from subproces: 56.12999839782715\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/auto_ml_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n"
     ]
    }
   ],
   "source": [
    "!python3 $HOME_DIRECTORY/tools/main_aml.py --n_GPU $num_GPU \\\n",
    "--port $port --sampling_fn $sampling_fn --lSet_partition $lSet_partition \\\n",
    "--seed_id $base_seed \\\n",
    "--init_partition $init_partition --step_partition $step_partition \\\n",
    "--dataset $dataset --budget_size $budget_size \\\n",
    "--out_dir $out_dir \\\n",
    "--num_aml_trials $num_aml_trials --num_classes $num_classes \\\n",
    "--al_max_iter $al_iterations \\\n",
    "--model_type $model_type --model_depth $model_depth \\\n",
    "--clf_epochs $clf_epochs \\\n",
    "--eval_period 1 --checkpoint_period 1 \\\n",
    "--lSetPath $lSetPath --uSetPath $uSetPath --valSetPath $valSetPath \\\n",
    "--train_dir $train_dir --test_dir $test_dir \\\n",
    "--dropout_iterations 25 \\\n",
    "--cfg configs/$dataset/$model_style/$model_type/R-18_4gpu_unreg.yaml \\\n",
    "--vaal_z_dim 32 --vaal_vae_bs 64 --vaal_epochs 2 \\\n",
    "--vaal_vae_lr 5e-4 --vaal_disc_lr 5e-4 --vaal_beta 1.0 --vaal_adv_param 1.0 \\\n",
    "--isTransferExp --transfer_model_type resnet_2 \\\n",
    "--transfer_model_style resnet_style --transfer_model_depth 18 --transfer_dir_specific vanilla \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8a15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets explore the results folder where all the transfer models are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5893faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Checkpoints dirs\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "Found /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_transfer/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints\n"
     ]
    }
   ],
   "source": [
    "dirlist = []\n",
    "for root, dirs, files in os.walk(out_dir+\"/best_automl_results/\"):\n",
    "    for d in dirs:\n",
    "        #append the dir name to the list\n",
    "        if os.path.basename(d)==\"checkpoints\":\n",
    "            dirlist.append(os.path.join(root,d))\n",
    "\n",
    "dirlist.sort()            \n",
    "\n",
    "#print all the dir names\n",
    "print(\"-\"*20)\n",
    "print(\"Checkpoints dirs\")\n",
    "for d in dirlist:\n",
    "    print(\"Found\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6cc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also check the logged test accuracies for these transfer learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5834c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_results(fpath, out_dir):\n",
    "    fp = open(fpath, 'r')\n",
    "    for line in fp.readlines():\n",
    "        line=line.rstrip(\"\\n\")\n",
    "        cur_path, cur_acc = line.split(\" \")\n",
    "        print(\"=\"*20)\n",
    "        print(f\"PATH: {cur_path.replace(out_dir, '')}\") \n",
    "        print(f\"TEST ACCURACY: {cur_acc}\")\n",
    "        print(\"=\"*20)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6a0f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "PATH: /best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_47.3_model_epoch_0006.pyth\n",
      "TEST ACCURACY: 48.020000228881834\n",
      "====================\n",
      "====================\n",
      "PATH: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_50.01999969482422_model_epoch_0006.pyth\n",
      "TEST ACCURACY: 51.04999931335449\n",
      "====================\n",
      "====================\n",
      "PATH: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_65.63999855041504_model_epoch_0006.pyth\n",
      "TEST ACCURACY: 65.24999839782714\n",
      "====================\n",
      "====================\n",
      "PATH: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_64.77999839782714_model_epoch_0006.pyth\n",
      "TEST ACCURACY: 65.47999843597412\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#10% model results\n",
    "fpath=f\"{out_dir}/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/test_acc_.txt\"\n",
    "check_results(fpath, out_dir)\n",
    "\n",
    "#20% model results\n",
    "fpath=f\"{out_dir}/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/test_acc_.txt\"\n",
    "check_results(fpath, out_dir)\n",
    "\n",
    "#30% model results\n",
    "fpath=f\"{out_dir}/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/test_acc_.txt\"\n",
    "check_results(fpath, out_dir)\n",
    "\n",
    "#40% model results\n",
    "fpath=f\"{out_dir}/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/test_acc_.txt\"\n",
    "check_results(fpath, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb361b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
