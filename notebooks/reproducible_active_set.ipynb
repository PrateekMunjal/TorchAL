{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d38f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "HOME_DIRECTORY=os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "os.chdir(HOME_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6048aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # sync ids with nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"]=\"1\"\n",
    "\n",
    "port=10002 #when running more than one experiment on same  use different port for each experiment as \n",
    "sampling_fn=\"uncertainty\"\n",
    "\n",
    "lSet_partition=1\n",
    "base_seed=1\n",
    "num_GPU=1\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "clf_lr=5e-4\n",
    "clf_wt_decay=5e-4\n",
    "init_partition=10\n",
    "step_partition=10\n",
    "swa_lr=5e-4\n",
    "swa_freq=50\n",
    "swa_epochs=2\n",
    "optim_type=\"adam\"\n",
    "clf_epochs=5 #100\n",
    "num_classes=10\n",
    "\n",
    "tr_bs=64\n",
    "ts_bs=200\n",
    "log_iter=40\n",
    "\n",
    "#Data arguments\n",
    "train_dir=\"./data/CIFAR10/train-CIFAR10/\"\n",
    "test_dir=\"./data/CIFAR10/test-CIFAR10/\"\n",
    "lSetPath=f\"./data/CIFAR10/partition_{lSet_partition}/lSet_CIFAR10.npy\"\n",
    "uSetPath=f\"./data/CIFAR10/partition_{lSet_partition}/uSet_CIFAR10.npy\"\n",
    "valSetPath=f\"./data/CIFAR10/partition_{lSet_partition}/valSet_CIFAR10.npy\"\n",
    "out_dir=f\"./results/best_automl_results/lSet_{lSet_partition}/start_{base_seed}/\"\n",
    "\n",
    "\n",
    "model_style=\"vgg_style\"\n",
    "model_type=\"vgg\"\n",
    "model_depth=16\n",
    "\n",
    "model_cfg_file=f\"configs/{dataset}/{model_style}/{model_type}/R-18_4gpu.yaml\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2277bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== al_model_phase: True ==\n",
      "========= [NO ADVANCED REGULARIZATION TRICK ACTIVATED] =========\n",
      "Directory_specific: vanilla\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "~~ Constructing al_args for 20.0 with alStart: True\n",
      "best_model_path chosen: ./results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_70.47999824523926_model_epoch_0144.pyth\n",
      "======Inside get_al_args=====\n",
      "al_args: ['ACTIVE_LEARNING.LSET_PATH', './data/CIFAR10/partition_1/lSet_CIFAR10.npy', 'ACTIVE_LEARNING.USET_PATH', './data/CIFAR10/partition_1/uSet_CIFAR10.npy', 'ACTIVE_LEARNING.ACTIVATE', True, 'OUT_DIR', './results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/', 'ACTIVE_LEARNING.N_BINS', 0, 'ACTIVE_LEARNING.VALSET_PATH', './data/CIFAR10/partition_1/valSet_CIFAR10.npy', 'ACTIVE_LEARNING.MODEL_LOAD_DIR', './results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_70.47999824523926_model_epoch_0144.pyth', 'ACTIVE_LEARNING.BUDGET_SIZE', 5000, 'ACTIVE_LEARNING.SAMPLING_FN', 'uncertainty', 'ACTIVE_LEARNING.DROPOUT_ITERATIONS', 0, 'ACTIVE_LEARNING.NOISY_ORACLE', 0.0, 'ACTIVE_LEARNING.DATA_SPLIT', 20.0, 'NUM_GPUS', 1, 'DIR_SPECIFIC', 'vanilla']\n",
      "=============================\n",
      "==============================\n",
      "check_path: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/\n",
      "==============================\n",
      "tempArgsFile: /tmp/active_sampling_7e0yyu_6.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform uncertainty sampling through subprocess\n",
      "len(uSetLoader): 625\n",
      "uSet Activations: 100%|███████████████████████| 625/625 [00:08<00:00, 77.52it/s]\n",
      "u_ranks.shape: (40000,)\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  35000\n",
      "len(lSEt):  5000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 10000 and len(uSet): 35000\n",
      "saving pickle values...\n",
      "Saving lSet at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/lSet.npy in numpy format!!\n",
      "Saving uSet at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/uSet.npy in numpy format!!\n",
      "Saving activeSet at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/lSet.txt in text format!!\n",
      "Saving uSet at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/uSet.txt in text format!!\n",
      "Saving activeSet at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  35000\n",
      "len(lSet):  10000\n",
      "For uncertainty sampling, activeSet accuracy:  33.76\n",
      "========[CMD ARGUMNETS]=======\n",
      "al_args: ['MODEL.NUM_CLASSES', 10, 'MODEL.TYPE', 'vgg', 'MODEL.DEPTH', 16, 'NUM_GPUS', 1, 'OPTIM.BASE_LR', 0.0005, 'OPTIM.WEIGHT_DECAY', 0.0005, 'OPTIM.MAX_EPOCH', 5, 'OPTIM.MOMENTUM', 0.9, 'OPTIM.NESTEROV', False, 'PORT', 10002, 'RNG_SEED', 1, 'TEST.BATCH_SIZE', 200, 'TEST.DATASET', 'CIFAR10', 'TRAIN.BATCH_SIZE', 64, 'TRAIN.DATASET', 'CIFAR10', 'TRAIN.EVAL_PERIOD', 1, 'TRAIN.CHECKPOINT_PERIOD', 1, 'TRAIN.IMBALANCED', False, 'TRAIN.TRANSFER_EXP', False, 'MODEL.TRANSFER_MODEL_TYPE', 'ResNet', 'MODEL.TRANSFER_MODEL_DEPTH', 50, 'MODEL.TRANSFER_MODEL_STYLE', 'ResNet', 'MODEL.TRANSFER_DIR_SPECIFIC', 'vanilla', 'TRAIN_DIR', './data/CIFAR10/train-CIFAR10/', 'TEST_DIR', './data/CIFAR10/test-CIFAR10/', 'SWA_MODE.ACTIVATE', False, 'SWA_MODE.LR', 0.005, 'SWA_MODE.START_ITER', 50, 'SWA_MODE.FREQ', 50, 'RANDAUG.ACTIVATE', False, 'RANDAUG.N', 1, 'RANDAUG.M', 5, 'OPTIM.TYPE', 'adam', 'LOG_PERIOD', 40, 'VAAL.TRAIN_VAAL', False, 'VAAL.VAE_EPOCHS', 15, 'VAAL.VAE_LR', 0.0005, 'VAAL.DISC_LR', 0.0005, 'VAAL.BETA', 1.0, 'VAAL.ADVERSARY_PARAM', 1.0, 'VAAL.VAE_BS', 64, 'VAAL.Z_DIM', 32, 'VAAL.IM_SIZE', 32, 'ENSEMBLE.MAX_EPOCH', 1, 'DATA_LOADER.NUM_WORKERS', 4, 'ACTIVE_LEARNING.LSET_PATH', './results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/lSet.npy', 'ACTIVE_LEARNING.USET_PATH', './results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/uSet.npy', 'ACTIVE_LEARNING.ACTIVATE', True, 'OUT_DIR', './results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/', 'ACTIVE_LEARNING.N_BINS', 0, 'ACTIVE_LEARNING.VALSET_PATH', './data/CIFAR10/partition_1/valSet_CIFAR10.npy', 'ACTIVE_LEARNING.MODEL_LOAD_DIR', './results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_70.47999824523926_model_epoch_0144.pyth', 'ACTIVE_LEARNING.BUDGET_SIZE', 5000, 'ACTIVE_LEARNING.SAMPLING_FN', 'uncertainty', 'ACTIVE_LEARNING.DROPOUT_ITERATIONS', 0, 'ACTIVE_LEARNING.NOISY_ORACLE', 0.0, 'ACTIVE_LEARNING.DATA_SPLIT', 20.0, 'NUM_GPUS', 1, 'DIR_SPECIFIC', 'vanilla']\n",
      "Using data_splits: [10.0, 20.0]\n",
      "==============================\n",
      "============================\n",
      "Running AL iteration #1\n",
      "~~~~temp_out_dir: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: ./results/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_70.47999824523926_model_epoch_0144.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:35000, valSet: 5000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 2.345817565918, \"lr\": 0.000500000000, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 2.245393753052, \"lr\": 0.000500000000, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 2.186176776886, \"lr\": 0.000500000000, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.388730607605, \"lr\": 0.000500000000, \"top1_err\": 84.060000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 83.820000000000, \"top1_err\": 83.820000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 2.040542125702, \"lr\": 0.000500000000, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 1.986630797386, \"lr\": 0.000500000000, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 1.963099718094, \"lr\": 0.000500000000, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.990457831192, \"lr\": 0.000500000000, \"top1_err\": 80.580000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 80.520000000000, \"top1_err\": 80.520000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 1.954071402550, \"lr\": 0.000500000000, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 1.911377072334, \"lr\": 0.000500000000, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 1.922652363777, \"lr\": 0.000500000000, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.923822847748, \"lr\": 0.000500000000, \"top1_err\": 77.120000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 79.240000000000, \"top1_err\": 79.240000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 1.862974405289, \"lr\": 0.000500000000, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 1.859015285969, \"lr\": 0.000500000000, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 1.851190686226, \"lr\": 0.000500000000, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.857504590988, \"lr\": 0.000500000000, \"top1_err\": 75.440000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 76.720000305176, \"top1_err\": 76.720000305176}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 1.818052172661, \"lr\": 0.000500000000, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 1.819254755974, \"lr\": 0.000500000000, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 1.812960088253, \"lr\": 0.000500000000, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.819297931671, \"lr\": 0.000500000000, \"top1_err\": 73.990000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 70.240001220703, \"top1_err\": 70.240001220703}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "['./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth']\n",
      "temp_out_dir: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/\n",
      "latest_model_path: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "Best Val Acc: 29.75999877929688, Best Val Epoch: 6\n",
      "============================\n",
      "=====BEST MODEL=====\n",
      "temp_out_dir: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/\n",
      "best_model_path chosen: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "best_model_path: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/config.yaml TEST.WEIGHTS ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 70.250007629395}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 70.490001525879, \"top1_err\": 70.490001525879}\n",
      "Test Accuracy: 29.510\n",
      "Test accuracy [npy|txt] are saved at ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:uncertainty;Seed:1]Test accuracy on CIFAR10 using 20.0% of data is 29.50999847412109\n",
      "\n",
      "Extracted Test Accuracy from subproces: 29.50999847412109\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "For 20.0% split, test accuracy: 29.510 where model was loaded from path: ./results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/checkpoints/vlBest_acc_29.75999877929688_model_epoch_0006.pyth\n"
     ]
    }
   ],
   "source": [
    "# Run active learning and lets see if the active set is reprooduced using uncertainty method.\n",
    "# Precisely, we compare the active set drawn after running the below command and the active set which was used to \n",
    "# report the perfomance in main paper.\n",
    "\n",
    "\n",
    "!python3 $HOME_DIRECTORY/tools/train_al.py --n_GPU $num_GPU \\\n",
    "--port $port --out_dir $out_dir --dataset $dataset --seed_id $base_seed \\\n",
    "--model_type $model_type --model_depth $model_depth --train_batch_size $tr_bs --test_batch_size $ts_bs \\\n",
    "--lr $clf_lr --wt_decay $clf_wt_decay --clf_epochs $clf_epochs --num_classes $num_classes --eval_period 1 \\\n",
    "--checkpoint_period 1 --cfg configs/$dataset/$model_style/$model_type/R-18_4gpu.yaml \\\n",
    "--lSetPath $lSetPath --uSetPath $uSetPath --valSetPath $valSetPath \\\n",
    "--train_dir $train_dir --test_dir $test_dir \\\n",
    "--init_partition $init_partition --al_mode --sampling_fn $sampling_fn \\\n",
    "--step_partition $step_partition --al_max_iter 2 --budget_size 5000 \\\n",
    "--optim $optim_type --log_iter $log_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582e8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the AL sets drawn are saved at path: $out_dir/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty \n",
    "# --> According to the code following files are saved: \n",
    "# 1. activeSet.txt --> containing the indices for active set.\n",
    "# 2. actualScores.txt --> contains the uncertainty scores for unlabeled set. (uncertainty == maximum confidence among prob for all classes)\n",
    "\n",
    "\n",
    "#To check reproducibility old active set\n",
    "\n",
    "old_as_fpath = \"/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/iclr_results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/uncertainty/vgg_depth_16/vanilla/activeSet.txt\"\n",
    "new_as_fpath = \"/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/results/best_automl_results/lSet_1/start_1/CIFAR10/20.0/1/vgg_depth_16/vanilla/uncertainty/activeSet.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c151412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(fpath):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    fpath (str, required): Path to the text file.\n",
    "    \n",
    "    Returns: \n",
    "    List: Returns a list containing data line by line. New line character is removed from each line, if exists.\n",
    "    \"\"\"\n",
    "    file_content = []\n",
    "    assert os.path.isfile(fpath), f\"Expected {os.path.basename(fpath)} file to exist here!\"\n",
    "    fp = open(fpath, \"r\")\n",
    "    \n",
    "    for line in fp.readlines():\n",
    "        line = line.rstrip(\"\\n\")\n",
    "\n",
    "        file_content.append(line)\n",
    "    fp.close()\n",
    "    return file_content\n",
    "             \n",
    "old_active_set = read_text_file(old_as_fpath)\n",
    "new_active_set = read_text_file(new_as_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fc1988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Points in old active set:  5000\n",
      "#Points in new active set:  5000\n"
     ]
    }
   ],
   "source": [
    "print(\"#Points in old active set: \",len(old_active_set))\n",
    "print(\"#Points in new active set: \",len(new_active_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219b0a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len intersection set:  5000\n"
     ]
    }
   ],
   "source": [
    "# Lets check if they are same: i.e if the len(intersection) == len(both sets) then both the active sets are same.\n",
    "\n",
    "intersection_set = set(old_active_set).intersection(set(new_active_set))\n",
    "print(\"Len intersection set: \", len(intersection_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the length of intersection set matches the length of both active sets. As both active sets are same, \n",
    "# hence we conclude reproducibility of active sets by this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
