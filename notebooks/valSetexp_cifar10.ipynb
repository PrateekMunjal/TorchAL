{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b6a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21f4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIRECTORY=os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "os.chdir(HOME_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93287d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # sync ids with nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" \n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb399c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script params\n",
    "port=5259\n",
    "sampling_fn=\"random\"\n",
    "lSet_partition=1\n",
    "base_seed=1\n",
    "num_GPU=1\n",
    "al_iterations=4\n",
    "num_aml_trials=5 #50\n",
    "budget_size=5000 #2500\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "init_partition=10\n",
    "step_partition=10\n",
    "clf_epochs=5 #150\n",
    "num_classes=10\n",
    "swa_lr=5e-4\n",
    "swa_freq=50\n",
    "swa_epochs=5 #50\n",
    "\n",
    "log_iter=40\n",
    "\n",
    "#Data arguments\n",
    "# Note the change in following paths - this is changed compared to other notebooks\n",
    "\n",
    "train_dir=f\"{HOME_DIRECTORY}/data/{dataset}/train-{dataset}/\"\n",
    "test_dir=f\"{HOME_DIRECTORY}/data/{dataset}/test-{dataset}/\"\n",
    "lSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/val-set-1k/partition_{lSet_partition}/lSet_{dataset}.npy\"\n",
    "uSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/val-set-1k/partition_{lSet_partition}/uSet_{dataset}.npy\"\n",
    "valSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/val-set-1k/partition_{lSet_partition}/valSet_{dataset}.npy\"\n",
    "\n",
    "out_dir=f\"{HOME_DIRECTORY}/sample_results_aml_valSetExp2Percent\"\n",
    "\n",
    "model_style=\"vgg_style\"\n",
    "model_type=\"vgg\"\n",
    "model_depth=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d143ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= [NO ADVANCED REGULARIZATION TRICK ACTIVATED] =========\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_zgtk7s_2.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:11:11,359]\u001b[0m A new study created in memory with name: no-name-797eec6f-56af-42ff-9744-12d3218fceff\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.0019230719988444726\n",
      "Weight Decay : 1.5821802508323706e-07\n",
      "Batch Size   : 512\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0019230719988444726\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.5821802508323706e-07\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:44000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 10\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.305327662659, \"lr\": 0.001923071999, \"top1_err\": 89.100000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.264235546112, \"lr\": 0.001923071999, \"top1_err\": 85.420000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 88.500000000000, \"top1_err\": 88.500000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.206463338089, \"lr\": 0.001923071999, \"top1_err\": 81.700000256348}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 88.500000000000, \"top1_err\": 88.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.107206256104, \"lr\": 0.001923071999, \"top1_err\": 77.540000195313}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 88.500000000000, \"top1_err\": 89.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.981022191429, \"lr\": 0.001923071999, \"top1_err\": 73.979999853516}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 84.500000000000, \"top1_err\": 84.500000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_15.5_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_15.5_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:11:50,825]\u001b[0m Trial 0 finished with value: 15.5 and parameters: {'learning_rate': 0.0019230719988444726, 'weight_decay': 1.5821802508323706e-07, 'batch_size': 512, 'optimizer': 'SGD'}. Best is trial 0 with value: 15.5.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 0.0023861294227546896\n",
      "Weight Decay : 5.1565819095249016e-05\n",
      "Batch Size   : 16\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0023861294227546896\n",
      "    weight_decay: 5.1565819095249016e-05\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:44000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 2.801434874535, \"lr\": 0.002386129423, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 2.304005265236, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 2.304229855537, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 2.301562428474, \"lr\": 0.002386129423, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 2.303779721260, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 2.302867293358, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 2.302170157433, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 3.574206759262, \"lr\": 0.002386129423, \"top1_err\": 89.880000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 2.303249359131, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 2.302893280983, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 2.302942156792, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 2.303016304970, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 2.300474047661, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 2.305762290955, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 2.304136514664, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.303730353546, \"lr\": 0.002386129423, \"top1_err\": 89.040000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 2.304200053215, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 2.303736567497, \"lr\": 0.002386129423, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 2.299698829651, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 2.299091577530, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 2.307694196701, \"lr\": 0.002386129423, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 2.305094957352, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 2.312350988388, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.317631285858, \"lr\": 0.002386129423, \"top1_err\": 89.460000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 2.312142968178, \"lr\": 0.002386129423, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 2.316305160522, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 2.301028370857, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 2.304133772850, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 2.304196834564, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 2.305118680000, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 2.301830291748, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.340823297882, \"lr\": 0.002386129423, \"top1_err\": 88.940000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 2.303151726723, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 2.303283929825, \"lr\": 0.002386129423, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 2.303110122681, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 2.301259398460, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 2.311706542969, \"lr\": 0.002386129423, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 2.304295659065, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 2.301596045494, \"lr\": 0.002386129423, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.321168660355, \"lr\": 0.002386129423, \"top1_err\": 88.900000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_10.200000000000003_model_epoch_0002.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_10.200000000000003_model_epoch_0002.pyth\n",
      "\u001b[32m[I 2022-03-22 01:13:59,999]\u001b[0m Trial 1 finished with value: 10.200000000000003 and parameters: {'learning_rate': 0.0023861294227546896, 'weight_decay': 5.1565819095249016e-05, 'batch_size': 16, 'optimizer': 'ADAM'}. Best is trial 0 with value: 15.5.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.005138931309018333\n",
      "Weight Decay : 5.473168528772623e-07\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.005138931309018333\n",
      "    weight_decay: 5.473168528772623e-07\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:44000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 2.911287665367, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 2.299913287163, \"lr\": 0.005138931309, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 2.304449439049, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 9.481711006927, \"lr\": 0.005138931309, \"top1_err\": 90.100000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 2.302786827087, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 2.302364706993, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 2.303303718567, \"lr\": 0.005138931309, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.309793211746, \"lr\": 0.005138931309, \"top1_err\": 88.980000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 2.302953958511, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 2.298230051994, \"lr\": 0.005138931309, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 2.303235054016, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.304739110565, \"lr\": 0.005138931309, \"top1_err\": 89.200000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 2.304929018021, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 2.302399873734, \"lr\": 0.005138931309, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 2.303345561028, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.306407847595, \"lr\": 0.005138931309, \"top1_err\": 89.080000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 2.302535653114, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 2.302680611610, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 2.304671406746, \"lr\": 0.005138931309, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.318625048065, \"lr\": 0.005138931309, \"top1_err\": 89.340000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 89.800000000000, \"top1_err\": 89.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_10.200000000000003_model_epoch_0002.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_10.200000000000003_model_epoch_0002.pyth\n",
      "\u001b[32m[I 2022-03-22 01:15:21,603]\u001b[0m Trial 2 finished with value: 10.200000000000003 and parameters: {'learning_rate': 0.005138931309018333, 'weight_decay': 5.473168528772623e-07, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 0 with value: 15.5.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 5.416650761313898e-05\n",
      "Weight Decay : 1.1119065830853489e-05\n",
      "Batch Size   : 8\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 5.416650761313898e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.1119065830853489e-05\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:44000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 625\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/625\", \"loss\": 2.313581347466, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/625\", \"loss\": 2.302761793137, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/625\", \"loss\": 2.306040525436, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/625\", \"loss\": 2.274367094040, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/625\", \"loss\": 2.296756267548, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/625\", \"loss\": 2.272839665413, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/625\", \"loss\": 2.298581242561, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/625\", \"loss\": 2.260762691498, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/625\", \"loss\": 2.284860372543, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/625\", \"loss\": 2.273320078850, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/625\", \"loss\": 2.248684644699, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/625\", \"loss\": 2.242083668709, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/625\", \"loss\": 2.251981258392, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/625\", \"loss\": 2.207791566849, \"lr\": 0.000054166508, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/625\", \"loss\": 2.211884260178, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.268080652237, \"lr\": 0.000054166508, \"top1_err\": 86.140000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 79.800000000000, \"top1_err\": 79.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/625\", \"loss\": 2.170533418655, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/625\", \"loss\": 2.175161361694, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/625\", \"loss\": 2.188616394997, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/625\", \"loss\": 2.172120332718, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/625\", \"loss\": 2.128110051155, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/625\", \"loss\": 2.103335976601, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/625\", \"loss\": 2.131606936455, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/625\", \"loss\": 2.112336277962, \"lr\": 0.000054166508, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/625\", \"loss\": 2.070102930069, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/625\", \"loss\": 2.026932239532, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/625\", \"loss\": 2.013116955757, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/625\", \"loss\": 1.998083233833, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/625\", \"loss\": 2.025376081467, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/625\", \"loss\": 1.961179316044, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/625\", \"loss\": 2.010534048080, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.087784768867, \"lr\": 0.000054166508, \"top1_err\": 78.220000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 77.000000000000, \"top1_err\": 77.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/625\", \"loss\": 1.918786406517, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/625\", \"loss\": 1.952822387218, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/625\", \"loss\": 1.948844850063, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/625\", \"loss\": 2.022141218185, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/625\", \"loss\": 1.938640296459, \"lr\": 0.000054166508, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/625\", \"loss\": 1.905102849007, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/625\", \"loss\": 1.854990780354, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/625\", \"loss\": 1.982081592083, \"lr\": 0.000054166508, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/625\", \"loss\": 1.909452199936, \"lr\": 0.000054166508, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/625\", \"loss\": 1.921698510647, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/625\", \"loss\": 1.927107930183, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/625\", \"loss\": 1.905025780201, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/625\", \"loss\": 1.892714202404, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/625\", \"loss\": 1.819828450680, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/625\", \"loss\": 1.921377778053, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.961693754387, \"lr\": 0.000054166508, \"top1_err\": 75.400000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 74.000000000000, \"top1_err\": 74.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/625\", \"loss\": 1.899740576744, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/625\", \"loss\": 1.788318037987, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/625\", \"loss\": 1.830470740795, \"lr\": 0.000054166508, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/625\", \"loss\": 1.857523918152, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/625\", \"loss\": 1.949854373932, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/625\", \"loss\": 1.881484746933, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/625\", \"loss\": 1.775805890560, \"lr\": 0.000054166508, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/625\", \"loss\": 1.835272550583, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/625\", \"loss\": 1.737161874771, \"lr\": 0.000054166508, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/625\", \"loss\": 1.814871609211, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/625\", \"loss\": 1.734964311123, \"lr\": 0.000054166508, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/625\", \"loss\": 2.000166416168, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/625\", \"loss\": 1.832780539989, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/625\", \"loss\": 1.866922497749, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/625\", \"loss\": 1.819579780102, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.855532815933, \"lr\": 0.000054166508, \"top1_err\": 71.280000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 66.400000000000, \"top1_err\": 66.400000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/625\", \"loss\": 1.890994250774, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/625\", \"loss\": 1.692414522171, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/625\", \"loss\": 1.739212214947, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/625\", \"loss\": 1.809404551983, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/625\", \"loss\": 1.820890963078, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/625\", \"loss\": 1.801846027374, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/625\", \"loss\": 1.711740136147, \"lr\": 0.000054166508, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/625\", \"loss\": 1.747197747231, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/625\", \"loss\": 1.669100522995, \"lr\": 0.000054166508, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/625\", \"loss\": 1.693542122841, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/625\", \"loss\": 1.765801191330, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/625\", \"loss\": 1.800256431103, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/625\", \"loss\": 1.653210461140, \"lr\": 0.000054166508, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/625\", \"loss\": 1.700132191181, \"lr\": 0.000054166508, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/625\", \"loss\": 1.701484620571, \"lr\": 0.000054166508, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.775021436882, \"lr\": 0.000054166508, \"top1_err\": 68.440000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 64.000000000000, \"top1_err\": 64.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:19:18,152]\u001b[0m Trial 3 finished with value: 36.0 and parameters: {'learning_rate': 5.416650761313898e-05, 'weight_decay': 1.1119065830853489e-05, 'batch_size': 8, 'optimizer': 'SGD'}. Best is trial 3 with value: 36.0.\u001b[0m\n",
      "== al_model_phase: False ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.0034757621172866932\n",
      "Weight Decay : 0.0001687843632281244\n",
      "Batch Size   : 8\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0034757621172866932\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001687843632281244\n",
      ")\n",
      "=========================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 5000, uSet:44000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 625\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/625\", \"loss\": 2.351516604424, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/625\", \"loss\": 2.305743098259, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/625\", \"loss\": 2.269301176071, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/625\", \"loss\": 2.236481904984, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/625\", \"loss\": 2.194472193718, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/625\", \"loss\": 2.172376751900, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/625\", \"loss\": 2.248237490654, \"lr\": 0.003475762117, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/625\", \"loss\": 2.156206846237, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/625\", \"loss\": 2.176630258560, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/625\", \"loss\": 2.165951728821, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/625\", \"loss\": 2.119409322739, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/625\", \"loss\": 2.094886064529, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/625\", \"loss\": 2.066025018692, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/625\", \"loss\": 2.090634346008, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/625\", \"loss\": 2.080567479134, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.204501385307, \"lr\": 0.003475762117, \"top1_err\": 84.560000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 83.600000000000, \"top1_err\": 83.600000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/625\", \"loss\": 2.106209754944, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/625\", \"loss\": 2.007682740688, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/625\", \"loss\": 2.100546836853, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/625\", \"loss\": 2.111146211624, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/625\", \"loss\": 1.969289898872, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/625\", \"loss\": 2.041753530502, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/625\", \"loss\": 2.108798146248, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/625\", \"loss\": 2.055730104446, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/625\", \"loss\": 2.023693323135, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/625\", \"loss\": 2.005758643150, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/625\", \"loss\": 2.077723741531, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/625\", \"loss\": 2.049101948738, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/625\", \"loss\": 2.024136185646, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/625\", \"loss\": 2.017691850662, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/625\", \"loss\": 1.980783939362, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.085474638367, \"lr\": 0.003475762117, \"top1_err\": 82.800000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 82.200000000000, \"top1_err\": 82.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/625\", \"loss\": 2.050224661827, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/625\", \"loss\": 2.038528203964, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/625\", \"loss\": 2.064055562019, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/625\", \"loss\": 2.046209096909, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/625\", \"loss\": 2.046826243401, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/625\", \"loss\": 2.053574919701, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/625\", \"loss\": 1.989737808704, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/625\", \"loss\": 2.050616621971, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/625\", \"loss\": 2.025996804237, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/625\", \"loss\": 1.998625695705, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/625\", \"loss\": 2.074701905251, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/625\", \"loss\": 2.001125633717, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/625\", \"loss\": 2.009822010994, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/625\", \"loss\": 1.940631687641, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/625\", \"loss\": 2.025342464447, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.079695932198, \"lr\": 0.003475762117, \"top1_err\": 82.020000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 79.800000000000, \"top1_err\": 79.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/625\", \"loss\": 1.955309748650, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/625\", \"loss\": 2.043245077133, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/625\", \"loss\": 2.007504284382, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/625\", \"loss\": 2.032196044922, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/625\", \"loss\": 1.991952180862, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/625\", \"loss\": 2.013446331024, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/625\", \"loss\": 1.844822943211, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/625\", \"loss\": 2.027494072914, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/625\", \"loss\": 1.934160351753, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/625\", \"loss\": 1.942962586880, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/625\", \"loss\": 1.897376358509, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/625\", \"loss\": 2.040272712708, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/625\", \"loss\": 2.003489375114, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/625\", \"loss\": 1.980211794376, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/625\", \"loss\": 1.953938901424, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.019318424034, \"lr\": 0.003475762117, \"top1_err\": 80.820000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 77.200000000000, \"top1_err\": 77.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/625\", \"loss\": 1.923461556435, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/625\", \"loss\": 1.943936944008, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/625\", \"loss\": 1.910550355911, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/625\", \"loss\": 1.978870570660, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/625\", \"loss\": 1.976704180241, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/625\", \"loss\": 1.947154521942, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/625\", \"loss\": 2.013600170612, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/625\", \"loss\": 2.006622195244, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/625\", \"loss\": 1.876753568649, \"lr\": 0.003475762117, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/625\", \"loss\": 1.917145311832, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/625\", \"loss\": 1.854136884212, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/625\", \"loss\": 1.870588481426, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/625\", \"loss\": 1.874368607998, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/625\", \"loss\": 1.903624296188, \"lr\": 0.003475762117, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/625\", \"loss\": 1.885325074196, \"lr\": 0.003475762117, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.977446479607, \"lr\": 0.003475762117, \"top1_err\": 77.880000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 75.400000000000, \"top1_err\": 75.400000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_24.599999999999994_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_24.599999999999994_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:23:16,376]\u001b[0m Trial 4 finished with value: 24.599999999999994 and parameters: {'learning_rate': 0.0034757621172866932, 'weight_decay': 0.0001687843632281244, 'batch_size': 8, 'optimizer': 'SGD'}. Best is trial 3 with value: 36.0.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 725.0170691013336 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 36.0\n",
      "  Params: \n",
      "    learning_rate: 5.416650761313898e-05\n",
      "    weight_decay: 1.1119065830853489e-05\n",
      "    batch_size: 8\n",
      "    optimizer: SGD\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_lg7b3d2p.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  39000\n",
      "len(lSEt):  5000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 10000 and len(uSet): 39000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  39000\n",
      "len(lSet):  10000\n",
      "For random sampling, activeSet accuracy:  35.14\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 64.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 64.690000228882, \"top1_err\": 64.690000228882}\n",
      "Test Accuracy: 35.310\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 10.0% of data is 35.30999977111816\n",
      "\n",
      "Extracted Test Accuracy from subproces: 35.30999977111816\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_g223gsb5.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:25:09,737]\u001b[0m A new study created in memory with name: no-name-b2651ea2-2467-439d-9e8f-8261530b37fb\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 2.7932615616157487e-05\n",
      "Weight Decay : 0.0001311207595747139\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 2.7932615616157487e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001311207595747139\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:39000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.318655490875, \"lr\": 0.000027932616, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.316984653473, \"lr\": 0.000027932616, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.314001083374, \"lr\": 0.000027932616, \"top1_err\": 90.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 2.307961225510, \"lr\": 0.000027932616, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 2.297419309616, \"lr\": 0.000027932616, \"top1_err\": 88.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 2.312325239182, \"lr\": 0.000027932616, \"top1_err\": 89.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 2.303656458855, \"lr\": 0.000027932616, \"top1_err\": 89.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.310616784668, \"lr\": 0.000027932616, \"top1_err\": 89.720000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 88.000000000000, \"top1_err\": 88.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 2.304375767708, \"lr\": 0.000027932616, \"top1_err\": 90.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 2.300207734108, \"lr\": 0.000027932616, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 2.305135011673, \"lr\": 0.000027932616, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 2.306871891022, \"lr\": 0.000027932616, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 2.289963722229, \"lr\": 0.000027932616, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 2.293062448502, \"lr\": 0.000027932616, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 2.295552730560, \"lr\": 0.000027932616, \"top1_err\": 88.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.299921337128, \"lr\": 0.000027932616, \"top1_err\": 89.160000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 85.500000000000, \"top1_err\": 85.500000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 2.303380608559, \"lr\": 0.000027932616, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 2.289013624191, \"lr\": 0.000027932616, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 2.297389745712, \"lr\": 0.000027932616, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 2.289790034294, \"lr\": 0.000027932616, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 2.294599413872, \"lr\": 0.000027932616, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 2.285108089447, \"lr\": 0.000027932616, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 2.285222411156, \"lr\": 0.000027932616, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.292060540009, \"lr\": 0.000027932616, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 85.300000000000, \"top1_err\": 85.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 2.289841175079, \"lr\": 0.000027932616, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 2.288456201553, \"lr\": 0.000027932616, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 2.288858890533, \"lr\": 0.000027932616, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 2.284479379654, \"lr\": 0.000027932616, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 2.284099102020, \"lr\": 0.000027932616, \"top1_err\": 87.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 2.286039352417, \"lr\": 0.000027932616, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 2.280561923981, \"lr\": 0.000027932616, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.286722751999, \"lr\": 0.000027932616, \"top1_err\": 87.540000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 84.700000000000, \"top1_err\": 84.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 2.277481436729, \"lr\": 0.000027932616, \"top1_err\": 83.203125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 2.273938179016, \"lr\": 0.000027932616, \"top1_err\": 86.718750000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 2.282650351524, \"lr\": 0.000027932616, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 2.272464632988, \"lr\": 0.000027932616, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 2.275442719460, \"lr\": 0.000027932616, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 2.267398715019, \"lr\": 0.000027932616, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 2.274422168732, \"lr\": 0.000027932616, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.275639151764, \"lr\": 0.000027932616, \"top1_err\": 85.880000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 82.000000000000, \"top1_err\": 82.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_18.0_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_18.0_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:26:17,873]\u001b[0m Trial 0 finished with value: 18.0 and parameters: {'learning_rate': 2.7932615616157487e-05, 'weight_decay': 0.0001311207595747139, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 0 with value: 18.0.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 8.142347648430073e-05\n",
      "Weight Decay : 9.980435033040393e-07\n",
      "Batch Size   : 256\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 8.142347648430073e-05\n",
      "    weight_decay: 9.980435033040393e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:39000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 40\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/40\", \"loss\": 2.301876068115, \"lr\": 0.000081423476, \"top1_err\": 85.351562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/40\", \"loss\": 2.048680543900, \"lr\": 0.000081423476, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/40\", \"loss\": 1.848632931709, \"lr\": 0.000081423476, \"top1_err\": 74.414062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/40\", \"loss\": 1.708744406700, \"lr\": 0.000081423476, \"top1_err\": 67.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.994605025482, \"lr\": 0.000081423476, \"top1_err\": 76.460000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 84.300000000000, \"top1_err\": 84.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/40\", \"loss\": 1.612280786037, \"lr\": 0.000081423476, \"top1_err\": 63.867187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/40\", \"loss\": 1.529303729534, \"lr\": 0.000081423476, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/40\", \"loss\": 1.449137210846, \"lr\": 0.000081423476, \"top1_err\": 57.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/40\", \"loss\": 1.404390692711, \"lr\": 0.000081423476, \"top1_err\": 56.054687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.510839037132, \"lr\": 0.000081423476, \"top1_err\": 58.450000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 57.100001525879, \"top1_err\": 57.100001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/40\", \"loss\": 1.325605988503, \"lr\": 0.000081423476, \"top1_err\": 49.023437500000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/40\", \"loss\": 1.251035392284, \"lr\": 0.000081423476, \"top1_err\": 48.632812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/40\", \"loss\": 1.231481015682, \"lr\": 0.000081423476, \"top1_err\": 45.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/40\", \"loss\": 1.201790392399, \"lr\": 0.000081423476, \"top1_err\": 44.726562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.263740807819, \"lr\": 0.000081423476, \"top1_err\": 48.060000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 57.100001525879, \"top1_err\": 58.400000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/40\", \"loss\": 1.102627754211, \"lr\": 0.000081423476, \"top1_err\": 41.601562500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/40\", \"loss\": 1.051231443882, \"lr\": 0.000081423476, \"top1_err\": 39.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/40\", \"loss\": 1.046141266823, \"lr\": 0.000081423476, \"top1_err\": 39.257812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/40\", \"loss\": 1.058202743530, \"lr\": 0.000081423476, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.067881994247, \"lr\": 0.000081423476, \"top1_err\": 39.800000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 51.999998474121, \"top1_err\": 51.999998474121}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/40\", \"loss\": 0.881248533726, \"lr\": 0.000081423476, \"top1_err\": 32.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/40\", \"loss\": 0.873794645071, \"lr\": 0.000081423476, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/40\", \"loss\": 0.844047605991, \"lr\": 0.000081423476, \"top1_err\": 33.007812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/40\", \"loss\": 0.872821450233, \"lr\": 0.000081423476, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.877415109253, \"lr\": 0.000081423476, \"top1_err\": 32.680000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 51.999998474121, \"top1_err\": 54.900001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 01:27:18,068]\u001b[0m Trial 1 finished with value: 48.00000152587891 and parameters: {'learning_rate': 8.142347648430073e-05, 'weight_decay': 9.980435033040393e-07, 'batch_size': 256, 'optimizer': 'ADAM'}. Best is trial 1 with value: 48.00000152587891.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.0019954790875051026\n",
      "Weight Decay : 0.00014624542822294832\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0019954790875051026\n",
      "    weight_decay: 0.00014624542822294832\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:39000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 20\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/20\", \"loss\": 8.266717195511, \"lr\": 0.001995479088, \"top1_err\": 89.550781250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/20\", \"loss\": 2.314256906509, \"lr\": 0.001995479088, \"top1_err\": 88.867187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 11.146717338181, \"lr\": 0.001995479088, \"top1_err\": 89.420000061035}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 86.500000000000, \"top1_err\": 86.500000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/20\", \"loss\": 2.281942486763, \"lr\": 0.001995479088, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/20\", \"loss\": 2.261643052101, \"lr\": 0.001995479088, \"top1_err\": 87.988281250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.275491243362, \"lr\": 0.001995479088, \"top1_err\": 88.519999890137}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 86.500000000000, \"top1_err\": 87.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/20\", \"loss\": 2.257959485054, \"lr\": 0.001995479088, \"top1_err\": 88.085937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/20\", \"loss\": 2.256571531296, \"lr\": 0.001995479088, \"top1_err\": 87.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.263307680130, \"lr\": 0.001995479088, \"top1_err\": 87.660000061035}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 85.200000000000, \"top1_err\": 85.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/20\", \"loss\": 2.245219945908, \"lr\": 0.001995479088, \"top1_err\": 86.914062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/20\", \"loss\": 2.234606981277, \"lr\": 0.001995479088, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.242983565521, \"lr\": 0.001995479088, \"top1_err\": 86.400000048828}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 83.900000000000, \"top1_err\": 83.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/20\", \"loss\": 2.202719449997, \"lr\": 0.001995479088, \"top1_err\": 85.058593750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/20\", \"loss\": 2.202401995659, \"lr\": 0.001995479088, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.201711910629, \"lr\": 0.001995479088, \"top1_err\": 85.360000036621}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 82.700000000000, \"top1_err\": 82.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_17.299999999999997_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_17.299999999999997_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:28:09,752]\u001b[0m Trial 2 finished with value: 17.299999999999997 and parameters: {'learning_rate': 0.0019954790875051026, 'weight_decay': 0.00014624542822294832, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 1 with value: 48.00000152587891.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.009866436838402437\n",
      "Weight Decay : 3.3830116885541207e-07\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.009866436838402437\n",
      "    weight_decay: 3.3830116885541207e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:39000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 20\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/20\", \"loss\": 65.196136474609, \"lr\": 0.009866436838, \"top1_err\": 90.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/20\", \"loss\": 2.528145432472, \"lr\": 0.009866436838, \"top1_err\": 89.941406250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 211.203695207977, \"lr\": 0.009866436838, \"top1_err\": 90.140000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 88.800000000000, \"top1_err\": 88.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/20\", \"loss\": 2.308333277702, \"lr\": 0.009866436838, \"top1_err\": 90.527343750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/20\", \"loss\": 2.309885740280, \"lr\": 0.009866436838, \"top1_err\": 90.165443420410}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.314317762756, \"lr\": 0.009866436838, \"top1_err\": 90.350000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 88.800000000000, \"top1_err\": 88.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/20\", \"loss\": 2.304133653641, \"lr\": 0.009866436838, \"top1_err\": 90.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/20\", \"loss\": 2.304110646248, \"lr\": 0.009866436838, \"top1_err\": 90.527343750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.304530701447, \"lr\": 0.009866436838, \"top1_err\": 90.270000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 88.800000000000, \"top1_err\": 88.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/20\", \"loss\": 2.303234338760, \"lr\": 0.009866436838, \"top1_err\": 90.332031250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/20\", \"loss\": 2.303008198738, \"lr\": 0.009866436838, \"top1_err\": 90.332031250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.305513856125, \"lr\": 0.009866436838, \"top1_err\": 90.390000122070}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 88.800000000000, \"top1_err\": 89.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/20\", \"loss\": 2.302678704262, \"lr\": 0.009866436838, \"top1_err\": 90.820312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/20\", \"loss\": 2.302492380142, \"lr\": 0.009866436838, \"top1_err\": 88.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.303325062561, \"lr\": 0.009866436838, \"top1_err\": 89.790000012207}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 88.800000000000, \"top1_err\": 89.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_11.200000000000003_model_epoch_0002.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_11.200000000000003_model_epoch_0002.pyth\n",
      "\u001b[32m[I 2022-03-22 01:29:02,916]\u001b[0m Trial 3 finished with value: 11.200000000000003 and parameters: {'learning_rate': 0.009866436838402437, 'weight_decay': 3.3830116885541207e-07, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 1 with value: 48.00000152587891.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.0012238460419697781\n",
      "Weight Decay : 0.000399234823053322\n",
      "Batch Size   : 32\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0012238460419697781\n",
      "    weight_decay: 0.000399234823053322\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/10.0/vgg_depth_16/vanilla/checkpoints/vlBest_acc_36.0_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 10000, uSet:39000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/313\", \"loss\": 11.583740711212, \"lr\": 0.001223846042, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/313\", \"loss\": 2.952941894531, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/313\", \"loss\": 2.363220095634, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 2.345724940300, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/313\", \"loss\": 2.304394245148, \"lr\": 0.001223846042, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/313\", \"loss\": 2.313138723373, \"lr\": 0.001223846042, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/313\", \"loss\": 2.298378944397, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 2.302408337593, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/313\", \"loss\": 2.302010059357, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/313\", \"loss\": 2.302514314651, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/313\", \"loss\": 2.302107691765, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 2.302478909492, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/313\", \"loss\": 2.305857658386, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/313\", \"loss\": 2.305758357048, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/313\", \"loss\": 2.305820465088, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 2.302030205727, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/313\", \"loss\": 2.303168296814, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/313\", \"loss\": 2.302911400795, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/313\", \"loss\": 2.292969465256, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 2.306289792061, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/313\", \"loss\": 2.300503373146, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/313\", \"loss\": 2.301140427589, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/313\", \"loss\": 2.305150032043, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 2.298210382462, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/313\", \"loss\": 2.315969705582, \"lr\": 0.001223846042, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/313\", \"loss\": 2.302017331123, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/313\", \"loss\": 2.298096776009, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 2.310692310333, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/313\", \"loss\": 2.296285033226, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/313\", \"loss\": 2.314865350723, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/313\", \"loss\": 2.312905550003, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.725658519745, \"lr\": 0.001223846042, \"top1_err\": 90.200000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.500000000000, \"top1_err\": 89.500000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/313\", \"loss\": 2.302350878716, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/313\", \"loss\": 2.312248468399, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/313\", \"loss\": 2.297839045525, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 2.322894692421, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/313\", \"loss\": 2.301882505417, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/313\", \"loss\": 2.295553803444, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/313\", \"loss\": 2.285490632057, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 2.333655238152, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/313\", \"loss\": 2.305833101273, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/313\", \"loss\": 2.347592353821, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/313\", \"loss\": 2.312736511230, \"lr\": 0.001223846042, \"top1_err\": 96.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 2.283002257347, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/313\", \"loss\": 2.302901744843, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/313\", \"loss\": 2.321641206741, \"lr\": 0.001223846042, \"top1_err\": 92.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/313\", \"loss\": 2.312691092491, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 2.325520038605, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/313\", \"loss\": 2.366245269775, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/313\", \"loss\": 2.317109346390, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/313\", \"loss\": 2.296569824219, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 2.256595492363, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/313\", \"loss\": 2.254904985428, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/313\", \"loss\": 2.334262728691, \"lr\": 0.001223846042, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/313\", \"loss\": 2.287740468979, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 2.279679775238, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/313\", \"loss\": 2.317572593689, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/313\", \"loss\": 2.306078314781, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/313\", \"loss\": 2.255023479462, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 2.288469910622, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/313\", \"loss\": 2.244156360626, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/313\", \"loss\": 2.281006217003, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/313\", \"loss\": 2.287906050682, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.316006435394, \"lr\": 0.001223846042, \"top1_err\": 88.520000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 87.300000000000, \"top1_err\": 87.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/313\", \"loss\": 2.283891916275, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/313\", \"loss\": 2.247017502785, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/313\", \"loss\": 2.275444865227, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 2.285553574562, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/313\", \"loss\": 2.280437111855, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/313\", \"loss\": 2.266802310944, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/313\", \"loss\": 2.279327750206, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 2.258827209473, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/313\", \"loss\": 2.326411008835, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/313\", \"loss\": 2.262015581131, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/313\", \"loss\": 2.231012225151, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 2.197765469551, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/313\", \"loss\": 2.180308938026, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/313\", \"loss\": 2.194251894951, \"lr\": 0.001223846042, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/313\", \"loss\": 2.245578765869, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 2.207452654839, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/313\", \"loss\": 2.201614141464, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/313\", \"loss\": 2.288137555122, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/313\", \"loss\": 2.246369600296, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 2.256535291672, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/313\", \"loss\": 2.218125700951, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/313\", \"loss\": 2.221671223640, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/313\", \"loss\": 2.193218827248, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 2.146600961685, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/313\", \"loss\": 2.167051553726, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/313\", \"loss\": 2.167622923851, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/313\", \"loss\": 2.209689974785, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 2.247338652611, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/313\", \"loss\": 2.183050394058, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/313\", \"loss\": 2.213396668434, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/313\", \"loss\": 2.189371347427, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.247055766296, \"lr\": 0.001223846042, \"top1_err\": 85.760000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 85.000000000000, \"top1_err\": 85.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/313\", \"loss\": 2.156718969345, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/313\", \"loss\": 2.118233919144, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/313\", \"loss\": 2.196674704552, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 2.174445867538, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/313\", \"loss\": 2.155937314034, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/313\", \"loss\": 2.134965538979, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/313\", \"loss\": 2.142822504044, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 2.166232585907, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/313\", \"loss\": 2.138015985489, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/313\", \"loss\": 2.197352170944, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/313\", \"loss\": 2.169867753983, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 2.136773228645, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/313\", \"loss\": 2.138528108597, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/313\", \"loss\": 2.147450447083, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/313\", \"loss\": 2.106990933418, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 2.149546623230, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/313\", \"loss\": 2.136605024338, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/313\", \"loss\": 2.160649657249, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/313\", \"loss\": 2.137439966202, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 2.133559465408, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/313\", \"loss\": 2.167582392693, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/313\", \"loss\": 2.137329220772, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/313\", \"loss\": 2.187436342239, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 2.136613965034, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/313\", \"loss\": 2.046840548515, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/313\", \"loss\": 2.163357496262, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/313\", \"loss\": 2.080625534058, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 2.131015539169, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/313\", \"loss\": 2.138292431831, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/313\", \"loss\": 2.098340868950, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/313\", \"loss\": 2.085686206818, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.153127469635, \"lr\": 0.001223846042, \"top1_err\": 83.050000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 85.000000000000, \"top1_err\": 86.100000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/313\", \"loss\": 2.125697731972, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/313\", \"loss\": 2.136181473732, \"lr\": 0.001223846042, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/313\", \"loss\": 2.090557336807, \"lr\": 0.001223846042, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 2.119512438774, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/313\", \"loss\": 2.035098433495, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/313\", \"loss\": 2.156372547150, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/313\", \"loss\": 2.092302203178, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 2.017718195915, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/313\", \"loss\": 2.040100693703, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/313\", \"loss\": 2.074805617332, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/313\", \"loss\": 2.056795477867, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 2.077976107597, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/313\", \"loss\": 2.111004590988, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/313\", \"loss\": 2.252901434898, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/313\", \"loss\": 2.212911605835, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 2.150151968002, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/313\", \"loss\": 2.181954622269, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/313\", \"loss\": 2.143228054047, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/313\", \"loss\": 2.123955368996, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 2.167899012566, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/313\", \"loss\": 2.109615564346, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/313\", \"loss\": 2.134597063065, \"lr\": 0.001223846042, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/313\", \"loss\": 2.155872106552, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 2.050085544586, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/313\", \"loss\": 2.070902585983, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/313\", \"loss\": 2.082914471626, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/313\", \"loss\": 2.095346212387, \"lr\": 0.001223846042, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 2.086874842644, \"lr\": 0.001223846042, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/313\", \"loss\": 2.167719244957, \"lr\": 0.001223846042, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/313\", \"loss\": 2.077936053276, \"lr\": 0.001223846042, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/313\", \"loss\": 2.114809870720, \"lr\": 0.001223846042, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.124482676315, \"lr\": 0.001223846042, \"top1_err\": 83.160000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 82.900000000000, \"top1_err\": 82.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_17.099999999999994_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_17.099999999999994_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:31:17,539]\u001b[0m Trial 4 finished with value: 17.099999999999994 and parameters: {'learning_rate': 0.0012238460419697781, 'weight_decay': 0.000399234823053322, 'batch_size': 32, 'optimizer': 'ADAM'}. Best is trial 1 with value: 48.00000152587891.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 367.80316042900085 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 48.00000152587891\n",
      "  Params: \n",
      "    learning_rate: 8.142347648430073e-05\n",
      "    weight_decay: 9.980435033040393e-07\n",
      "    batch_size: 256\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_g11lirzo.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  34000\n",
      "len(lSEt):  10000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 15000 and len(uSet): 34000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/uSet.txt in text format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  34000\n",
      "len(lSet):  15000\n",
      "For random sampling, activeSet accuracy:  49.82\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 49.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 49.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 51.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 48.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 47.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 49.650000228882, \"top1_err\": 49.650000228882}\n",
      "Test Accuracy: 50.350\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 20.0% of data is 50.34999977111816\n",
      "\n",
      "Extracted Test Accuracy from subproces: 50.34999977111816\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_m3po0f4h.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:33:42,238]\u001b[0m A new study created in memory with name: no-name-7513e213-16e3-46c3-b1e6-36eb4d2cd134\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.0001389085031457764\n",
      "Weight Decay : 2.5957175665999373e-07\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0001389085031457764\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.5957175665999373e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:34000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 118\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/118\", \"loss\": 2.318414092064, \"lr\": 0.000138908503, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/118\", \"loss\": 2.311364889145, \"lr\": 0.000138908503, \"top1_err\": 89.062500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/118\", \"loss\": 2.306479930878, \"lr\": 0.000138908503, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/118\", \"loss\": 2.303348302841, \"lr\": 0.000138908503, \"top1_err\": 87.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/118\", \"loss\": 2.290565371513, \"lr\": 0.000138908503, \"top1_err\": 88.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/118\", \"loss\": 2.292956113815, \"lr\": 0.000138908503, \"top1_err\": 87.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/118\", \"loss\": 2.296881437302, \"lr\": 0.000138908503, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/118\", \"loss\": 2.279305219650, \"lr\": 0.000138908503, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/118\", \"loss\": 2.273091197014, \"lr\": 0.000138908503, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/118\", \"loss\": 2.269192099571, \"lr\": 0.000138908503, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/118\", \"loss\": 2.272215723991, \"lr\": 0.000138908503, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.290849913152, \"lr\": 0.000138908503, \"top1_err\": 87.446666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 82.100000000000, \"top1_err\": 82.100000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/118\", \"loss\": 2.265261530876, \"lr\": 0.000138908503, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/118\", \"loss\": 2.259153604507, \"lr\": 0.000138908503, \"top1_err\": 85.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/118\", \"loss\": 2.253246426582, \"lr\": 0.000138908503, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/118\", \"loss\": 2.245637297630, \"lr\": 0.000138908503, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/118\", \"loss\": 2.242455959320, \"lr\": 0.000138908503, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/118\", \"loss\": 2.229184746742, \"lr\": 0.000138908503, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/118\", \"loss\": 2.222313165665, \"lr\": 0.000138908503, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/118\", \"loss\": 2.211116433144, \"lr\": 0.000138908503, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/118\", \"loss\": 2.203759193420, \"lr\": 0.000138908503, \"top1_err\": 80.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/118\", \"loss\": 2.197460412979, \"lr\": 0.000138908503, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/118\", \"loss\": 2.193291068077, \"lr\": 0.000138908503, \"top1_err\": 80.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.229137280146, \"lr\": 0.000138908503, \"top1_err\": 82.313333325195}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 76.900000000000, \"top1_err\": 76.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/118\", \"loss\": 2.150675058365, \"lr\": 0.000138908503, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/118\", \"loss\": 2.171565771103, \"lr\": 0.000138908503, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/118\", \"loss\": 2.151420235634, \"lr\": 0.000138908503, \"top1_err\": 79.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/118\", \"loss\": 2.149674534798, \"lr\": 0.000138908503, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/118\", \"loss\": 2.132437944412, \"lr\": 0.000138908503, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/118\", \"loss\": 2.118066310883, \"lr\": 0.000138908503, \"top1_err\": 80.078125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/118\", \"loss\": 2.101520180702, \"lr\": 0.000138908503, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/118\", \"loss\": 2.108267188072, \"lr\": 0.000138908503, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/118\", \"loss\": 2.086467862129, \"lr\": 0.000138908503, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/118\", \"loss\": 2.083484292030, \"lr\": 0.000138908503, \"top1_err\": 76.171875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/118\", \"loss\": 2.045778512955, \"lr\": 0.000138908503, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.113639581426, \"lr\": 0.000138908503, \"top1_err\": 77.553333331299}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 75.300001525879, \"top1_err\": 75.300001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/118\", \"loss\": 2.040007352829, \"lr\": 0.000138908503, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/118\", \"loss\": 2.014492988586, \"lr\": 0.000138908503, \"top1_err\": 75.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/118\", \"loss\": 2.018496394157, \"lr\": 0.000138908503, \"top1_err\": 73.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/118\", \"loss\": 2.003026247025, \"lr\": 0.000138908503, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/118\", \"loss\": 1.976966559887, \"lr\": 0.000138908503, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/118\", \"loss\": 1.957263410091, \"lr\": 0.000138908503, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/118\", \"loss\": 1.946678459644, \"lr\": 0.000138908503, \"top1_err\": 74.609375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/118\", \"loss\": 1.967775046825, \"lr\": 0.000138908503, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/118\", \"loss\": 1.953884422779, \"lr\": 0.000138908503, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/118\", \"loss\": 1.933414041996, \"lr\": 0.000138908503, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/118\", \"loss\": 1.918951392174, \"lr\": 0.000138908503, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.972334619713, \"lr\": 0.000138908503, \"top1_err\": 73.699999995931}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 69.300000000000, \"top1_err\": 69.300000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/118\", \"loss\": 1.888466954231, \"lr\": 0.000138908503, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/118\", \"loss\": 1.882490396500, \"lr\": 0.000138908503, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/118\", \"loss\": 1.888860285282, \"lr\": 0.000138908503, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/118\", \"loss\": 1.854679346085, \"lr\": 0.000138908503, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/118\", \"loss\": 1.858096539974, \"lr\": 0.000138908503, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/118\", \"loss\": 1.860653340816, \"lr\": 0.000138908503, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/118\", \"loss\": 1.842589080334, \"lr\": 0.000138908503, \"top1_err\": 69.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/118\", \"loss\": 1.865840613842, \"lr\": 0.000138908503, \"top1_err\": 72.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/118\", \"loss\": 1.858470678329, \"lr\": 0.000138908503, \"top1_err\": 70.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/118\", \"loss\": 1.819563090801, \"lr\": 0.000138908503, \"top1_err\": 69.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/118\", \"loss\": 1.845811724663, \"lr\": 0.000138908503, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.864955487251, \"lr\": 0.000138908503, \"top1_err\": 70.666666662598}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 69.300000000000, \"top1_err\": 69.800003051758}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_30.700000000000003_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_30.700000000000003_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 01:35:02,300]\u001b[0m Trial 0 finished with value: 30.700000000000003 and parameters: {'learning_rate': 0.0001389085031457764, 'weight_decay': 2.5957175665999373e-07, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 0 with value: 30.700000000000003.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 3.586261179330355e-05\n",
      "Weight Decay : 2.2613121931465503e-07\n",
      "Batch Size   : 64\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 3.586261179330355e-05\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 2.2613121931465503e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:34000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 235\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/235\", \"loss\": 2.313350677490, \"lr\": 0.000035862612, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/235\", \"loss\": 2.317506313324, \"lr\": 0.000035862612, \"top1_err\": 91.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/235\", \"loss\": 2.314449667931, \"lr\": 0.000035862612, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/235\", \"loss\": 2.322085857391, \"lr\": 0.000035862612, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/235\", \"loss\": 2.312213420868, \"lr\": 0.000035862612, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/235\", \"loss\": 2.313778877258, \"lr\": 0.000035862612, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/235\", \"loss\": 2.303928732872, \"lr\": 0.000035862612, \"top1_err\": 88.281250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/235\", \"loss\": 2.314811706543, \"lr\": 0.000035862612, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/235\", \"loss\": 2.296056628227, \"lr\": 0.000035862612, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/235\", \"loss\": 2.296920895576, \"lr\": 0.000035862612, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/235\", \"loss\": 2.300748467445, \"lr\": 0.000035862612, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/235\", \"loss\": 2.301041722298, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/235\", \"loss\": 2.302623152733, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/235\", \"loss\": 2.304274559021, \"lr\": 0.000035862612, \"top1_err\": 88.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/235\", \"loss\": 2.289386272430, \"lr\": 0.000035862612, \"top1_err\": 91.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/235\", \"loss\": 2.279827713966, \"lr\": 0.000035862612, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/235\", \"loss\": 2.290078520775, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/235\", \"loss\": 2.295002102852, \"lr\": 0.000035862612, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/235\", \"loss\": 2.282718777657, \"lr\": 0.000035862612, \"top1_err\": 89.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/235\", \"loss\": 2.293941855431, \"lr\": 0.000035862612, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/235\", \"loss\": 2.293089866638, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/235\", \"loss\": 2.283481478691, \"lr\": 0.000035862612, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/235\", \"loss\": 2.297200202942, \"lr\": 0.000035862612, \"top1_err\": 89.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.300248630905, \"lr\": 0.000035862612, \"top1_err\": 88.533333325195}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 85.400000000000, \"top1_err\": 85.400000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/235\", \"loss\": 2.297911763191, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/235\", \"loss\": 2.274963974953, \"lr\": 0.000035862612, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/235\", \"loss\": 2.279508590698, \"lr\": 0.000035862612, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/235\", \"loss\": 2.270305037498, \"lr\": 0.000035862612, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/235\", \"loss\": 2.288840770721, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/235\", \"loss\": 2.288358449936, \"lr\": 0.000035862612, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/235\", \"loss\": 2.266313672066, \"lr\": 0.000035862612, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/235\", \"loss\": 2.271468281746, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/235\", \"loss\": 2.274544477463, \"lr\": 0.000035862612, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/235\", \"loss\": 2.283457040787, \"lr\": 0.000035862612, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/235\", \"loss\": 2.281629204750, \"lr\": 0.000035862612, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/235\", \"loss\": 2.270884275436, \"lr\": 0.000035862612, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/235\", \"loss\": 2.282027602196, \"lr\": 0.000035862612, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/235\", \"loss\": 2.281835436821, \"lr\": 0.000035862612, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/235\", \"loss\": 2.265959620476, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/235\", \"loss\": 2.257014751434, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/235\", \"loss\": 2.262868046761, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/235\", \"loss\": 2.268926143646, \"lr\": 0.000035862612, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/235\", \"loss\": 2.266489267349, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/235\", \"loss\": 2.253463149071, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/235\", \"loss\": 2.250872731209, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/235\", \"loss\": 2.258917927742, \"lr\": 0.000035862612, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/235\", \"loss\": 2.252274751663, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 2.271220013682, \"lr\": 0.000035862612, \"top1_err\": 84.833333329264}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 80.300000000000, \"top1_err\": 80.300000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/235\", \"loss\": 2.235343217850, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/235\", \"loss\": 2.264798760414, \"lr\": 0.000035862612, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/235\", \"loss\": 2.274312376976, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/235\", \"loss\": 2.250937223434, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/235\", \"loss\": 2.245875477791, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/235\", \"loss\": 2.246217608452, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/235\", \"loss\": 2.265740633011, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/235\", \"loss\": 2.258401632309, \"lr\": 0.000035862612, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/235\", \"loss\": 2.248455405235, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/235\", \"loss\": 2.257294297218, \"lr\": 0.000035862612, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/235\", \"loss\": 2.246152400970, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/235\", \"loss\": 2.248707056046, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/235\", \"loss\": 2.246508121490, \"lr\": 0.000035862612, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/235\", \"loss\": 2.226219773293, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/235\", \"loss\": 2.220937848091, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/235\", \"loss\": 2.233253717422, \"lr\": 0.000035862612, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/235\", \"loss\": 2.243411660194, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/235\", \"loss\": 2.225303292274, \"lr\": 0.000035862612, \"top1_err\": 85.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/235\", \"loss\": 2.230117678642, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/235\", \"loss\": 2.241700053215, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/235\", \"loss\": 2.211766481400, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/235\", \"loss\": 2.209792613983, \"lr\": 0.000035862612, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/235\", \"loss\": 2.212600231171, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 2.239447231547, \"lr\": 0.000035862612, \"top1_err\": 82.079999995931}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 78.700000000000, \"top1_err\": 78.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/235\", \"loss\": 2.217488884926, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/235\", \"loss\": 2.205139756203, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/235\", \"loss\": 2.228600382805, \"lr\": 0.000035862612, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/235\", \"loss\": 2.205002903938, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/235\", \"loss\": 2.210444211960, \"lr\": 0.000035862612, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/235\", \"loss\": 2.220508098602, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/235\", \"loss\": 2.195461869240, \"lr\": 0.000035862612, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/235\", \"loss\": 2.183648467064, \"lr\": 0.000035862612, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/235\", \"loss\": 2.190019845963, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/235\", \"loss\": 2.203607201576, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/235\", \"loss\": 2.184321284294, \"lr\": 0.000035862612, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/235\", \"loss\": 2.187787652016, \"lr\": 0.000035862612, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/235\", \"loss\": 2.194315552711, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/235\", \"loss\": 2.188835263252, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/235\", \"loss\": 2.182371139526, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/235\", \"loss\": 2.181047081947, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/235\", \"loss\": 2.177342534065, \"lr\": 0.000035862612, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/235\", \"loss\": 2.186976790428, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/235\", \"loss\": 2.183861970901, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/235\", \"loss\": 2.173323273659, \"lr\": 0.000035862612, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/235\", \"loss\": 2.165555357933, \"lr\": 0.000035862612, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/235\", \"loss\": 2.149526119232, \"lr\": 0.000035862612, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/235\", \"loss\": 2.171775102615, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 2.190268703206, \"lr\": 0.000035862612, \"top1_err\": 79.979999991862}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 75.900000000000, \"top1_err\": 75.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/235\", \"loss\": 2.144380331039, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/235\", \"loss\": 2.151363730431, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/235\", \"loss\": 2.165939927101, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/235\", \"loss\": 2.147806286812, \"lr\": 0.000035862612, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/235\", \"loss\": 2.138592243195, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/235\", \"loss\": 2.158755779266, \"lr\": 0.000035862612, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/235\", \"loss\": 2.120468735695, \"lr\": 0.000035862612, \"top1_err\": 78.125000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/235\", \"loss\": 2.147649049759, \"lr\": 0.000035862612, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/235\", \"loss\": 2.122375845909, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/235\", \"loss\": 2.138123750687, \"lr\": 0.000035862612, \"top1_err\": 82.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/235\", \"loss\": 2.140890717506, \"lr\": 0.000035862612, \"top1_err\": 80.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/235\", \"loss\": 2.151845693588, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/235\", \"loss\": 2.117142319679, \"lr\": 0.000035862612, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/235\", \"loss\": 2.093592762947, \"lr\": 0.000035862612, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/235\", \"loss\": 2.110514879227, \"lr\": 0.000035862612, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/235\", \"loss\": 2.109493613243, \"lr\": 0.000035862612, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/235\", \"loss\": 2.139971613884, \"lr\": 0.000035862612, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/235\", \"loss\": 2.114836573601, \"lr\": 0.000035862612, \"top1_err\": 78.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/235\", \"loss\": 2.099793553352, \"lr\": 0.000035862612, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/235\", \"loss\": 2.124186396599, \"lr\": 0.000035862612, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/235\", \"loss\": 2.097990155220, \"lr\": 0.000035862612, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/235\", \"loss\": 2.081513285637, \"lr\": 0.000035862612, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/235\", \"loss\": 2.114148259163, \"lr\": 0.000035862612, \"top1_err\": 79.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 2.125719555283, \"lr\": 0.000035862612, \"top1_err\": 77.839999991862}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 73.400000000000, \"top1_err\": 73.400000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_26.599999999999994_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_26.599999999999994_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:37:08,738]\u001b[0m Trial 1 finished with value: 26.599999999999994 and parameters: {'learning_rate': 3.586261179330355e-05, 'weight_decay': 2.2613121931465503e-07, 'batch_size': 64, 'optimizer': 'SGD'}. Best is trial 0 with value: 30.700000000000003.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 7.62829165305698e-05\n",
      "Weight Decay : 1.3461824438960038e-08\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 7.62829165305698e-05\n",
      "    weight_decay: 1.3461824438960038e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:34000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 30\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/30\", \"loss\": 2.231638669968, \"lr\": 0.000076282917, \"top1_err\": 83.007812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/30\", \"loss\": 1.918292760849, \"lr\": 0.000076282917, \"top1_err\": 72.167968750000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/30\", \"loss\": 1.706172049046, \"lr\": 0.000076282917, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.964228629176, \"lr\": 0.000076282917, \"top1_err\": 74.106666703288}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 88.800000000000, \"top1_err\": 88.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/30\", \"loss\": 1.572921693325, \"lr\": 0.000076282917, \"top1_err\": 59.472656250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/30\", \"loss\": 1.479506611824, \"lr\": 0.000076282917, \"top1_err\": 56.152343750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/30\", \"loss\": 1.408255994320, \"lr\": 0.000076282917, \"top1_err\": 53.515625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.482722062174, \"lr\": 0.000076282917, \"top1_err\": 56.266666670736}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 59.700002288818, \"top1_err\": 59.700002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/30\", \"loss\": 1.269680440426, \"lr\": 0.000076282917, \"top1_err\": 48.144531250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/30\", \"loss\": 1.222672045231, \"lr\": 0.000076282917, \"top1_err\": 45.800781250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/30\", \"loss\": 1.148320734501, \"lr\": 0.000076282917, \"top1_err\": 43.261718750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.216978139687, \"lr\": 0.000076282917, \"top1_err\": 45.613333347575}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 47.500000762939, \"top1_err\": 47.500000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/30\", \"loss\": 1.028172910213, \"lr\": 0.000076282917, \"top1_err\": 38.574218750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/30\", \"loss\": 0.986349701881, \"lr\": 0.000076282917, \"top1_err\": 36.425781250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/30\", \"loss\": 0.990663796663, \"lr\": 0.000076282917, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.996947733879, \"lr\": 0.000076282917, \"top1_err\": 36.540000026449}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 47.500000762939, \"top1_err\": 49.700000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/30\", \"loss\": 0.860914528370, \"lr\": 0.000076282917, \"top1_err\": 31.347656250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/30\", \"loss\": 0.840544670820, \"lr\": 0.000076282917, \"top1_err\": 30.371093750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/30\", \"loss\": 0.823468953371, \"lr\": 0.000076282917, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.838355950356, \"lr\": 0.000076282917, \"top1_err\": 30.506666652425}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 45.600001525879, \"top1_err\": 45.600001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_54.39999847412109_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_54.39999847412109_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:38:05,187]\u001b[0m Trial 2 finished with value: 54.39999847412109 and parameters: {'learning_rate': 7.62829165305698e-05, 'weight_decay': 1.3461824438960038e-08, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 2 with value: 54.39999847412109.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.0040957158921162366\n",
      "Weight Decay : 0.000675042274609726\n",
      "Batch Size   : 16\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0040957158921162366\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.000675042274609726\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:34000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 938\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/938\", \"loss\": 2.337843656540, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/938\", \"loss\": 2.292412877083, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/938\", \"loss\": 2.313265681267, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/938\", \"loss\": 2.307471394539, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/938\", \"loss\": 2.334377765656, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/938\", \"loss\": 2.235030651093, \"lr\": 0.004095715892, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/938\", \"loss\": 2.233793377876, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/938\", \"loss\": 2.141781330109, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/938\", \"loss\": 2.212393641472, \"lr\": 0.004095715892, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/938\", \"loss\": 2.101665019989, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/938\", \"loss\": 2.117553830147, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/938\", \"loss\": 2.059111237526, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/938\", \"loss\": 2.130600333214, \"lr\": 0.004095715892, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/938\", \"loss\": 1.959330320358, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/938\", \"loss\": 1.955807685852, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/938\", \"loss\": 2.007667779922, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/938\", \"loss\": 2.030765652657, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/938\", \"loss\": 2.004731893539, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/938\", \"loss\": 2.075651645660, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/938\", \"loss\": 1.945288538933, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/938\", \"loss\": 2.155783414841, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/938\", \"loss\": 2.001864135265, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/938\", \"loss\": 1.943877398968, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/938\", \"loss\": 2.009812533855, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/938\", \"loss\": 1.937645077705, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/938\", \"loss\": 1.970083415508, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/938\", \"loss\": 1.969124555588, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/938\", \"loss\": 2.036299347878, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/938\", \"loss\": 1.900178134441, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/938\", \"loss\": 1.872806370258, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/938\", \"loss\": 1.798401772976, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/938\", \"loss\": 2.110169172287, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/938\", \"loss\": 2.070589303970, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/938\", \"loss\": 1.994001090527, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/938\", \"loss\": 1.880480885506, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/938\", \"loss\": 1.970345318317, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/938\", \"loss\": 1.986521363258, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/938\", \"loss\": 1.992616355419, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/938\", \"loss\": 1.864587783813, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/938\", \"loss\": 1.888401508331, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/938\", \"loss\": 1.993940830231, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/938\", \"loss\": 1.963971495628, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/938\", \"loss\": 2.049120068550, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/938\", \"loss\": 1.946307480335, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/938\", \"loss\": 1.810138106346, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/938\", \"loss\": 1.940323591232, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/938\", \"loss\": 1.768483340740, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/938\", \"loss\": 1.998354673386, \"lr\": 0.004095715892, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/938\", \"loss\": 2.047688245773, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/938\", \"loss\": 1.923241972923, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/938\", \"loss\": 1.990793228149, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/938\", \"loss\": 2.001092672348, \"lr\": 0.004095715892, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/938\", \"loss\": 1.681434810162, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/938\", \"loss\": 1.851280570030, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/938\", \"loss\": 1.806801557541, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/938\", \"loss\": 1.834645032883, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/938\", \"loss\": 1.723841547966, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/938\", \"loss\": 1.893171429634, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/938\", \"loss\": 1.630941748619, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/938\", \"loss\": 2.032572865486, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/938\", \"loss\": 1.749016523361, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/938\", \"loss\": 1.761373698711, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/938\", \"loss\": 2.056922316551, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/938\", \"loss\": 1.801746129990, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/938\", \"loss\": 1.819124281406, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/938\", \"loss\": 1.674472689629, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/938\", \"loss\": 1.878343045712, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/938\", \"loss\": 1.803984045982, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/938\", \"loss\": 1.846415162086, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/938\", \"loss\": 1.670578002930, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/938\", \"loss\": 1.679385542870, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/938\", \"loss\": 1.848875999451, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/938\", \"loss\": 1.869112491608, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/938\", \"loss\": 1.654521703720, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/938\", \"loss\": 1.872522652149, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/938\", \"loss\": 1.881709218025, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/938\", \"loss\": 1.846953392029, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/938\", \"loss\": 1.717781960964, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/938\", \"loss\": 1.663409054279, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/938\", \"loss\": 1.861105084419, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/938\", \"loss\": 1.719505429268, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/938\", \"loss\": 1.828199923038, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/938\", \"loss\": 1.656625330448, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/938\", \"loss\": 1.747447788715, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/938\", \"loss\": 1.635682404041, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/938\", \"loss\": 1.644924581051, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/938\", \"loss\": 1.545490562916, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/938\", \"loss\": 1.843695282936, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/938\", \"loss\": 1.952181816101, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/938\", \"loss\": 1.621349751949, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/938\", \"loss\": 1.769202470779, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/938\", \"loss\": 1.730774581432, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/938\", \"loss\": 1.650323569775, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.945664376195, \"lr\": 0.004095715892, \"top1_err\": 73.506666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 64.100000000000, \"top1_err\": 64.100000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/938\", \"loss\": 1.623320519924, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/938\", \"loss\": 1.589129924774, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/938\", \"loss\": 1.685842394829, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/938\", \"loss\": 1.698382675648, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/938\", \"loss\": 1.756103575230, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/938\", \"loss\": 1.618035733700, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/938\", \"loss\": 1.751291573048, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/938\", \"loss\": 1.771103620529, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/938\", \"loss\": 1.884525954723, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/938\", \"loss\": 1.701245605946, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/938\", \"loss\": 1.499352633953, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/938\", \"loss\": 1.717574119568, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/938\", \"loss\": 1.738054215908, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/938\", \"loss\": 1.825359523296, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/938\", \"loss\": 1.731354355812, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/938\", \"loss\": 1.746252357960, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/938\", \"loss\": 1.641103684902, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/938\", \"loss\": 1.747523903847, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/938\", \"loss\": 1.850116372108, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/938\", \"loss\": 1.745065867901, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/938\", \"loss\": 1.632921516895, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/938\", \"loss\": 1.782759487629, \"lr\": 0.004095715892, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/938\", \"loss\": 1.621962130070, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/938\", \"loss\": 1.584478139877, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/938\", \"loss\": 1.883503437042, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/938\", \"loss\": 1.649535179138, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/938\", \"loss\": 1.794457852840, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/938\", \"loss\": 1.659643590450, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/938\", \"loss\": 1.549138665199, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/938\", \"loss\": 1.733786761761, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/938\", \"loss\": 1.586087703705, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/938\", \"loss\": 1.452463924885, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/938\", \"loss\": 1.651216030121, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/938\", \"loss\": 1.686675846577, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/938\", \"loss\": 1.588282167912, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/938\", \"loss\": 1.652613937855, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/938\", \"loss\": 1.552505791187, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/938\", \"loss\": 1.678029835224, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/938\", \"loss\": 1.645163357258, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/938\", \"loss\": 1.670124053955, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/938\", \"loss\": 1.502227365971, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/938\", \"loss\": 1.778224289417, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/938\", \"loss\": 1.733115136623, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/938\", \"loss\": 1.689953148365, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/938\", \"loss\": 1.646409928799, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/938\", \"loss\": 1.681285023689, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/938\", \"loss\": 1.652611792088, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/938\", \"loss\": 1.555994033813, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/938\", \"loss\": 1.602402985096, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/938\", \"loss\": 1.463154137135, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/938\", \"loss\": 1.787798047066, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/938\", \"loss\": 1.560051560402, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/938\", \"loss\": 1.410814225674, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/938\", \"loss\": 1.472820758820, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/938\", \"loss\": 1.491729855537, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/938\", \"loss\": 1.654872179031, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/938\", \"loss\": 1.582007646561, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/938\", \"loss\": 1.616138577461, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/938\", \"loss\": 1.460219562054, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/938\", \"loss\": 1.777461469173, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/938\", \"loss\": 1.628977060318, \"lr\": 0.004095715892, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/938\", \"loss\": 1.622561931610, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/938\", \"loss\": 1.472805321217, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/938\", \"loss\": 1.672611415386, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/938\", \"loss\": 1.515996038914, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/938\", \"loss\": 1.539025425911, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/938\", \"loss\": 1.497035324574, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/938\", \"loss\": 1.501431107521, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/938\", \"loss\": 1.496560811996, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/938\", \"loss\": 1.371451675892, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/938\", \"loss\": 1.316087782383, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/938\", \"loss\": 1.548529386520, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/938\", \"loss\": 1.549119234085, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/938\", \"loss\": 1.559385955334, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/938\", \"loss\": 1.524472177029, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/938\", \"loss\": 1.552364945412, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/938\", \"loss\": 1.514841020107, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/938\", \"loss\": 1.482357323170, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/938\", \"loss\": 1.476435124874, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/938\", \"loss\": 1.759074032307, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/938\", \"loss\": 1.553237974644, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/938\", \"loss\": 1.557194173336, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/938\", \"loss\": 1.599259018898, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/938\", \"loss\": 1.511435329914, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/938\", \"loss\": 1.771893262863, \"lr\": 0.004095715892, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/938\", \"loss\": 1.634782075882, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/938\", \"loss\": 1.485957443714, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/938\", \"loss\": 1.827200472355, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/938\", \"loss\": 1.706244945526, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/938\", \"loss\": 1.495263218880, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/938\", \"loss\": 1.483277201653, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/938\", \"loss\": 1.515395045280, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/938\", \"loss\": 1.639236867428, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.650186457443, \"lr\": 0.004095715892, \"top1_err\": 60.913333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 60.000002288818, \"top1_err\": 60.000002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/938\", \"loss\": 1.600163757801, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/938\", \"loss\": 1.618053674698, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/938\", \"loss\": 1.383301556110, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/938\", \"loss\": 1.598667025566, \"lr\": 0.004095715892, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/938\", \"loss\": 1.504507958889, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/938\", \"loss\": 1.310666084290, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/938\", \"loss\": 1.294302999973, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/938\", \"loss\": 1.485001683235, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/938\", \"loss\": 1.422851681709, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/938\", \"loss\": 1.524304211140, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/938\", \"loss\": 1.679298877716, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/938\", \"loss\": 1.427740275860, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/938\", \"loss\": 1.487242579460, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/938\", \"loss\": 1.396624326706, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/938\", \"loss\": 1.430059432983, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/938\", \"loss\": 1.555863857269, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/938\", \"loss\": 1.570527017117, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/938\", \"loss\": 1.416182696819, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/938\", \"loss\": 1.603839397430, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/938\", \"loss\": 1.406312644482, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/938\", \"loss\": 1.535251379013, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/938\", \"loss\": 1.431254923344, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/938\", \"loss\": 1.456735074520, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/938\", \"loss\": 1.625293433666, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/938\", \"loss\": 1.406885504723, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/938\", \"loss\": 1.523323535919, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/938\", \"loss\": 1.542683243752, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/938\", \"loss\": 1.453287184238, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/938\", \"loss\": 1.628498613834, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/938\", \"loss\": 1.359652817249, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/938\", \"loss\": 1.454053640366, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/938\", \"loss\": 1.471059322357, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/938\", \"loss\": 1.616935074329, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/938\", \"loss\": 1.527887880802, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/938\", \"loss\": 1.549724578857, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/938\", \"loss\": 1.344063043594, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/938\", \"loss\": 1.366686224937, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/938\", \"loss\": 1.422344624996, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/938\", \"loss\": 1.291461646557, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/938\", \"loss\": 1.550217330456, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/938\", \"loss\": 1.463514268398, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/938\", \"loss\": 1.365340292454, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/938\", \"loss\": 1.378918409348, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/938\", \"loss\": 1.473415434361, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/938\", \"loss\": 1.521521866322, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/938\", \"loss\": 1.630666136742, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/938\", \"loss\": 1.353076696396, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/938\", \"loss\": 1.279906272888, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/938\", \"loss\": 1.499930262566, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/938\", \"loss\": 1.521153748035, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/938\", \"loss\": 1.469924688339, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/938\", \"loss\": 1.308590054512, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/938\", \"loss\": 1.517534732819, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/938\", \"loss\": 1.435620009899, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/938\", \"loss\": 1.641957998276, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/938\", \"loss\": 1.328227221966, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/938\", \"loss\": 1.374939680099, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/938\", \"loss\": 1.258384704590, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/938\", \"loss\": 1.553588807583, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/938\", \"loss\": 1.354223489761, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/938\", \"loss\": 1.362110853195, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/938\", \"loss\": 1.587229788303, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/938\", \"loss\": 1.383151113987, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/938\", \"loss\": 1.360486268997, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/938\", \"loss\": 1.380124688148, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/938\", \"loss\": 1.459230124950, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/938\", \"loss\": 1.376144647598, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/938\", \"loss\": 1.295539617538, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/938\", \"loss\": 1.454674601555, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/938\", \"loss\": 1.388537228107, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/938\", \"loss\": 1.326536834240, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/938\", \"loss\": 1.563324749470, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/938\", \"loss\": 1.329565525055, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/938\", \"loss\": 1.516921639442, \"lr\": 0.004095715892, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/938\", \"loss\": 1.399840176105, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/938\", \"loss\": 1.558075308800, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/938\", \"loss\": 1.479342818260, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/938\", \"loss\": 1.328270852566, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/938\", \"loss\": 1.526939809322, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/938\", \"loss\": 1.425196528435, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/938\", \"loss\": 1.494142651558, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/938\", \"loss\": 1.259342610836, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/938\", \"loss\": 1.298972129822, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/938\", \"loss\": 1.275887966156, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/938\", \"loss\": 1.231029212475, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/938\", \"loss\": 1.300450980663, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/938\", \"loss\": 1.340133666992, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/938\", \"loss\": 1.287677645683, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/938\", \"loss\": 1.353911876678, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/938\", \"loss\": 1.235921621323, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/938\", \"loss\": 1.414129972458, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/938\", \"loss\": 1.537430524826, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/938\", \"loss\": 1.318005204201, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.463309178829, \"lr\": 0.004095715892, \"top1_err\": 54.093333333333}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 52.399999237061, \"top1_err\": 52.399999237061}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/938\", \"loss\": 1.396281063557, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/938\", \"loss\": 1.508627414703, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/938\", \"loss\": 1.233372211456, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/938\", \"loss\": 1.378087043762, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/938\", \"loss\": 1.372784733772, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/938\", \"loss\": 1.511013388634, \"lr\": 0.004095715892, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/938\", \"loss\": 1.574529826641, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/938\", \"loss\": 1.358132600784, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/938\", \"loss\": 1.172561943531, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/938\", \"loss\": 1.212349712849, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/938\", \"loss\": 1.277270972729, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/938\", \"loss\": 1.456841647625, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/938\", \"loss\": 1.333838880062, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/938\", \"loss\": 1.358665823936, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/938\", \"loss\": 1.244577586651, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/938\", \"loss\": 1.286500930786, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/938\", \"loss\": 1.456639051437, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/938\", \"loss\": 1.446933031082, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/938\", \"loss\": 1.407772481441, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/938\", \"loss\": 1.145025670528, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/938\", \"loss\": 1.181188285351, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/938\", \"loss\": 1.432859838009, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/938\", \"loss\": 1.186824738979, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/938\", \"loss\": 1.371390998363, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/938\", \"loss\": 1.218888163567, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/938\", \"loss\": 1.142913460732, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/938\", \"loss\": 1.224594712257, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/938\", \"loss\": 1.457985341549, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/938\", \"loss\": 1.210347354412, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/938\", \"loss\": 1.326723158360, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/938\", \"loss\": 1.189651250839, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/938\", \"loss\": 1.265961289406, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/938\", \"loss\": 1.317726075649, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/938\", \"loss\": 1.262761950493, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/938\", \"loss\": 1.314588785172, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/938\", \"loss\": 1.370642960072, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/938\", \"loss\": 1.439402341843, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/938\", \"loss\": 1.366061270237, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/938\", \"loss\": 1.359570503235, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/938\", \"loss\": 1.360099136829, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/938\", \"loss\": 1.260823726654, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/938\", \"loss\": 1.104748666286, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/938\", \"loss\": 1.192736506462, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/938\", \"loss\": 1.289241969585, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/938\", \"loss\": 1.321257352829, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/938\", \"loss\": 1.461162030697, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/938\", \"loss\": 1.315188705921, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/938\", \"loss\": 1.382747769356, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/938\", \"loss\": 1.426102101803, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/938\", \"loss\": 1.388901293278, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/938\", \"loss\": 1.312687933445, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/938\", \"loss\": 1.468043148518, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/938\", \"loss\": 1.302146017551, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/938\", \"loss\": 1.195905148983, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/938\", \"loss\": 1.349041044712, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/938\", \"loss\": 1.603133976460, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/938\", \"loss\": 1.486630260944, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/938\", \"loss\": 1.356031060219, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/938\", \"loss\": 1.184951543808, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/938\", \"loss\": 1.175483942032, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/938\", \"loss\": 1.063322126865, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/938\", \"loss\": 1.421806991100, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/938\", \"loss\": 1.160348713398, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/938\", \"loss\": 1.270226001740, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/938\", \"loss\": 1.158870220184, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/938\", \"loss\": 1.277567744255, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/938\", \"loss\": 1.275842726231, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/938\", \"loss\": 1.104483127594, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/938\", \"loss\": 1.159579932690, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/938\", \"loss\": 1.208390831947, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/938\", \"loss\": 1.394201457500, \"lr\": 0.004095715892, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/938\", \"loss\": 1.197127819061, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/938\", \"loss\": 1.385162353516, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/938\", \"loss\": 1.279656887054, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/938\", \"loss\": 1.017969906330, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/938\", \"loss\": 1.429938495159, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/938\", \"loss\": 1.316603958607, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/938\", \"loss\": 1.200801432133, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/938\", \"loss\": 1.149731814861, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/938\", \"loss\": 1.154480397701, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/938\", \"loss\": 1.097478985786, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/938\", \"loss\": 1.379324138165, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/938\", \"loss\": 1.244773268700, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/938\", \"loss\": 1.161691725254, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/938\", \"loss\": 1.226215779781, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/938\", \"loss\": 1.192142724991, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/938\", \"loss\": 1.186097443104, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/938\", \"loss\": 1.307225227356, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/938\", \"loss\": 1.080007374287, \"lr\": 0.004095715892, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/938\", \"loss\": 1.161221921444, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/938\", \"loss\": 1.197629034519, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/938\", \"loss\": 1.366423726082, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/938\", \"loss\": 1.270520865917, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.322766416868, \"lr\": 0.004095715892, \"top1_err\": 46.206666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 44.100000000000, \"top1_err\": 44.100000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/938\", \"loss\": 1.079105019569, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/938\", \"loss\": 1.156922101974, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/938\", \"loss\": 1.236232221127, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/938\", \"loss\": 1.171154975891, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/938\", \"loss\": 1.166548728943, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/938\", \"loss\": 1.225005626678, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/938\", \"loss\": 1.236007392406, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/938\", \"loss\": 1.228619396687, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/938\", \"loss\": 1.262745082378, \"lr\": 0.004095715892, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/938\", \"loss\": 1.171306967735, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/938\", \"loss\": 1.089720129967, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/938\", \"loss\": 1.091698944569, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/938\", \"loss\": 1.160037040710, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/938\", \"loss\": 1.035660326481, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/938\", \"loss\": 1.181004226208, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/938\", \"loss\": 1.181073009968, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/938\", \"loss\": 1.008116841316, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/938\", \"loss\": 1.079108655453, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/938\", \"loss\": 1.124986588955, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/938\", \"loss\": 1.215679347515, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/938\", \"loss\": 1.276521623135, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/938\", \"loss\": 1.222430884838, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/938\", \"loss\": 1.291240453720, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/938\", \"loss\": 1.206514060497, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/938\", \"loss\": 1.225692689419, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/938\", \"loss\": 0.948349237442, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/938\", \"loss\": 0.948374330997, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/938\", \"loss\": 1.112817466259, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/938\", \"loss\": 1.128336340189, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/938\", \"loss\": 1.053354203701, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/938\", \"loss\": 1.352621853352, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/938\", \"loss\": 1.394977450371, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/938\", \"loss\": 1.112620025873, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/938\", \"loss\": 1.020170122385, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/938\", \"loss\": 1.148410797119, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/938\", \"loss\": 1.320187926292, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/938\", \"loss\": 1.245937645435, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/938\", \"loss\": 1.307796895504, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/938\", \"loss\": 1.092759966850, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/938\", \"loss\": 1.181046843529, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/938\", \"loss\": 1.344304859638, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/938\", \"loss\": 1.296403765678, \"lr\": 0.004095715892, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/938\", \"loss\": 1.094542801380, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/938\", \"loss\": 1.004782348871, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/938\", \"loss\": 1.158237338066, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/938\", \"loss\": 1.257294595242, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/938\", \"loss\": 1.120902597904, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/938\", \"loss\": 1.314688742161, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/938\", \"loss\": 1.185497760773, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/938\", \"loss\": 1.070824027061, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/938\", \"loss\": 0.907982051373, \"lr\": 0.004095715892, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/938\", \"loss\": 1.035444200039, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/938\", \"loss\": 1.056331753731, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/938\", \"loss\": 1.096880853176, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/938\", \"loss\": 0.973118335009, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/938\", \"loss\": 0.811476111412, \"lr\": 0.004095715892, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/938\", \"loss\": 1.266258597374, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/938\", \"loss\": 1.105378091335, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/938\", \"loss\": 1.247481465340, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/938\", \"loss\": 1.064142227173, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/938\", \"loss\": 1.215369820595, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/938\", \"loss\": 0.997341662645, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/938\", \"loss\": 1.263437390327, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/938\", \"loss\": 1.087548792362, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/938\", \"loss\": 1.012267172337, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/938\", \"loss\": 1.193569123745, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/938\", \"loss\": 1.138684451580, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/938\", \"loss\": 1.293855071068, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/938\", \"loss\": 1.140361726284, \"lr\": 0.004095715892, \"top1_err\": 46.875000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/938\", \"loss\": 1.248289227486, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/938\", \"loss\": 1.039994657040, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/938\", \"loss\": 1.127647221088, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/938\", \"loss\": 1.074344873428, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/938\", \"loss\": 1.002018928528, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/938\", \"loss\": 0.833558589220, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/938\", \"loss\": 1.145253121853, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/938\", \"loss\": 1.157875478268, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/938\", \"loss\": 1.219544529915, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/938\", \"loss\": 1.155409276485, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/938\", \"loss\": 1.028024077415, \"lr\": 0.004095715892, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/938\", \"loss\": 1.196373105049, \"lr\": 0.004095715892, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/938\", \"loss\": 0.982958495617, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/938\", \"loss\": 1.269631206989, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/938\", \"loss\": 1.024470150471, \"lr\": 0.004095715892, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/938\", \"loss\": 1.147577106953, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/938\", \"loss\": 1.089613378048, \"lr\": 0.004095715892, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/938\", \"loss\": 0.970316082239, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/938\", \"loss\": 1.036557793617, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/938\", \"loss\": 1.037106156349, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/938\", \"loss\": 1.103604584932, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/938\", \"loss\": 1.135111391544, \"lr\": 0.004095715892, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/938\", \"loss\": 1.131495654583, \"lr\": 0.004095715892, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/938\", \"loss\": 1.011930078268, \"lr\": 0.004095715892, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.165513274161, \"lr\": 0.004095715892, \"top1_err\": 39.566666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 37.500001525879, \"top1_err\": 37.500001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 01:44:06,722]\u001b[0m Trial 3 finished with value: 62.49999847412109 and parameters: {'learning_rate': 0.0040957158921162366, 'weight_decay': 0.000675042274609726, 'batch_size': 16, 'optimizer': 'SGD'}. Best is trial 3 with value: 62.49999847412109.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.00018626781664764596\n",
      "Weight Decay : 4.527343524155812e-07\n",
      "Batch Size   : 8\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00018626781664764596\n",
      "    weight_decay: 4.527343524155812e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/20.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_48.00000152587891_model_epoch_0005.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Partitions Loaded =======\n",
      "lSet: 15000, uSet:34000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 1875\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/1875\", \"loss\": 2.771419763565, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/1875\", \"loss\": 2.956034898758, \"lr\": 0.000186267817, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/1875\", \"loss\": 2.326007723808, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/1875\", \"loss\": 2.452193021774, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/1875\", \"loss\": 2.429344892502, \"lr\": 0.000186267817, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/1875\", \"loss\": 2.287092447281, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/1875\", \"loss\": 2.213421583176, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/1875\", \"loss\": 2.492922306061, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/1875\", \"loss\": 2.288223505020, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/1875\", \"loss\": 2.334476113319, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/1875\", \"loss\": 2.280703425407, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/1875\", \"loss\": 2.277275085449, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/1875\", \"loss\": 2.197358131409, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/1875\", \"loss\": 2.113701105118, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/1875\", \"loss\": 2.142030119896, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/1875\", \"loss\": 2.151561617851, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/1875\", \"loss\": 2.145764350891, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/1875\", \"loss\": 2.142320394516, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/1875\", \"loss\": 2.038134336472, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/1875\", \"loss\": 1.993418276310, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/1875\", \"loss\": 2.254064679146, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/1875\", \"loss\": 2.189411997795, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/1875\", \"loss\": 2.082502484322, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/1875\", \"loss\": 2.111505866051, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/1875\", \"loss\": 2.077183127403, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/1875\", \"loss\": 1.978719353676, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/1875\", \"loss\": 1.995913147926, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/1875\", \"loss\": 2.068866372108, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/1875\", \"loss\": 2.014766454697, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/1875\", \"loss\": 2.011241495609, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/1875\", \"loss\": 1.993751823902, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/1875\", \"loss\": 1.936545610428, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/1875\", \"loss\": 2.066405534744, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/1875\", \"loss\": 2.079555511475, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/1875\", \"loss\": 2.079514622688, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/1875\", \"loss\": 2.028043925762, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/1875\", \"loss\": 2.037307858467, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/1875\", \"loss\": 2.099392652512, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/1875\", \"loss\": 1.933091700077, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/1875\", \"loss\": 2.072913527489, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/1875\", \"loss\": 2.230546951294, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/1875\", \"loss\": 1.978793025017, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/1875\", \"loss\": 1.938087522984, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/1875\", \"loss\": 2.030725359917, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/1875\", \"loss\": 2.024905920029, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/1875\", \"loss\": 1.983040153980, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/1875\", \"loss\": 2.029992341995, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/1875\", \"loss\": 2.015943408012, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/1875\", \"loss\": 1.910795450211, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/1875\", \"loss\": 1.994489550591, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/1875\", \"loss\": 2.015531301498, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/1875\", \"loss\": 2.129076123238, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/1875\", \"loss\": 2.130075335503, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/1875\", \"loss\": 1.975881397724, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/1875\", \"loss\": 2.112619400024, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/1875\", \"loss\": 1.917535424232, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/1875\", \"loss\": 1.931777238846, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/1875\", \"loss\": 2.058955311775, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/1875\", \"loss\": 2.043900012970, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/1875\", \"loss\": 2.032706975937, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/1875\", \"loss\": 2.013444542885, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/1875\", \"loss\": 1.783168256283, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/1875\", \"loss\": 2.089417338371, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/1875\", \"loss\": 2.041583895683, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/1875\", \"loss\": 1.979960203171, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/1875\", \"loss\": 1.885900139809, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/1875\", \"loss\": 1.951025605202, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/1875\", \"loss\": 2.080526351929, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/1875\", \"loss\": 2.075083851814, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/1875\", \"loss\": 2.006162881851, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/1875\", \"loss\": 1.973976075649, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/1875\", \"loss\": 1.949562489986, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/1875\", \"loss\": 1.876917779446, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/1875\", \"loss\": 1.974713921547, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/1875\", \"loss\": 2.097555518150, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/1875\", \"loss\": 2.008652210236, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/1875\", \"loss\": 1.863579928875, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/1875\", \"loss\": 2.010241210461, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/1875\", \"loss\": 2.052457213402, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/1875\", \"loss\": 2.036964774132, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/1875\", \"loss\": 2.115967750549, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/1875\", \"loss\": 2.008943617344, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/1875\", \"loss\": 1.918089687824, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/1875\", \"loss\": 1.912676215172, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/1875\", \"loss\": 2.087013006210, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/1875\", \"loss\": 2.071636080742, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/1875\", \"loss\": 2.032768845558, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/1875\", \"loss\": 1.947501420975, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/1875\", \"loss\": 1.972479820251, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/1875\", \"loss\": 2.024493455887, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/1875\", \"loss\": 2.006080210209, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/1875\", \"loss\": 1.940957844257, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/1875\", \"loss\": 1.960984408855, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"940/1875\", \"loss\": 1.984197735786, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"950/1875\", \"loss\": 1.952198266983, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"960/1875\", \"loss\": 1.910541772842, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"970/1875\", \"loss\": 2.084916591644, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"980/1875\", \"loss\": 2.135672926903, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"990/1875\", \"loss\": 1.993451833725, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1000/1875\", \"loss\": 1.906634151936, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1010/1875\", \"loss\": 1.971926987171, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1020/1875\", \"loss\": 1.987778067589, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1030/1875\", \"loss\": 1.998854756355, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1040/1875\", \"loss\": 1.918286085129, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1050/1875\", \"loss\": 1.963768839836, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1060/1875\", \"loss\": 1.940767943859, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1070/1875\", \"loss\": 1.982927560806, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1080/1875\", \"loss\": 1.870056331158, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1090/1875\", \"loss\": 1.923786342144, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1100/1875\", \"loss\": 1.870004594326, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1110/1875\", \"loss\": 1.841614067554, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1120/1875\", \"loss\": 1.915331125259, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1130/1875\", \"loss\": 2.039910554886, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1140/1875\", \"loss\": 1.915668964386, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1150/1875\", \"loss\": 2.062950611115, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1160/1875\", \"loss\": 2.026336312294, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1170/1875\", \"loss\": 1.948289692402, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1180/1875\", \"loss\": 1.921113014221, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1190/1875\", \"loss\": 2.055623531342, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1200/1875\", \"loss\": 2.042180299759, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1210/1875\", \"loss\": 1.940297365189, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1220/1875\", \"loss\": 1.916678607464, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1230/1875\", \"loss\": 1.965629875660, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1240/1875\", \"loss\": 1.887056291103, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1250/1875\", \"loss\": 1.925009965897, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1260/1875\", \"loss\": 2.111266493797, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1270/1875\", \"loss\": 1.990628182888, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1280/1875\", \"loss\": 1.981982469559, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1290/1875\", \"loss\": 1.860865414143, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1300/1875\", \"loss\": 1.947863638401, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1310/1875\", \"loss\": 1.843554854393, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1320/1875\", \"loss\": 1.796523928642, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1330/1875\", \"loss\": 2.167754888535, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1340/1875\", \"loss\": 1.997217714787, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1350/1875\", \"loss\": 1.959063529968, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1360/1875\", \"loss\": 1.868443489075, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1370/1875\", \"loss\": 1.992862820625, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1380/1875\", \"loss\": 2.016349673271, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1390/1875\", \"loss\": 1.914506375790, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1400/1875\", \"loss\": 1.942897319794, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1410/1875\", \"loss\": 1.846440792084, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1420/1875\", \"loss\": 2.001297056675, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1430/1875\", \"loss\": 2.022189617157, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1440/1875\", \"loss\": 1.880345344543, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1450/1875\", \"loss\": 1.956080436707, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1460/1875\", \"loss\": 1.875637054443, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1470/1875\", \"loss\": 1.879454016685, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1480/1875\", \"loss\": 1.842685163021, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1490/1875\", \"loss\": 1.957648634911, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1500/1875\", \"loss\": 1.894685745239, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1510/1875\", \"loss\": 2.131410121918, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1520/1875\", \"loss\": 2.018892884254, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1530/1875\", \"loss\": 2.010562837124, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1540/1875\", \"loss\": 1.914197206497, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1550/1875\", \"loss\": 2.015836000443, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1560/1875\", \"loss\": 1.830271124840, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1570/1875\", \"loss\": 1.878366351128, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1580/1875\", \"loss\": 1.936272978783, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1590/1875\", \"loss\": 1.893213152885, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1600/1875\", \"loss\": 1.988421142101, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1610/1875\", \"loss\": 1.901465177536, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1620/1875\", \"loss\": 1.798069536686, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1630/1875\", \"loss\": 1.919914305210, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1640/1875\", \"loss\": 1.808243989944, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1650/1875\", \"loss\": 1.885307073593, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1660/1875\", \"loss\": 1.949569761753, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1670/1875\", \"loss\": 2.008816719055, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1680/1875\", \"loss\": 1.836960732937, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1690/1875\", \"loss\": 1.899859964848, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1700/1875\", \"loss\": 1.980581283569, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1710/1875\", \"loss\": 1.894640147686, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1720/1875\", \"loss\": 1.809227466583, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1730/1875\", \"loss\": 1.918230533600, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1740/1875\", \"loss\": 1.837843418121, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1750/1875\", \"loss\": 1.953059434891, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1760/1875\", \"loss\": 2.079764485359, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1770/1875\", \"loss\": 2.018855094910, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1780/1875\", \"loss\": 1.943522155285, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1790/1875\", \"loss\": 1.884834587574, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1800/1875\", \"loss\": 1.809117674828, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1810/1875\", \"loss\": 1.968308269978, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1820/1875\", \"loss\": 1.944860577583, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1830/1875\", \"loss\": 1.976626336575, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1840/1875\", \"loss\": 1.823420882225, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1850/1875\", \"loss\": 1.920832693577, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1860/1875\", \"loss\": 1.978656172752, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1870/1875\", \"loss\": 2.018548846245, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.055320432790, \"lr\": 0.000186267817, \"top1_err\": 81.860000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 79.200000000000, \"top1_err\": 79.200000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/1875\", \"loss\": 1.982310414314, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/1875\", \"loss\": 2.049207091331, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/1875\", \"loss\": 1.916702687740, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/1875\", \"loss\": 2.021583378315, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/1875\", \"loss\": 1.924799025059, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/1875\", \"loss\": 1.877673089504, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/1875\", \"loss\": 1.852330982685, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/1875\", \"loss\": 1.917116343975, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/1875\", \"loss\": 2.277128815651, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/1875\", \"loss\": 1.951713502407, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/1875\", \"loss\": 1.949723958969, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/1875\", \"loss\": 2.040040612221, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/1875\", \"loss\": 2.035837173462, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/1875\", \"loss\": 2.006079971790, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/1875\", \"loss\": 1.918212652206, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/1875\", \"loss\": 2.032504558563, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/1875\", \"loss\": 1.932287156582, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/1875\", \"loss\": 1.876125693321, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/1875\", \"loss\": 1.887470245361, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/1875\", \"loss\": 1.819570243359, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/1875\", \"loss\": 1.779465794563, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/1875\", \"loss\": 1.932693421841, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/1875\", \"loss\": 1.992974281311, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/1875\", \"loss\": 1.969202339649, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/1875\", \"loss\": 1.872039973736, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/1875\", \"loss\": 2.025202393532, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/1875\", \"loss\": 1.887320101261, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/1875\", \"loss\": 1.876863896847, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/1875\", \"loss\": 1.866135597229, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/1875\", \"loss\": 2.021238327026, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/1875\", \"loss\": 1.902567982674, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/1875\", \"loss\": 1.945744693279, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/1875\", \"loss\": 1.858787953854, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/1875\", \"loss\": 1.893935024738, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/1875\", \"loss\": 1.898960232735, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/1875\", \"loss\": 1.819159269333, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/1875\", \"loss\": 2.030287742615, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/1875\", \"loss\": 1.962647378445, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/1875\", \"loss\": 1.868713021278, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/1875\", \"loss\": 1.898411631584, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/1875\", \"loss\": 1.882507383823, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/1875\", \"loss\": 1.892078697681, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/1875\", \"loss\": 1.987428009510, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/1875\", \"loss\": 1.824636816978, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/1875\", \"loss\": 1.890570580959, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/1875\", \"loss\": 1.869203627110, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/1875\", \"loss\": 1.944646477699, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/1875\", \"loss\": 1.883888244629, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/1875\", \"loss\": 1.828486204147, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/1875\", \"loss\": 1.940542936325, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/1875\", \"loss\": 1.879414021969, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/1875\", \"loss\": 2.047115921974, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/1875\", \"loss\": 1.956362247467, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/1875\", \"loss\": 1.947559654713, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/1875\", \"loss\": 1.932074129581, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/1875\", \"loss\": 1.908638298512, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/1875\", \"loss\": 1.842152059078, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/1875\", \"loss\": 1.784667611122, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/1875\", \"loss\": 1.927142441273, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/1875\", \"loss\": 1.967329084873, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/1875\", \"loss\": 1.970918178558, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/1875\", \"loss\": 1.814176321030, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/1875\", \"loss\": 1.710881650448, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/1875\", \"loss\": 1.805026710033, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/1875\", \"loss\": 1.890591442585, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/1875\", \"loss\": 1.802144885063, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/1875\", \"loss\": 1.788610816002, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/1875\", \"loss\": 1.956508219242, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/1875\", \"loss\": 1.790945827961, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/1875\", \"loss\": 1.851029396057, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/1875\", \"loss\": 2.023581743240, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/1875\", \"loss\": 1.853947937489, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/1875\", \"loss\": 1.828020095825, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/1875\", \"loss\": 1.830070078373, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/1875\", \"loss\": 1.920929431915, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/1875\", \"loss\": 1.915523529053, \"lr\": 0.000186267817, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/1875\", \"loss\": 1.830876171589, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/1875\", \"loss\": 1.936897099018, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/1875\", \"loss\": 1.765428602695, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/1875\", \"loss\": 1.822847545147, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/1875\", \"loss\": 1.858212947845, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/1875\", \"loss\": 1.994643747807, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/1875\", \"loss\": 1.932149231434, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/1875\", \"loss\": 1.848626315594, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/1875\", \"loss\": 1.846778094769, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/1875\", \"loss\": 2.007899403572, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/1875\", \"loss\": 1.859227180481, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/1875\", \"loss\": 1.999863862991, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/1875\", \"loss\": 1.907538175583, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/1875\", \"loss\": 1.852995514870, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/1875\", \"loss\": 1.787429690361, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/1875\", \"loss\": 2.195259094238, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/1875\", \"loss\": 1.816766262054, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"940/1875\", \"loss\": 1.865699529648, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"950/1875\", \"loss\": 1.882608473301, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"960/1875\", \"loss\": 1.902667224407, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"970/1875\", \"loss\": 2.014941692352, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"980/1875\", \"loss\": 1.895014762878, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"990/1875\", \"loss\": 1.912871897221, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1000/1875\", \"loss\": 1.884256720543, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1010/1875\", \"loss\": 1.909838616848, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1020/1875\", \"loss\": 1.880526006222, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1030/1875\", \"loss\": 1.902823388577, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1040/1875\", \"loss\": 1.934758663177, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1050/1875\", \"loss\": 1.841598331928, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1060/1875\", \"loss\": 1.719652593136, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1070/1875\", \"loss\": 1.947816371918, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1080/1875\", \"loss\": 1.832846522331, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1090/1875\", \"loss\": 2.040875792503, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1100/1875\", \"loss\": 1.834210216999, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1110/1875\", \"loss\": 1.835082054138, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1120/1875\", \"loss\": 1.918833434582, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1130/1875\", \"loss\": 1.907442569733, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1140/1875\", \"loss\": 1.861536502838, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1150/1875\", \"loss\": 1.835247159004, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1160/1875\", \"loss\": 1.883702516556, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1170/1875\", \"loss\": 1.881693124771, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1180/1875\", \"loss\": 1.846954107285, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1190/1875\", \"loss\": 1.888386905193, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1200/1875\", \"loss\": 2.108413100243, \"lr\": 0.000186267817, \"top1_err\": 100.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1210/1875\", \"loss\": 1.891593158245, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1220/1875\", \"loss\": 1.970988810062, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1230/1875\", \"loss\": 1.871738553047, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1240/1875\", \"loss\": 1.888885319233, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1250/1875\", \"loss\": 1.806047499180, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1260/1875\", \"loss\": 1.941625475883, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1270/1875\", \"loss\": 1.888699829578, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1280/1875\", \"loss\": 1.874331057072, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1290/1875\", \"loss\": 1.829775333405, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1300/1875\", \"loss\": 1.823098480701, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1310/1875\", \"loss\": 1.792520105839, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1320/1875\", \"loss\": 1.846497774124, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1330/1875\", \"loss\": 1.799020051956, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1340/1875\", \"loss\": 1.809059798717, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1350/1875\", \"loss\": 1.771076500416, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1360/1875\", \"loss\": 1.775578379631, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1370/1875\", \"loss\": 1.868621885777, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1380/1875\", \"loss\": 1.800757706165, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1390/1875\", \"loss\": 1.840184092522, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1400/1875\", \"loss\": 1.914408385754, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1410/1875\", \"loss\": 1.697062373161, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1420/1875\", \"loss\": 1.639447748661, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1430/1875\", \"loss\": 1.717111647129, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1440/1875\", \"loss\": 2.023210287094, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1450/1875\", \"loss\": 1.832078635693, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1460/1875\", \"loss\": 2.087364792824, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1470/1875\", \"loss\": 1.988012433052, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1480/1875\", \"loss\": 1.889646470547, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1490/1875\", \"loss\": 1.914837241173, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1500/1875\", \"loss\": 1.955130815506, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1510/1875\", \"loss\": 1.938881099224, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1520/1875\", \"loss\": 1.955204367638, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1530/1875\", \"loss\": 1.795587360859, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1540/1875\", \"loss\": 1.919468939304, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1550/1875\", \"loss\": 1.908061385155, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1560/1875\", \"loss\": 1.898583769798, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1570/1875\", \"loss\": 1.854991257191, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1580/1875\", \"loss\": 1.842431187630, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1590/1875\", \"loss\": 1.886738955975, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1600/1875\", \"loss\": 1.771335482597, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1610/1875\", \"loss\": 1.839119195938, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1620/1875\", \"loss\": 1.839223027229, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1630/1875\", \"loss\": 1.744537830353, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1640/1875\", \"loss\": 1.746847569942, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1650/1875\", \"loss\": 1.911218404770, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1660/1875\", \"loss\": 1.982108771801, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1670/1875\", \"loss\": 1.896633863449, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1680/1875\", \"loss\": 1.880325019360, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1690/1875\", \"loss\": 1.893028974533, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1700/1875\", \"loss\": 1.875699520111, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1710/1875\", \"loss\": 1.923453271389, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1720/1875\", \"loss\": 1.796838819981, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1730/1875\", \"loss\": 1.798764824867, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1740/1875\", \"loss\": 1.671418488026, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1750/1875\", \"loss\": 2.049224734306, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1760/1875\", \"loss\": 1.965185701847, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1770/1875\", \"loss\": 1.716393828392, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1780/1875\", \"loss\": 1.861958503723, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1790/1875\", \"loss\": 1.853702425957, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1800/1875\", \"loss\": 1.850348412991, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1810/1875\", \"loss\": 1.753692388535, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1820/1875\", \"loss\": 1.784180581570, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1830/1875\", \"loss\": 1.742346584797, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1840/1875\", \"loss\": 1.837359845638, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1850/1875\", \"loss\": 1.708427965641, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1860/1875\", \"loss\": 1.817669034004, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1870/1875\", \"loss\": 1.987691044807, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.928891217041, \"lr\": 0.000186267817, \"top1_err\": 79.406666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 75.800001525879, \"top1_err\": 75.800001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/1875\", \"loss\": 1.873337566853, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/1875\", \"loss\": 1.649800717831, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/1875\", \"loss\": 1.717505156994, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/1875\", \"loss\": 1.731885910034, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/1875\", \"loss\": 1.742659568787, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/1875\", \"loss\": 1.677649140358, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/1875\", \"loss\": 1.777308225632, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/1875\", \"loss\": 1.640593528748, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/1875\", \"loss\": 2.073637485504, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/1875\", \"loss\": 1.882876157761, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/1875\", \"loss\": 1.703462839127, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/1875\", \"loss\": 1.866557300091, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/1875\", \"loss\": 1.833515048027, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/1875\", \"loss\": 1.673896133900, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/1875\", \"loss\": 1.814504861832, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/1875\", \"loss\": 1.692352652550, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/1875\", \"loss\": 1.784638285637, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/1875\", \"loss\": 1.740683197975, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/1875\", \"loss\": 1.833950281143, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/1875\", \"loss\": 1.880659520626, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/1875\", \"loss\": 1.937744975090, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/1875\", \"loss\": 1.878678143024, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/1875\", \"loss\": 1.806329190731, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/1875\", \"loss\": 1.689963698387, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/1875\", \"loss\": 1.762830317020, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/1875\", \"loss\": 1.782346010208, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/1875\", \"loss\": 1.743661284447, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/1875\", \"loss\": 1.741838216782, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/1875\", \"loss\": 1.707078099251, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/1875\", \"loss\": 1.798931598663, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/1875\", \"loss\": 1.789924979210, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/1875\", \"loss\": 1.636253654957, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/1875\", \"loss\": 1.937140226364, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/1875\", \"loss\": 1.804768204689, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/1875\", \"loss\": 1.615381479263, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/1875\", \"loss\": 1.652827084064, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/1875\", \"loss\": 1.812614202499, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/1875\", \"loss\": 1.717430472374, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/1875\", \"loss\": 1.912908911705, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/1875\", \"loss\": 1.707920849323, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/1875\", \"loss\": 1.647448956966, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/1875\", \"loss\": 1.737156987190, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/1875\", \"loss\": 1.826637923717, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/1875\", \"loss\": 1.678762674332, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/1875\", \"loss\": 1.915892183781, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/1875\", \"loss\": 1.833765149117, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/1875\", \"loss\": 1.718043565750, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/1875\", \"loss\": 1.671398222446, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/1875\", \"loss\": 1.842736124992, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/1875\", \"loss\": 1.605423212051, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/1875\", \"loss\": 1.678869009018, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/1875\", \"loss\": 1.698022484779, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/1875\", \"loss\": 1.876853287220, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/1875\", \"loss\": 1.732900857925, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/1875\", \"loss\": 1.953256547451, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/1875\", \"loss\": 1.684636473656, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/1875\", \"loss\": 1.690967857838, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/1875\", \"loss\": 1.765924930573, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/1875\", \"loss\": 1.756234645844, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/1875\", \"loss\": 1.548458755016, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/1875\", \"loss\": 1.697449028492, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/1875\", \"loss\": 1.754423141479, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/1875\", \"loss\": 1.940740346909, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/1875\", \"loss\": 1.741977155209, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/1875\", \"loss\": 1.693888485432, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/1875\", \"loss\": 1.681317389011, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/1875\", \"loss\": 1.689025640488, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/1875\", \"loss\": 1.736991524696, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/1875\", \"loss\": 1.715512096882, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/1875\", \"loss\": 1.780253350735, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/1875\", \"loss\": 1.769555747509, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/1875\", \"loss\": 1.818746328354, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/1875\", \"loss\": 1.616939008236, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/1875\", \"loss\": 1.588462293148, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/1875\", \"loss\": 1.593896567822, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/1875\", \"loss\": 1.741819024086, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/1875\", \"loss\": 1.736693441868, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/1875\", \"loss\": 1.604797840118, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/1875\", \"loss\": 1.763334453106, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/1875\", \"loss\": 1.593307971954, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/1875\", \"loss\": 1.855453133583, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/1875\", \"loss\": 1.642379224300, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/1875\", \"loss\": 1.662012100220, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/1875\", \"loss\": 1.697879850864, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/1875\", \"loss\": 1.707862615585, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/1875\", \"loss\": 1.903459966183, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/1875\", \"loss\": 1.895522356033, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/1875\", \"loss\": 1.737311124802, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/1875\", \"loss\": 1.620773673058, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/1875\", \"loss\": 1.679428458214, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/1875\", \"loss\": 1.808460474014, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/1875\", \"loss\": 1.864758551121, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/1875\", \"loss\": 1.590135991573, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"940/1875\", \"loss\": 1.664836168289, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"950/1875\", \"loss\": 1.624659538269, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"960/1875\", \"loss\": 1.640176832676, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"970/1875\", \"loss\": 1.632526814938, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"980/1875\", \"loss\": 1.712765455246, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"990/1875\", \"loss\": 1.631962835789, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1000/1875\", \"loss\": 1.641080260277, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1010/1875\", \"loss\": 1.727941513062, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1020/1875\", \"loss\": 1.897520780563, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1030/1875\", \"loss\": 1.715726912022, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1040/1875\", \"loss\": 1.643354952335, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1050/1875\", \"loss\": 1.678434431553, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1060/1875\", \"loss\": 1.973359227180, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1070/1875\", \"loss\": 1.555954575539, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1080/1875\", \"loss\": 1.726378917694, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1090/1875\", \"loss\": 1.944649636745, \"lr\": 0.000186267817, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1100/1875\", \"loss\": 1.718561649323, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1110/1875\", \"loss\": 1.809382736683, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1120/1875\", \"loss\": 1.708134353161, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1130/1875\", \"loss\": 1.795098781586, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1140/1875\", \"loss\": 1.726703882217, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1150/1875\", \"loss\": 1.560014367104, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1160/1875\", \"loss\": 1.707206904888, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1170/1875\", \"loss\": 1.682904720306, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1180/1875\", \"loss\": 1.670915961266, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1190/1875\", \"loss\": 1.615078628063, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1200/1875\", \"loss\": 1.686440765858, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1210/1875\", \"loss\": 1.745194196701, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1220/1875\", \"loss\": 1.774289190769, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1230/1875\", \"loss\": 1.706905245781, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1240/1875\", \"loss\": 1.781296193600, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1250/1875\", \"loss\": 1.691102981567, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1260/1875\", \"loss\": 1.813106775284, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1270/1875\", \"loss\": 1.660088956356, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1280/1875\", \"loss\": 1.629902124405, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1290/1875\", \"loss\": 1.726020753384, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1300/1875\", \"loss\": 1.692368209362, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1310/1875\", \"loss\": 1.812479496002, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1320/1875\", \"loss\": 1.833566069603, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1330/1875\", \"loss\": 1.725480437279, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1340/1875\", \"loss\": 1.706526279449, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1350/1875\", \"loss\": 1.596574962139, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1360/1875\", \"loss\": 1.772949576378, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1370/1875\", \"loss\": 1.758452117443, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1380/1875\", \"loss\": 1.820946514606, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1390/1875\", \"loss\": 1.815808713436, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1400/1875\", \"loss\": 1.667682886124, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1410/1875\", \"loss\": 1.662434697151, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1420/1875\", \"loss\": 1.812001705170, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1430/1875\", \"loss\": 1.868671596050, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1440/1875\", \"loss\": 1.622124969959, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1450/1875\", \"loss\": 1.742750465870, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1460/1875\", \"loss\": 1.489733099937, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1470/1875\", \"loss\": 1.550439834595, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1480/1875\", \"loss\": 1.761255800724, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1490/1875\", \"loss\": 1.668252468109, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1500/1875\", \"loss\": 1.628638803959, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1510/1875\", \"loss\": 1.525631308556, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1520/1875\", \"loss\": 1.693507671356, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1530/1875\", \"loss\": 1.821644663811, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1540/1875\", \"loss\": 1.879961669445, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1550/1875\", \"loss\": 1.669700324535, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1560/1875\", \"loss\": 1.728298783302, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1570/1875\", \"loss\": 1.687210738659, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1580/1875\", \"loss\": 1.752955138683, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1590/1875\", \"loss\": 1.433393836021, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1600/1875\", \"loss\": 1.634823322296, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1610/1875\", \"loss\": 1.885111451149, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1620/1875\", \"loss\": 1.558117687702, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1630/1875\", \"loss\": 1.596663415432, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1640/1875\", \"loss\": 1.644301295280, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1650/1875\", \"loss\": 1.730957567692, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1660/1875\", \"loss\": 1.585768163204, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1670/1875\", \"loss\": 1.676395177841, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1680/1875\", \"loss\": 1.669668674469, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1690/1875\", \"loss\": 1.651075243950, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1700/1875\", \"loss\": 1.596873164177, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1710/1875\", \"loss\": 1.598232328892, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1720/1875\", \"loss\": 1.695528864861, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1730/1875\", \"loss\": 1.669314682484, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1740/1875\", \"loss\": 1.676040351391, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1750/1875\", \"loss\": 1.561578929424, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1760/1875\", \"loss\": 1.714888691902, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1770/1875\", \"loss\": 1.713359713554, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1780/1875\", \"loss\": 1.596406042576, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1790/1875\", \"loss\": 1.596813678741, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1800/1875\", \"loss\": 1.639652848244, \"lr\": 0.000186267817, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1810/1875\", \"loss\": 1.755512356758, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1820/1875\", \"loss\": 1.630732119083, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1830/1875\", \"loss\": 1.619292199612, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1840/1875\", \"loss\": 1.711854875088, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1850/1875\", \"loss\": 1.853490829468, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1860/1875\", \"loss\": 1.542160391808, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1870/1875\", \"loss\": 1.668210089207, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.756402692032, \"lr\": 0.000186267817, \"top1_err\": 71.280000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 67.000000000000, \"top1_err\": 67.000000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/1875\", \"loss\": 1.646641016006, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/1875\", \"loss\": 1.771031320095, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/1875\", \"loss\": 1.723800241947, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/1875\", \"loss\": 1.716377913952, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/1875\", \"loss\": 1.479662835598, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/1875\", \"loss\": 1.719513416290, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/1875\", \"loss\": 1.660368621349, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/1875\", \"loss\": 1.582441926003, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/1875\", \"loss\": 1.586388528347, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/1875\", \"loss\": 1.578775107861, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/1875\", \"loss\": 1.657516419888, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/1875\", \"loss\": 1.466049790382, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/1875\", \"loss\": 1.627148091793, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/1875\", \"loss\": 1.752129435539, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/1875\", \"loss\": 1.495403468609, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/1875\", \"loss\": 1.712734639645, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/1875\", \"loss\": 1.732655704021, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/1875\", \"loss\": 1.538777828217, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/1875\", \"loss\": 1.657262623310, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/1875\", \"loss\": 1.570831477642, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/1875\", \"loss\": 1.577565133572, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/1875\", \"loss\": 1.739493787289, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/1875\", \"loss\": 1.566007733345, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/1875\", \"loss\": 1.721933007240, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/1875\", \"loss\": 1.691226482391, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/1875\", \"loss\": 1.581354260445, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/1875\", \"loss\": 1.489853680134, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/1875\", \"loss\": 1.762285351753, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/1875\", \"loss\": 1.502433240414, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/1875\", \"loss\": 1.809228420258, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/1875\", \"loss\": 1.479163050652, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/1875\", \"loss\": 1.423481345177, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/1875\", \"loss\": 1.756557703018, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/1875\", \"loss\": 1.603734552860, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/1875\", \"loss\": 1.727970302105, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/1875\", \"loss\": 1.519877910614, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/1875\", \"loss\": 1.507818341255, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/1875\", \"loss\": 1.717595994473, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/1875\", \"loss\": 1.491491734982, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/1875\", \"loss\": 1.467121839523, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/1875\", \"loss\": 1.463848412037, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/1875\", \"loss\": 1.587722599506, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/1875\", \"loss\": 2.106407046318, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/1875\", \"loss\": 1.653678417206, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/1875\", \"loss\": 1.541762471199, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/1875\", \"loss\": 1.513297438622, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/1875\", \"loss\": 1.456296622753, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/1875\", \"loss\": 1.628834843636, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/1875\", \"loss\": 1.593239128590, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/1875\", \"loss\": 1.696545779705, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/1875\", \"loss\": 1.726819097996, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/1875\", \"loss\": 1.517979621887, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/1875\", \"loss\": 1.617680132389, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/1875\", \"loss\": 1.582126080990, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/1875\", \"loss\": 1.477096915245, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/1875\", \"loss\": 1.586725354195, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/1875\", \"loss\": 1.589677572250, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/1875\", \"loss\": 1.519694447517, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/1875\", \"loss\": 1.772769391537, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/1875\", \"loss\": 1.636884689331, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/1875\", \"loss\": 1.565878927708, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/1875\", \"loss\": 1.620847225189, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/1875\", \"loss\": 1.549882173538, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/1875\", \"loss\": 1.362265229225, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/1875\", \"loss\": 1.467482447624, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/1875\", \"loss\": 1.692360937595, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/1875\", \"loss\": 1.773114621639, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/1875\", \"loss\": 1.532113015652, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/1875\", \"loss\": 1.621591687202, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/1875\", \"loss\": 1.533764421940, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/1875\", \"loss\": 1.584331393242, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/1875\", \"loss\": 1.634293794632, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/1875\", \"loss\": 1.950022339821, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/1875\", \"loss\": 1.569169938564, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/1875\", \"loss\": 1.733252108097, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/1875\", \"loss\": 1.630890488625, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/1875\", \"loss\": 1.520168662071, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/1875\", \"loss\": 1.725010871887, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/1875\", \"loss\": 1.728817105293, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/1875\", \"loss\": 1.571851193905, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/1875\", \"loss\": 1.481297612190, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/1875\", \"loss\": 1.503757596016, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/1875\", \"loss\": 1.632199108601, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/1875\", \"loss\": 1.578075110912, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/1875\", \"loss\": 1.552827060223, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/1875\", \"loss\": 1.588032722473, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/1875\", \"loss\": 1.662912368774, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/1875\", \"loss\": 1.532510459423, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/1875\", \"loss\": 1.569594025612, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/1875\", \"loss\": 1.623253524303, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/1875\", \"loss\": 1.661689996719, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/1875\", \"loss\": 1.442457616329, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/1875\", \"loss\": 1.371022105217, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"940/1875\", \"loss\": 1.613283634186, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"950/1875\", \"loss\": 1.553742706776, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"960/1875\", \"loss\": 1.693201780319, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"970/1875\", \"loss\": 1.777806222439, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"980/1875\", \"loss\": 1.444070041180, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"990/1875\", \"loss\": 1.558855235577, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1000/1875\", \"loss\": 1.632239401340, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1010/1875\", \"loss\": 1.677256941795, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1020/1875\", \"loss\": 1.517472743988, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1030/1875\", \"loss\": 1.583949744701, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1040/1875\", \"loss\": 1.560948610306, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1050/1875\", \"loss\": 1.552755832672, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1060/1875\", \"loss\": 1.421851336956, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1070/1875\", \"loss\": 1.501715719700, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1080/1875\", \"loss\": 1.429803133011, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1090/1875\", \"loss\": 1.682108044624, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1100/1875\", \"loss\": 1.575794577599, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1110/1875\", \"loss\": 1.581332802773, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1120/1875\", \"loss\": 1.715619564056, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1130/1875\", \"loss\": 1.638130784035, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1140/1875\", \"loss\": 1.469790756702, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1150/1875\", \"loss\": 1.663562357426, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1160/1875\", \"loss\": 1.436438739300, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1170/1875\", \"loss\": 1.639443218708, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1180/1875\", \"loss\": 1.533133625984, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1190/1875\", \"loss\": 1.536085128784, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1200/1875\", \"loss\": 1.650007128716, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1210/1875\", \"loss\": 1.379586994648, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1220/1875\", \"loss\": 1.791482269764, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1230/1875\", \"loss\": 1.762207210064, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1240/1875\", \"loss\": 1.453483760357, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1250/1875\", \"loss\": 1.755129098892, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1260/1875\", \"loss\": 1.441217541695, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1270/1875\", \"loss\": 1.735864698887, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1280/1875\", \"loss\": 1.543869554996, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1290/1875\", \"loss\": 1.584288120270, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1300/1875\", \"loss\": 1.612900018692, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1310/1875\", \"loss\": 1.538239181042, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1320/1875\", \"loss\": 1.429818749428, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1330/1875\", \"loss\": 1.593149125576, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1340/1875\", \"loss\": 1.598900437355, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1350/1875\", \"loss\": 1.499366581440, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1360/1875\", \"loss\": 1.411141216755, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1370/1875\", \"loss\": 1.605558335781, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1380/1875\", \"loss\": 1.526521027088, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1390/1875\", \"loss\": 1.525900363922, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1400/1875\", \"loss\": 1.676528871059, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1410/1875\", \"loss\": 1.835986912251, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1420/1875\", \"loss\": 1.722827255726, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1430/1875\", \"loss\": 1.601595997810, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1440/1875\", \"loss\": 1.548125624657, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1450/1875\", \"loss\": 1.552376210690, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1460/1875\", \"loss\": 1.609685182571, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1470/1875\", \"loss\": 1.547118067741, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1480/1875\", \"loss\": 1.389628291130, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1490/1875\", \"loss\": 1.404177784920, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1500/1875\", \"loss\": 1.305139124393, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1510/1875\", \"loss\": 1.483538866043, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1520/1875\", \"loss\": 1.357533276081, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1530/1875\", \"loss\": 1.491412878036, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1540/1875\", \"loss\": 1.569687187672, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1550/1875\", \"loss\": 1.692733943462, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1560/1875\", \"loss\": 1.649012684822, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1570/1875\", \"loss\": 1.362774550915, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1580/1875\", \"loss\": 1.516837179661, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1590/1875\", \"loss\": 1.536423683167, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1600/1875\", \"loss\": 1.388136982918, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1610/1875\", \"loss\": 1.619869172573, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1620/1875\", \"loss\": 1.589114129543, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1630/1875\", \"loss\": 1.630956232548, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1640/1875\", \"loss\": 1.638771057129, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1650/1875\", \"loss\": 1.509294390678, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1660/1875\", \"loss\": 1.604784309864, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1670/1875\", \"loss\": 1.565941929817, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1680/1875\", \"loss\": 1.368191599846, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1690/1875\", \"loss\": 1.569055855274, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1700/1875\", \"loss\": 1.500226020813, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1710/1875\", \"loss\": 1.628570377827, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1720/1875\", \"loss\": 1.298442661762, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1730/1875\", \"loss\": 1.659649550915, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1740/1875\", \"loss\": 1.486915349960, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1750/1875\", \"loss\": 1.348847568035, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1760/1875\", \"loss\": 1.747387051582, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1770/1875\", \"loss\": 1.825285434723, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1780/1875\", \"loss\": 1.317419350147, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1790/1875\", \"loss\": 1.504934251308, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1800/1875\", \"loss\": 1.647731065750, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1810/1875\", \"loss\": 1.529520630836, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1820/1875\", \"loss\": 1.655353307724, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1830/1875\", \"loss\": 1.457450389862, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1840/1875\", \"loss\": 1.517298221588, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1850/1875\", \"loss\": 1.406342327595, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1860/1875\", \"loss\": 1.625952839851, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1870/1875\", \"loss\": 1.597526431084, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.617044503721, \"lr\": 0.000186267817, \"top1_err\": 64.166666666667}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 57.500003051758, \"top1_err\": 57.500003051758}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/1875\", \"loss\": 1.647278368473, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/1875\", \"loss\": 1.488805890083, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/1875\", \"loss\": 1.391051888466, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/1875\", \"loss\": 1.614679694176, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/1875\", \"loss\": 1.391043186188, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/1875\", \"loss\": 1.666875243187, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/1875\", \"loss\": 1.464955151081, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/1875\", \"loss\": 1.418257176876, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/1875\", \"loss\": 1.320937037468, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/1875\", \"loss\": 1.364229738712, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/1875\", \"loss\": 1.543375551701, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/1875\", \"loss\": 1.631226360798, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/1875\", \"loss\": 1.509347915649, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/1875\", \"loss\": 1.518927514553, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/1875\", \"loss\": 1.635188817978, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/1875\", \"loss\": 1.489795804024, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/1875\", \"loss\": 1.448754251003, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/1875\", \"loss\": 1.289245784283, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/1875\", \"loss\": 1.493583977222, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/1875\", \"loss\": 1.605017781258, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/1875\", \"loss\": 1.570409893990, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/1875\", \"loss\": 1.526786029339, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/1875\", \"loss\": 1.396289825439, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/1875\", \"loss\": 1.422130703926, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/1875\", \"loss\": 1.730753302574, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/1875\", \"loss\": 1.575702250004, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/1875\", \"loss\": 1.569246649742, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/1875\", \"loss\": 1.696832716465, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/1875\", \"loss\": 1.603865802288, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/1875\", \"loss\": 1.285634458065, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/1875\", \"loss\": 1.519143342972, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/1875\", \"loss\": 1.577581048012, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/1875\", \"loss\": 1.313886582851, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/1875\", \"loss\": 1.515289545059, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/1875\", \"loss\": 1.431462883949, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/1875\", \"loss\": 1.362805485725, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/1875\", \"loss\": 1.493793010712, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/1875\", \"loss\": 1.622666180134, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/1875\", \"loss\": 1.432192862034, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/1875\", \"loss\": 1.438563406467, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/1875\", \"loss\": 1.513883709908, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/1875\", \"loss\": 1.483886063099, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/1875\", \"loss\": 1.418273568153, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/1875\", \"loss\": 1.576014757156, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/1875\", \"loss\": 1.613972783089, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/1875\", \"loss\": 1.585963845253, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/1875\", \"loss\": 1.586933493614, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/1875\", \"loss\": 1.573548257351, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/1875\", \"loss\": 1.541972279549, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/1875\", \"loss\": 1.376844227314, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/1875\", \"loss\": 1.303811550140, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/1875\", \"loss\": 1.554412662983, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/1875\", \"loss\": 1.472452819347, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/1875\", \"loss\": 1.470651745796, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/1875\", \"loss\": 1.574331045151, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/1875\", \"loss\": 1.382467389107, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/1875\", \"loss\": 1.407320439816, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/1875\", \"loss\": 1.334006011486, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/1875\", \"loss\": 1.506362855434, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/1875\", \"loss\": 1.588760435581, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/1875\", \"loss\": 1.553116679192, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/1875\", \"loss\": 1.502262234688, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/1875\", \"loss\": 1.383555591106, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/1875\", \"loss\": 1.397117495537, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/1875\", \"loss\": 1.422539710999, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/1875\", \"loss\": 1.385426104069, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/1875\", \"loss\": 1.289486587048, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/1875\", \"loss\": 1.782519042492, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/1875\", \"loss\": 1.487509489059, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/1875\", \"loss\": 1.330051302910, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/1875\", \"loss\": 1.496422052383, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/1875\", \"loss\": 1.400830268860, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/1875\", \"loss\": 1.464785039425, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/1875\", \"loss\": 1.338016808033, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/1875\", \"loss\": 1.436333179474, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/1875\", \"loss\": 1.273529946804, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/1875\", \"loss\": 1.552176773548, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/1875\", \"loss\": 1.495416820049, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/1875\", \"loss\": 1.495853364468, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/1875\", \"loss\": 1.609571278095, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/1875\", \"loss\": 1.478795409203, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/1875\", \"loss\": 1.593646347523, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/1875\", \"loss\": 1.567931413651, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/1875\", \"loss\": 1.449367165565, \"lr\": 0.000186267817, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/1875\", \"loss\": 1.384729802608, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/1875\", \"loss\": 1.361850857735, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/1875\", \"loss\": 1.584880590439, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/1875\", \"loss\": 1.390258610249, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/1875\", \"loss\": 1.360578417778, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/1875\", \"loss\": 1.526658535004, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/1875\", \"loss\": 1.593573451042, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/1875\", \"loss\": 1.530081331730, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/1875\", \"loss\": 1.625746190548, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"940/1875\", \"loss\": 1.685467600822, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"950/1875\", \"loss\": 1.424007356167, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"960/1875\", \"loss\": 1.560406327248, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"970/1875\", \"loss\": 1.514530360699, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"980/1875\", \"loss\": 1.417616069317, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"990/1875\", \"loss\": 1.429476976395, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1000/1875\", \"loss\": 1.236741602421, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1010/1875\", \"loss\": 1.132126629353, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1020/1875\", \"loss\": 1.449976980686, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1030/1875\", \"loss\": 1.557658314705, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1040/1875\", \"loss\": 1.486205756664, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1050/1875\", \"loss\": 1.525235056877, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1060/1875\", \"loss\": 1.282835841179, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1070/1875\", \"loss\": 1.209052503109, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1080/1875\", \"loss\": 1.402734100819, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1090/1875\", \"loss\": 1.446660339832, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1100/1875\", \"loss\": 1.530844032764, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1110/1875\", \"loss\": 1.601412355900, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1120/1875\", \"loss\": 1.258073210716, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1130/1875\", \"loss\": 1.326132476330, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1140/1875\", \"loss\": 1.346355915070, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1150/1875\", \"loss\": 1.602117538452, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1160/1875\", \"loss\": 1.426353693008, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1170/1875\", \"loss\": 1.666134774685, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1180/1875\", \"loss\": 1.412817239761, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1190/1875\", \"loss\": 1.656537115574, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1200/1875\", \"loss\": 1.371817529202, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1210/1875\", \"loss\": 1.466399192810, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1220/1875\", \"loss\": 1.413684368134, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1230/1875\", \"loss\": 1.315617620945, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1240/1875\", \"loss\": 1.260587632656, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1250/1875\", \"loss\": 1.445626974106, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1260/1875\", \"loss\": 1.346784174442, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1270/1875\", \"loss\": 1.728766500950, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1280/1875\", \"loss\": 1.512813627720, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1290/1875\", \"loss\": 1.496590793133, \"lr\": 0.000186267817, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1300/1875\", \"loss\": 1.475599229336, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1310/1875\", \"loss\": 1.310531020164, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1320/1875\", \"loss\": 1.435889780521, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1330/1875\", \"loss\": 1.327598690987, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1340/1875\", \"loss\": 1.399510979652, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1350/1875\", \"loss\": 1.356972754002, \"lr\": 0.000186267817, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1360/1875\", \"loss\": 1.558220326900, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1370/1875\", \"loss\": 1.587743103504, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1380/1875\", \"loss\": 1.324167907238, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1390/1875\", \"loss\": 1.584351658821, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1400/1875\", \"loss\": 1.395602643490, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1410/1875\", \"loss\": 1.495095014572, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1420/1875\", \"loss\": 1.388772010803, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1430/1875\", \"loss\": 1.480876326561, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1440/1875\", \"loss\": 1.506308615208, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1450/1875\", \"loss\": 1.459367036819, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1460/1875\", \"loss\": 1.313396036625, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1470/1875\", \"loss\": 1.159060895443, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1480/1875\", \"loss\": 1.301148951054, \"lr\": 0.000186267817, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1490/1875\", \"loss\": 1.271311342716, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1500/1875\", \"loss\": 1.548038601875, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1510/1875\", \"loss\": 1.393897771835, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1520/1875\", \"loss\": 1.419191241264, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1530/1875\", \"loss\": 1.493245899677, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1540/1875\", \"loss\": 1.651936531067, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1550/1875\", \"loss\": 1.577449738979, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1560/1875\", \"loss\": 1.463932394981, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1570/1875\", \"loss\": 1.565120697021, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1580/1875\", \"loss\": 1.379249095917, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1590/1875\", \"loss\": 1.208830773830, \"lr\": 0.000186267817, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1600/1875\", \"loss\": 1.381016910076, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1610/1875\", \"loss\": 1.356668114662, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1620/1875\", \"loss\": 1.564628601074, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1630/1875\", \"loss\": 1.209582567215, \"lr\": 0.000186267817, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1640/1875\", \"loss\": 1.479781985283, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1650/1875\", \"loss\": 1.620689988136, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1660/1875\", \"loss\": 1.642966210842, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1670/1875\", \"loss\": 1.380574107170, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1680/1875\", \"loss\": 1.435044169426, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1690/1875\", \"loss\": 1.397875845432, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1700/1875\", \"loss\": 1.339594662189, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1710/1875\", \"loss\": 1.309639453888, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1720/1875\", \"loss\": 1.303136467934, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1730/1875\", \"loss\": 1.378951251507, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1740/1875\", \"loss\": 1.550466656685, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1750/1875\", \"loss\": 1.289158463478, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1760/1875\", \"loss\": 1.500974595547, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1770/1875\", \"loss\": 1.385004341602, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1780/1875\", \"loss\": 1.489839553833, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1790/1875\", \"loss\": 1.266024112701, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1800/1875\", \"loss\": 1.329781770706, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1810/1875\", \"loss\": 1.391899704933, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1820/1875\", \"loss\": 1.793882966042, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1830/1875\", \"loss\": 1.547370195389, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1840/1875\", \"loss\": 1.685797631741, \"lr\": 0.000186267817, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1850/1875\", \"loss\": 1.340504348278, \"lr\": 0.000186267817, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1860/1875\", \"loss\": 1.375817954540, \"lr\": 0.000186267817, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1870/1875\", \"loss\": 1.719458580017, \"lr\": 0.000186267817, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.494824234867, \"lr\": 0.000186267817, \"top1_err\": 58.566666666667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 57.500003051758, \"top1_err\": 59.300002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_42.499996948242185_model_epoch_0005.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_42.499996948242185_model_epoch_0005.pyth\n",
      "\u001b[32m[I 2022-03-22 01:56:46,387]\u001b[0m Trial 4 finished with value: 42.499996948242185 and parameters: {'learning_rate': 0.00018626781664764596, 'weight_decay': 4.527343524155812e-07, 'batch_size': 8, 'optimizer': 'ADAM'}. Best is trial 3 with value: 62.49999847412109.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 1384.1486785411835 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 62.49999847412109\n",
      "  Params: \n",
      "    learning_rate: 0.0040957158921162366\n",
      "    weight_decay: 0.000675042274609726\n",
      "    batch_size: 16\n",
      "    optimizer: SGD\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_9hhwlqgw.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  29000\n",
      "len(lSEt):  15000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 20000 and len(uSet): 29000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/lSet.txt in text format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  29000\n",
      "len(lSet):  20000\n",
      "For random sampling, activeSet accuracy:  60.48\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 36.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 39.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 37.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 39.250001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 37.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 38.320001144409, \"top1_err\": 38.320001144409}\n",
      "Test Accuracy: 61.680\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 30.0% of data is 61.67999885559082\n",
      "\n",
      "Extracted Test Accuracy from subproces: 61.67999885559082\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "~~~ out_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "check_aml_path: \n",
      "/nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_dkjbqk60.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 0\n",
      "\u001b[32m[I 2022-03-22 01:58:35,350]\u001b[0m A new study created in memory with name: no-name-7a8afcee-7df1-40d1-afad-b140e38e4285\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.0008236089903712815\n",
      "Weight Decay : 1.1046209750128704e-08\n",
      "Batch Size   : 128\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    lr: 0.0008236089903712815\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1.1046209750128704e-08\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:29000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 157\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/157\", \"loss\": 2.314551115036, \"lr\": 0.000823608990, \"top1_err\": 89.453125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/157\", \"loss\": 2.299559235573, \"lr\": 0.000823608990, \"top1_err\": 90.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/157\", \"loss\": 2.269900202751, \"lr\": 0.000823608990, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/157\", \"loss\": 2.260697245598, \"lr\": 0.000823608990, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/157\", \"loss\": 2.224573731422, \"lr\": 0.000823608990, \"top1_err\": 81.640625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/157\", \"loss\": 2.189834594727, \"lr\": 0.000823608990, \"top1_err\": 82.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/157\", \"loss\": 2.156243443489, \"lr\": 0.000823608990, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/157\", \"loss\": 2.083264350891, \"lr\": 0.000823608990, \"top1_err\": 77.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/157\", \"loss\": 2.009629487991, \"lr\": 0.000823608990, \"top1_err\": 74.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/157\", \"loss\": 1.969178795815, \"lr\": 0.000823608990, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/157\", \"loss\": 1.901378452778, \"lr\": 0.000823608990, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/157\", \"loss\": 1.906205594540, \"lr\": 0.000823608990, \"top1_err\": 73.828125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/157\", \"loss\": 1.849776923656, \"lr\": 0.000823608990, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/157\", \"loss\": 1.825305521488, \"lr\": 0.000823608990, \"top1_err\": 70.312500000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/157\", \"loss\": 1.808755159378, \"lr\": 0.000823608990, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.061808716583, \"lr\": 0.000823608990, \"top1_err\": 78.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 69.800000000000, \"top1_err\": 69.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/157\", \"loss\": 1.730220019817, \"lr\": 0.000823608990, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/157\", \"loss\": 1.721774697304, \"lr\": 0.000823608990, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/157\", \"loss\": 1.770918846130, \"lr\": 0.000823608990, \"top1_err\": 68.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/157\", \"loss\": 1.687524199486, \"lr\": 0.000823608990, \"top1_err\": 62.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/157\", \"loss\": 1.692921102047, \"lr\": 0.000823608990, \"top1_err\": 66.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/157\", \"loss\": 1.596539556980, \"lr\": 0.000823608990, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/157\", \"loss\": 1.640085816383, \"lr\": 0.000823608990, \"top1_err\": 62.890625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/157\", \"loss\": 1.632477939129, \"lr\": 0.000823608990, \"top1_err\": 63.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/157\", \"loss\": 1.631421566010, \"lr\": 0.000823608990, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/157\", \"loss\": 1.640623986721, \"lr\": 0.000823608990, \"top1_err\": 60.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/157\", \"loss\": 1.587285995483, \"lr\": 0.000823608990, \"top1_err\": 61.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/157\", \"loss\": 1.577472746372, \"lr\": 0.000823608990, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/157\", \"loss\": 1.626118183136, \"lr\": 0.000823608990, \"top1_err\": 60.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/157\", \"loss\": 1.510987341404, \"lr\": 0.000823608990, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/157\", \"loss\": 1.506678998470, \"lr\": 0.000823608990, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.633449736595, \"lr\": 0.000823608990, \"top1_err\": 61.915000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 61.400001525879, \"top1_err\": 61.400001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/157\", \"loss\": 1.459834039211, \"lr\": 0.000823608990, \"top1_err\": 57.421875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/157\", \"loss\": 1.448795735836, \"lr\": 0.000823608990, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/157\", \"loss\": 1.427905499935, \"lr\": 0.000823608990, \"top1_err\": 51.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/157\", \"loss\": 1.445002198219, \"lr\": 0.000823608990, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/157\", \"loss\": 1.384403944016, \"lr\": 0.000823608990, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/157\", \"loss\": 1.413717031479, \"lr\": 0.000823608990, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/157\", \"loss\": 1.483408033848, \"lr\": 0.000823608990, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/157\", \"loss\": 1.417314648628, \"lr\": 0.000823608990, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/157\", \"loss\": 1.456964135170, \"lr\": 0.000823608990, \"top1_err\": 54.296875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/157\", \"loss\": 1.389804720879, \"lr\": 0.000823608990, \"top1_err\": 51.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/157\", \"loss\": 1.326434016228, \"lr\": 0.000823608990, \"top1_err\": 52.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/157\", \"loss\": 1.364826321602, \"lr\": 0.000823608990, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/157\", \"loss\": 1.438205003738, \"lr\": 0.000823608990, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/157\", \"loss\": 1.370296359062, \"lr\": 0.000823608990, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/157\", \"loss\": 1.423862934113, \"lr\": 0.000823608990, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.417996200371, \"lr\": 0.000823608990, \"top1_err\": 52.840000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 53.500001525879, \"top1_err\": 53.500001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/157\", \"loss\": 1.338415622711, \"lr\": 0.000823608990, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/157\", \"loss\": 1.277840256691, \"lr\": 0.000823608990, \"top1_err\": 48.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/157\", \"loss\": 1.333714008331, \"lr\": 0.000823608990, \"top1_err\": 47.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/157\", \"loss\": 1.226446866989, \"lr\": 0.000823608990, \"top1_err\": 44.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/157\", \"loss\": 1.272644519806, \"lr\": 0.000823608990, \"top1_err\": 47.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/157\", \"loss\": 1.236523687840, \"lr\": 0.000823608990, \"top1_err\": 48.046875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/157\", \"loss\": 1.224711537361, \"lr\": 0.000823608990, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/157\", \"loss\": 1.269501328468, \"lr\": 0.000823608990, \"top1_err\": 46.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/157\", \"loss\": 1.264223933220, \"lr\": 0.000823608990, \"top1_err\": 45.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/157\", \"loss\": 1.237728714943, \"lr\": 0.000823608990, \"top1_err\": 46.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/157\", \"loss\": 1.241599261761, \"lr\": 0.000823608990, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/157\", \"loss\": 1.231571972370, \"lr\": 0.000823608990, \"top1_err\": 46.093750000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/157\", \"loss\": 1.275520622730, \"lr\": 0.000823608990, \"top1_err\": 47.265625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/157\", \"loss\": 1.223790645599, \"lr\": 0.000823608990, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/157\", \"loss\": 1.180352091789, \"lr\": 0.000823608990, \"top1_err\": 43.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.259935630798, \"lr\": 0.000823608990, \"top1_err\": 46.655000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 49.100000762939, \"top1_err\": 49.100000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/157\", \"loss\": 1.222913086414, \"lr\": 0.000823608990, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/157\", \"loss\": 1.152030050755, \"lr\": 0.000823608990, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/157\", \"loss\": 1.130837082863, \"lr\": 0.000823608990, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/157\", \"loss\": 1.179598271847, \"lr\": 0.000823608990, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/157\", \"loss\": 1.200188279152, \"lr\": 0.000823608990, \"top1_err\": 42.578125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/157\", \"loss\": 1.123702585697, \"lr\": 0.000823608990, \"top1_err\": 44.531250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/157\", \"loss\": 1.120682775974, \"lr\": 0.000823608990, \"top1_err\": 40.234375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/157\", \"loss\": 1.113854050636, \"lr\": 0.000823608990, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/157\", \"loss\": 1.141048431396, \"lr\": 0.000823608990, \"top1_err\": 44.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/157\", \"loss\": 1.157724201679, \"lr\": 0.000823608990, \"top1_err\": 41.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/157\", \"loss\": 1.225654065609, \"lr\": 0.000823608990, \"top1_err\": 43.359375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/157\", \"loss\": 1.102242648602, \"lr\": 0.000823608990, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/157\", \"loss\": 1.142246484756, \"lr\": 0.000823608990, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/157\", \"loss\": 1.124564111233, \"lr\": 0.000823608990, \"top1_err\": 41.015625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/157\", \"loss\": 1.134190440178, \"lr\": 0.000823608990, \"top1_err\": 41.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.154635080910, \"lr\": 0.000823608990, \"top1_err\": 42.450000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 45.600002288818, \"top1_err\": 45.600002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_54.39999771118164_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-0/checkpoints/vlBest_acc_54.39999771118164_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 02:00:24,193]\u001b[0m Trial 0 finished with value: 54.39999771118164 and parameters: {'learning_rate': 0.0008236089903712815, 'weight_decay': 1.1046209750128704e-08, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 0 with value: 54.39999771118164.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 1 ========\n",
      "Learning Rate: 2.7905352670549165e-05\n",
      "Weight Decay : 1.7907964456825628e-05\n",
      "Batch Size   : 64\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 2.7905352670549165e-05\n",
      "    weight_decay: 1.7907964456825628e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:29000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 313\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/313\", \"loss\": 2.314378619194, \"lr\": 0.000027905353, \"top1_err\": 86.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/313\", \"loss\": 2.266234993935, \"lr\": 0.000027905353, \"top1_err\": 83.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/313\", \"loss\": 2.216703891754, \"lr\": 0.000027905353, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/313\", \"loss\": 2.123753309250, \"lr\": 0.000027905353, \"top1_err\": 82.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/313\", \"loss\": 2.032062053680, \"lr\": 0.000027905353, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/313\", \"loss\": 1.967063784599, \"lr\": 0.000027905353, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/313\", \"loss\": 1.917082130909, \"lr\": 0.000027905353, \"top1_err\": 75.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/313\", \"loss\": 1.942853510380, \"lr\": 0.000027905353, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/313\", \"loss\": 1.794605433941, \"lr\": 0.000027905353, \"top1_err\": 70.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/313\", \"loss\": 1.843441903591, \"lr\": 0.000027905353, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/313\", \"loss\": 1.704309642315, \"lr\": 0.000027905353, \"top1_err\": 66.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/313\", \"loss\": 1.712752282619, \"lr\": 0.000027905353, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/313\", \"loss\": 1.758638620377, \"lr\": 0.000027905353, \"top1_err\": 67.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/313\", \"loss\": 1.682617247105, \"lr\": 0.000027905353, \"top1_err\": 64.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/313\", \"loss\": 1.552044630051, \"lr\": 0.000027905353, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/313\", \"loss\": 1.647396564484, \"lr\": 0.000027905353, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/313\", \"loss\": 1.558161437511, \"lr\": 0.000027905353, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/313\", \"loss\": 1.591325640678, \"lr\": 0.000027905353, \"top1_err\": 60.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/313\", \"loss\": 1.628254413605, \"lr\": 0.000027905353, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/313\", \"loss\": 1.501152634621, \"lr\": 0.000027905353, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/313\", \"loss\": 1.549322485924, \"lr\": 0.000027905353, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/313\", \"loss\": 1.484500885010, \"lr\": 0.000027905353, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/313\", \"loss\": 1.553665995598, \"lr\": 0.000027905353, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/313\", \"loss\": 1.525460898876, \"lr\": 0.000027905353, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/313\", \"loss\": 1.478541254997, \"lr\": 0.000027905353, \"top1_err\": 54.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/313\", \"loss\": 1.585929811001, \"lr\": 0.000027905353, \"top1_err\": 57.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/313\", \"loss\": 1.492588818073, \"lr\": 0.000027905353, \"top1_err\": 53.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/313\", \"loss\": 1.477786004543, \"lr\": 0.000027905353, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/313\", \"loss\": 1.458724677563, \"lr\": 0.000027905353, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/313\", \"loss\": 1.402814567089, \"lr\": 0.000027905353, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/313\", \"loss\": 1.415544807911, \"lr\": 0.000027905353, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.717724349976, \"lr\": 0.000027905353, \"top1_err\": 64.820000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 55.299999237061, \"top1_err\": 55.299999237061}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/313\", \"loss\": 1.349378168583, \"lr\": 0.000027905353, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/313\", \"loss\": 1.400861442089, \"lr\": 0.000027905353, \"top1_err\": 55.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/313\", \"loss\": 1.367130339146, \"lr\": 0.000027905353, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/313\", \"loss\": 1.234604239464, \"lr\": 0.000027905353, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/313\", \"loss\": 1.351781547070, \"lr\": 0.000027905353, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/313\", \"loss\": 1.325035274029, \"lr\": 0.000027905353, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/313\", \"loss\": 1.246853649616, \"lr\": 0.000027905353, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/313\", \"loss\": 1.348946154118, \"lr\": 0.000027905353, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/313\", \"loss\": 1.299523711205, \"lr\": 0.000027905353, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/313\", \"loss\": 1.290223419666, \"lr\": 0.000027905353, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/313\", \"loss\": 1.235349416733, \"lr\": 0.000027905353, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/313\", \"loss\": 1.310309886932, \"lr\": 0.000027905353, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/313\", \"loss\": 1.358471810818, \"lr\": 0.000027905353, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/313\", \"loss\": 1.336038589478, \"lr\": 0.000027905353, \"top1_err\": 49.218750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/313\", \"loss\": 1.291548430920, \"lr\": 0.000027905353, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/313\", \"loss\": 1.287128329277, \"lr\": 0.000027905353, \"top1_err\": 47.656250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/313\", \"loss\": 1.367049038410, \"lr\": 0.000027905353, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/313\", \"loss\": 1.337921679020, \"lr\": 0.000027905353, \"top1_err\": 51.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/313\", \"loss\": 1.327113926411, \"lr\": 0.000027905353, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/313\", \"loss\": 1.288181424141, \"lr\": 0.000027905353, \"top1_err\": 50.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/313\", \"loss\": 1.273463845253, \"lr\": 0.000027905353, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/313\", \"loss\": 1.161993682384, \"lr\": 0.000027905353, \"top1_err\": 42.968750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/313\", \"loss\": 1.284500718117, \"lr\": 0.000027905353, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/313\", \"loss\": 1.272233247757, \"lr\": 0.000027905353, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/313\", \"loss\": 1.354735136032, \"lr\": 0.000027905353, \"top1_err\": 52.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/313\", \"loss\": 1.274629890919, \"lr\": 0.000027905353, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/313\", \"loss\": 1.235376358032, \"lr\": 0.000027905353, \"top1_err\": 47.656250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/313\", \"loss\": 1.140795230865, \"lr\": 0.000027905353, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/313\", \"loss\": 1.273296475410, \"lr\": 0.000027905353, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/313\", \"loss\": 1.258037686348, \"lr\": 0.000027905353, \"top1_err\": 46.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/313\", \"loss\": 1.206708312035, \"lr\": 0.000027905353, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.301816360474, \"lr\": 0.000027905353, \"top1_err\": 47.975000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 48.700000762939, \"top1_err\": 48.700000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/313\", \"loss\": 1.057571351528, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/313\", \"loss\": 1.059720307589, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/313\", \"loss\": 0.991827905178, \"lr\": 0.000027905353, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/313\", \"loss\": 1.028881490231, \"lr\": 0.000027905353, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/313\", \"loss\": 1.087687015533, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/313\", \"loss\": 1.120995759964, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/313\", \"loss\": 1.135744154453, \"lr\": 0.000027905353, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/313\", \"loss\": 1.162553071976, \"lr\": 0.000027905353, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/313\", \"loss\": 1.054072380066, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/313\", \"loss\": 1.021287262440, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/313\", \"loss\": 1.112440526485, \"lr\": 0.000027905353, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/313\", \"loss\": 1.154390931129, \"lr\": 0.000027905353, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/313\", \"loss\": 1.227290809155, \"lr\": 0.000027905353, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/313\", \"loss\": 1.167209208012, \"lr\": 0.000027905353, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/313\", \"loss\": 1.162271738052, \"lr\": 0.000027905353, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/313\", \"loss\": 1.092299759388, \"lr\": 0.000027905353, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/313\", \"loss\": 1.142159938812, \"lr\": 0.000027905353, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/313\", \"loss\": 1.083273351192, \"lr\": 0.000027905353, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/313\", \"loss\": 1.094860851765, \"lr\": 0.000027905353, \"top1_err\": 45.312500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/313\", \"loss\": 1.054758310318, \"lr\": 0.000027905353, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/313\", \"loss\": 0.972274541855, \"lr\": 0.000027905353, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/313\", \"loss\": 1.021950036287, \"lr\": 0.000027905353, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/313\", \"loss\": 1.125529408455, \"lr\": 0.000027905353, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/313\", \"loss\": 1.122793316841, \"lr\": 0.000027905353, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/313\", \"loss\": 1.048278093338, \"lr\": 0.000027905353, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/313\", \"loss\": 1.055590569973, \"lr\": 0.000027905353, \"top1_err\": 41.406250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/313\", \"loss\": 1.093228340149, \"lr\": 0.000027905353, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/313\", \"loss\": 1.124871551991, \"lr\": 0.000027905353, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/313\", \"loss\": 1.109394073486, \"lr\": 0.000027905353, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/313\", \"loss\": 1.127411782742, \"lr\": 0.000027905353, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/313\", \"loss\": 1.093982398510, \"lr\": 0.000027905353, \"top1_err\": 39.843750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.102240243053, \"lr\": 0.000027905353, \"top1_err\": 40.035000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 45.100000762939, \"top1_err\": 45.100000762939}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/313\", \"loss\": 0.916775822639, \"lr\": 0.000027905353, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/313\", \"loss\": 0.897757470608, \"lr\": 0.000027905353, \"top1_err\": 30.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/313\", \"loss\": 0.889760732651, \"lr\": 0.000027905353, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/313\", \"loss\": 0.791880995035, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/313\", \"loss\": 1.008273690939, \"lr\": 0.000027905353, \"top1_err\": 39.062500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/313\", \"loss\": 0.940771013498, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/313\", \"loss\": 0.902821838856, \"lr\": 0.000027905353, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/313\", \"loss\": 0.926336824894, \"lr\": 0.000027905353, \"top1_err\": 35.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/313\", \"loss\": 1.018126606941, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/313\", \"loss\": 0.916455149651, \"lr\": 0.000027905353, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/313\", \"loss\": 0.919530659914, \"lr\": 0.000027905353, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/313\", \"loss\": 0.944669365883, \"lr\": 0.000027905353, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/313\", \"loss\": 0.918875306845, \"lr\": 0.000027905353, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/313\", \"loss\": 0.876004993916, \"lr\": 0.000027905353, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/313\", \"loss\": 0.899608671665, \"lr\": 0.000027905353, \"top1_err\": 30.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/313\", \"loss\": 1.004326343536, \"lr\": 0.000027905353, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/313\", \"loss\": 0.997240215540, \"lr\": 0.000027905353, \"top1_err\": 36.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/313\", \"loss\": 0.904081970453, \"lr\": 0.000027905353, \"top1_err\": 30.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/313\", \"loss\": 0.967036753893, \"lr\": 0.000027905353, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/313\", \"loss\": 0.941283971071, \"lr\": 0.000027905353, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/313\", \"loss\": 0.921385616064, \"lr\": 0.000027905353, \"top1_err\": 35.156250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/313\", \"loss\": 0.910171121359, \"lr\": 0.000027905353, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/313\", \"loss\": 0.932959645987, \"lr\": 0.000027905353, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/313\", \"loss\": 0.916468292475, \"lr\": 0.000027905353, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/313\", \"loss\": 1.027162373066, \"lr\": 0.000027905353, \"top1_err\": 38.281250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/313\", \"loss\": 1.015494406223, \"lr\": 0.000027905353, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/313\", \"loss\": 0.908037096262, \"lr\": 0.000027905353, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/313\", \"loss\": 0.883581221104, \"lr\": 0.000027905353, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/313\", \"loss\": 0.969161182642, \"lr\": 0.000027905353, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/313\", \"loss\": 0.974134504795, \"lr\": 0.000027905353, \"top1_err\": 32.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/313\", \"loss\": 0.915777564049, \"lr\": 0.000027905353, \"top1_err\": 33.593750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 0.943903966141, \"lr\": 0.000027905353, \"top1_err\": 34.020000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 44.700000762939, \"top1_err\": 44.700000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/313\", \"loss\": 0.819775700569, \"lr\": 0.000027905353, \"top1_err\": 32.812500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/313\", \"loss\": 0.780544877052, \"lr\": 0.000027905353, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/313\", \"loss\": 0.683145433664, \"lr\": 0.000027905353, \"top1_err\": 25.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/313\", \"loss\": 0.756758660078, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/313\", \"loss\": 0.718668580055, \"lr\": 0.000027905353, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/313\", \"loss\": 0.799232095480, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/313\", \"loss\": 0.771754384041, \"lr\": 0.000027905353, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/313\", \"loss\": 0.837609261274, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/313\", \"loss\": 0.769233584404, \"lr\": 0.000027905353, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/313\", \"loss\": 0.878006994724, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/313\", \"loss\": 0.741368889809, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/313\", \"loss\": 0.728982329369, \"lr\": 0.000027905353, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/313\", \"loss\": 0.799073249102, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/313\", \"loss\": 0.792404294014, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/313\", \"loss\": 0.777208149433, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/313\", \"loss\": 0.757434785366, \"lr\": 0.000027905353, \"top1_err\": 28.125000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/313\", \"loss\": 0.766011297703, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/313\", \"loss\": 0.778516650200, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/313\", \"loss\": 0.806783199310, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/313\", \"loss\": 0.841536134481, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/313\", \"loss\": 0.839819163084, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/313\", \"loss\": 0.758722841740, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/313\", \"loss\": 0.764311313629, \"lr\": 0.000027905353, \"top1_err\": 27.343750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/313\", \"loss\": 0.716976344585, \"lr\": 0.000027905353, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/313\", \"loss\": 0.857112258673, \"lr\": 0.000027905353, \"top1_err\": 29.687500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/313\", \"loss\": 0.744413614273, \"lr\": 0.000027905353, \"top1_err\": 25.781250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/313\", \"loss\": 0.804540872574, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/313\", \"loss\": 0.750292301178, \"lr\": 0.000027905353, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/313\", \"loss\": 0.835195213556, \"lr\": 0.000027905353, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/313\", \"loss\": 0.858493626118, \"lr\": 0.000027905353, \"top1_err\": 30.468750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/313\", \"loss\": 0.800553560257, \"lr\": 0.000027905353, \"top1_err\": 28.906250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.793703953838, \"lr\": 0.000027905353, \"top1_err\": 28.330000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 42.000000762939, \"top1_err\": 42.000000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_57.99999923706055_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-1/checkpoints/vlBest_acc_57.99999923706055_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 02:03:10,845]\u001b[0m Trial 1 finished with value: 57.99999923706055 and parameters: {'learning_rate': 2.7905352670549165e-05, 'weight_decay': 1.7907964456825628e-05, 'batch_size': 64, 'optimizer': 'ADAM'}. Best is trial 1 with value: 57.99999923706055.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 2 ========\n",
      "Learning Rate: 0.00016281809694736513\n",
      "Weight Decay : 6.557750344356986e-07\n",
      "Batch Size   : 16\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00016281809694736513\n",
      "    weight_decay: 6.557750344356986e-07\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:29000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 1250\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/1250\", \"loss\": 2.672719240189, \"lr\": 0.000162818097, \"top1_err\": 93.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/1250\", \"loss\": 2.477062344551, \"lr\": 0.000162818097, \"top1_err\": 87.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/1250\", \"loss\": 2.256095647812, \"lr\": 0.000162818097, \"top1_err\": 93.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/1250\", \"loss\": 2.248623728752, \"lr\": 0.000162818097, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/1250\", \"loss\": 2.342865347862, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/1250\", \"loss\": 2.140718817711, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/1250\", \"loss\": 2.065794587135, \"lr\": 0.000162818097, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"80/1250\", \"loss\": 2.019233703613, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"90/1250\", \"loss\": 2.064479351044, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"100/1250\", \"loss\": 1.971226572990, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"110/1250\", \"loss\": 2.053719282150, \"lr\": 0.000162818097, \"top1_err\": 84.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"120/1250\", \"loss\": 2.046522378922, \"lr\": 0.000162818097, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"130/1250\", \"loss\": 1.990841865540, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"140/1250\", \"loss\": 1.978186607361, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"150/1250\", \"loss\": 2.000296711922, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"160/1250\", \"loss\": 1.912599861622, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"170/1250\", \"loss\": 1.918092846870, \"lr\": 0.000162818097, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"180/1250\", \"loss\": 1.846633970737, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"190/1250\", \"loss\": 1.878460943699, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"200/1250\", \"loss\": 1.952641963959, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"210/1250\", \"loss\": 2.050337672234, \"lr\": 0.000162818097, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"220/1250\", \"loss\": 2.139842510223, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"230/1250\", \"loss\": 1.999479413033, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"240/1250\", \"loss\": 1.872694253922, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"250/1250\", \"loss\": 1.763328492641, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"260/1250\", \"loss\": 1.845551669598, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"270/1250\", \"loss\": 1.858998537064, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"280/1250\", \"loss\": 1.828479170799, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"290/1250\", \"loss\": 1.879341721535, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"300/1250\", \"loss\": 1.922724783421, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"310/1250\", \"loss\": 1.748521745205, \"lr\": 0.000162818097, \"top1_err\": 78.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"320/1250\", \"loss\": 1.945714294910, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"330/1250\", \"loss\": 1.793435275555, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"340/1250\", \"loss\": 1.801069140434, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"350/1250\", \"loss\": 1.860599517822, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"360/1250\", \"loss\": 1.888979256153, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"370/1250\", \"loss\": 1.813207745552, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"380/1250\", \"loss\": 1.947447896004, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"390/1250\", \"loss\": 1.848879873753, \"lr\": 0.000162818097, \"top1_err\": 81.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"400/1250\", \"loss\": 1.813491761684, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"410/1250\", \"loss\": 1.802677273750, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"420/1250\", \"loss\": 1.700600266457, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"430/1250\", \"loss\": 1.830165445805, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"440/1250\", \"loss\": 1.768459379673, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"450/1250\", \"loss\": 1.720611989498, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"460/1250\", \"loss\": 1.827740371227, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"470/1250\", \"loss\": 1.762885093689, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"480/1250\", \"loss\": 1.710092961788, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"490/1250\", \"loss\": 1.584469854832, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"500/1250\", \"loss\": 1.775789558887, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"510/1250\", \"loss\": 1.816681563854, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"520/1250\", \"loss\": 1.899786174297, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"530/1250\", \"loss\": 1.691214084625, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"540/1250\", \"loss\": 1.808568239212, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"550/1250\", \"loss\": 1.647046089172, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"560/1250\", \"loss\": 1.665110945702, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"570/1250\", \"loss\": 1.652847111225, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"580/1250\", \"loss\": 1.676322221756, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"590/1250\", \"loss\": 1.575550138950, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"600/1250\", \"loss\": 1.758876383305, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"610/1250\", \"loss\": 1.810262620449, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"620/1250\", \"loss\": 1.841756165028, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"630/1250\", \"loss\": 1.795944571495, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"640/1250\", \"loss\": 1.643878221512, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"650/1250\", \"loss\": 1.669315934181, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"660/1250\", \"loss\": 1.539690971375, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"670/1250\", \"loss\": 1.761344850063, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"680/1250\", \"loss\": 1.663393139839, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"690/1250\", \"loss\": 1.627142131329, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"700/1250\", \"loss\": 1.624299585819, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"710/1250\", \"loss\": 1.586469292641, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"720/1250\", \"loss\": 1.749083697796, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"730/1250\", \"loss\": 1.746944904327, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"740/1250\", \"loss\": 1.685177624226, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"750/1250\", \"loss\": 1.683335721493, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"760/1250\", \"loss\": 1.607814729214, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"770/1250\", \"loss\": 1.543377399445, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"780/1250\", \"loss\": 1.676747322083, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"790/1250\", \"loss\": 1.784185290337, \"lr\": 0.000162818097, \"top1_err\": 75.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"800/1250\", \"loss\": 1.648478209972, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"810/1250\", \"loss\": 1.540871143341, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"820/1250\", \"loss\": 1.638512074947, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"830/1250\", \"loss\": 1.745200395584, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"840/1250\", \"loss\": 1.568316817284, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"850/1250\", \"loss\": 1.472632884979, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"860/1250\", \"loss\": 1.622769415379, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"870/1250\", \"loss\": 1.612477242947, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"880/1250\", \"loss\": 1.684323251247, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"890/1250\", \"loss\": 1.494843184948, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"900/1250\", \"loss\": 1.517867445946, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"910/1250\", \"loss\": 1.523800194263, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"920/1250\", \"loss\": 1.587338984013, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"930/1250\", \"loss\": 1.498403191566, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"940/1250\", \"loss\": 1.508103907108, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"950/1250\", \"loss\": 1.613484919071, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"960/1250\", \"loss\": 1.633208394051, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"970/1250\", \"loss\": 1.448939621449, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"980/1250\", \"loss\": 1.587160646915, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"990/1250\", \"loss\": 1.528485476971, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1000/1250\", \"loss\": 1.673674106598, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1010/1250\", \"loss\": 1.529244184494, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1020/1250\", \"loss\": 1.673339366913, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1030/1250\", \"loss\": 1.666819989681, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1040/1250\", \"loss\": 1.624436557293, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1050/1250\", \"loss\": 1.619569659233, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1060/1250\", \"loss\": 1.570216834545, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1070/1250\", \"loss\": 1.450289189816, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1080/1250\", \"loss\": 1.667061507702, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1090/1250\", \"loss\": 1.623633086681, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1100/1250\", \"loss\": 1.697864711285, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1110/1250\", \"loss\": 1.518483042717, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1120/1250\", \"loss\": 1.513929307461, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1130/1250\", \"loss\": 1.548366665840, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1140/1250\", \"loss\": 1.578474164009, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1150/1250\", \"loss\": 1.578550934792, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1160/1250\", \"loss\": 1.532187461853, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1170/1250\", \"loss\": 1.437797307968, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1180/1250\", \"loss\": 1.679733395576, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1190/1250\", \"loss\": 1.585157990456, \"lr\": 0.000162818097, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1200/1250\", \"loss\": 1.555843830109, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1210/1250\", \"loss\": 1.616952478886, \"lr\": 0.000162818097, \"top1_err\": 68.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1220/1250\", \"loss\": 1.503813147545, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1230/1250\", \"loss\": 1.445403873920, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1240/1250\", \"loss\": 1.406787097454, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"1250/1250\", \"loss\": 1.665379941463, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 1.765057700872, \"lr\": 0.000162818097, \"top1_err\": 67.140000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 66.900000000000, \"top1_err\": 66.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/1250\", \"loss\": 1.557912468910, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/1250\", \"loss\": 1.581428229809, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/1250\", \"loss\": 1.380655467510, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/1250\", \"loss\": 1.716334819794, \"lr\": 0.000162818097, \"top1_err\": 65.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/1250\", \"loss\": 1.477113008499, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/1250\", \"loss\": 1.509849846363, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/1250\", \"loss\": 1.379042088985, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"80/1250\", \"loss\": 1.459542870522, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"90/1250\", \"loss\": 1.458683967590, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"100/1250\", \"loss\": 1.397556900978, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"110/1250\", \"loss\": 1.407041013241, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"120/1250\", \"loss\": 1.419561326504, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"130/1250\", \"loss\": 1.237651169300, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"140/1250\", \"loss\": 1.554467439651, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"150/1250\", \"loss\": 1.565049171448, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"160/1250\", \"loss\": 1.446266353130, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"170/1250\", \"loss\": 1.396999537945, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"180/1250\", \"loss\": 1.499711513519, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"190/1250\", \"loss\": 1.551846086979, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"200/1250\", \"loss\": 1.545999705791, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"210/1250\", \"loss\": 1.494909882545, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"220/1250\", \"loss\": 1.512907147408, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"230/1250\", \"loss\": 1.443973422050, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"240/1250\", \"loss\": 1.418169975281, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"250/1250\", \"loss\": 1.233448028564, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"260/1250\", \"loss\": 1.401536822319, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"270/1250\", \"loss\": 1.632536888123, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"280/1250\", \"loss\": 1.346913695335, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"290/1250\", \"loss\": 1.528985559940, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"300/1250\", \"loss\": 1.506075441837, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"310/1250\", \"loss\": 1.374410212040, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"320/1250\", \"loss\": 1.415057063103, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"330/1250\", \"loss\": 1.395839333534, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"340/1250\", \"loss\": 1.434615254402, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"350/1250\", \"loss\": 1.530704736710, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"360/1250\", \"loss\": 1.281041443348, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"370/1250\", \"loss\": 1.667217254639, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"380/1250\", \"loss\": 1.377413272858, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"390/1250\", \"loss\": 1.447710454464, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"400/1250\", \"loss\": 1.454480588436, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"410/1250\", \"loss\": 1.409026384354, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"420/1250\", \"loss\": 1.446258485317, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"430/1250\", \"loss\": 1.420240700245, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"440/1250\", \"loss\": 1.272748410702, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"450/1250\", \"loss\": 1.483258068562, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"460/1250\", \"loss\": 1.311481952667, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"470/1250\", \"loss\": 1.492062032223, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"480/1250\", \"loss\": 1.252818763256, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"490/1250\", \"loss\": 1.367336332798, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"500/1250\", \"loss\": 1.216492414474, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"510/1250\", \"loss\": 1.533642590046, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"520/1250\", \"loss\": 1.394785106182, \"lr\": 0.000162818097, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"530/1250\", \"loss\": 1.297844111919, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"540/1250\", \"loss\": 1.456633865833, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"550/1250\", \"loss\": 1.470110774040, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"560/1250\", \"loss\": 1.429281115532, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"570/1250\", \"loss\": 1.380457937717, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"580/1250\", \"loss\": 1.469883441925, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"590/1250\", \"loss\": 1.424478411674, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"600/1250\", \"loss\": 1.266791284084, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"610/1250\", \"loss\": 1.622715175152, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"620/1250\", \"loss\": 1.315136969090, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"630/1250\", \"loss\": 1.469535231590, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"640/1250\", \"loss\": 1.340054392815, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"650/1250\", \"loss\": 1.276865839958, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"660/1250\", \"loss\": 1.427457153797, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"670/1250\", \"loss\": 1.382819235325, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"680/1250\", \"loss\": 1.420826315880, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"690/1250\", \"loss\": 1.496854901314, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"700/1250\", \"loss\": 1.254780292511, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"710/1250\", \"loss\": 1.284643828869, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"720/1250\", \"loss\": 1.505288302898, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"730/1250\", \"loss\": 1.171792566776, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"740/1250\", \"loss\": 1.419270157814, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"750/1250\", \"loss\": 1.454195022583, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"760/1250\", \"loss\": 1.318494319916, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"770/1250\", \"loss\": 1.291365206242, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"780/1250\", \"loss\": 1.596391022205, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"790/1250\", \"loss\": 1.433840215206, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"800/1250\", \"loss\": 1.328643083572, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"810/1250\", \"loss\": 1.211614966393, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"820/1250\", \"loss\": 1.309578239918, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"830/1250\", \"loss\": 1.271831691265, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"840/1250\", \"loss\": 1.305868208408, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"850/1250\", \"loss\": 1.467757880688, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"860/1250\", \"loss\": 1.455012798309, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"870/1250\", \"loss\": 1.352638244629, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"880/1250\", \"loss\": 1.148611426353, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"890/1250\", \"loss\": 1.316731989384, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"900/1250\", \"loss\": 1.322403132915, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"910/1250\", \"loss\": 1.612287580967, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"920/1250\", \"loss\": 1.332769572735, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"930/1250\", \"loss\": 1.396122872829, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"940/1250\", \"loss\": 1.279925525188, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"950/1250\", \"loss\": 1.361996769905, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"960/1250\", \"loss\": 1.150371313095, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"970/1250\", \"loss\": 1.428527474403, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"980/1250\", \"loss\": 1.483939826488, \"lr\": 0.000162818097, \"top1_err\": 59.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"990/1250\", \"loss\": 1.257133245468, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1000/1250\", \"loss\": 1.314464151859, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1010/1250\", \"loss\": 1.196780443192, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1020/1250\", \"loss\": 1.304971277714, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1030/1250\", \"loss\": 1.421018004417, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1040/1250\", \"loss\": 1.390288412571, \"lr\": 0.000162818097, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1050/1250\", \"loss\": 1.341218829155, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1060/1250\", \"loss\": 1.271459579468, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1070/1250\", \"loss\": 1.274502813816, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1080/1250\", \"loss\": 1.292136728764, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1090/1250\", \"loss\": 1.244904696941, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1100/1250\", \"loss\": 1.238047301769, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1110/1250\", \"loss\": 1.151684343815, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1120/1250\", \"loss\": 1.154960691929, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1130/1250\", \"loss\": 1.282788574696, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1140/1250\", \"loss\": 1.268719732761, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1150/1250\", \"loss\": 1.050690829754, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1160/1250\", \"loss\": 1.362101495266, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1170/1250\", \"loss\": 1.266686439514, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1180/1250\", \"loss\": 1.105251848698, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1190/1250\", \"loss\": 1.239826261997, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1200/1250\", \"loss\": 1.356681585312, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1210/1250\", \"loss\": 1.180016100407, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1220/1250\", \"loss\": 1.388063609600, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1230/1250\", \"loss\": 1.155075788498, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1240/1250\", \"loss\": 1.185492277145, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"1250/1250\", \"loss\": 1.282718360424, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.413679224682, \"lr\": 0.000162818097, \"top1_err\": 52.010000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 48.900000762939, \"top1_err\": 48.900000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/1250\", \"loss\": 1.325129330158, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/1250\", \"loss\": 1.239987254143, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/1250\", \"loss\": 1.069078683853, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/1250\", \"loss\": 1.318352460861, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/1250\", \"loss\": 1.244449138641, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/1250\", \"loss\": 1.238403379917, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/1250\", \"loss\": 1.195619881153, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"80/1250\", \"loss\": 1.081045806408, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"90/1250\", \"loss\": 1.195300161839, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"100/1250\", \"loss\": 1.261692941189, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"110/1250\", \"loss\": 1.167613744736, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"120/1250\", \"loss\": 1.203129827976, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"130/1250\", \"loss\": 1.287195742130, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"140/1250\", \"loss\": 1.252407491207, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"150/1250\", \"loss\": 1.072303175926, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"160/1250\", \"loss\": 1.158933043480, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"170/1250\", \"loss\": 1.233290016651, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"180/1250\", \"loss\": 1.264555513859, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"190/1250\", \"loss\": 1.142172217369, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"200/1250\", \"loss\": 1.168700635433, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"210/1250\", \"loss\": 1.294833123684, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"220/1250\", \"loss\": 1.224206924438, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"230/1250\", \"loss\": 1.208274424076, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"240/1250\", \"loss\": 1.353923976421, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"250/1250\", \"loss\": 1.424521267414, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"260/1250\", \"loss\": 1.249871671200, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"270/1250\", \"loss\": 1.102634847164, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"280/1250\", \"loss\": 1.265481591225, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"290/1250\", \"loss\": 1.368811428547, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"300/1250\", \"loss\": 1.204890131950, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"310/1250\", \"loss\": 1.169224560261, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"320/1250\", \"loss\": 1.305533707142, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"330/1250\", \"loss\": 1.314095020294, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"340/1250\", \"loss\": 0.993182152510, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"350/1250\", \"loss\": 1.071676373482, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"360/1250\", \"loss\": 1.133250415325, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"370/1250\", \"loss\": 1.118564546108, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"380/1250\", \"loss\": 1.139294624329, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"390/1250\", \"loss\": 1.350413918495, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"400/1250\", \"loss\": 1.270798444748, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"410/1250\", \"loss\": 1.297272562981, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"420/1250\", \"loss\": 1.245893239975, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"430/1250\", \"loss\": 1.047460317612, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"440/1250\", \"loss\": 1.210320770741, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"450/1250\", \"loss\": 1.224356353283, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"460/1250\", \"loss\": 1.175203680992, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"470/1250\", \"loss\": 1.157599091530, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"480/1250\", \"loss\": 1.169137239456, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"490/1250\", \"loss\": 1.126501798630, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"500/1250\", \"loss\": 1.254034459591, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"510/1250\", \"loss\": 1.259788513184, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"520/1250\", \"loss\": 1.297397315502, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"530/1250\", \"loss\": 1.135218441486, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"540/1250\", \"loss\": 1.479046404362, \"lr\": 0.000162818097, \"top1_err\": 53.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"550/1250\", \"loss\": 1.226815283298, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"560/1250\", \"loss\": 1.181185960770, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"570/1250\", \"loss\": 1.340422272682, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"580/1250\", \"loss\": 1.245458543301, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"590/1250\", \"loss\": 1.153550863266, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"600/1250\", \"loss\": 1.190443456173, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"610/1250\", \"loss\": 1.053397536278, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"620/1250\", \"loss\": 1.078488230705, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"630/1250\", \"loss\": 1.127848446369, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"640/1250\", \"loss\": 1.159282147884, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"650/1250\", \"loss\": 1.116310775280, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"660/1250\", \"loss\": 0.947630703449, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"670/1250\", \"loss\": 1.182589054108, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"680/1250\", \"loss\": 0.880882591009, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"690/1250\", \"loss\": 1.127622246742, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"700/1250\", \"loss\": 1.273277580738, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"710/1250\", \"loss\": 1.119127035141, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"720/1250\", \"loss\": 1.223692178726, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"730/1250\", \"loss\": 1.206575155258, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"740/1250\", \"loss\": 1.265524685383, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"750/1250\", \"loss\": 1.071807503700, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"760/1250\", \"loss\": 1.075267732143, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"770/1250\", \"loss\": 1.151871502399, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"780/1250\", \"loss\": 1.053452640772, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"790/1250\", \"loss\": 1.000637412071, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"800/1250\", \"loss\": 1.034585535526, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"810/1250\", \"loss\": 1.063550591469, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"820/1250\", \"loss\": 1.243318676949, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"830/1250\", \"loss\": 1.115446090698, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"840/1250\", \"loss\": 1.130963981152, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"850/1250\", \"loss\": 1.000556528568, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"860/1250\", \"loss\": 1.069841086864, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"870/1250\", \"loss\": 0.945723891258, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"880/1250\", \"loss\": 1.036289751530, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"890/1250\", \"loss\": 1.167927742004, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"900/1250\", \"loss\": 1.252156853676, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"910/1250\", \"loss\": 1.046858966351, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"920/1250\", \"loss\": 1.028719186783, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"930/1250\", \"loss\": 1.129867017269, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"940/1250\", \"loss\": 1.194324791431, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"950/1250\", \"loss\": 1.120340287685, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"960/1250\", \"loss\": 1.161583125591, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"970/1250\", \"loss\": 1.054951548576, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"980/1250\", \"loss\": 0.999227881432, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"990/1250\", \"loss\": 1.038090705872, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1000/1250\", \"loss\": 1.105800986290, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1010/1250\", \"loss\": 1.370372653008, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1020/1250\", \"loss\": 1.112927615643, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1030/1250\", \"loss\": 1.040866196156, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1040/1250\", \"loss\": 1.048149794340, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1050/1250\", \"loss\": 1.012557983398, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1060/1250\", \"loss\": 1.137403964996, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1070/1250\", \"loss\": 1.162137269974, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1080/1250\", \"loss\": 1.055399596691, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1090/1250\", \"loss\": 1.146457910538, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1100/1250\", \"loss\": 1.132269799709, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1110/1250\", \"loss\": 1.111248612404, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1120/1250\", \"loss\": 1.354222893715, \"lr\": 0.000162818097, \"top1_err\": 50.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1130/1250\", \"loss\": 1.040116727352, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1140/1250\", \"loss\": 1.158484578133, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1150/1250\", \"loss\": 1.106121480465, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1160/1250\", \"loss\": 1.327343404293, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1170/1250\", \"loss\": 1.114444077015, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1180/1250\", \"loss\": 1.176849782467, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1190/1250\", \"loss\": 0.947954952717, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1200/1250\", \"loss\": 1.160991966724, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1210/1250\", \"loss\": 1.069203257561, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1220/1250\", \"loss\": 1.107912600040, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1230/1250\", \"loss\": 1.125957250595, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1240/1250\", \"loss\": 1.073528945446, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"1250/1250\", \"loss\": 1.045079708099, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.188233701849, \"lr\": 0.000162818097, \"top1_err\": 41.790000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 38.900002288818, \"top1_err\": 38.900002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/1250\", \"loss\": 0.900051683187, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/1250\", \"loss\": 0.996186822653, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/1250\", \"loss\": 1.120267033577, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/1250\", \"loss\": 1.041626036167, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/1250\", \"loss\": 1.058398663998, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/1250\", \"loss\": 0.922356069088, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/1250\", \"loss\": 0.895205408335, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"80/1250\", \"loss\": 1.179990530014, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"90/1250\", \"loss\": 0.920265108347, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"100/1250\", \"loss\": 1.179610669613, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"110/1250\", \"loss\": 0.940206676722, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"120/1250\", \"loss\": 0.933241397142, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"130/1250\", \"loss\": 1.006982743740, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"140/1250\", \"loss\": 1.075261652470, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"150/1250\", \"loss\": 0.988403856754, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"160/1250\", \"loss\": 1.065163254738, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"170/1250\", \"loss\": 1.025508224964, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"180/1250\", \"loss\": 1.134423196316, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"190/1250\", \"loss\": 1.129241406918, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"200/1250\", \"loss\": 1.080731093884, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"210/1250\", \"loss\": 0.872462809086, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"220/1250\", \"loss\": 1.100038826466, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"230/1250\", \"loss\": 1.147506415844, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"240/1250\", \"loss\": 1.055765718222, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"250/1250\", \"loss\": 0.921095281839, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"260/1250\", \"loss\": 1.119108080864, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"270/1250\", \"loss\": 0.983836472034, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"280/1250\", \"loss\": 0.863018274307, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"290/1250\", \"loss\": 1.180265069008, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"300/1250\", \"loss\": 0.954873323441, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"310/1250\", \"loss\": 1.224363684654, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"320/1250\", \"loss\": 0.874037444592, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"330/1250\", \"loss\": 1.092679262161, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"340/1250\", \"loss\": 0.991048008204, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"350/1250\", \"loss\": 1.130896866322, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"360/1250\", \"loss\": 0.901230901480, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"370/1250\", \"loss\": 0.901070088148, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"380/1250\", \"loss\": 1.037151485682, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"390/1250\", \"loss\": 0.891110122204, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"400/1250\", \"loss\": 1.305200278759, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"410/1250\", \"loss\": 1.084008634090, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"420/1250\", \"loss\": 0.855209618807, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"430/1250\", \"loss\": 0.811484605074, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"440/1250\", \"loss\": 0.977174043655, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"450/1250\", \"loss\": 0.988344073296, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"460/1250\", \"loss\": 0.969837546349, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"470/1250\", \"loss\": 1.175711989403, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"480/1250\", \"loss\": 0.960061460733, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"490/1250\", \"loss\": 1.054705739021, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"500/1250\", \"loss\": 1.028633236885, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"510/1250\", \"loss\": 0.812900841236, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"520/1250\", \"loss\": 0.989290952682, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"530/1250\", \"loss\": 1.066744506359, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"540/1250\", \"loss\": 0.946012407541, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"550/1250\", \"loss\": 1.030310332775, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"560/1250\", \"loss\": 1.146910965443, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"570/1250\", \"loss\": 0.957929909229, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"580/1250\", \"loss\": 1.055434703827, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"590/1250\", \"loss\": 1.141833424568, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"600/1250\", \"loss\": 0.872648298740, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"610/1250\", \"loss\": 0.963042557240, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"620/1250\", \"loss\": 1.020465552807, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"630/1250\", \"loss\": 1.076880514622, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"640/1250\", \"loss\": 1.099165081978, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"650/1250\", \"loss\": 1.086319446564, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"660/1250\", \"loss\": 1.026666313410, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"670/1250\", \"loss\": 1.132045745850, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"680/1250\", \"loss\": 1.013304710388, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"690/1250\", \"loss\": 0.854069471359, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"700/1250\", \"loss\": 0.944901883602, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"710/1250\", \"loss\": 1.145915150642, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"720/1250\", \"loss\": 0.973849326372, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"730/1250\", \"loss\": 1.072122454643, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"740/1250\", \"loss\": 1.027844071388, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"750/1250\", \"loss\": 0.915335804224, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"760/1250\", \"loss\": 0.868146300316, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"770/1250\", \"loss\": 0.926472753286, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"780/1250\", \"loss\": 1.142967581749, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"790/1250\", \"loss\": 1.112540781498, \"lr\": 0.000162818097, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"800/1250\", \"loss\": 1.065807819366, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"810/1250\", \"loss\": 0.960635721684, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"820/1250\", \"loss\": 0.915883004665, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"830/1250\", \"loss\": 1.031004607677, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"840/1250\", \"loss\": 0.858204692602, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"850/1250\", \"loss\": 0.897617608309, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"860/1250\", \"loss\": 0.891609340906, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"870/1250\", \"loss\": 0.922748953104, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"880/1250\", \"loss\": 0.832702875137, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"890/1250\", \"loss\": 0.907200217247, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"900/1250\", \"loss\": 1.162415206432, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"910/1250\", \"loss\": 1.080949485302, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"920/1250\", \"loss\": 1.038139760494, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"930/1250\", \"loss\": 0.970868796110, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"940/1250\", \"loss\": 0.889899492264, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"950/1250\", \"loss\": 0.949770838022, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"960/1250\", \"loss\": 1.022607088089, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"970/1250\", \"loss\": 1.053288996220, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"980/1250\", \"loss\": 1.037898659706, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"990/1250\", \"loss\": 1.126137912273, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1000/1250\", \"loss\": 1.017737865448, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1010/1250\", \"loss\": 1.072221338749, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1020/1250\", \"loss\": 1.060420274734, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1030/1250\", \"loss\": 1.092643767595, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1040/1250\", \"loss\": 0.987859964371, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1050/1250\", \"loss\": 0.988992929459, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1060/1250\", \"loss\": 1.099320113659, \"lr\": 0.000162818097, \"top1_err\": 43.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1070/1250\", \"loss\": 0.982739150524, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1080/1250\", \"loss\": 1.009899199009, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1090/1250\", \"loss\": 0.835874795914, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1100/1250\", \"loss\": 0.989286810160, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1110/1250\", \"loss\": 0.933846861124, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1120/1250\", \"loss\": 0.830283641815, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1130/1250\", \"loss\": 1.065329849720, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1140/1250\", \"loss\": 0.972341716290, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1150/1250\", \"loss\": 0.968991905451, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1160/1250\", \"loss\": 0.859210938215, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1170/1250\", \"loss\": 0.980132699013, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1180/1250\", \"loss\": 1.085037827492, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1190/1250\", \"loss\": 0.999863624573, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1200/1250\", \"loss\": 1.111685693264, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1210/1250\", \"loss\": 0.934250831604, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1220/1250\", \"loss\": 0.888566136360, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1230/1250\", \"loss\": 1.077867627144, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1240/1250\", \"loss\": 0.936585366726, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"1250/1250\", \"loss\": 1.036422789097, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.034859206510, \"lr\": 0.000162818097, \"top1_err\": 35.845000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 35.800000000000, \"top1_err\": 35.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/1250\", \"loss\": 0.935031980276, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/1250\", \"loss\": 0.965521126986, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/1250\", \"loss\": 0.790353149176, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/1250\", \"loss\": 0.971644282341, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/1250\", \"loss\": 0.859946876764, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/1250\", \"loss\": 0.879045814276, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/1250\", \"loss\": 0.883456647396, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"80/1250\", \"loss\": 1.078083217144, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"90/1250\", \"loss\": 0.947726607323, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"100/1250\", \"loss\": 0.799495756626, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"110/1250\", \"loss\": 0.851017624140, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"120/1250\", \"loss\": 0.942699581385, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"130/1250\", \"loss\": 1.090666711330, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"140/1250\", \"loss\": 1.080452561378, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"150/1250\", \"loss\": 0.857990473509, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"160/1250\", \"loss\": 1.024639576674, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"170/1250\", \"loss\": 0.943915188313, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"180/1250\", \"loss\": 0.803215146065, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"190/1250\", \"loss\": 0.766822546721, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"200/1250\", \"loss\": 0.921927213669, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"210/1250\", \"loss\": 0.812080204487, \"lr\": 0.000162818097, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"220/1250\", \"loss\": 0.955104291439, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"230/1250\", \"loss\": 0.735913276672, \"lr\": 0.000162818097, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"240/1250\", \"loss\": 0.911118984222, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"250/1250\", \"loss\": 1.010408818722, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"260/1250\", \"loss\": 0.917284756899, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"270/1250\", \"loss\": 0.962086915970, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"280/1250\", \"loss\": 0.971243232489, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"290/1250\", \"loss\": 0.853375792503, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"300/1250\", \"loss\": 0.964596718550, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"310/1250\", \"loss\": 0.936978220940, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"320/1250\", \"loss\": 0.987033814192, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"330/1250\", \"loss\": 1.001048773527, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"340/1250\", \"loss\": 0.837337017059, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"350/1250\", \"loss\": 1.004121840000, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"360/1250\", \"loss\": 1.051961004734, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"370/1250\", \"loss\": 0.897759079933, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"380/1250\", \"loss\": 0.892605066299, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"390/1250\", \"loss\": 1.195186853409, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"400/1250\", \"loss\": 0.938900560141, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"410/1250\", \"loss\": 0.810944855213, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"420/1250\", \"loss\": 0.900109410286, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"430/1250\", \"loss\": 0.909940421581, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"440/1250\", \"loss\": 0.800421655178, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"450/1250\", \"loss\": 0.897386401892, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"460/1250\", \"loss\": 0.743138968945, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"470/1250\", \"loss\": 0.876839905977, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"480/1250\", \"loss\": 0.857284128666, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"490/1250\", \"loss\": 1.009326666594, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"500/1250\", \"loss\": 0.874698340893, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"510/1250\", \"loss\": 0.854781031609, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"520/1250\", \"loss\": 0.683754712343, \"lr\": 0.000162818097, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"530/1250\", \"loss\": 0.875137239695, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"540/1250\", \"loss\": 0.918853014708, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"550/1250\", \"loss\": 0.805453032255, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"560/1250\", \"loss\": 0.792500168085, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"570/1250\", \"loss\": 0.933788448572, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"580/1250\", \"loss\": 0.969220221043, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"590/1250\", \"loss\": 1.035335063934, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"600/1250\", \"loss\": 0.816891193390, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"610/1250\", \"loss\": 0.990381896496, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"620/1250\", \"loss\": 0.671024322510, \"lr\": 0.000162818097, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"630/1250\", \"loss\": 0.942197650671, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"640/1250\", \"loss\": 0.795905679464, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"650/1250\", \"loss\": 1.100982546806, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"660/1250\", \"loss\": 0.919622957706, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"670/1250\", \"loss\": 0.875226378441, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"680/1250\", \"loss\": 0.793878197670, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"690/1250\", \"loss\": 0.879149854183, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"700/1250\", \"loss\": 0.854835748672, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"710/1250\", \"loss\": 0.846034556627, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"720/1250\", \"loss\": 0.948091834784, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"730/1250\", \"loss\": 0.900785982609, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"740/1250\", \"loss\": 1.007827520370, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"750/1250\", \"loss\": 0.865585923195, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"760/1250\", \"loss\": 0.874370604753, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"770/1250\", \"loss\": 0.760262906551, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"780/1250\", \"loss\": 0.808192551136, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"790/1250\", \"loss\": 0.925097107887, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"800/1250\", \"loss\": 0.900165975094, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"810/1250\", \"loss\": 0.812946885824, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"820/1250\", \"loss\": 1.048230886459, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"830/1250\", \"loss\": 1.038365840912, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"840/1250\", \"loss\": 0.928751289845, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"850/1250\", \"loss\": 0.804920077324, \"lr\": 0.000162818097, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"860/1250\", \"loss\": 0.894434988499, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"870/1250\", \"loss\": 0.963706851006, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"880/1250\", \"loss\": 0.974464714527, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"890/1250\", \"loss\": 0.877356588840, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"900/1250\", \"loss\": 0.907157242298, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"910/1250\", \"loss\": 0.916866689920, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"920/1250\", \"loss\": 0.793843209743, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"930/1250\", \"loss\": 0.779354989529, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"940/1250\", \"loss\": 0.747589975595, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"950/1250\", \"loss\": 0.844414174557, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"960/1250\", \"loss\": 0.898919224739, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"970/1250\", \"loss\": 0.779217690229, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"980/1250\", \"loss\": 0.987743347883, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"990/1250\", \"loss\": 1.086139351130, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1000/1250\", \"loss\": 0.903558224440, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1010/1250\", \"loss\": 0.703239321709, \"lr\": 0.000162818097, \"top1_err\": 18.750000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1020/1250\", \"loss\": 0.922133594751, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1030/1250\", \"loss\": 0.709464460611, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1040/1250\", \"loss\": 0.691938579082, \"lr\": 0.000162818097, \"top1_err\": 21.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1050/1250\", \"loss\": 0.796234041452, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1060/1250\", \"loss\": 0.911973863840, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1070/1250\", \"loss\": 0.963346153498, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1080/1250\", \"loss\": 0.831632226706, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1090/1250\", \"loss\": 0.849022835493, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1100/1250\", \"loss\": 0.854573965073, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1110/1250\", \"loss\": 0.883295178413, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1120/1250\", \"loss\": 0.741932958364, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1130/1250\", \"loss\": 0.667002081871, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1140/1250\", \"loss\": 0.813172936440, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1150/1250\", \"loss\": 0.815595716238, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1160/1250\", \"loss\": 0.703468471766, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1170/1250\", \"loss\": 0.831683009863, \"lr\": 0.000162818097, \"top1_err\": 34.375000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1180/1250\", \"loss\": 1.043722033501, \"lr\": 0.000162818097, \"top1_err\": 40.625000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1190/1250\", \"loss\": 0.786168575287, \"lr\": 0.000162818097, \"top1_err\": 25.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1200/1250\", \"loss\": 0.765997350216, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1210/1250\", \"loss\": 0.827639788389, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1220/1250\", \"loss\": 0.761195272207, \"lr\": 0.000162818097, \"top1_err\": 28.125000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1230/1250\", \"loss\": 0.936037302017, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1240/1250\", \"loss\": 0.952850282192, \"lr\": 0.000162818097, \"top1_err\": 31.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"1250/1250\", \"loss\": 0.898610234261, \"lr\": 0.000162818097, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 0.921432080841, \"lr\": 0.000162818097, \"top1_err\": 31.655000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 32.000001144409, \"top1_err\": 32.000001144409}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_67.99999885559082_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_67.99999885559082_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 02:12:07,484]\u001b[0m Trial 2 finished with value: 67.99999885559082 and parameters: {'learning_rate': 0.00016281809694736513, 'weight_decay': 6.557750344356986e-07, 'batch_size': 16, 'optimizer': 'ADAM'}. Best is trial 2 with value: 67.99999885559082.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 3 ========\n",
      "Learning Rate: 0.000224377221490302\n",
      "Weight Decay : 0.00025664730169008175\n",
      "Batch Size   : 512\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.000224377221490302\n",
      "    weight_decay: 0.00025664730169008175\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:29000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 40\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/40\", \"loss\": 2.517352819443, \"lr\": 0.000224377221, \"top1_err\": 89.257812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/40\", \"loss\": 2.271146178246, \"lr\": 0.000224377221, \"top1_err\": 85.644531250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/40\", \"loss\": 2.223626971245, \"lr\": 0.000224377221, \"top1_err\": 86.035156250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/40\", \"loss\": 2.127878665924, \"lr\": 0.000224377221, \"top1_err\": 83.300781250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.345606061554, \"lr\": 0.000224377221, \"top1_err\": 86.100000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 89.400000000000, \"top1_err\": 89.400000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/40\", \"loss\": 2.049746394157, \"lr\": 0.000224377221, \"top1_err\": 81.054687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/40\", \"loss\": 1.910184025764, \"lr\": 0.000224377221, \"top1_err\": 78.027343750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/40\", \"loss\": 1.882204532623, \"lr\": 0.000224377221, \"top1_err\": 76.953125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/40\", \"loss\": 1.793165981770, \"lr\": 0.000224377221, \"top1_err\": 72.363281250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.910163783836, \"lr\": 0.000224377221, \"top1_err\": 77.215000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 79.700000000000, \"top1_err\": 79.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/40\", \"loss\": 1.751315176487, \"lr\": 0.000224377221, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/40\", \"loss\": 1.748714983463, \"lr\": 0.000224377221, \"top1_err\": 70.507812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/40\", \"loss\": 1.625965714455, \"lr\": 0.000224377221, \"top1_err\": 65.722656250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/40\", \"loss\": 1.602115452290, \"lr\": 0.000224377221, \"top1_err\": 63.574218750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.689214512444, \"lr\": 0.000224377221, \"top1_err\": 68.095000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 72.700000000000, \"top1_err\": 72.700000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/40\", \"loss\": 1.535894155502, \"lr\": 0.000224377221, \"top1_err\": 61.718750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/40\", \"loss\": 1.444420933723, \"lr\": 0.000224377221, \"top1_err\": 57.031250000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/40\", \"loss\": 1.418567717075, \"lr\": 0.000224377221, \"top1_err\": 56.250000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/40\", \"loss\": 1.375736176968, \"lr\": 0.000224377221, \"top1_err\": 52.832031250000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.458178042221, \"lr\": 0.000224377221, \"top1_err\": 57.635000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 60.400000762939, \"top1_err\": 60.400000762939}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/40\", \"loss\": 1.327158629894, \"lr\": 0.000224377221, \"top1_err\": 51.464843750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/40\", \"loss\": 1.258119106293, \"lr\": 0.000224377221, \"top1_err\": 46.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/40\", \"loss\": 1.243060112000, \"lr\": 0.000224377221, \"top1_err\": 47.949218750000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/40\", \"loss\": 1.191141426563, \"lr\": 0.000224377221, \"top1_err\": 44.921875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.253808823586, \"lr\": 0.000224377221, \"top1_err\": 47.925000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 50.100001525879, \"top1_err\": 50.100001525879}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/val_acc_epochs_y.npy in numpy format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_49.89999847412109_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-3/checkpoints/vlBest_acc_49.89999847412109_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 02:13:19,203]\u001b[0m Trial 3 finished with value: 49.89999847412109 and parameters: {'learning_rate': 0.000224377221490302, 'weight_decay': 0.00025664730169008175, 'batch_size': 512, 'optimizer': 'ADAM'}. Best is trial 2 with value: 67.99999885559082.\u001b[0m\n",
      "== al_model_phase: True ==\n",
      "======== Hyper-params for TRIAL: 4 ========\n",
      "Learning Rate: 0.0002723031602513968\n",
      "Weight Decay : 1.271197170039134e-05\n",
      "Batch Size   : 256\n",
      "Optimizer    : ADAM\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "========OPTIMIZER========\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0002723031602513968\n",
      "    weight_decay: 1.271197170039134e-05\n",
      ")\n",
      "=========================\n",
      "==================================\n",
      "We are not finetuning over the provided dataset CIFAR10\n",
      "So Although we can load best model from path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/30.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_62.49999847412109_model_epoch_0006.pyth -- but we won't do on CIFAR datsets\n",
      "Exiting model loafing function\n",
      "==================================\n",
      "====== Partitions Loaded =======\n",
      "lSet: 20000, uSet:29000, valSet: 1000\n",
      "================================\n",
      "[train_al.py: 420]: ==== Loading TestDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Number of testing datapoints: 10000\n",
      "Len(train_loader): 79\n",
      "[train_al.py: 450]: Start epoch: 1\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"10/79\", \"loss\": 2.583133220673, \"lr\": 0.000272303160, \"top1_err\": 88.867187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"20/79\", \"loss\": 2.321469545364, \"lr\": 0.000272303160, \"top1_err\": 88.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"30/79\", \"loss\": 2.272187232971, \"lr\": 0.000272303160, \"top1_err\": 86.328125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"40/79\", \"loss\": 2.247120261192, \"lr\": 0.000272303160, \"top1_err\": 85.742187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"50/79\", \"loss\": 2.187196731567, \"lr\": 0.000272303160, \"top1_err\": 85.937500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"60/79\", \"loss\": 2.067665815353, \"lr\": 0.000272303160, \"top1_err\": 81.445312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"1/5\", \"iter\": \"70/79\", \"loss\": 1.976140081882, \"lr\": 0.000272303160, \"top1_err\": 78.710937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"1/5\", \"loss\": 2.242454684830, \"lr\": 0.000272303160, \"top1_err\": 84.065000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 77.800000000000, \"top1_err\": 77.800000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"10/79\", \"loss\": 1.858973860741, \"lr\": 0.000272303160, \"top1_err\": 76.562500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"20/79\", \"loss\": 1.844295799732, \"lr\": 0.000272303160, \"top1_err\": 73.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"30/79\", \"loss\": 1.784828722477, \"lr\": 0.000272303160, \"top1_err\": 71.875000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"40/79\", \"loss\": 1.759059846401, \"lr\": 0.000272303160, \"top1_err\": 71.484375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"50/79\", \"loss\": 1.746068477631, \"lr\": 0.000272303160, \"top1_err\": 71.093750000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"60/79\", \"loss\": 1.681229054928, \"lr\": 0.000272303160, \"top1_err\": 67.382812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"2/5\", \"iter\": \"70/79\", \"loss\": 1.653718173504, \"lr\": 0.000272303160, \"top1_err\": 66.796875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"2/5\", \"loss\": 1.742806169319, \"lr\": 0.000272303160, \"top1_err\": 70.390000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"2/5\", \"min_top1_err\": 69.100003051758, \"top1_err\": 69.100003051758}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"10/79\", \"loss\": 1.505889236927, \"lr\": 0.000272303160, \"top1_err\": 62.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"20/79\", \"loss\": 1.542259216309, \"lr\": 0.000272303160, \"top1_err\": 62.109375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"30/79\", \"loss\": 1.498698771000, \"lr\": 0.000272303160, \"top1_err\": 60.546875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"40/79\", \"loss\": 1.526364743710, \"lr\": 0.000272303160, \"top1_err\": 58.789062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"50/79\", \"loss\": 1.465003848076, \"lr\": 0.000272303160, \"top1_err\": 55.859375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"60/79\", \"loss\": 1.350012958050, \"lr\": 0.000272303160, \"top1_err\": 51.757812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"3/5\", \"iter\": \"70/79\", \"loss\": 1.389562785625, \"lr\": 0.000272303160, \"top1_err\": 52.734375000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"3/5\", \"loss\": 1.463923975372, \"lr\": 0.000272303160, \"top1_err\": 56.965000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"3/5\", \"min_top1_err\": 58.000002288818, \"top1_err\": 58.000002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"10/79\", \"loss\": 1.324100971222, \"lr\": 0.000272303160, \"top1_err\": 50.390625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"20/79\", \"loss\": 1.241568326950, \"lr\": 0.000272303160, \"top1_err\": 47.656250000000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"30/79\", \"loss\": 1.223014652729, \"lr\": 0.000272303160, \"top1_err\": 48.242187500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"40/79\", \"loss\": 1.241185128689, \"lr\": 0.000272303160, \"top1_err\": 48.437500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"50/79\", \"loss\": 1.195535778999, \"lr\": 0.000272303160, \"top1_err\": 45.703125000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"60/79\", \"loss\": 1.219081282616, \"lr\": 0.000272303160, \"top1_err\": 44.140625000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"4/5\", \"iter\": \"70/79\", \"loss\": 1.156494319439, \"lr\": 0.000272303160, \"top1_err\": 43.164062500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"4/5\", \"loss\": 1.231650015068, \"lr\": 0.000272303160, \"top1_err\": 46.535000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"4/5\", \"min_top1_err\": 52.900000000000, \"top1_err\": 52.900000000000}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"10/79\", \"loss\": 1.269530773163, \"lr\": 0.000272303160, \"top1_err\": 47.070312500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"20/79\", \"loss\": 1.135742127895, \"lr\": 0.000272303160, \"top1_err\": 42.187500000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"30/79\", \"loss\": 1.115142226219, \"lr\": 0.000272303160, \"top1_err\": 42.382812500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"40/79\", \"loss\": 1.021540820599, \"lr\": 0.000272303160, \"top1_err\": 38.671875000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"50/79\", \"loss\": 1.048102378845, \"lr\": 0.000272303160, \"top1_err\": 38.085937500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"60/79\", \"loss\": 1.034455537796, \"lr\": 0.000272303160, \"top1_err\": 37.304687500000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_iter\", \"epoch\": \"5/5\", \"iter\": \"70/79\", \"loss\": 1.009543865919, \"lr\": 0.000272303160, \"top1_err\": 37.500000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"train_epoch\", \"epoch\": \"5/5\", \"loss\": 1.079001734161, \"lr\": 0.000272303160, \"top1_err\": 39.965000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"Val_epoch\", \"epoch\": \"5/5\", \"min_top1_err\": 43.100002288818, \"top1_err\": 43.100002288818}\n",
      "[train_al.py: 529]: Successfully logged numpy arrays!!\n",
      "~~~ isPruning Flag:  True\n",
      "~~~ isEvalEpoch:  True\n",
      "Saving plot_epoch_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/plot_epoch_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_epoch_yvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/plot_epoch_yvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_xvalues.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/plot_it_xvalues.npy.npy in numpy format!!\n",
      "Saving plot_it_y_values.npy at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/plot_it_y_values.npy.npy in numpy format!!\n",
      "Saving val_acc_epochs_x at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/val_acc_epochs_x.npy in numpy format!!\n",
      "Saving val_acc_epochs_y at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/val_acc_epochs_y.npy in numpy format!!\n",
      "Model checkpoint saved at path: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_56.89999771118164_model_epoch_0006.pyth\n",
      "[train_al.py: 579]: Wrote checkpoint to: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-4/checkpoints/vlBest_acc_56.89999771118164_model_epoch_0006.pyth\n",
      "\u001b[32m[I 2022-03-22 02:14:37,866]\u001b[0m Trial 4 finished with value: 56.89999771118164 and parameters: {'learning_rate': 0.0002723031602513968, 'weight_decay': 1.271197170039134e-05, 'batch_size': 256, 'optimizer': 'ADAM'}. Best is trial 2 with value: 67.99999885559082.\u001b[0m\n",
      "=================\n",
      "Time taken to finish study: 962.5157120227814 seconds\n",
      "==================\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls2/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning:\n",
      "\n",
      "`structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value: 67.99999885559082\n",
      "  Params: \n",
      "    learning_rate: 0.00016281809694736513\n",
      "    weight_decay: 6.557750344356986e-07\n",
      "    batch_size: 16\n",
      "    optimizer: ADAM\n",
      "Number of trials found at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/: 5\n",
      "best_model_path chosen: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/trial-2/checkpoints/vlBest_acc_67.99999885559082_model_epoch_0006.pyth\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "after dumping\n",
      "dest_path:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "tempArgsFile: /tmp/active_sampling_w0a9roax.pkl\n",
      "scriptname: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/al_sampling_exit.py\n",
      "########### cfg model type: vgg\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "Perform random sampling through subprocess\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "========BEFORE==========\n",
      "len(uSEt):  24000\n",
      "len(lSEt):  20000\n",
      "==================\n",
      "After including activeSet -- len(lSet): 25000 and len(uSet): 24000\n",
      "saving pickle values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/lSet.npy in numpy format!!\n",
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/uSet.npy in numpy format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/activeSet.npy in numpy format!!\n",
      "saved!!\n",
      "saving text values...\n",
      "Saving lSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/lSet.txt in text format!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving uSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/uSet.txt in text format!!\n",
      "Saving activeSet at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/activeSet.txt in text format!!\n",
      "saved!!\n",
      "======AFTER AL============\n",
      "ActiveSet:  5000\n",
      "len(uSet):  24000\n",
      "len(lSet):  25000\n",
      "For random sampling, activeSet accuracy:  68.48\n",
      "cfg.OUT_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.ACTIVE_LEARNING.MODEL_LOAD_DIR: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_67.99999885559082_model_epoch_0006.pyth\n",
      "Passing best model_cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/\n",
      "cfg_dir: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "=================================\n",
      "Started test net subprocess call\n",
      "Subprocess called as : \n",
      "\n",
      "/nfs/users/ext_prateek.munjal/anaconda3/envs/pycls/bin/python /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/tools/test_net.py --cfg /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/config.yaml TEST.WEIGHTS /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_67.99999885559082_model_epoch_0006.pyth\n",
      "avail_nGPUS:  b'1\\n'\n",
      "======================================\n",
      "~~~~~~ CFG.NUM_GPUS:  1\n",
      "======================================\n",
      "########### cfg model type: vgg\n",
      "[model_builder.py: 167]: Model loaded successfully!!\n",
      "Params: 119,590,474\n",
      "Flops: 418,059,264\n",
      "==============================\n",
      "cfg.NUM_GPUS:  1\n",
      "==============================\n",
      "Loaded model weights from: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/checkpoints/vlBest_acc_67.99999885559082_model_epoch_0006.pyth\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"10/50\", \"top1_err\": 35.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"20/50\", \"top1_err\": 31.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"30/50\", \"top1_err\": 32.750001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"40/50\", \"top1_err\": 32.000000000000}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_iter\", \"epoch\": \"1/5\", \"iter\": \"50/50\", \"top1_err\": 33.000001907349}\n",
      "[logging.py:  75]: json_stats: {\"_type\": \"test_epoch\", \"epoch\": \"1/5\", \"min_top1_err\": 32.510001792908, \"top1_err\": 32.510001792908}\n",
      "Test Accuracy: 67.490\n",
      "Test accuracy [npy|txt] are saved at /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/40.0/random/vgg_depth_16/vanilla/test_acc_\n",
      "==In main function==\n",
      "[Acquisition:random;Seed:1]Test accuracy on cifar10 using 40.0% of data is 67.48999820709228\n",
      "\n",
      "Extracted Test Accuracy from subproces: 67.48999820709228\n",
      "Finished test net subprocess call\n",
      "=================================\n",
      "prev_out_dir i.e cfg.OUT_DIR[old]:  /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[old]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/best_automl_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n",
      "cfg.OUT_DIR[new]: /nfs/users/ext_prateek.munjal/projects/active_learning_codebase_automl/sample_results_aml_valSetExp2Percent/auto_ml_results/lSet_1/start_1/CIFAR10/50.0/random/vgg_depth_16/vanilla/\n"
     ]
    }
   ],
   "source": [
    "!python3 $HOME_DIRECTORY/tools/main_aml.py --n_GPU $num_GPU \\\n",
    "--port $port --sampling_fn $sampling_fn --lSet_partition $lSet_partition \\\n",
    "--seed_id $base_seed \\\n",
    "--init_partition $init_partition --step_partition $step_partition \\\n",
    "--dataset $dataset --budget_size $budget_size \\\n",
    "--out_dir $out_dir \\\n",
    "--num_aml_trials $num_aml_trials --num_classes $num_classes \\\n",
    "--al_max_iter $al_iterations \\\n",
    "--model_type $model_type --model_depth $model_depth \\\n",
    "--clf_epochs $clf_epochs \\\n",
    "--eval_period 1 --checkpoint_period 1 \\\n",
    "--lSetPath $lSetPath --uSetPath $uSetPath --valSetPath $valSetPath \\\n",
    "--train_dir $train_dir --test_dir $test_dir \\\n",
    "--dropout_iterations 25 \\\n",
    "--cfg configs/$dataset/$model_style/$model_type/R-18_4gpu_unreg.yaml \\\n",
    "--vaal_z_dim 32 --vaal_vae_bs 64 --vaal_epochs 2 \\\n",
    "--vaal_vae_lr 5e-4 --vaal_disc_lr 5e-4 --vaal_beta 1.0 --vaal_adv_param 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f70453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c14aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
